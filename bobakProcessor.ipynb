{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "addressPrefix='C:/Users/sorush.omidvar/Google Drive/Documents/Educational/TAMU/Research/CGM Dataset/Bobak/'\n",
    "if not os.path.exists(addressPrefix):\n",
    "    addressPrefix='C:/GDrive/Documents/Educational/TAMU/Research/CGM Dataset/Bobak/'\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({'figure.facecolor':'white'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hashem [[42.5, 15, 12], [170, 60, 48]]\n",
      "hashem [[170, 15, 12], [170, 15, 12]]\n",
      "hashem [[170, 60, 12], [170, 60, 12]]\n",
      "hashem [[170, 15, 48], [42.5, 60, 12]]\n",
      "hashem [[170, 15, 12], [170, 60, 12]]\n",
      "hashem [[170, 60, 48], [42.5, 15, 12]]\n",
      "hashem [[42.5, 15, 12], [170, 60, 48]]\n",
      "hashem [[170, 15, 12], [42.5, 15, 12]]\n",
      "hashem [[170, 60, 12], [170, 15, 12]]\n",
      "hashem [[170, 15, 48], [42.5, 60, 12]]\n",
      "hashem [[170, 15, 12], [170, 15, 48]]\n",
      "hashem [[170, 60, 48], [42.5, 15, 12]]\n",
      "hashem [[42.5, 15, 12], [170, 15, 48]]\n",
      "[30, 42.5, 15, 12]\n",
      "[30, 170, 60, 48]\n",
      "[31, 170, 15, 12]\n",
      "[31, 170, 15, 12]\n",
      "[32, 170, 60, 12]\n",
      "[32, 170, 60, 12]\n",
      "[33, 170, 15, 48]\n",
      "[33, 42.5, 60, 12]\n",
      "[34, 170, 15, 12]\n",
      "[34, 170, 60, 12]\n",
      "[35, 170, 60, 48]\n",
      "[35, 42.5, 15, 12]\n",
      "[36, 42.5, 15, 12]\n",
      "[36, 170, 60, 48]\n",
      "[37, 170, 15, 12]\n",
      "[37, 42.5, 15, 12]\n",
      "[38, 170, 60, 12]\n",
      "[38, 170, 15, 12]\n",
      "[39, 170, 15, 48]\n",
      "[39, 42.5, 60, 12]\n",
      "[40, 170, 15, 12]\n",
      "[40, 170, 15, 48]\n",
      "[41, 170, 60, 48]\n",
      "[41, 42.5, 15, 12]\n",
      "[42, 42.5, 15, 12]\n",
      "[42, 170, 15, 48]\n"
     ]
    }
   ],
   "source": [
    "#Breakfast in CPF format\n",
    "B1=[42.5,15,12]\n",
    "B2=[170,15,12]\n",
    "B3=[170,60,12]\n",
    "B4=[170,15,48]\n",
    "B5=[170,15,12]\n",
    "B6=[170,60,48]\n",
    "\n",
    "#Lunch in CPF format\n",
    "L0=[42.5,60,12]\n",
    "L1=[42.5,15,12]\n",
    "L2=[170,15,12]\n",
    "L3=[170,60,12]\n",
    "L4=[170,15,48]\n",
    "L5=[170,15,12]\n",
    "L6=[170,60,48]\n",
    "L7=[170,60,48]\n",
    "L8=[170,60,12]\n",
    "L9=[170,15,48]\n",
    "L10=[42.5,60,12]\n",
    "L11=[42.5,15,48]\n",
    "L12=[42.5,15,12]\n",
    "\n",
    "macroData=[]\n",
    "\n",
    "macroData=[[30,B1,'11:54:04'],\n",
    "           [30,L6,'13:00:03'],\n",
    "           [31,B2,'07:52:34'],\n",
    "           [31,L2,'']\n",
    "\n",
    "\n",
    "\n",
    "           ]\n",
    "\n",
    "[B2,L2],\n",
    "[B3,L3],\n",
    "[B4,L0],\n",
    "[B5,L8],\n",
    "[B6,L1],\n",
    "[B1,L7],\n",
    "[B2,L1],\n",
    "[B3,L5],\n",
    "[B4,L10],\n",
    "[B5,L9],\n",
    "[B6,L12],\n",
    "[B1,L4]]\n",
    "flat_list = []\n",
    "for element in macroData:\n",
    "    print(\"hashem\",element)\n",
    "\n",
    "for counter,element in enumerate(macroData):\n",
    "    for subCounter,subElement in enumerate(element):\n",
    "        flat_list.append([counter+30,subElement[0],subElement[1],subElement[2]])\n",
    "for element in flat_list:\n",
    "    print(element)\n",
    "\n",
    "\n",
    "macroData=macroData.extend(macroData)\n",
    "\n",
    "# dfMacro=pd.DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def loadingDataReader(fileAddress,parameter):\n",
    "    try:\n",
    "        jsonFile = open(fileAddress, )\n",
    "        data = json.load(jsonFile)\n",
    "\n",
    "        dateList=[]\n",
    "        timeList=[]\n",
    "        valList=[]\n",
    "        for i in data:\n",
    "            for j in data[i]:\n",
    "                timeTemp=j[\"time\"]\n",
    "                timeTemp=int(timeTemp[0:2])*3600+int(timeTemp[3:5])*60+int(timeTemp[6:8])\n",
    "                timeList.append(timeTemp)\n",
    "\n",
    "                dateTemp=i\n",
    "                dateTemp = datetime.strptime(dateTemp, '%m-%d')+relativedelta(years=+121)\n",
    "                dateTemp=dateTemp.timetuple().tm_yday\n",
    "                dateList.append(dateTemp)\n",
    "                valList.append(float(j[\"value\"]))\n",
    "        jsonFile.close()\n",
    "    except:\n",
    "        print(\"An exception occurred\")\n",
    "\n",
    "    parList = []\n",
    "    for i in range (0,len(dateList)):\n",
    "        parList.append(parameter)\n",
    "\n",
    "    return dateList,timeList,valList,parList\n",
    "\n",
    "def loadingDataAux(fileAddress,parameter,allDate,allTime,allVal,allPar):\n",
    "    fileAddress=os.path.normpath(fileAddress)\n",
    "    [tempDate,tempTime,tempVal,tempPar]=loadingDataReader(fileAddress,parameter)\n",
    "    allDate.extend(tempDate)\n",
    "    allTime.extend(tempTime)\n",
    "    allVal.extend(tempVal)\n",
    "    allPar.extend(tempPar)\n",
    "    print(parameter,\" is done\")\n",
    "\n",
    "    return allDate,allTime,allVal,allPar\n",
    "\n",
    "def dataResEnhancer(df):\n",
    "    gapLength=1\n",
    "    df=df.sort_values(by=['Parameter', 'Date','Time'])\n",
    "    gapList=[]\n",
    "\n",
    "    highResSensor=['Acc','EDA','HR','Temp','CGM']\n",
    "    for sensor in highResSensor:\n",
    "        newQuery=df[df['Parameter']==sensor]\n",
    "        for counter in range(0,len(newQuery)-1):\n",
    "            if newQuery.iloc[counter+1,0]==newQuery.iloc[counter+1,0]:\n",
    "                if newQuery.iloc[counter+1,1]-newQuery.iloc[counter,1]>gapLength:\n",
    "                    gapList.append([newQuery.iloc[counter,0],newQuery.iloc[counter,1],newQuery.iloc[counter+1,1],newQuery.iloc[counter,3]])\n",
    "    appendedData=[]\n",
    "    for element in gapList:\n",
    "        duration= element[2]-element[1]\n",
    "        if duration%gapLength==0:\n",
    "            fillerNumber=int(duration/gapLength-1)\n",
    "        else:\n",
    "            fillerNumber=int(duration/gapLength)\n",
    "        for counter in range(0,fillerNumber):\n",
    "            appendedData.append([element[0],element[1]+(counter+1)*gapLength,float('nan'),element[3]])\n",
    "\n",
    "    df = df.append(pd.DataFrame(appendedData,columns=['Date','Time','Value','Parameter']),ignore_index = True)\n",
    "    df=df.sort_values(by=['Parameter','Date','Time'])\n",
    "\n",
    "    df=df.interpolate(method='linear')\n",
    "    return df\n",
    "\n",
    "def dataCleaner(df):\n",
    "    i = df[df.Date == 30].index #first data and noisy\n",
    "    df=df.drop(i)\n",
    "\n",
    "    i = df[df.Date == 40].index #Partial E4\n",
    "    df=df.drop(i)\n",
    "\n",
    "    i = df[df.Date == 41].index #No E4\n",
    "    df=df.drop(i)\n",
    "\n",
    "    i = df[df.Date >= 42].index #CGM becomes too noisy at the end of the study\n",
    "    df=df.drop(i)\n",
    "\n",
    "    return df\n",
    "\n",
    "def dataAmputator(df):\n",
    "    amputations=[[31,38290,39010],[31,61937,62638],[31,66226,71099],\n",
    "              [32,58667,59563],[32,63875,63902],\n",
    "              [33,25127,34731],[33,57996,58812],\n",
    "              [34,25556,30763],[34,58736,59877],[34,66069,66092],\n",
    "              [35,27945,31416],[35,57283,58147],\n",
    "              [36,29865,33926],[36,59231,60096],\n",
    "              [37,26911,32544],[37,40214,41380],\n",
    "              [38,26707,34560],[38,38172,39273],\n",
    "              [39,31053,35335],[39,57408,58655]]\n",
    "\n",
    "    for amputation in amputations:\n",
    "        i=df[(df['Date']==amputation[0]) & (df['Time']>=amputation[1]) & (df['Time']<=amputation[2])].index\n",
    "        df.loc[i,'Value']=float('nan')\n",
    "        # df=df.drop(i)\n",
    "\n",
    "    return df\n",
    "\n",
    "def loadingData(addressPrefix):\n",
    "    if not os.path.exists(addressPrefix+'Result-interpolated.csv'):\n",
    "        allDate=[]\n",
    "        allTime=[]\n",
    "        allVal=[]\n",
    "        allPar=[]\n",
    "\n",
    "        sensorList=[['intraday-ACC_E4.json','Acc'],['intraday-calories.json','Cal'],\n",
    "                    ['intraday-EDA_E4.json','EDA'],['intraday-HR_E4.json','HR'],\n",
    "                    ['intraday-steps.json','Step'],['intraday-TEMP_E4.json','Temp'],\n",
    "                    ['intraday-glucose.json','CGM']]\n",
    "\n",
    "        for element in sensorList:\n",
    "            fileAddress=addressPrefix+element[0]\n",
    "            allDate,allTime,allVal,allPar=loadingDataAux(fileAddress,element[1],allDate,allTime,allVal,allPar)\n",
    "\n",
    "        dfOriginal = pd.DataFrame(list(zip(allDate,allTime,allVal,allPar)),\n",
    "                          columns =['Date','Time','Value','Parameter'])\n",
    "        dfOriginal=dfOriginal.sort_values(by=['Parameter','Date','Time'])\n",
    "        dfOriginal.to_csv(addressPrefix+'Result-original.csv', header=True,index=False)\n",
    "        print(\"Result-Original is saved\")\n",
    "        dfInterp=dataCleaner(dfOriginal)\n",
    "        dfInterp=dataResEnhancer(dfInterp)\n",
    "        dfInterp=dataAmputator(dfInterp)\n",
    "        dfInterp.to_csv(addressPrefix+'Result-interpolated.csv', header=True,index=False)\n",
    "        print(\"Result-Interpolated is saved\")\n",
    "    else:\n",
    "        dfOriginal=pd.read_csv(addressPrefix+'Result-original.csv')\n",
    "        dfInterp=pd.read_csv(addressPrefix+'Result-interpolated.csv')\n",
    "    return dfOriginal,dfInterp\n",
    "\n",
    "dfOriginal,dfInterp=loadingData(addressPrefix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EDA', 'Step', 'Acc', 'CGM', 'Cal', 'Temp', 'HR']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list.append() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-24-ef20b3e1cd79>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     66\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtrainList\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtestList\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 68\u001B[1;33m \u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtestTrainSplitFunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdfInterp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     69\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-24-ef20b3e1cd79>\u001B[0m in \u001B[0;36mtestTrainSplitFunc\u001B[1;34m(df)\u001B[0m\n\u001B[0;32m     61\u001B[0m     \u001B[0mdfTest\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Date'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdaysTest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m     \u001B[0mtrainList\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtestTrainSplitFuncAux\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdfTrain\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m     \u001B[0mtestList\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtestTrainSplitFuncAux\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdfTest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-24-ef20b3e1cd79>\u001B[0m in \u001B[0;36mtestTrainSplitFuncAux\u001B[1;34m(df)\u001B[0m\n\u001B[0;32m     48\u001B[0m             \u001B[0mdfTemp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdfTemp\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdfTemp\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Time'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m>=\u001B[0m\u001B[0mstartHour\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;36m3600\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m             \u001B[0mdfTemp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdfTemp\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdfTemp\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Time'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m<=\u001B[0m\u001B[0mendHour\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;36m3600\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 50\u001B[1;33m             \u001B[0mdataList\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfeatureExtractor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdfTemp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     51\u001B[0m         \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-24-ef20b3e1cd79>\u001B[0m in \u001B[0;36mfeatureExtractor\u001B[1;34m(df)\u001B[0m\n\u001B[0;32m     34\u001B[0m         \u001B[0mvarTime\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mvarData\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Time'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m         \u001B[0mvarData\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mvarData\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Value'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 36\u001B[1;33m         \u001B[0mfeatureList\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     37\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mfeatureList\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: list.append() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "def STMI_XGBoost(trainData,testData,trainLabels,testLabels,patientName,testDay):\n",
    "    accuracyBest=-1\n",
    "    confMatrixBest=[]\n",
    "    for threshold in np.arange(0.4,0.8,0.2):\n",
    "        for eta in np.arange(0.05,0.50,0.05):\n",
    "            for maxDepth in np.arange(3,10):\n",
    "                clf = XGBClassifier(eta=eta,max_depth=maxDepth,objective = \"binary:logistic\",eval_metric = \"logloss\",use_label_encoder =False)\n",
    "                clf.fit(trainData, trainLabels)\n",
    "                slidingWindowPrediction = clf.predict_proba(testData)\n",
    "                slidingWindowPrediction=slidingWindowPrediction[:,1]\n",
    "                slidingWindowPrediction[slidingWindowPrediction>=threshold]=1\n",
    "                slidingWindowPrediction[slidingWindowPrediction<threshold]=0\n",
    "\n",
    "                confMatrix=sklearn.metrics.confusion_matrix(testLabels,slidingWindowPrediction)\n",
    "                accuracy=sklearn.metrics.accuracy_score(testLabels,slidingWindowPrediction)\n",
    "\n",
    "                if accuracy>accuracyBest:\n",
    "                    confMatrixBest=confMatrix\n",
    "                    accuracyBest=accuracy\n",
    "                    threshBest=threshold\n",
    "                    modelBest=clf\n",
    "\n",
    "    features=np.round(modelBest.feature_importances_*100,1)\n",
    "    # saveModel('XG',modelBest,threshBest,patientName,testDay)\n",
    "\n",
    "    return modelBest,confMatrixBest,threshBest,features\n",
    "\n",
    "def featureExtractor(df):\n",
    "    featureList=[]\n",
    "    sensors=['EDA', 'Step', 'Acc', 'CGM', 'Cal', 'Temp', 'HR']\n",
    "    for sensor in sensors:\n",
    "        varData=df[df['Parameter']==sensor]\n",
    "        varTime=varData['Time'].tolist()\n",
    "        varData=varData['Value'].tolist()\n",
    "\n",
    "        varTime=np.asarray(varTime)\n",
    "        varData=np.asarray(varData)\n",
    "        featureList.append(np.mean(varData))\n",
    "        featureList.append(np.median(varData))\n",
    "        featureList.append(np.mod(varData))\n",
    "        featureList.append(np.max(varData))\n",
    "        featureList.append(np.min(varData))\n",
    "        featureList.append(np.var(varData))\n",
    "\n",
    "        featureList.append(np.mean(np.diff(varData,n=1)))\n",
    "        featureList.append(np.median(np.diff(varData,n=1)))\n",
    "        featureList.append(np.mod(np.diff(varData,n=1)))\n",
    "        featureList.append(np.max(np.diff(varData,n=1)))\n",
    "        featureList.append(np.min(np.diff(varData,n=1)))\n",
    "        featureList.append(np.var(np.diff(varData,n=1)))\n",
    "\n",
    "        featureList.append(np.mean(np.diff(varData,n=2)))\n",
    "        featureList.append(np.median(np.diff(varData,n=2)))\n",
    "        featureList.append(np.mod(np.diff(varData,n=2)))\n",
    "        featureList.append(np.max(np.diff(varData,n=2)))\n",
    "        featureList.append(np.min(np.diff(varData,n=2)))\n",
    "        featureList.append(np.var(np.diff(varData,n=2)))\n",
    "\n",
    "        featureList.append(np.trapz(varData))\n",
    "\n",
    "    #TALK TO HOOMAN ON WHAT TO EXTRACT FROM CGM SIGNALS\n",
    "    #REDO IT WITH FITBIT AND E4\n",
    "    #TRAIN ON 5 DAYS AND TEST ON THE OTHER 5\n",
    "    #use XGBoost\n",
    "    #GET THE MACRO FROM BOBAK AND PUT IT THERE\n",
    "    #FOR MEAL TO MEAL PERSPECTIVE, MAKE THE WHOLE DAY INTO 3 CHUNCKS (MEAL TO MEAL)\n",
    "    #PLOT DAY-DAY VS MEAL TO MEAL AND SHOW THEM HOW WE ARE SEAPRATING THINGS (CGM,EDA,...)\n",
    "    #ADD AUC FOR ALL OF THE PARAMETERS\n",
    "\n",
    "\n",
    "    #https://github.com/fraunhoferportugal/tsfel/tree/9319db4368303cf10adb3aeb72cd4235a8085307\n",
    "\n",
    "\n",
    "    return featureList\n",
    "\n",
    "\n",
    "def testTrainSplitFuncAux(df):\n",
    "    dataList=[]\n",
    "    days=list(set(df['Date']))\n",
    "    for day in days:\n",
    "        for hourCounter in range(0,1):\n",
    "            startHour=hourCounter\n",
    "            endHour=startHour+24\n",
    "            dfTemp=df[df['Date']==day]\n",
    "            dfTemp=dfTemp[dfTemp['Time']>=startHour*3600]\n",
    "            dfTemp=dfTemp[dfTemp['Time']<=endHour*3600]\n",
    "            dataList.append(featureExtractor(dfTemp))\n",
    "        break\n",
    "\n",
    "    return dataList\n",
    "\n",
    "def testTrainSplitFunc(dfSensor, dfMacro):\n",
    "    days=list(set(df['Date']))\n",
    "    random.shuffle(days)\n",
    "    daysTrain=days[0:6]\n",
    "    daysTest=days[6:9]\n",
    "    dfTrain = df[df['Date'].isin(daysTrain)]\n",
    "    dfTest = df[df['Date'].isin(daysTest)]\n",
    "\n",
    "    trainList=testTrainSplitFuncAux(dfTrain)\n",
    "    testList=testTrainSplitFuncAux(dfTest)\n",
    "\n",
    "    return trainList, testList\n",
    "\n",
    "a,b=testTrainSplitFunc(dfInterp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "windowDuration=2\n",
    "lagTimes=np.arange(-2,2.5,0.5)\n",
    "mealTimes=[12.33,12.33,12.33,12.16,11.92,12.5,12.16,11.33,12.25]\n",
    "plotFlag=False\n",
    "plotParamter='Temp'\n",
    "\n",
    "pearsonRatios=[]\n",
    "days=dfInterp['Date']\n",
    "days=days.values.tolist()\n",
    "days=set(days)\n",
    "days=list(days)\n",
    "days.sort()\n",
    "pearsonRatios=np.zeros((len(lagTimes),len(days)))\n",
    "for i,lagTime in enumerate(lagTimes):\n",
    "    for counter,day in enumerate(days):\n",
    "        mealTime=mealTimes[counter]\n",
    "        queryCGM=dfInterp[dfInterp['Date']==day]\n",
    "        queryCGM['Time']=queryCGM['Time']/3600\n",
    "        queryCGM=queryCGM[queryCGM['Parameter']=='CGM']\n",
    "        queryCGM=queryCGM[queryCGM['Time']<=(mealTime+windowDuration)]\n",
    "        queryCGM=queryCGM[queryCGM['Time']>=mealTime]\n",
    "\n",
    "        queryVar=dfInterp[dfInterp['Date']==day]\n",
    "        queryVar['Time']=queryVar['Time']/3600\n",
    "        queryVar=queryVar[queryVar['Parameter']==plotParamter]\n",
    "        queryVar=queryVar[queryVar['Time']<=(mealTime+windowDuration+lagTime)]\n",
    "        queryVar=queryVar[queryVar['Time']>=(mealTime+lagTime)]\n",
    "        if plotFlag:\n",
    "            fig, ax1 = plt.subplots ()\n",
    "            ax2 = ax1.twinx ()\n",
    "\n",
    "            queryCGM.plot(ax=ax1,x='Time',y='Value',color='green')\n",
    "            ax1.tick_params (axis='y', labelcolor='green')\n",
    "\n",
    "            queryVar.plot(ax=ax2,x='Time',y='Value',color='red')\n",
    "            ax2.tick_params (axis='y', labelcolor='red')\n",
    "\n",
    "            ax1.set_ylabel('CGM')\n",
    "            ax1.set_xlabel('Day')\n",
    "            ax1.yaxis.label.set_color(\"green\")\n",
    "\n",
    "            ax2.set_ylabel(plotParamter)\n",
    "            ax2.yaxis.label.set_color(\"red\")\n",
    "\n",
    "            # plt.savefig(addressPrefix+'figure'+str(day)+'.jpg')\n",
    "            plt.title(\"Day=\"+str(day))\n",
    "            ax1.get_legend().remove()\n",
    "            ax2.get_legend().remove()\n",
    "            plt.show()\n",
    "        CGMData=queryCGM['Value'].values.tolist()\n",
    "        CGMData=np.asarray(CGMData)\n",
    "        varData=queryVar['Value'].values.tolist()\n",
    "        varData=np.asarray(varData)\n",
    "        discardIndex=np.argwhere(np.isnan(varData))\n",
    "        varData=np.delete(varData,discardIndex)\n",
    "        CGMData=np.delete(CGMData,discardIndex)\n",
    "        corr, pval = pearsonr(CGMData,varData)\n",
    "        # pearsonRatios.append([lagTime,day,np.round(corr,3)])\n",
    "        pearsonRatios[i,counter]=np.round(corr,3)\n",
    "\n",
    "for i,lagTime in enumerate(lagTimes):\n",
    "    print(\"Lag time=\",lagTime,\"Mean pearson=\",np.round(np.mean(pearsonRatios[i,:]),3))\n",
    "    print(pearsonRatios[i,:])\n",
    "    print(\"----------------------\")\n",
    "plt.boxplot(pearsonRatios)\n",
    "plt.xticks(np.arange(1,len(lagTimes)+1), lagTimes)\n",
    "plt.ylabel('Pearson Corr')\n",
    "plt.xlabel('Lag between CGM and Var [hr]')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}