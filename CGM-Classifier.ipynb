{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime,timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics\n",
    "from xgboost import XGBClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the test days from normal ones\n",
    "rootAddressAllData=r'C:\\GDrive\\Documents\\Educational\\TAMU\\Research\\Selected-38'\n",
    "rootAddressSanitized=r'C:\\GDrive\\Documents\\Educational\\TAMU\\Research\\Sanitized38\\TestDays_'\n",
    "os.chdir(rootAddressAllData)\n",
    "testDays=np.array([[datetime(2018,7,20),datetime(2018,7,13),datetime(2018,7,27),datetime(2018,7,10),datetime(2018,6,22),datetime(2018,7,3),datetime(2018,7,17),datetime(2018,6,25),datetime(2018,7,24)],\n",
    "           [datetime(2018,7,19),datetime(2018,6,28),datetime(2018,7,20),datetime(2018,7,27),datetime(2018,7,3),datetime(2018,6,22),datetime(2018,7,26),datetime(2018,6,29),datetime(2018,7,13)],\n",
    "           [datetime(2018,8,16),datetime(2018,8,8),datetime(2018,8,10),datetime(2018,7,30),datetime(2018,8,20),datetime(2018,8,3),datetime(2018,8,1),datetime(2018,8,17),datetime(2018,8,15)],\n",
    "           [datetime(2018,8,28),datetime(2018,8,15),datetime(2018,8,14),datetime(2018,8,29),datetime(2018,8,20),datetime(2018,8,22),datetime(2018,8,27),datetime(2018,8,21),datetime(2018,8,16)],\n",
    "           [datetime(2018,9,4),datetime(2018,9,5),datetime(2018,9,6),datetime(2018,9,11),datetime(2018,9,13),datetime(2018,9,14),datetime(2018,9,17),datetime(2018,9,18),datetime(2018,9,20)],\n",
    "           [datetime(2018,9,13),datetime(2018,9,14),datetime(2018,9,17),datetime(2018,9,18),datetime(2018,9,25),datetime(2018,9,26),datetime(2018,9,27),datetime(2018,10,2),datetime(2018,10,3)],    \n",
    "           [datetime(2018,9,25),datetime(2018,9,26),datetime(2018,9,27),datetime(2018,10,2),datetime(2018,10,3),datetime(2018,10,4),datetime(2018,10,9),datetime(2018,10,10),datetime(2018,10,11)]\n",
    "           ]).astype(datetime)\n",
    "\n",
    "patientName=['38A','38B','38C','38D','38E','38F','38H']\n",
    "\n",
    "myFiles=os.listdir()\n",
    "\n",
    "for myFile in myFiles:\n",
    "    for counter in range(0,7):\n",
    "        if(patientName[counter] in myFile):\n",
    "            currentPatient=counter\n",
    "            break    \n",
    "    testDayCounter=1\n",
    "    print(myFile)\n",
    "    myDf=pd.read_csv(myFile)\n",
    "    for myColumn in myDf.columns: \n",
    "        if myColumn not in ['time','BG','Participant']:\n",
    "            del myDf[myColumn]\n",
    "    myDf=myDf.dropna()\n",
    "    myDf=myDf.drop_duplicates(subset=['time'], keep='last')\n",
    "    myDf['time']= pd.to_datetime(myDf['time'])\n",
    "        \n",
    "    myDf.insert(3,\"StandardTest\",0)\n",
    "    for rowCounter in range(0,len(myDf)):\n",
    "        for counter in range(0,9):\n",
    "            if myDf.iloc[rowCounter,1].date()==testDays[currentPatient][counter].date():\n",
    "                myDf.iloc[rowCounter,3]=counter+1\n",
    "                break\n",
    "    myDf=myDf[myDf.StandardTest > 0]\n",
    "    myFileAddress=rootAddressSanitized+patientName[currentPatient]+'.csv'\n",
    "    myDf.to_csv(myFileAddress,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading..... TestDays_38A.csv\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "The BG base line is not found for the following date 2018 6 25\n",
      "Patient= TestDays_38A.csv best class prediction threshold= 0.4 best tree number= 6 best max depth= 7 best positive weight= 2.0 best accuracy= 0.96 best recall= 0.83\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 71\t\t 2 \n",
      "\n",
      "True Pos\t 1\t\t 5 \n",
      "\n",
      "Reading..... TestDays_38B.csv\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "The BG base line is not found for the following date 2018 7 19\n",
      "Patient= TestDays_38B.csv best class prediction threshold= 0.6 best tree number= 7 best max depth= 7 best positive weight= 632.46 best accuracy= 0.9 best recall= 0.33\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 63\t\t 3 \n",
      "\n",
      "True Pos\t 4\t\t 2 \n",
      "\n",
      "Reading..... TestDays_38C.csv\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "The BG base line is not found for the following date 2018 8 8\n",
      "Patient= TestDays_38C.csv best class prediction threshold= 0.4 best tree number= 7 best max depth= 8 best positive weight= 632.46 best accuracy= 0.94 best recall= 0.67\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 73\t\t 3 \n",
      "\n",
      "True Pos\t 2\t\t 4 \n",
      "\n",
      "Reading..... TestDays_38D.csv\n",
      "Patient= TestDays_38D.csv best class prediction threshold= 0.6 best tree number= 7 best max depth= 4 best positive weight= 6.32 best accuracy= 0.94 best recall= 0.71\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 74\t\t 3 \n",
      "\n",
      "True Pos\t 2\t\t 5 \n",
      "\n",
      "Reading..... TestDays_38E.csv\n",
      "Patient= TestDays_38E.csv best class prediction threshold= 0.6 best tree number= 9 best max depth= 7 best positive weight= 632.46 best accuracy= 0.95 best recall= 0.82\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 72\t\t 2 \n",
      "\n",
      "True Pos\t 2\t\t 9 \n",
      "\n",
      "Reading..... TestDays_38F.csv\n",
      "=================Patient F is discarded===============\n",
      "Reading..... TestDays_38H.csv\n",
      "Patient= TestDays_38H.csv best class prediction threshold= 0.4 best tree number= 8 best max depth= 6 best positive weight= 632.46 best accuracy= 0.92 best recall= 0.83\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 60\t\t 5 \n",
      "\n",
      "True Pos\t 1\t\t 5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Running the Random Forest and XGBoost functions\n",
    "#This is the older version of the Algorithm which uses time window rather than point number\n",
    "def STMI_random_forest(trains_data_func,test_data_func,train_labels_func,test_labels_func,patient_name_func):\n",
    "    best_tree_number=-1;\n",
    "    best_max_depth=-1;\n",
    "    best_accuracy=-1;\n",
    "    best_recall=-1;\n",
    "    best_positive_weight=-1;\n",
    "    best_confusion_matrix=[];\n",
    "    for threshold_counter in np.arange(0.4,0.8,0.2):\n",
    "        threshold_counter=round(threshold_counter,2)\n",
    "        for tree_number_counter in np.arange(3,10):\n",
    "            for max_depth_counter in np.arange(3,10):\n",
    "                for positive_weight_counter in np.arange(1,4,0.5):\n",
    "                    treeNumber=tree_number_counter\n",
    "                    maxDepth=max_depth_counter\n",
    "                    positive_weight=0.2*10**positive_weight_counter\n",
    "\n",
    "                    clf=RandomForestClassifier(n_estimators=treeNumber,criterion='entropy',random_state=0,max_depth=maxDepth,class_weight={0: 1, 1: positive_weight})\n",
    "                    clf.fit(trains_data_func,train_labels_func)\n",
    "                    sliddingWindowPrediction=clf.predict_proba(test_data_func)\n",
    "                    sliddingWindowPrediction=sliddingWindowPrediction[:,1]\n",
    "                    sliddingWindowPrediction[sliddingWindowPrediction>=threshold_counter]=1\n",
    "                    sliddingWindowPrediction[sliddingWindowPrediction<threshold_counter]=0\n",
    "\n",
    "                    confusionMatrix=sklearn.metrics.confusion_matrix(test_labels_func,sliddingWindowPrediction);\n",
    "                    accuracy_score_value=sklearn.metrics.accuracy_score(test_labels_func,sliddingWindowPrediction);\n",
    "                    recall_score_value=sklearn.metrics.recall_score(test_labels_func,sliddingWindowPrediction);            \n",
    "\n",
    "                    if(accuracy_score_value>=best_accuracy and recall_score_value>=best_recall):\n",
    "                        best_accuracy=accuracy_score_value;\n",
    "                        best_recall=recall_score_value;\n",
    "                        best_tree_number=treeNumber;\n",
    "                        best_positive_weight=positive_weight;\n",
    "                        best_max_depth=maxDepth;                \n",
    "                        best_confusion_matrix=confusionMatrix;\n",
    "                        best_threshold=threshold_counter\n",
    "\n",
    "    best_confusion_matrix=[['\\t\\t','Pred Neg\\t','Pred Pos'],['True Neg\\t',str(best_confusion_matrix[0,0])+\"\\t\\t\",best_confusion_matrix[0,1]],['True Pos\\t',str(best_confusion_matrix[1,0])+\"\\t\\t\",best_confusion_matrix[1,1]]]\n",
    "    file_name = \"C:\\GDrive\\Documents\\Educational\\TAMU\\Research\\Sanitized38\\RF\"+patient_name_func+\".pkl\"\n",
    "    pickle.dump(clf, open(file_name, \"wb\"))    \n",
    "    return best_threshold,best_tree_number,best_max_depth,best_positive_weight,best_accuracy,best_recall,best_confusion_matrix;\n",
    "\n",
    "\n",
    "def STMI_XGBoost(train_data_func,test_data_func,train_labels_func,test_labels_func,patient_name_func):\n",
    "    best_eta=-1;\n",
    "    best_max_depth=-1;\n",
    "    best_accuracy=-1;\n",
    "    best_recall=-1;\n",
    "    best_positive_weight=-1;\n",
    "    best_confusion_matrix=[];\n",
    "    for threshold_counter in np.arange(0.4,0.8,0.2):\n",
    "        threshold_counter=round(threshold_counter,2)\n",
    "        for eta_counter in np.arange(0.05,0.50,0.05):\n",
    "            for max_depth_counter in np.arange(3,10):\n",
    "                for positive_weight_counter in np.arange(1,4,0.5):\n",
    "                    eta_value=eta_counter;\n",
    "                    maxDepth=max_depth_counter;\n",
    "                    positive_weight=0.2*10**positive_weight_counter;\n",
    "\n",
    "                    model = XGBClassifier(eta=eta_value,max_depth=maxDepth,scale_pos_weight=positive_weight,objective = \"binary:logistic\",eval_metric = \"logloss\",use_label_encoder =False);\n",
    "                    model.fit(train_data_func, train_labels_func);\n",
    "                    sliddingWindowPrediction = model.predict_proba(test_data_func);\n",
    "                    sliddingWindowPrediction=sliddingWindowPrediction[:,1]\n",
    "                    sliddingWindowPrediction[sliddingWindowPrediction>=threshold_counter]=1\n",
    "                    sliddingWindowPrediction[sliddingWindowPrediction<threshold_counter]=0\n",
    "\n",
    "                    confusionMatrix=sklearn.metrics.confusion_matrix(test_labels_func,sliddingWindowPrediction);\n",
    "                    accuracy_score_value=sklearn.metrics.accuracy_score(test_labels_func,sliddingWindowPrediction);\n",
    "                    recall_score_value=sklearn.metrics.recall_score(test_labels_func,sliddingWindowPrediction);     \n",
    "\n",
    "                    if(accuracy_score_value>=best_accuracy and recall_score_value>=best_recall):\n",
    "                        best_accuracy=accuracy_score_value;\n",
    "                        best_recall=recall_score_value;\n",
    "                        best_eta=eta_value;\n",
    "                        best_positive_weight=positive_weight;\n",
    "                        best_max_depth=maxDepth;                \n",
    "                        best_confusion_matrix=confusionMatrix; \n",
    "                        best_threshold=threshold_counter\n",
    "        \n",
    "    best_confusion_matrix=[['\\t\\t','Pred Neg\\t','Pred Pos'],['True Neg\\t',str(best_confusion_matrix[0,0])+\"\\t\\t\",best_confusion_matrix[0,1]],['True Pos\\t',str(best_confusion_matrix[1,0])+\"\\t\\t\",best_confusion_matrix[1,1]]]\n",
    "    file_name = \"C:\\GDrive\\Documents\\Educational\\TAMU\\Research\\Sanitized38\\XG\"+patient_name_func+\".pkl\"\n",
    "    pickle.dump(model, open(file_name, \"wb\"))    \n",
    "    return best_threshold,best_eta,best_max_depth,best_positive_weight,best_accuracy,best_recall,best_confusion_matrix;\n",
    "\n",
    "\n",
    "rootAddress=r\"C:\\GDrive\\Documents\\Educational\\TAMU\\Research\\Sanitized38\"\n",
    "os.chdir(rootAddress)\n",
    "timeWindow=120;\n",
    "timeStep=60;\n",
    "breakfastTime=datetime(2020,1,1,8,0)\n",
    "myFiles=os.listdir()\n",
    "\n",
    "for myFile in myFiles:\n",
    "    if('.pkl' in myFile):\n",
    "        continue;\n",
    "    print('Reading.....',myFile)\n",
    "    fileAddress=myFile\n",
    "    if (myFile=='TestDays_38F.csv'):\n",
    "        print(\"=================Patient F is discarded===============\");\n",
    "        continue;\n",
    "    sliddingWindow=[]\n",
    "    sliddingWindowResult=[]\n",
    "\n",
    "    raw1=pd.read_csv(fileAddress) \n",
    "    raw1['time']= pd.to_datetime(raw1['time'])\n",
    "    raw1=raw1.dropna()\n",
    "    raw1=raw1.drop_duplicates(subset=['time'], keep='last')\n",
    "\n",
    "    startTime=raw1.iloc[0,1]\n",
    "    endTime=startTime+timedelta(minutes = timeWindow)\n",
    "    counter=0;\n",
    "    baseLine=-10;\n",
    "\n",
    "    while(True):\n",
    "        #Establishing the base line between 6 and 8 AM of every day\n",
    "        baseLineQuery=raw1[raw1.time.dt.month==startTime.month];\n",
    "        baseLineQuery=baseLineQuery[baseLineQuery.time.dt.day==startTime.day];\n",
    "        baseLineQuery=baseLineQuery[baseLineQuery.time.dt.hour>=6];\n",
    "        baseLineQuery=baseLineQuery[baseLineQuery.time.dt.hour<8];\n",
    "        if(not np.isnan(baseLineQuery.BG.mean())):\n",
    "           baseLine=baseLineQuery.BG.mean()\n",
    "        else:\n",
    "            newQuery=raw1\n",
    "            newQuery=newQuery[newQuery.time.dt.month==startTime.month]\n",
    "            newQuery=newQuery[newQuery.time.dt.day==startTime.day]\n",
    "            if(not np.isnan(newQuery.BG.mean())):\n",
    "                print(\"The BG base line is not found for the following date\",startTime.year,startTime.month,startTime.day)\n",
    "        if (raw1.iloc[-1,1]<endTime):\n",
    "            break\n",
    "        myQuery=raw1[raw1.time >= startTime]\n",
    "        myQuery=myQuery[myQuery.time <= endTime]\n",
    "           \n",
    "        if (len(myQuery)<=1):\n",
    "            startTime+=timedelta(minutes=timeStep)\n",
    "            endTime+=timedelta(minutes=timeStep)\n",
    "            continue\n",
    "\n",
    "        if(startTime.time()<=breakfastTime.time() and endTime.time()>=breakfastTime.time()):\n",
    "            eatFlag=1\n",
    "        else:\n",
    "            eatFlag=0\n",
    "            \n",
    "        integralValue=0\n",
    "        maxSlope=0\n",
    "        for counter in range(0,len(myQuery)-1):\n",
    "            timeSpanTemp=myQuery.iloc[counter+1,1]-myQuery.iloc[counter,1]\n",
    "            timeSpanTemp=timeSpanTemp.total_seconds()\n",
    "            if(timeSpanTemp==0):\n",
    "                print(startTime,endTime)\n",
    "                continue;\n",
    "            integralValue+=timeSpanTemp*((myQuery.iloc[counter+1,2]+myQuery.iloc[counter,2])/2-baseLine)\n",
    "            currentSlope=(myQuery.iloc[counter+1,2]-myQuery.iloc[counter,2])/timeSpanTemp\n",
    "            currentSlope=abs(currentSlope)\n",
    "            if(currentSlope>maxSlope):\n",
    "                maxSlope=currentSlope\n",
    "        patientName=myQuery.iloc[0,0]\n",
    "        meanValue=round(myQuery['BG'].mean()-baseLine,2)\n",
    "        stdValue=round(myQuery['BG'].std(),2)\n",
    "        minValue=round(myQuery['BG'].min()-baseLine,2)\n",
    "        maxValue=round(myQuery['BG'].max()-baseLine,2)\n",
    "        slopeValue=round(maxSlope,2)\n",
    "        intValue=round(integralValue,2)\n",
    "        \n",
    "        sliddingWindow.append([meanValue,stdValue,minValue,maxValue,slopeValue,intValue,baseLine,patientName,startTime,endTime])\n",
    "\n",
    "        sliddingWindowResult.append(eatFlag);\n",
    "        startTime+=timedelta(minutes=timeStep);\n",
    "        endTime+=timedelta(minutes=timeStep);\n",
    "\n",
    "    sliddingWindow=np.array(sliddingWindow);\n",
    "    sliddingWindow=sliddingWindow[:,0:6]#dropping baseline, patientname, starttime and endtime    \n",
    "\n",
    "    sliddingWindowResult=np.array(sliddingWindowResult);\n",
    "    balancedSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.4)\n",
    "\n",
    "    for train_index, test_index in balancedSplit.split(sliddingWindow, sliddingWindowResult):\n",
    "        train_data, test_data = sliddingWindow[train_index], sliddingWindow[test_index]\n",
    "        train_labels, test_labels = sliddingWindowResult[train_index], sliddingWindowResult[test_index]\n",
    "    \n",
    "    RF_best_threshold,RF_best_tree_number,RF_best_max_depth,RF_best_positive_weight,RF_best_accuracy,RF_best_recall,RF_best_confusion_matrix=STMI_random_forest(train_data,test_data,train_labels,test_labels,patientName);\n",
    "    print(\"Patient=\",myFile,\"best class prediction threshold=\",RF_best_threshold,\"best tree number=\",RF_best_tree_number,\"best max depth=\",RF_best_max_depth,\"best positive weight=\",round(RF_best_positive_weight,2),\"best accuracy=\",round(RF_best_accuracy,2),\"best recall=\",round(RF_best_recall,2))\n",
    "    print(\"\\n\")\n",
    "    for r in RF_best_confusion_matrix:\n",
    "        for c in r:\n",
    "            print(c,end = \" \")\n",
    "        print(\"\\n\")\n",
    "    \n",
    "#     XG_best_threshold,XG_best_eta,XG_best_max_depth,XG_best_positive_weight,XG_best_accuracy,XG_best_recall,XG_best_confusion_matrix=STMI_XGBoost(train_data,test_data,train_labels,test_labels,myFile[myFile.index('_')+1:myFile.index('.')]);\n",
    "#     print(\"Patient=\",myFile,\"best class prediction threshold=\",XG_best_threshold,\"best eta=\",XG_best_eta,\"best max depth=\",XG_best_max_depth,\"best positive weight=\",round(XG_best_positive_weight,2),\"best accuracy=\",round(XG_best_accuracy,2),\"best recall=\",round(XG_best_recall,2))\n",
    "#     print(\"\\n\")\n",
    "#     for r in XG_best_confusion_matrix:\n",
    "#         for c in r:\n",
    "#             print(c,end = \" \")\n",
    "#         print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading..... TestDays_38A.csv\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "The BG base line is not found for the following date: 2018-06-25 47.0\n",
      "Patient= TestDays_38A.csv best tree number= 3 best max depth= 9 best positive weight= 200.0 best accuracy= 0.98 best recall= 0.5\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 83\t\t 0 \n",
      "\n",
      "True Pos\t 2\t\t 2 \n",
      "\n",
      "Reading..... TestDays_38B.csv\n",
      "The BG base line is not found for the following date: 2018-07-19 48.0\n",
      "The BG base line is not found for the following date: 2018-07-19 48.0\n",
      "The BG base line is not found for the following date: 2018-07-19 48.0\n",
      "The BG base line is not found for the following date: 2018-07-19 48.0\n",
      "The BG base line is not found for the following date: 2018-07-19 48.0\n",
      "The BG base line is not found for the following date: 2018-07-19 48.0\n",
      "The BG base line is not found for the following date: 2018-07-19 48.0\n",
      "Patient= TestDays_38B.csv best tree number= 9 best max depth= 9 best positive weight= 632.46 best accuracy= 0.95 best recall= 0.17\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 103\t\t 0 \n",
      "\n",
      "True Pos\t 5\t\t 1 \n",
      "\n",
      "Reading..... TestDays_38C.csv\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "The BG base line is not found for the following date: 2018-08-08 40.0\n",
      "Patient= TestDays_38C.csv best tree number= 7 best max depth= 3 best positive weight= 2.0 best accuracy= 0.95 best recall= 0.17\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 87\t\t 0 \n",
      "\n",
      "True Pos\t 5\t\t 1 \n",
      "\n",
      "Reading..... TestDays_38D.csv\n",
      "Patient= TestDays_38D.csv best tree number= 8 best max depth= 9 best positive weight= 20.0 best accuracy= 0.94 best recall= 0.0\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 93\t\t 0 \n",
      "\n",
      "True Pos\t 6\t\t 0 \n",
      "\n",
      "Reading..... TestDays_38E.csv\n",
      "Patient= TestDays_38E.csv best tree number= 9 best max depth= 9 best positive weight= 632.46 best accuracy= 0.95 best recall= 0.0\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 95\t\t 0 \n",
      "\n",
      "True Pos\t 5\t\t 0 \n",
      "\n",
      "Reading..... TestDays_38F.csv\n",
      "Patient= TestDays_38F.csv best tree number= 8 best max depth= 3 best positive weight= 6.32 best accuracy= 1.0 best recall= 1.0\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 96\t\t 0 \n",
      "\n",
      "True Pos\t 0\t\t 3 \n",
      "\n",
      "Reading..... TestDays_38H.csv\n",
      "Patient= TestDays_38H.csv best tree number= 9 best max depth= 9 best positive weight= 632.46 best accuracy= 0.96 best recall= 0.0\n",
      "\n",
      "\n",
      "\t\t Pred Neg\t Pred Pos \n",
      "\n",
      "True Neg\t 79\t\t 0 \n",
      "\n",
      "True Pos\t 3\t\t 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Running the Random Forest and XGBoost functions\n",
    "#The time windows is based on the number of points rather than actual time\n",
    "def STMI_random_forest(trains_data_func,test_data_func,train_labels_func,test_labels_func,patient_name_func):\n",
    "    best_tree_number=-1;\n",
    "    best_max_depth=-1;\n",
    "    best_accuracy=-1;\n",
    "    best_recall=-1;\n",
    "    best_positive_weight=-1;\n",
    "    best_confusion_matrix=[];\n",
    "    for tree_number_counter in np.arange(3,10):\n",
    "        for max_depth_counter in np.arange(3,10):\n",
    "            for positive_weight_counter in np.arange(1,4,0.5):\n",
    "                treeNumber=tree_number_counter;\n",
    "                maxDepth=max_depth_counter;\n",
    "                positive_weight=0.2*10**positive_weight_counter;\n",
    "\n",
    "                clf=RandomForestClassifier(n_estimators=treeNumber,criterion='entropy',random_state=0,max_depth=maxDepth,class_weight={0: 1, 1: positive_weight});\n",
    "                clf.fit(trains_data_func,train_labels_func);\n",
    "                sliddingWindowPrediction=clf.predict(test_data_func);\n",
    "\n",
    "                confusionMatrix=sklearn.metrics.confusion_matrix(test_labels_func,sliddingWindowPrediction);\n",
    "                accuracy_score_value=sklearn.metrics.accuracy_score(test_labels_func,sliddingWindowPrediction);\n",
    "                recall_score_value=sklearn.metrics.recall_score(test_labels_func,sliddingWindowPrediction);            \n",
    "\n",
    "                if(accuracy_score_value>=best_accuracy and recall_score_value>=best_recall):\n",
    "                    best_accuracy=accuracy_score_value;\n",
    "                    best_recall=recall_score_value;\n",
    "                    best_tree_number=treeNumber;\n",
    "                    best_positive_weight=positive_weight;\n",
    "                    best_max_depth=maxDepth;                \n",
    "                    best_confusion_matrix=confusionMatrix;\n",
    "    best_confusion_matrix=[['\\t\\t','Pred Neg\\t','Pred Pos'],['True Neg\\t',str(best_confusion_matrix[0,0])+\"\\t\\t\",best_confusion_matrix[0,1]],['True Pos\\t',str(best_confusion_matrix[1,0])+\"\\t\\t\",best_confusion_matrix[1,1]]]\n",
    "    file_name = \"C:\\GDrive\\Documents\\Educational\\TAMU\\Research\\Sanitized38\\RF\"+patient_name_func+\".pkl\"\n",
    "    pickle.dump(clf, open(file_name, \"wb\"))    \n",
    "    return best_tree_number,best_max_depth,best_positive_weight,best_accuracy,best_recall,best_confusion_matrix;\n",
    "\n",
    "\n",
    "def STMI_XGBoost(train_data_func,test_data_func,train_labels_func,test_labels_func,patient_name_func):\n",
    "    best_eta=-1;\n",
    "    best_max_depth=-1;\n",
    "    best_accuracy=-1;\n",
    "    best_recall=-1;\n",
    "    best_positive_weight=-1;\n",
    "    best_confusion_matrix=[];\n",
    "    for eta_counter in np.arange(0.05,0.50,0.05):\n",
    "        for max_depth_counter in np.arange(3,10):\n",
    "            for positive_weight_counter in np.arange(1,4,0.5):\n",
    "                eta_value=eta_counter;\n",
    "                maxDepth=max_depth_counter;\n",
    "                positive_weight=0.2*10**positive_weight_counter;\n",
    "\n",
    "                model = XGBClassifier(eta=eta_value,max_depth=maxDepth,scale_pos_weight=positive_weight,objective = \"binary:logistic\",eval_metric = \"logloss\",use_label_encoder =False);\n",
    "                model.fit(train_data_func, train_labels_func);\n",
    "                sliddingWindowPrediction = model.predict(test_data_func);\n",
    "\n",
    "                confusionMatrix=sklearn.metrics.confusion_matrix(test_labels_func,sliddingWindowPrediction);\n",
    "                accuracy_score_value=sklearn.metrics.accuracy_score(test_labels_func,sliddingWindowPrediction);\n",
    "                recall_score_value=sklearn.metrics.recall_score(test_labels_func,sliddingWindowPrediction);     \n",
    "\n",
    "                if(accuracy_score_value>=best_accuracy and recall_score_value>=best_recall):\n",
    "                    best_accuracy=accuracy_score_value;\n",
    "                    best_recall=recall_score_value;\n",
    "                    best_eta=eta_value;\n",
    "                    best_positive_weight=positive_weight;\n",
    "                    best_max_depth=maxDepth;                \n",
    "                    best_confusion_matrix=confusionMatrix;   \n",
    "\n",
    "    best_confusion_matrix=[['\\t\\t','Pred Neg\\t','Pred Pos'],['True Neg\\t',str(best_confusion_matrix[0,0])+\"\\t\\t\",best_confusion_matrix[0,1]],['True Pos\\t',str(best_confusion_matrix[1,0])+\"\\t\\t\",best_confusion_matrix[1,1]]]\n",
    "    file_name = \"C:\\GDrive\\Documents\\Educational\\TAMU\\Research\\Sanitized38\\XG\"+patient_name_func+\".pkl\"\n",
    "    pickle.dump(model, open(file_name, \"wb\"))    \n",
    "    return best_eta,best_max_depth,best_positive_weight,best_accuracy,best_recall,best_confusion_matrix;\n",
    "\n",
    "\n",
    "rootAddress=r\"C:\\GDrive\\Documents\\Educational\\TAMU\\Research\\Sanitized38\"\n",
    "os.chdir(rootAddress)\n",
    "windowPointNumber=8\n",
    "sliddingPointNumber=4\n",
    "\n",
    "breakfastTime=datetime(2020,1,1,8,0)\n",
    "myFiles=os.listdir()\n",
    "\n",
    "for myFile in myFiles:\n",
    "    if('.csv' not in myFile):\n",
    "        continue;\n",
    "    print('Reading.....',myFile)\n",
    "    fileAddress=myFile\n",
    "#     if (myFile!='TestDays_38F.csv'):\n",
    "#         print(\"=================Patient F is discarded===============\");\n",
    "#         continue;\n",
    "    sliddingWindow=[]\n",
    "    sliddingWindowResult=[]\n",
    "\n",
    "    rawData=pd.read_csv(fileAddress) \n",
    "    rawData['time']= pd.to_datetime(rawData['time'])\n",
    "    rawData=rawData.dropna()\n",
    "    rawData=rawData.drop_duplicates(subset=['time'], keep='last')\n",
    "    wholeTime= pd.to_datetime(rawData['time'])\n",
    "\n",
    "    startPoint=0\n",
    "    endPoint=windowPointNumber-1\n",
    "    baseLine=-10;\n",
    "    while(True):\n",
    "        if endPoint>=len(rawData):#end of the file\n",
    "            break\n",
    "#         print(startPoint,endPoint, len(rawData))\n",
    "        if rawData.iloc[startPoint,1].date()!=rawData.iloc[endPoint,1].date():#the reading is not in the same date\n",
    "            startPoint+=sliddingPointNumber\n",
    "            endPoint+=sliddingPointNumber\n",
    "            continue       \n",
    "            \n",
    "        #Establishing the base line between 6 and 8 AM of every day\n",
    "        baseLineQuery=rawData[rawData.time.dt.month==wholeTime[startPoint].month]\n",
    "        baseLineQuery=baseLineQuery[baseLineQuery.time.dt.day==wholeTime[startPoint].day]\n",
    "        \n",
    "        baseLineReserved=baseLineQuery.BG.min()\n",
    "        baseLineReservedDate=baseLineQuery.iloc[0,1].date()\n",
    "        \n",
    "        baseLineQuery=baseLineQuery[baseLineQuery.time.dt.hour>=6]\n",
    "        baseLineQuery=baseLineQuery[baseLineQuery.time.dt.hour<8]\n",
    "        if(not np.isnan(baseLineQuery.BG.mean())):\n",
    "           baseLine=baseLineQuery.BG.mean()\n",
    "        else:\n",
    "            print(\"The BG base line is not found for the following date:\",baseLineReservedDate,baseLineReserved)\n",
    "            baseLine=baseLineReserved #the baseline is not found and it is replaced by the minimum BG\n",
    "        myQuery=rawData.iloc[startPoint:endPoint,:]\n",
    "        if(myQuery.iloc[0,1].time()<breakfastTime.time() and myQuery.iloc[-1,1].time()>breakfastTime.time()):\n",
    "            eatFlag=1\n",
    "        else:\n",
    "            eatFlag=0\n",
    "\n",
    "        readingData=myQuery['BG'];\n",
    "        readingData=readingData.values;\n",
    "        readingData=np.diff(readingData)\n",
    "        sliddingWindow.append(readingData);\n",
    "        sliddingWindowResult.append(eatFlag);\n",
    "        startPoint+=sliddingPointNumber;\n",
    "        endPoint+=sliddingPointNumber;\n",
    "\n",
    "    sliddingWindow=np.array(sliddingWindow);\n",
    "    sliddingWindow=np.squeeze(sliddingWindow);\n",
    "    \n",
    "    sliddingWindowResult=np.array(sliddingWindowResult);\n",
    "    sliddingWindowResult=sliddingWindowResult.ravel();\n",
    "    \n",
    "    train_data,test_data,train_labels,test_labels=train_test_split(sliddingWindow,sliddingWindowResult,test_size=0.5,random_state=0,shuffle=True);\n",
    "\n",
    "    \n",
    "    RF_best_tree_number,RF_best_max_depth,RF_best_positive_weight,RF_best_accuracy,RF_best_recall,RF_best_confusion_matrix=STMI_random_forest(train_data,test_data,train_labels,test_labels,myFile[myFile.index('_')+1:myFile.index('.')]);    \n",
    "    print(\"Patient=\",myFile,\"best tree number=\",RF_best_tree_number,\"best max depth=\",RF_best_max_depth,\"best positive weight=\",round(RF_best_positive_weight,2),\"best accuracy=\",round(RF_best_accuracy,2),\"best recall=\",round(RF_best_recall,2))\n",
    "    print(\"\\n\")\n",
    "    for r in RF_best_confusion_matrix:\n",
    "        for c in r:\n",
    "            print(c,end = \" \")\n",
    "        print(\"\\n\")\n",
    "\n",
    "#     XG_best_eta,XG_best_max_depth,XG_best_positive_weight,XG_best_accuracy,XG_best_recall,XG_best_confusion_matrix=STMI_XGBoost(train_data,test_data,train_labels,test_labels,myFile[myFile.index('_')+1:myFile.index('.')]);\n",
    "#     print(\"Patient=\",myFile,\"best eta=\",XG_best_eta,\"best max depth=\",XG_best_max_depth,\"best positive weight=\",round(XG_best_positive_weight,2),\"best accuracy=\",round(XG_best_accuracy,2),\"best recall=\",round(XG_best_recall,2))\n",
    "#     print(\"\\n\")\n",
    "#     for r in XG_best_confusion_matrix:\n",
    "#         for c in r:\n",
    "#             print(c,end = \" \")\n",
    "#         print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "model=sm.OLS(sliddingWindowResult_train,sliddingWindow_train)\n",
    "results=model.fit()\n",
    "results.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
