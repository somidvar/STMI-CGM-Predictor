{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import struct\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import pearsonr, mode\n",
    "from scipy.signal import savgol_filter\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import struct\n",
    "\n",
    "addressPrefix='C:/Users/sorush.omidvar/Google Drive/Documents/Educational/TAMU/Research/CGM Dataset/Hoover/'\n",
    "if not os.path.exists(addressPrefix):\n",
    "    addressPrefix='C:/GDrive/Documents/Educational/TAMU/Research/CGM Dataset/Hoover/'\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({'figure.facecolor':'white'})\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "# def dfCompactor(df):\n",
    "#     df['Date']=df['Date'].astype(int)\n",
    "#     df['Time']=df['Time']*1000\n",
    "#     df['Time']=df['Time'].astype(int)\n",
    "#     df.rename(columns={\"Time\": \"Time[ms]\"})\n",
    "#\n",
    "#     df['GyroX']=df['GyroX'].astype(float)\n",
    "#     df['GyroX']=df['GyroX']*1000*1000\n",
    "#     df['GyroX']=df['GyroX'].astype(int)\n",
    "#     df.rename(columns={\"GyroX\": \"GyroX[microD/s]\"})\n",
    "#\n",
    "#     df['GyroY']=df['GyroY'].astype(float)\n",
    "#     df['GyroY']=df['GyroY']*1000*1000\n",
    "#     df['GyroY']=df['GyroY'].astype(int)\n",
    "#     df.rename(columns={\"GyroY\": \"GyroY[microD/s]\"})\n",
    "#\n",
    "#     df['GyroZ']=df['GyroZ'].astype(float)\n",
    "#     df['GyroZ']=df['GyroZ']*1000*1000\n",
    "#     df['GyroZ']=df['GyroZ'].astype(int)\n",
    "#     df.rename(columns={\"GyroZ\": \"GyroZ[microD/s]\"})\n",
    "#\n",
    "#     df['AccelX']=df['AccelX'].astype(float)\n",
    "#     df['AccelX']=df['AccelX']*1000*1000\n",
    "#     df['AccelX']=df['AccelX'].astype(int)\n",
    "#     df.rename(columns={\"AccelX\": \"AccelX[microm/s2]\"})\n",
    "#\n",
    "#     df['AccelY']=df['AccelY'].astype(float)\n",
    "#     df['AccelY']=df['AccelY']*1000*1000\n",
    "#     df['AccelY']=df['AccelY'].astype(int)\n",
    "#     df.rename(columns={\"AccelY\": \"AccelY[microm/s2]\"})\n",
    "#\n",
    "#     df['AccelZ']=df['AccelZ'].astype(float)\n",
    "#     df['AccelZ']=df['AccelZ']*1000*1000\n",
    "#     df['AccelZ']=df['AccelZ'].astype(int)\n",
    "#     df.rename(columns={\"AccelZ\": \"AccelZ[microm/s2]\"})\n",
    "#\n",
    "#     return df\n",
    "#\n",
    "# def dfOrganizer(df):\n",
    "#     df.columns.values[2]='TimeStamp'\n",
    "#\n",
    "#     df.columns.values[8]='GyroX'\n",
    "#     df.columns.values[9]='GyroY'\n",
    "#     df.columns.values[10]='GyroZ'\n",
    "#\n",
    "#     df.columns.values[11]='AccelX'\n",
    "#     df.columns.values[12]='AccelY'\n",
    "#     df.columns.values[13]='AccelZ'\n",
    "#\n",
    "#     df = df.filter(['Name','TimeStamp','GyroX','GyroY','GyroZ','AccelX','AccelY','AccelZ'])\n",
    "#     df['TimeStamp'] = df['TimeStamp'].astype(float)\n",
    "#     df['TimeStamp']=df['TimeStamp']-1000*3600*4 #fixing the timezone\n",
    "#\n",
    "#     df.insert(2,'Date',float('nan'))\n",
    "#     df.insert(3,'Time',float('nan'))\n",
    "#\n",
    "#     df['Date']=pd.to_datetime(df['TimeStamp'],unit='ms')\n",
    "#     df['Time']=pd.to_datetime(df['TimeStamp'],unit='ms')\n",
    "#     df['Date']=df['Date'].dt.dayofyear\n",
    "#     df['Time']=df['Time'].dt.hour*3600+df['Time'].dt.minute*60+df['Time'].dt.second+df['Time'].dt.microsecond*0.001*0.001\n",
    "#\n",
    "#     df.drop(columns=['TimeStamp'],inplace=True)\n",
    "#     return df\n",
    "#\n",
    "# def csvReader(addressPrefix):\n",
    "#     dataFiles=[]\n",
    "#     for root, dirs, files in os.walk(addressPrefix, topdown=False):\n",
    "#        for name in files:\n",
    "#            if '.csv' in name:\n",
    "#                dataFiles.append([os.path.join(root,name)])\n",
    "#     for counter,element in enumerate(dataFiles):\n",
    "#         print(element)\n",
    "#         rows = []\n",
    "#         with open(element[0], 'r') as csvfile:\n",
    "#             csvreader = csv.reader(csvfile,delimiter = \"\\t\")\n",
    "#             next(csvreader) #skipping the first junk line\n",
    "#             headers = next(csvreader) #column titles\n",
    "#             while '' in headers:\n",
    "#                 headers.remove(\"\")\n",
    "#             if len(headers)!=17:\n",
    "#                 continue\n",
    "#             next(csvreader) #skipping the units\n",
    "#             for row in csvreader:\n",
    "#                 rows.append(row)\n",
    "#         df = pd.DataFrame(rows,columns=headers)\n",
    "#         participantName=element[0]\n",
    "#         participantName=participantName[participantName.find('CSV1')+5:participantName.find('CSV1')+10]\n",
    "#         df.insert(0,'Name',participantName)\n",
    "#\n",
    "#         df=dfOrganizer(df)\n",
    "#         df=dfCompactor(df)\n",
    "#\n",
    "#         if counter==0:\n",
    "#             dfTotal=df\n",
    "#         else:\n",
    "#             frames=[dfTotal,df]\n",
    "#             dfTotal=pd.concat(frames)\n",
    "#\n",
    "#         # if counter==1:\n",
    "#         #     break\n",
    "#     dfTotal.sort_values(by=['Name', 'Date','Time'],inplace=True)\n",
    "#     return dfTotal\n",
    "#\n",
    "# def preProcessor(dfTotal,R):\n",
    "#     columns=dfTotal.columns.values\n",
    "#     names=dfTotal['Name'].tolist()\n",
    "#     names=list(set(names))\n",
    "#\n",
    "#     dfProc=pd.DataFrame([],columns=columns)\n",
    "#     for counter,name in enumerate(names):\n",
    "#         print(name, (counter+1)/len(names))\n",
    "#         df=dfTotal[dfTotal['Name']==name]\n",
    "#         for column in columns:\n",
    "#             if column!='Time' and column!='Date' and column!='Name':\n",
    "#                 df[column]=list(gaussian_filter1d(df[column].tolist(),sigma=R))\n",
    "#             df['GyroX']=df['GyroX'].astype(float)\n",
    "#\n",
    "#         df['GyroX']=df['GyroX'].astype(int)\n",
    "#         df['GyroY']=df['GyroY'].astype(int)\n",
    "#         df['GyroZ']=df['GyroZ'].astype(int)\n",
    "#         df['AccelX']=df['AccelX'].astype(int)\n",
    "#         df['AccelY']=df['AccelY'].astype(int)\n",
    "#         df['AccelZ']=df['AccelZ'].astype(int)\n",
    "#\n",
    "#         frames=[dfProc,df]\n",
    "#         dfProc=pd.concat(frames)\n",
    "#         nameIndex = dfTotal[(dfTotal.Name == name)].index\n",
    "#         dfTotal.drop(nameIndex,inplace=True)\n",
    "#     return dfProc\n",
    "#\n",
    "# def funcCaller(addressPrefix):\n",
    "#     if os.path.exists(os.path.join(addressPrefix,'RawData.csv')):\n",
    "#         dfRaw=pd.read_csv(os.path.join(addressPrefix,'RawData.csv'))\n",
    "#     else:\n",
    "#         dfRaw=csvReader(os.path.join(addressPrefix,'CSV1'))\n",
    "#         dfRaw.to_csv(os.path.join(addressPrefix,'RawData.csv'),index=False)\n",
    "#     names=dfRaw['Name'].tolist()\n",
    "#     names=list(set(names))\n",
    "#     print('Total particpant number=',len(names))\n",
    "#\n",
    "#     if os.path.exists(os.path.join(addressPrefix,'FilteredData.csv')):\n",
    "#         dfProcessed=pd.read_csv(os.path.join(addressPrefix,'FilteredData.csv'))\n",
    "#     else:\n",
    "#         dfProcessed=preProcessor(dfRaw,R=3)\n",
    "#         dfProcessed.to_csv(os.path.join(addressPrefix,'FilteredData.csv'),index=False)\n",
    "#     return dfProcessed\n",
    "#\n",
    "# dfTotal=funcCaller(addressPrefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 191/354 [16:54<12:55,  4.76s/it]  "
     ]
    }
   ],
   "source": [
    "def shimmerReader(addressPrefix):\n",
    "    dataFiles=[]\n",
    "    for root, dirs, files in os.walk(addressPrefix, topdown=False):\n",
    "       for name in files:\n",
    "           if '.shm' in name:\n",
    "               dataFiles.append([os.path.join(root,name),name])\n",
    "    dataSize=0\n",
    "    for element in dataFiles:\n",
    "        with open(element[0], mode='rb') as txtfile:\n",
    "            fileData = txtfile.read()\n",
    "            dataSize+=int(len(fileData)/4/6)\n",
    "        txtfile.close()\n",
    "\n",
    "    sensorData=np.zeros(dataSize,7)\n",
    "    recordCounter=0\n",
    "    for iteration,element in enumerate(tqdm(dataFiles)):\n",
    "        nameTemp=element[1]\n",
    "        nameTemp=nameTemp[:nameTemp.find('.shm')]\n",
    "        with open(element[0], mode='rb') as txtfile:\n",
    "            fileData = txtfile.read()\n",
    "            tempData=np.zeros(int(len(fileData)/4),7,dtype='int16')\n",
    "            tempData[:,6]=int(nameTemp[1:])\n",
    "            for i in range(int(len(fileData)/4/6)):\n",
    "                for j in range(0,6):\n",
    "                    tempVal=fileData[(i*6+j)*4:(i*6+j+1)*4]\n",
    "                    tempVal=struct.unpack('f',tempVal)\n",
    "                    tempVal=tempVal[0]\n",
    "\n",
    "                    if j%6<3:\n",
    "                        tempVal*=1000\n",
    "                    else:\n",
    "                        tempVal*=100\n",
    "                    tempData[i,j]=tempVal\n",
    "        txtfile.close()\n",
    "        if iteration==355:\n",
    "            break\n",
    "\n",
    "    dfSensor=pd.DataFrame(sensorData,columns=[ 'X','Y','Z','Yaw','Pitch','Roll','Name'])\n",
    "    dfSensor=dfSensor[['Name','X','Y','Z','Yaw','Pitch','Roll']]\n",
    "    del sensorData\n",
    "    dfSensor.to_csv(r'C:\\GitHub\\HooverData.csv')\n",
    "\n",
    "    return dfSensor\n",
    "\n",
    "\n",
    "def pdFromatter(df):\n",
    "    df['Start'] = pd.to_datetime(df['Start'],format= '%H:%M:%S',errors='coerce')\n",
    "    df = df[df['Start'].notna()]\n",
    "    df['Start']=df['Start'].dt.hour*3600*1000+df['Start'].dt.minute*60*1000+df['Start'].dt.second*1000\n",
    "\n",
    "    df['End'] = pd.to_datetime(df['End'],format= '%H:%M:%S',errors='coerce')\n",
    "    df = df[df['End'].notna()]\n",
    "    df['End']=df['End'].dt.hour*3600*1000+df['End'].dt.minute*60*1000+df['End'].dt.second*1000\n",
    "    df.sort_values(by=['Name', 'Start','End'],inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def labelReader(addressPrefix):\n",
    "    dataFiles=[]\n",
    "    for root, dirs, files in os.walk(addressPrefix, topdown=False):\n",
    "       for name in files:\n",
    "           if '.txt' in name:\n",
    "               dataFiles.append([os.path.join(root,name),name])\n",
    "    mealTime=[]\n",
    "    sensorTiming=[]\n",
    "    for element in dataFiles:\n",
    "        nameTemp=element[1]\n",
    "        nameTemp=nameTemp[:nameTemp.find('-events')]\n",
    "        with open(element[0], 'r+') as txtfile:\n",
    "            fileData = txtfile.read()\n",
    "            fileData=fileData.splitlines()\n",
    "            while '' in fileData:\n",
    "                fileData.remove('')\n",
    "            tempStart=fileData[0]\n",
    "            tempStart=tempStart.split()\n",
    "            tempStart=tempStart[2]\n",
    "\n",
    "            tempEnd=fileData[-1]\n",
    "            tempEnd=tempEnd.split()\n",
    "            tempEnd=tempEnd[2]\n",
    "\n",
    "            sensorTiming.append([nameTemp,tempStart,tempEnd])\n",
    "            for counter in range(1,len(fileData)-1):\n",
    "                tempStr=fileData[counter]\n",
    "                tempStr=tempStr.split()\n",
    "                mealTime.append([nameTemp,tempStr[1],tempStr[2]])\n",
    "\n",
    "    dfMeal=pd.DataFrame(mealTime,columns=['Name','Start','End'])\n",
    "    dfMeal=pdFromatter(dfMeal)\n",
    "\n",
    "    dfSensor=pd.DataFrame(sensorTiming,columns=['Name','Start','End'])\n",
    "    dfSensor=pdFromatter(dfSensor)\n",
    "\n",
    "    return dfMeal,dfSensor\n",
    "\n",
    "def featureExtractor(df):\n",
    "    windowLength=30*1000\n",
    "    featureData=[]\n",
    "    names=df['Name'].tolist()\n",
    "    names=list(set(names))\n",
    "    for name in tqdm(names):\n",
    "        dfName=df[df['Name']==name]\n",
    "        startTime=dfName['Time'].min()\n",
    "        endTime=startTime+windowLength\n",
    "        while startTime<24*3600*1000:\n",
    "            dfTemp=dfName[dfName['Time']>=startTime]\n",
    "            dfTemp=dfTemp[dfTemp['Time']<endTime]\n",
    "            if len(dfTemp)>5:\n",
    "                f2=abs(dfTemp['X'].values)+abs(dfTemp['Y'].values)+abs(dfTemp['Z'].values)\n",
    "                f1=abs(dfTemp['Yaw'].values)+abs(dfTemp['Roll'].values)+abs(dfTemp['Pitch'].values)\n",
    "                f1=f1/f2\n",
    "                f1=np.mean(f1)\n",
    "                f2=np.mean(f2)\n",
    "                featureData.append([name,startTime,endTime,f1,f2])\n",
    "            startTime+=windowLength\n",
    "            endTime+=windowLength\n",
    "    return featureData\n",
    "\n",
    "def timeFinder(dfData,dfTime):\n",
    "    names=dfData['Name'].tolist()\n",
    "    names=list(set(names))\n",
    "    dfData.insert(1,'Time',float('nan'))\n",
    "    for name in tqdm(names):\n",
    "        dfTemp=dfTime[dfTime['Name']==name]\n",
    "        if len(dfTemp)>1:\n",
    "            print('More than one event file for:',name)\n",
    "            break\n",
    "        elif len(dfTemp)==0:\n",
    "            print('No event file for:',name)\n",
    "            break\n",
    "        startTemp=dfTemp['Start'].tolist()\n",
    "        endTemp=dfTemp['End'].tolist()\n",
    "        indices = dfSensor[dfSensor['Name']==name].index.tolist()\n",
    "        tempTimeStamp=np.linspace(startTemp,endTemp,num=len(indices))\n",
    "        dfData.loc[indices,'Time']=tempTimeStamp\n",
    "    return dfData\n",
    "\n",
    "def labelExtractor(dfLabel,features):\n",
    "    dataTotal=[]\n",
    "    for feature in tqdm(features):\n",
    "        windowName=feature[0]\n",
    "        windowStart=feature[1]\n",
    "        windowEnd=feature[2]\n",
    "        f1=feature[3]\n",
    "        f2=feature[4]\n",
    "        dfTemp=dfLabel[dfLabel['Name']==windowName]\n",
    "        if len(dfTemp)==0:\n",
    "            print('skipped',windowName)\n",
    "            continue\n",
    "        eatingFlag=False\n",
    "        for counter in range(0,len(dfTemp)):\n",
    "            if dfTemp.iloc[counter,1]<windowEnd and dfTemp.iloc[counter,2]>windowStart:\n",
    "                eatingFlag=True\n",
    "                break\n",
    "        dataTotal.append([f1,f2,eatingFlag])\n",
    "    dataTotal=np.asarray(dataTotal)\n",
    "    return dataTotal\n",
    "\n",
    "dfSensor=shimmerReader(os.path.join(addressPrefix,'SHMfiles'))\n",
    "dfLabel,dfTiming=labelReader(os.path.join(addressPrefix,'EVENTfiles'))\n",
    "dfSensor=timeFinder(dfSensor,dfTiming)\n",
    "featureData=featureExtractor(dfSensor)\n",
    "data=labelExtractor(dfLabel,featureData)\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def XGClassifier(dataList, labelList,randomSeed):\n",
    "    trainData, testData, trainLabels, testLabels = train_test_split(dataList, labelList, test_size=0.25,random_state=randomSeed)\n",
    "    trainData, valData, trainLabels, valLabels = train_test_split(trainData, trainLabels, test_size=0.33,random_state=randomSeed)\n",
    "    accuracyBest=0\n",
    "    for maxDepth in np.arange(3,30):\n",
    "        for estimator in np.arange(5,50,2):\n",
    "            clf = xgb.XGBClassifier(n_estimators=estimator,max_depth=maxDepth,objective = \"binary:logistic\",\n",
    "                                    eval_metric = \"logloss\",use_label_encoder =False,scale_pos_weight=20)\n",
    "            clf.fit(trainData, trainLabels)\n",
    "            slidingWindowPrediction = clf.predict_proba(valData)\n",
    "            slidingWindowPrediction=slidingWindowPrediction[:,1]\n",
    "            slidingWindowPrediction[slidingWindowPrediction>=0.5]=1\n",
    "            slidingWindowPrediction[slidingWindowPrediction<0.5]=0\n",
    "\n",
    "            confMatrix=sklearn.metrics.confusion_matrix(valLabels,slidingWindowPrediction)\n",
    "            accuracy=sklearn.metrics.accuracy_score(valLabels,slidingWindowPrediction)\n",
    "            recall=sklearn.metrics.recall_score(valLabels,slidingWindowPrediction)\n",
    "            precision=sklearn.metrics.precision_score(valLabels,slidingWindowPrediction)\n",
    "\n",
    "            if accuracy>accuracyBest:\n",
    "                confMatrixBest=confMatrix\n",
    "                accuracyBest=accuracy\n",
    "                modelBest=clf\n",
    "                recallBest=recall\n",
    "                precisionBest=precision\n",
    "    print('Testing on validation dataset:')\n",
    "    print(confMatrixBest)\n",
    "    print('Accuracy',np.round(100*accuracyBest,0),'Recall',np.round(100*recallBest,0),'Precision',np.round(100*precisionBest,0))\n",
    "\n",
    "    slidingWindowPrediction = modelBest.predict_proba(testData)\n",
    "    slidingWindowPrediction=slidingWindowPrediction[:,1]\n",
    "    slidingWindowPrediction[slidingWindowPrediction>=0.5]=1\n",
    "    slidingWindowPrediction[slidingWindowPrediction<0.5]=0\n",
    "\n",
    "    confMatrix=sklearn.metrics.confusion_matrix(testLabels,slidingWindowPrediction)\n",
    "    accuracy=sklearn.metrics.accuracy_score(testLabels,slidingWindowPrediction)\n",
    "    recall=sklearn.metrics.recall_score(testLabels,slidingWindowPrediction)\n",
    "    precision=sklearn.metrics.precision_score(testLabels,slidingWindowPrediction)\n",
    "\n",
    "    print('Testing on validation dataset:')\n",
    "    print(confMatrix)\n",
    "    print('Accuracy',np.round(100*accuracy,0),'Recall',np.round(100*recall,0),'Precision',np.round(100*precision,0))\n",
    "\n",
    "allData=data[:,0:2]\n",
    "allLabel=data[:,2]\n",
    "XGClassifier(allData, allLabel,randomSeed=53)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}