{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import struct\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import pearsonr, mode, kurtosis, skew\n",
    "from scipy.signal import savgol_filter\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import copy\n",
    "import warnings\n",
    "import multiprocessing\n",
    "\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import mean_squared_error, plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from joblib import Parallel, delayed\n",
    "import tsfel\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "if \"/home/grads/s/\" in os.getcwd():\n",
    "    addressPrefix = \"/home/grads/s/sorush.omidvar/CGMDataset/Hoover/\"\n",
    "else:\n",
    "    addressPrefix = \"C:/Users/sorush.omidvar/Google Drive/Documents/Educational/TAMU/Research/CGM Dataset/Hoover/\"\n",
    "    if not os.path.exists(addressPrefix):\n",
    "        addressPrefix = \"C:/GDrive/Documents/Educational/TAMU/Research/CGM Dataset/Hoover/\"\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({\"figure.facecolor\": \"white\"})\n",
    "coreNumber = np.min([multiprocessing.cpu_count(), 24])\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of core to be used: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354/354 [10:50<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "def pdFormatter(df):\n",
    "    for counter in range(len(df)):\n",
    "        tempStr = df.iloc[counter, 1]\n",
    "        tempVal = int(tempStr[0:2]) * 3600 + int(tempStr[3:5]) * 60 + int(tempStr[6:8])\n",
    "        tempVal *= 1000\n",
    "        df.iloc[counter, 1] = tempVal\n",
    "\n",
    "        tempStr = df.iloc[counter, 2]\n",
    "        tempVal = int(tempStr[0:2]) * 3600 + int(tempStr[3:5]) * 60 + int(tempStr[6:8])\n",
    "        tempVal *= 1000\n",
    "        df.iloc[counter, 2] = tempVal\n",
    "        if df.iloc[counter, 1] > df.iloc[counter, 2]:\n",
    "            df.iloc[counter, 2] += 24 * 3600 * 1000\n",
    "    df.sort_values(by=[\"Name\", \"Start\", \"End\"], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def labelReader(addressPrefix):\n",
    "    labelFiles = []\n",
    "    for root, dirs, files in os.walk(addressPrefix, topdown=False):\n",
    "        for name in files:\n",
    "            if \".txt\" in name:\n",
    "                labelFiles.append([os.path.join(root, name), name])\n",
    "    mealTime = []\n",
    "    sensorTiming = []\n",
    "    for element in labelFiles:\n",
    "        nameTemp = element[1]\n",
    "        nameTemp = nameTemp[: nameTemp.find(\"-events\")]\n",
    "        with open(element[0], \"r+\") as txtfile:\n",
    "            fileData = txtfile.read()\n",
    "            fileData = fileData.splitlines()\n",
    "            while \"\" in fileData:\n",
    "                fileData.remove(\"\")\n",
    "            tempStart = fileData[0]\n",
    "            tempStart = tempStart.split()\n",
    "            tempStart = tempStart[2]\n",
    "\n",
    "            tempEnd = fileData[-1]\n",
    "            tempEnd = tempEnd.split()\n",
    "            tempEnd = tempEnd[2]\n",
    "\n",
    "            sensorTiming.append([nameTemp, tempStart, tempEnd])\n",
    "            for counter in range(1, len(fileData) - 1):\n",
    "                tempStr = fileData[counter]\n",
    "                tempStr = tempStr.split()\n",
    "                mealTime.append([nameTemp, tempStr[1], tempStr[2]])\n",
    "\n",
    "    dfMeal = pd.DataFrame(mealTime, columns=[\"Name\", \"Start\", \"End\"])\n",
    "    dfMeal = pdFormatter(dfMeal)\n",
    "\n",
    "    dfTime = pd.DataFrame(sensorTiming, columns=[\"Name\", \"Start\", \"End\"])\n",
    "    dfTime = pdFormatter(dfTime)\n",
    "\n",
    "    return dfMeal, dfTime\n",
    "\n",
    "\n",
    "def shimmerReader(element):\n",
    "    nameTemp = element[1]\n",
    "    dataList = []\n",
    "    tempList = []\n",
    "    with open(element[0], mode=\"rb\") as txtfile:\n",
    "        fileData = txtfile.read()\n",
    "        for i in range(int(len(fileData) / 4)):\n",
    "            if i % 6 == 0 and i != 0:\n",
    "                tempList.append(nameTemp)\n",
    "                dataList.append(tempList)\n",
    "                tempList = []\n",
    "            tempVal = fileData[i * 4 : (i + 1) * 4]\n",
    "            tempVal = struct.unpack(\"f\", tempVal)\n",
    "            tempVal = tempVal[0]\n",
    "            tempList.append(tempVal)\n",
    "    txtfile.close()\n",
    "\n",
    "    dfSensor = pd.DataFrame(dataList, columns=[\"X\", \"Y\", \"Z\", \"Yaw\", \"Pitch\", \"Roll\", \"Name\"])\n",
    "    dfSensor = dfSensor[[\"Name\", \"X\", \"Y\", \"Z\", \"Yaw\", \"Pitch\", \"Roll\"]]\n",
    "    del dataList\n",
    "    return dfSensor\n",
    "\n",
    "\n",
    "def timeFinder(dfSensor, dfTime):\n",
    "    dfSensor.insert(1, \"Time\", float(\"nan\"))\n",
    "    name = dfSensor[\"Name\"].tolist()\n",
    "    name = name[0]\n",
    "    dfTemp = dfTime[dfTime[\"Name\"] == name]\n",
    "\n",
    "    if len(dfTemp) > 1:\n",
    "        print(\"More than one event file for:\", name)\n",
    "        return\n",
    "    elif len(dfTemp) == 0:\n",
    "        print(\"No event file for:\", name)\n",
    "        return\n",
    "    startTemp = dfTemp[\"Start\"].tolist()\n",
    "    endTemp = dfTemp[\"End\"].tolist()\n",
    "    tempTimeStamp = np.linspace(startTemp, endTemp, num=len(dfSensor))\n",
    "    dfSensor[\"Time\"] = tempTimeStamp\n",
    "    return dfSensor\n",
    "\n",
    "\n",
    "def labelExtractor(dfMeal, features):\n",
    "    dataTotal = []\n",
    "    for feature in features:\n",
    "        dataTemp = []\n",
    "        windowName = feature[-3]\n",
    "        windowStart = feature[-2]\n",
    "        windowEnd = feature[-1]\n",
    "        dfTemp = dfMeal[dfMeal[\"Name\"] == windowName]\n",
    "        if len(dfTemp) == 0:\n",
    "            print(\"skipped\", windowName)\n",
    "            break\n",
    "        eatingFlag = False\n",
    "        for counter in range(0, len(dfTemp)):\n",
    "            if dfTemp.iloc[counter, 1] < windowEnd and dfTemp.iloc[counter, 2] > windowStart:\n",
    "                eatingFlag = True\n",
    "                break\n",
    "        dataTemp.extend(feature[: len(feature) - 3])\n",
    "        dataTemp.extend([windowName, eatingFlag])\n",
    "        dataTotal.append(dataTemp)\n",
    "\n",
    "    return dataTotal\n",
    "\n",
    "\n",
    "def labelFinder(dfMeals, windowLength, name, start, end):\n",
    "    dfMeal = dfMeals[dfMeals[\"Name\"] == name]\n",
    "    eatingFlag = False\n",
    "    for counter in range(0, len(dfMeal)):\n",
    "        if dfMeal.iloc[counter][\"Start\"] <= end - windowLength / 2 and dfMeal.iloc[counter].loc[\"End\"] >= start + windowLength / 2:\n",
    "            eatingFlag = True\n",
    "            break\n",
    "    return eatingFlag\n",
    "\n",
    "\n",
    "def windowMaker(dfSensor, dfMeal):\n",
    "    windowLength = 60 * 1000\n",
    "    features = []\n",
    "    startTime = dfSensor[\"Time\"].min()\n",
    "    endTime = startTime + windowLength\n",
    "    while startTime < 24 * 3600 * 1000:\n",
    "        dfTemp = dfSensor[dfSensor[\"Time\"] >= startTime]\n",
    "        dfTemp = dfTemp[dfTemp[\"Time\"] < endTime]\n",
    "        if len(dfTemp) > 40 * 15:\n",
    "            eatingFlag = labelFinder(dfMeal, windowLength, dfTemp.iloc[0].loc[\"Name\"], dfTemp[\"Time\"].min(), dfTemp[\"Time\"].max())\n",
    "            dfTemp.insert(8, \"EatingFlag\", eatingFlag)\n",
    "            features.append(featureExtractor(dfTemp))\n",
    "        startTime += windowLength\n",
    "        endTime += windowLength\n",
    "    columnList = [\"Name\", \"EatingFlag\", \"Start\", \"End\", \"F1-Mean\", \"F1-Std\", \"F1-Range\", \"F2-Mean\", \"F2-Std\", \"F2-Range\"]\n",
    "    features = pd.DataFrame(features, columns=columnList)\n",
    "    # print(features)\n",
    "    return features\n",
    "\n",
    "\n",
    "def featureExtractor(df):\n",
    "    # cfg = tsfel.get_features_by_domain()\n",
    "    name = df.iloc[0, 0]\n",
    "    start = df.iloc[:, 1].min()\n",
    "    end = df.iloc[:, 1].max()\n",
    "    eatingFlag = df[\"EatingFlag\"].iloc[0]\n",
    "\n",
    "    f2 = df[\"X\"].abs() + df[\"Y\"].abs() + df[\"Z\"].abs() + 0.0001  # To avoid getting nan for F1\n",
    "    f2 = np.asarray(f2)\n",
    "    f1 = df[\"Yaw\"].abs() + df[\"Pitch\"].abs() + df[\"Roll\"].abs()\n",
    "    f1 = np.asarray(f1)\n",
    "    f1 = f1 / f2\n",
    "    featureData = [name, eatingFlag, start, end, np.mean(f1), np.std(f1), np.max(f1) - np.min(f1), np.mean(f2), np.std(f2), np.max(f2) - np.min(f2)]\n",
    "    return featureData\n",
    "\n",
    "\n",
    "def parallelCall(element, dfMeal, dfTime):\n",
    "    dfSensor = shimmerReader(element)\n",
    "    dfSensor = timeFinder(dfSensor, dfTime)\n",
    "    features = windowMaker(dfSensor, dfMeal)\n",
    "    return features\n",
    "\n",
    "\n",
    "def main(addressPrefix):\n",
    "    shimmerFiles = []\n",
    "    dfMeal, dfTime = labelReader(os.path.join(addressPrefix, \"EVENTfiles\"))\n",
    "    for root, dirs, files in os.walk(os.path.join(addressPrefix, \"SHMfiles\"), topdown=False):\n",
    "        for name in files:\n",
    "            if \".shm\" in name:\n",
    "                shimmerFiles.append([os.path.join(root, name), name[:-4]])\n",
    "    # shimmerFiles=shimmerFiles[0:20]\n",
    "    print(\"The number of core to be used:\", coreNumber)\n",
    "    dfFeatures = Parallel(n_jobs=coreNumber)(delayed(parallelCall)(i, dfMeal, dfTime) for i in tqdm(shimmerFiles))\n",
    "    # dfFeatures=parallelCall(shimmerFiles[0],dfMeal,dfTime)\n",
    "    dfFeatures = pd.concat(dfFeatures)\n",
    "    dfFeatures.sort_values(by=[\"Name\", \"Start\"])\n",
    "    dfFeatures.reset_index(drop=True, inplace=True)\n",
    "    dfFeatures.to_csv(os.path.join(addressPrefix, \"dfFeatures.csv\"), index=False)\n",
    "\n",
    "    return dfFeatures\n",
    "\n",
    "\n",
    "dfFeatures = main(addressPrefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'P2001'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-3a396ca17e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0mSMOTEFlag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0mrandomSeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m78\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m \u001b[0mdataSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSMOTEFlag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalFlag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandomSeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-3a396ca17e79>\u001b[0m in \u001b[0;36mdataSplitter\u001b[0;34m(SMOTEFlag, normalFlag, randomSeed)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mxDataPos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0myDataPos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mposNegSeparator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxDataPos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myDataPos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mxDataNeg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-3a396ca17e79>\u001b[0m in \u001b[0;36mposNegSeparator\u001b[0;34m(df, xData, yData, statLabel)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"EatingFlag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Start\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"End\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mxData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfTemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mxData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfoldMaker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatLabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdfTemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'P2001'"
     ]
    }
   ],
   "source": [
    "def modelVisualizer(testData, testLabels, modelBest):\n",
    "    slidingWindowPrediction = modelBest.predict(testData)\n",
    "    confMatrix = sklearn.metrics.confusion_matrix(testLabels, slidingWindowPrediction, normalize=\"all\")\n",
    "    accuracy = sklearn.metrics.accuracy_score(testLabels, slidingWindowPrediction)\n",
    "    recall = sklearn.metrics.recall_score(testLabels, slidingWindowPrediction)\n",
    "    precision = sklearn.metrics.precision_score(testLabels, slidingWindowPrediction)\n",
    "\n",
    "    print(\"Testing on test dataset:\")\n",
    "    print(confMatrix)\n",
    "    print(\"Accuracy\", np.round(100 * accuracy, 0), \"Recall\", np.round(100 * recall, 0), \"Precision\", np.round(100 * precision, 0))\n",
    "\n",
    "    titles_options = [(\"Confusion matrix, without normalization\", None), (\"Normalized confusion matrix\", \"true\")]\n",
    "\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(modelBest, testData, testLabels, display_labels=[\"Non Eating\", \"Eating\"], cmap=plt.cm.Blues, normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "    plt.show()\n",
    "    return confMatrix\n",
    "\n",
    "\n",
    "def xgClassifier(xTrain, yTrain, xTest, yTest, randomSeed, NormalFlag, SMOTEFlag):\n",
    "    if normalFlag:\n",
    "        for dimensionCounter in range(xTrain.shape[1]):\n",
    "            xTest[:, dimensionCounter] -= np.mean(xTrain[:, dimensionCounter])\n",
    "            xTest[:, dimensionCounter] /= np.std(xTrain[:, dimensionCounter])\n",
    "\n",
    "            xTrain[:, dimensionCounter] -= np.mean(xTrain[:, dimensionCounter])\n",
    "            xTrain[:, dimensionCounter] /= np.std(xTrain[:, dimensionCounter])\n",
    "\n",
    "    stratShuffle = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=randomSeed)\n",
    "    for trainInd, valInd in stratShuffle.split(xTrain, yTrain):\n",
    "        xTrain, xVal = xTrain[trainInd, :], xTrain[valInd, :]\n",
    "        yTrain, yVal = yTrain[trainInd], yTrain[valInd]\n",
    "\n",
    "    if SMOTEFlag:\n",
    "        oversample = SMOTE()\n",
    "        xTrain, yTrain = oversample.fit_resample(xTrain, yTrain)\n",
    "\n",
    "    f1Best = -1\n",
    "    for maxDepth in np.arange(4, 7, 5):\n",
    "        for estimator in np.arange(200, 301, 150):\n",
    "            posWeight = len(yTrain) / np.sum(yTrain)\n",
    "            clf = xgb.XGBClassifier(n_estimators=estimator, max_depth=maxDepth, objective=\"binary:logistic\", scale_pos_weight=posWeight, random_state=randomSeed, n_jobs=-1, eval_metric=\"logloss\", use_label_encoder=False)\n",
    "            clf.fit(xTrain, yTrain)\n",
    "            valPrediction = clf.predict(xVal)\n",
    "            accuracy = sklearn.metrics.accuracy_score(yVal, valPrediction)\n",
    "            recall = sklearn.metrics.recall_score(yVal, valPrediction)\n",
    "            precision = sklearn.metrics.precision_score(yVal, valPrediction)\n",
    "            f1Score = sklearn.metrics.f1_score(yVal, valPrediction, average=\"weighted\")\n",
    "\n",
    "            if f1Score > f1Best:\n",
    "                f1Best = f1Score\n",
    "                modelBest = clf\n",
    "\n",
    "    confMatrixTest = modelVisualizer(xTest, yTest, modelBest)\n",
    "    return clf, f1Score, confMatrixTest\n",
    "\n",
    "\n",
    "# def randomForestClassifier(dataList, labelList, randomSeed):\n",
    "#     trainData, testData, trainLabels, testLabels = train_test_split(dataList, labelList, test_size=0.25, random_state=randomSeed)\n",
    "#     trainData, valData, trainLabels, valLabels = train_test_split(trainData, trainLabels, test_size=0.33, random_state=randomSeed)\n",
    "#     oversample = SMOTE()\n",
    "#     trainData, trainLabels = oversample.fit_resample(trainData, trainLabels)\n",
    "#     f1Best = 0\n",
    "#     for treeNum in np.arange(10, 100, 10):\n",
    "#         for maxDepth in np.arange(3, 10):\n",
    "#             clf = RandomForestClassifier(n_estimators=treeNum, criterion=\"entropy\", random_state=0, max_depth=maxDepth, n_jobs=coreNumber)\n",
    "#             clf.fit(trainData, trainLabels)\n",
    "#             slidingWindowPrediction = clf.predict(valData)\n",
    "#             accuracy = sklearn.metrics.accuracy_score(valLabels, slidingWindowPrediction)\n",
    "#             recall = sklearn.metrics.recall_score(valLabels, slidingWindowPrediction)\n",
    "#             precision = sklearn.metrics.precision_score(valLabels, slidingWindowPrediction)\n",
    "#             f1 = sklearn.metrics.f1_score(valLabels, slidingWindowPrediction, average=\"weighted\")\n",
    "\n",
    "#             if f1 > f1Best:\n",
    "#                 f1Best = f1\n",
    "#                 maxDepthBest = maxDepth\n",
    "#                 treeNumBest = treeNum\n",
    "#                 accuracyBest = accuracy\n",
    "#                 modelBest = clf\n",
    "#                 recallBest = recall\n",
    "#                 precisionBest = precision\n",
    "\n",
    "#     modelVisualizer(testData, testLabels, modelBest)\n",
    "\n",
    "\n",
    "# def dataSplitter(normalFlag,randomSeed):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def foldRunnerAux(df,xData,yData,xTrain,yTrain,xTest,yTest):\n",
    "    tempVal = df[\"Train\"].to_list()\n",
    "    tempVal = np.asarray(tempVal).astype(int)\n",
    "    tempVal = tempVal.flatten()\n",
    "    if len(yTrain)==0:\n",
    "        xTrain = xData[tempVal, :]\n",
    "        yTrain = yData[tempVal]\n",
    "    else:\n",
    "        xTrain = np.concatenate((xTrain, xData[tempVal, :]), axis=0)\n",
    "        yTrain = np.concatenate((yTrain, yData[tempVal]), axis=0)        \n",
    "\n",
    "    tempVal = df[\"Test\"].to_list()\n",
    "    tempVal = np.asarray(tempVal).astype(int)\n",
    "    tempVal = tempVal.flatten()\n",
    "    if len(yTest)==0:\n",
    "        xTest = xData[tempVal, :]\n",
    "        yTest = yData[tempVal]\n",
    "    else:\n",
    "        xTest = np.concatenate((xTest, xData[tempVal, :]), axis=0)\n",
    "        yTest = np.concatenate((yTest, yData[tempVal]), axis=0)              \n",
    "\n",
    "def foldRunner(dfData,posXData,posYData,negXData,negYData,xTrain,yTrain,xTest,yTest):\n",
    "    dfTemp = dfData[dfData[\"Set\"] == setData]\n",
    "    dfPos = dfTemp[dfTemp[\"Stat\"] == \"Pos\"]    \n",
    "    foldRunnerAux(dfPos,posXData,posYData,xTrain,yTrain,xTest,yTest)\n",
    "\n",
    "    dfTemp = dfData[dfData[\"Set\"] == setData]\n",
    "    dfNeg = dfTemp[dfTemp[\"Stat\"] == \"Neg\"]\n",
    "    foldRunnerAux(dfNeg,negXData,negYData,xTrain,yTrain,xTest,yTest)\n",
    "\n",
    "def posNegSeparator(df,xData,yData,statLabel):\n",
    "    dfTemp=df[df[\"EatingFlag\"]==statLabel]\n",
    "    yData = dfTemp[\"EatingFlag\"].to_list()\n",
    "    yData = np.asarray(yData).astype(float)\n",
    "\n",
    "    df.drop(columns=[\"EatingFlag\", \"Name\", \"Start\", \"End\"], inplace=True)\n",
    "    xData = dfTemp.values\n",
    "    xData = np.asarray(xData).astype(float)\n",
    "\n",
    "def foldMaker(statLabel,yData,dfTemp):\n",
    "    setCounter=0\n",
    "    kf = KFold(n_splits=5, shuffle=False)\n",
    "    for trainIndex, testIndex in kf.split(yData):\n",
    "        dfTemp.append([statLabel, trainIndex, testIndex, setCounter])\n",
    "        setCounter += 1\n",
    "\n",
    "\n",
    "def dataSummarizer(f1ScoreSets,confMatrixSets):\n",
    "    f1ScoreSets = np.asarray(f1ScoreSets).astype(float)\n",
    "    f1ScoreSets = np.round(f1ScoreSets, 3)\n",
    "    confMatrixMean = np.mean(np.asarray(confMatrixSets), axis=0)\n",
    "    print(\"All F1 scores\", f1ScoreSets)\n",
    "    print(\"Average F1:\", np.mean(f1ScoreSets))\n",
    "    print(\"Average Conf Matrix:\", confMatrixMean)\n",
    "    accuracy = (confMatrixMean[0][0] + confMatrixMean[1][1]) / (confMatrixMean[0][0] + confMatrixMean[0][1] + confMatrixMean[1][0] + confMatrixMean[1][1])  # (TP+NP)/(TP+NP+FP+FN)\n",
    "    sensitivity = confMatrixMean[1][1] / (confMatrixMean[1][0] + confMatrixMean[1][1])  # TP/(TP+FN)\n",
    "    specificity = confMatrixMean[0][0] / (confMatrixMean[0][0] + confMatrixMean[0][1])  # TN/(TN+FP)\n",
    "    precision = confMatrixMean[1][1] / (confMatrixMean[1][1] + confMatrixMean[0][1])  # TP/(TP+FP)\n",
    "    # CONF Matrix Struct=[TN,FP;FN,TP]\n",
    "    print(\"Average value of accuracy:\", np.round(accuracy, 2), \"\\t recal:\", np.round(sensitivity, 2), \"\\t specificity:\", np.round(specificity, 2), \"\\t precisiion\", np.round(precision, 2))\n",
    "\n",
    "def dataSplitter(SMOTEFlag,normalFlag,randomSeed):\n",
    "    dfData = pd.read_csv(os.path.join(addressPrefix, \"dfFeatures.csv\"))\n",
    "    dfData.sort_values([\"Name\", \"Start\"], ascending=(True, True), inplace=True)\n",
    "    dfData.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    xDataPos=[]\n",
    "    yDataPos=[]    \n",
    "    posNegSeparator(dfData,xDataPos,yDataPos,1)\n",
    "\n",
    "    xDataNeg=[]\n",
    "    yDataNeg=[]\n",
    "    posNegSeparator(dfData,xDataNeg,yDataNeg,0)\n",
    "\n",
    "    dfTemp = []\n",
    "    foldMaker(\"Pos\",yDataPos,dfTemp)\n",
    "    foldMaker(\"Neg\",yDataNeg,dfTemp)\n",
    "\n",
    "    dfData = pd.DataFrame(dfData, columns=[\"Stat\", \"Train\", \"Test\", \"Set\"])\n",
    "    setDatas = list(set(dfData[\"Set\"].to_list()))\n",
    "    f1ScoreSets = []\n",
    "    confMatrixSets = []\n",
    "    for counter in len(setDatas):\n",
    "        xTrain=[]\n",
    "        yTrain=[]\n",
    "        xTest=[]\n",
    "        yTest=[]\n",
    "        foldRunner(dfData,xDataPos,yDataPos,xDataNeg,yDataNeg,xTrain,yTrain,xTest,yTest)\n",
    "        clf, f1ScoreTemp, confMatrixTest = xgClassifier(xTrain, yTrain, xTest, yTest, randomSeed, normalFlag, SMOTEFlag)\n",
    "        f1ScoreSets.append(f1ScoreTemp)\n",
    "        confMatrixSets.append(confMatrixTest)\n",
    "    dataSummarizer()\n",
    "\n",
    "normalFlag = True\n",
    "SMOTEFlag=True\n",
    "randomSeed = 78\n",
    "dataSplitter(SMOTEFlag,normalFlag,randomSeed)\n",
    "\n",
    "\n",
    "\n",
    "# posYData = positiveData[\"EatingFlag\"].to_list()\n",
    "# posYData = np.asarray(posYData).astype(float)\n",
    "\n",
    "# negYData = negativeData[\"EatingFlag\"].to_list()\n",
    "# negYData = np.asarray(negYData).astype(float)\n",
    "\n",
    "# positiveData.drop(columns=[\"EatingFlag\", \"Name\", \"Start\", \"End\"], inplace=True)\n",
    "# posXData = positiveData.values\n",
    "# posXData = np.asarray(posXData).astype(float)\n",
    "\n",
    "# negativeData.drop(columns=[\"EatingFlag\", \"Name\", \"Start\", \"End\"], inplace=True)\n",
    "\n",
    "# negXData = negativeData.values\n",
    "# negXData = np.asarray(negXData).astype(float)\n",
    "\n",
    "# kf = KFold(n_splits=5, shuffle=False)\n",
    "# dfData = []\n",
    "# setCounter = 0\n",
    "# for trainIndex, testIndex in kf.split(posYData):\n",
    "#     dfData.append([\"Pos\", trainIndex, testIndex, setCounter])\n",
    "#     setCounter += 1\n",
    "\n",
    "# setCounter = 0\n",
    "# for trainIndex, testIndex in kf.split(negYData):\n",
    "#     dfData.append([\"Neg\", trainIndex, testIndex, setCounter])\n",
    "#     setCounter += 1\n",
    "\n",
    "# dfData = pd.DataFrame(dfData, columns=[\"Stat\", \"Train\", \"Test\", \"Set\"])\n",
    "# setDatas = list(set(dfData[\"Set\"].to_list()))\n",
    "# f1ScoreSets = []\n",
    "# confMatrixSets = []\n",
    "# for setData in setDatas:\n",
    "#     dfTemp = dfData[dfData[\"Set\"] == setData]\n",
    "#     dfPos = dfTemp[dfTemp[\"Stat\"] == \"Pos\"]\n",
    "\n",
    "#     tempVal = dfPos[\"Train\"].to_list()\n",
    "#     tempVal = np.asarray(tempVal).astype(int)\n",
    "#     tempVal = tempVal.flatten()\n",
    "#     xTrain = posXData[tempVal, :]\n",
    "#     yTrain = posYData[tempVal]\n",
    "\n",
    "#     tempVal = dfPos[\"Test\"].to_list()\n",
    "#     tempVal = np.asarray(tempVal).astype(int)\n",
    "#     tempVal = tempVal.flatten()\n",
    "#     xTest = posXData[tempVal, :]\n",
    "#     yTest = posYData[tempVal]\n",
    "\n",
    "#     dfTemp = dfData[dfData[\"Set\"] == setData]\n",
    "#     dfNeg = dfTemp[dfTemp[\"Stat\"] == \"Neg\"]\n",
    "\n",
    "#     tempVal = dfNeg[\"Train\"].to_list()\n",
    "#     tempVal = np.asarray(tempVal).astype(int)\n",
    "#     tempVal = tempVal.flatten()\n",
    "#     xTrain = np.concatenate((xTrain, negXData[tempVal, :]), axis=0)\n",
    "#     yTrain = np.concatenate((yTrain, negYData[tempVal]), axis=0)\n",
    "\n",
    "#     tempVal = dfNeg[\"Test\"].to_list()\n",
    "#     tempVal = np.asarray(tempVal).astype(int)\n",
    "#     tempVal = tempVal.flatten()\n",
    "#     xTest = np.concatenate((xTest, negXData[tempVal, :]), axis=0)\n",
    "#     yTest = np.concatenate((yTest, negYData[tempVal]), axis=0)\n",
    "\n",
    "#     clf, f1ScoreTemp, confMatrixTest = xgClassifier(xTrain, yTrain, xTest, yTest, randomSeed, NormalFlag=True, SMOTEFlag=True)\n",
    "#     f1ScoreSets.append(f1ScoreTemp)\n",
    "#     confMatrixSets.append(confMatrixTest)\n",
    "\n",
    "# f1ScoreSets = np.asarray(f1ScoreSets).astype(float)\n",
    "# f1ScoreSets = np.round(f1ScoreSets, 3)\n",
    "# confMatrixMean = np.mean(np.asarray(confMatrixSets), axis=0)\n",
    "# print(\"All F1 scores\", f1ScoreSets)\n",
    "# print(\"Average F1:\", np.mean(f1ScoreSets))\n",
    "# print(\"Average Conf Matrix:\", confMatrixMean)\n",
    "# accuracy = (confMatrixMean[0][0] + confMatrixMean[1][1]) / (confMatrixMean[0][0] + confMatrixMean[0][1] + confMatrixMean[1][0] + confMatrixMean[1][1])  # (TP+NP)/(TP+NP+FP+FN)\n",
    "# sensitivity = confMatrixMean[1][1] / (confMatrixMean[1][0] + confMatrixMean[1][1])  # TP/(TP+FN)\n",
    "# specificity = confMatrixMean[0][0] / (confMatrixMean[0][0] + confMatrixMean[0][1])  # TN/(TN+FP)\n",
    "# precision = confMatrixMean[1][1] / (confMatrixMean[1][1] + confMatrixMean[0][1])  # TP/(TP+FP)\n",
    "# # CONF Matrix Struct=[TN,FP;FN,TP]\n",
    "# print(\"Average value of accuracy:\", np.round(accuracy, 2), \"\\t recal:\", np.round(sensitivity, 2), \"\\t specificity:\", np.round(specificity, 2), \"\\t precisiion\", np.round(precision, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7414333e4a832e37764beae57bbbaf9ec9a12bc709a61fd48cde13ae0db02074"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('miniconda3': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
