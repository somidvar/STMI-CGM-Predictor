{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import copy\n",
    "import math\n",
    "import struct\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import pearsonr, mode\n",
    "from scipy.signal import savgol_filter\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import copy\n",
    "import warnings\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import mean_squared_error,plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "if '/home/grads/s/' in os.getcwd():\n",
    "    addressPrefix='/home/grads/s/sorush.omidvar/CGMDataset/Hoover/'\n",
    "else:\n",
    "    addressPrefix='C:/Users/sorush.omidvar/Google Drive/Documents/Educational/TAMU/Research/CGM Dataset/Hoover/'\n",
    "    if not os.path.exists(addressPrefix):\n",
    "        addressPrefix='C:/GDrive/Documents/Educational/TAMU/Research/CGM Dataset/Hoover/'\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({'figure.facecolor':'white'})\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "num_cores=np.min([num_cores,36])\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# def dfCompactor(df):\n",
    "#     df['Date']=df['Date'].astype(int)\n",
    "#     df['Time']=df['Time']*1000\n",
    "#     df['Time']=df['Time'].astype(int)\n",
    "#     df.rename(columns={\"Time\": \"Time[ms]\"})\n",
    "#\n",
    "#     df['GyroX']=df['GyroX'].astype(float)\n",
    "#     df['GyroX']=df['GyroX']*1000*1000\n",
    "#     df['GyroX']=df['GyroX'].astype(int)\n",
    "#     df.rename(columns={\"GyroX\": \"GyroX[microD/s]\"})\n",
    "#\n",
    "#     df['GyroY']=df['GyroY'].astype(float)\n",
    "#     df['GyroY']=df['GyroY']*1000*1000\n",
    "#     df['GyroY']=df['GyroY'].astype(int)\n",
    "#     df.rename(columns={\"GyroY\": \"GyroY[microD/s]\"})\n",
    "#\n",
    "#     df['GyroZ']=df['GyroZ'].astype(float)\n",
    "#     df['GyroZ']=df['GyroZ']*1000*1000\n",
    "#     df['GyroZ']=df['GyroZ'].astype(int)\n",
    "#     df.rename(columns={\"GyroZ\": \"GyroZ[microD/s]\"})\n",
    "#\n",
    "#     df['AccelX']=df['AccelX'].astype(float)\n",
    "#     df['AccelX']=df['AccelX']*1000*1000\n",
    "#     df['AccelX']=df['AccelX'].astype(int)\n",
    "#     df.rename(columns={\"AccelX\": \"AccelX[microm/s2]\"})\n",
    "#\n",
    "#     df['AccelY']=df['AccelY'].astype(float)\n",
    "#     df['AccelY']=df['AccelY']*1000*1000\n",
    "#     df['AccelY']=df['AccelY'].astype(int)\n",
    "#     df.rename(columns={\"AccelY\": \"AccelY[microm/s2]\"})\n",
    "#\n",
    "#     df['AccelZ']=df['AccelZ'].astype(float)\n",
    "#     df['AccelZ']=df['AccelZ']*1000*1000\n",
    "#     df['AccelZ']=df['AccelZ'].astype(int)\n",
    "#     df.rename(columns={\"AccelZ\": \"AccelZ[microm/s2]\"})\n",
    "#\n",
    "#     return df\n",
    "#\n",
    "# def dfOrganizer(df):\n",
    "#     df.columns.values[2]='TimeStamp'\n",
    "#\n",
    "#     df.columns.values[8]='GyroX'\n",
    "#     df.columns.values[9]='GyroY'\n",
    "#     df.columns.values[10]='GyroZ'\n",
    "#\n",
    "#     df.columns.values[11]='AccelX'\n",
    "#     df.columns.values[12]='AccelY'\n",
    "#     df.columns.values[13]='AccelZ'\n",
    "#\n",
    "#     df = df.filter(['Name','TimeStamp','GyroX','GyroY','GyroZ','AccelX','AccelY','AccelZ'])\n",
    "#     df['TimeStamp'] = df['TimeStamp'].astype(float)\n",
    "#     df['TimeStamp']=df['TimeStamp']-1000*3600*4 #fixing the timezone\n",
    "#\n",
    "#     df.insert(2,'Date',float('nan'))\n",
    "#     df.insert(3,'Time',float('nan'))\n",
    "#\n",
    "#     df['Date']=pd.to_datetime(df['TimeStamp'],unit='ms')\n",
    "#     df['Time']=pd.to_datetime(df['TimeStamp'],unit='ms')\n",
    "#     df['Date']=df['Date'].dt.dayofyear\n",
    "#     df['Time']=df['Time'].dt.hour*3600+df['Time'].dt.minute*60+df['Time'].dt.second+df['Time'].dt.microsecond*0.001*0.001\n",
    "#\n",
    "#     df.drop(columns=['TimeStamp'],inplace=True)\n",
    "#     return df\n",
    "#\n",
    "# def csvReader(addressPrefix):\n",
    "#     dataFiles=[]\n",
    "#     for root, dirs, files in os.walk(addressPrefix, topdown=False):\n",
    "#        for name in files:\n",
    "#            if '.csv' in name:\n",
    "#                dataFiles.append([os.path.join(root,name)])\n",
    "#     for counter,element in enumerate(dataFiles):\n",
    "#         print(element)\n",
    "#         rows = []\n",
    "#         with open(element[0], 'r') as csvfile:\n",
    "#             csvreader = csv.reader(csvfile,delimiter = \"\\t\")\n",
    "#             next(csvreader) #skipping the first junk line\n",
    "#             headers = next(csvreader) #column titles\n",
    "#             while '' in headers:\n",
    "#                 headers.remove(\"\")\n",
    "#             if len(headers)!=17:\n",
    "#                 continue\n",
    "#             next(csvreader) #skipping the units\n",
    "#             for row in csvreader:\n",
    "#                 rows.append(row)\n",
    "#         df = pd.DataFrame(rows,columns=headers)\n",
    "#         participantName=element[0]\n",
    "#         participantName=participantName[participantName.find('CSV1')+5:participantName.find('CSV1')+10]\n",
    "#         df.insert(0,'Name',participantName)\n",
    "#\n",
    "#         df=dfOrganizer(df)\n",
    "#         df=dfCompactor(df)\n",
    "#\n",
    "#         if counter==0:\n",
    "#             dfTotal=df\n",
    "#         else:\n",
    "#             frames=[dfTotal,df]\n",
    "#             dfTotal=pd.concat(frames)\n",
    "#\n",
    "#         # if counter==1:\n",
    "#         #     break\n",
    "#     dfTotal.sort_values(by=['Name', 'Date','Time'],inplace=True)\n",
    "#     return dfTotal\n",
    "#\n",
    "# def preProcessor(dfTotal,R):\n",
    "#     columns=dfTotal.columns.values\n",
    "#     names=dfTotal['Name'].tolist()\n",
    "#     names=list(set(names))\n",
    "#\n",
    "#     dfProc=pd.DataFrame([],columns=columns)\n",
    "#     for counter,name in enumerate(names):\n",
    "#         print(name, (counter+1)/len(names))\n",
    "#         df=dfTotal[dfTotal['Name']==name]\n",
    "#         for column in columns:\n",
    "#             if column!='Time' and column!='Date' and column!='Name':\n",
    "#                 df[column]=list(gaussian_filter1d(df[column].tolist(),sigma=R))\n",
    "#             df['GyroX']=df['GyroX'].astype(float)\n",
    "#\n",
    "#         df['GyroX']=df['GyroX'].astype(int)\n",
    "#         df['GyroY']=df['GyroY'].astype(int)\n",
    "#         df['GyroZ']=df['GyroZ'].astype(int)\n",
    "#         df['AccelX']=df['AccelX'].astype(int)\n",
    "#         df['AccelY']=df['AccelY'].astype(int)\n",
    "#         df['AccelZ']=df['AccelZ'].astype(int)\n",
    "#\n",
    "#         frames=[dfProc,df]\n",
    "#         dfProc=pd.concat(frames)\n",
    "#         nameIndex = dfTotal[(dfTotal.Name == name)].index\n",
    "#         dfTotal.drop(nameIndex,inplace=True)\n",
    "#     return dfProc\n",
    "#\n",
    "# def funcCaller(addressPrefix):\n",
    "#     if os.path.exists(os.path.join(addressPrefix,'RawData.csv')):\n",
    "#         dfRaw=pd.read_csv(os.path.join(addressPrefix,'RawData.csv'))\n",
    "#     else:\n",
    "#         dfRaw=csvReader(os.path.join(addressPrefix,'CSV1'))\n",
    "#         dfRaw.to_csv(os.path.join(addressPrefix,'RawData.csv'),index=False)\n",
    "#     names=dfRaw['Name'].tolist()\n",
    "#     names=list(set(names))\n",
    "#     print('Total particpant number=',len(names))\n",
    "#\n",
    "#     if os.path.exists(os.path.join(addressPrefix,'FilteredData.csv')):\n",
    "#         dfProcessed=pd.read_csv(os.path.join(addressPrefix,'FilteredData.csv'))\n",
    "#     else:\n",
    "#         dfProcessed=preProcessor(dfRaw,R=3)\n",
    "#         dfProcessed.to_csv(os.path.join(addressPrefix,'FilteredData.csv'),index=False)\n",
    "#     return dfProcessed\n",
    "#\n",
    "# dfTotal=funcCaller(addressPrefix)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def pdFromatter(df):\n",
    "    for counter in range(len(df)):\n",
    "        tempStr=df.iloc[counter,1]\n",
    "        tempVal=int(tempStr[0:2])*3600+int(tempStr[3:5])*60+int(tempStr[6:8])\n",
    "        tempVal*=1000\n",
    "        df.iloc[counter,1]=tempVal\n",
    "\n",
    "        tempStr=df.iloc[counter,2]\n",
    "        tempVal=int(tempStr[0:2])*3600+int(tempStr[3:5])*60+int(tempStr[6:8])\n",
    "        tempVal*=1000\n",
    "        df.iloc[counter,2]=tempVal\n",
    "        if df.iloc[counter,1]>df.iloc[counter,2]:\n",
    "            df.iloc[counter,2]+=24*3600*1000\n",
    "    df.sort_values(by=['Name','Start','End'],inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def labelReader(addressPrefix):\n",
    "    labelFiles=[]\n",
    "    for root, dirs, files in os.walk(addressPrefix, topdown=False):\n",
    "       for name in files:\n",
    "           if '.txt' in name:\n",
    "               labelFiles.append([os.path.join(root,name),name])\n",
    "    mealTime=[]\n",
    "    sensorTiming=[]\n",
    "    for element in labelFiles:\n",
    "        nameTemp=element[1]\n",
    "        nameTemp=nameTemp[:nameTemp.find('-events')]\n",
    "        with open(element[0], 'r+') as txtfile:\n",
    "            fileData = txtfile.read()\n",
    "            fileData=fileData.splitlines()\n",
    "            while '' in fileData:\n",
    "                fileData.remove('')\n",
    "            tempStart=fileData[0]\n",
    "            tempStart=tempStart.split()\n",
    "            tempStart=tempStart[2]\n",
    "\n",
    "            tempEnd=fileData[-1]\n",
    "            tempEnd=tempEnd.split()\n",
    "            tempEnd=tempEnd[2]\n",
    "\n",
    "            sensorTiming.append([nameTemp,tempStart,tempEnd])\n",
    "            for counter in range(1,len(fileData)-1):\n",
    "                tempStr=fileData[counter]\n",
    "                tempStr=tempStr.split()\n",
    "                mealTime.append([nameTemp,tempStr[1],tempStr[2]])\n",
    "\n",
    "    dfMeal=pd.DataFrame(mealTime,columns=['Name','Start','End'])\n",
    "    dfMeal=pdFromatter(dfMeal)\n",
    "\n",
    "    dfTime=pd.DataFrame(sensorTiming,columns=['Name','Start','End'])\n",
    "    dfTime=pdFromatter(dfTime)\n",
    "\n",
    "    return dfMeal,dfTime\n",
    "\n",
    "def shimmerReader(element):\n",
    "    nameTemp=element[1]\n",
    "    dataList=[]\n",
    "    tempList=[]\n",
    "    with open(element[0], mode='rb') as txtfile:\n",
    "        fileData = txtfile.read()\n",
    "        for i in range(int(len(fileData)/4)):\n",
    "            if i%6==0 and i!=0:\n",
    "                tempList.append(nameTemp)\n",
    "                dataList.append(tempList)\n",
    "                tempList=[]\n",
    "            tempVal=fileData[i*4:(i+1)*4]\n",
    "            tempVal=struct.unpack('f',tempVal)\n",
    "            tempVal=tempVal[0]\n",
    "            tempList.append(tempVal)\n",
    "    txtfile.close()\n",
    "\n",
    "    dfSensor=pd.DataFrame(dataList,columns=[ 'X','Y','Z','Yaw','Pitch','Roll','Name'])\n",
    "    dfSensor=dfSensor[['Name','X','Y','Z','Yaw','Pitch','Roll']]\n",
    "    dfSensor.to_csv(r'C:\\GitHub\\mamad.csv')\n",
    "    del dataList\n",
    "    return dfSensor\n",
    "\n",
    "def timeFinder(dfSensor,dfTime):\n",
    "    dfSensor.insert(1,'Time',float('nan'))\n",
    "    name=dfSensor['Name'].tolist()\n",
    "    name=name[0]\n",
    "    dfTemp=dfTime[dfTime['Name']==name]\n",
    "\n",
    "    if len(dfTemp)>1:\n",
    "        print('More than one event file for:',name)\n",
    "        return\n",
    "    elif len(dfTemp)==0:\n",
    "        print('No event file for:',name)\n",
    "        return\n",
    "    startTemp=dfTemp['Start'].tolist()\n",
    "    endTemp=dfTemp['End'].tolist()\n",
    "    tempTimeStamp=np.linspace(startTemp,endTemp,num=len(dfSensor))\n",
    "    dfSensor['Time']=tempTimeStamp\n",
    "    return dfSensor\n",
    "\n",
    "def featureExtractor(df):\n",
    "    windowLength=60*1000\n",
    "    featureData=[]\n",
    "    name=df['Name'].tolist()\n",
    "    name=name[0]\n",
    "    dfName=df[df['Name']==name]\n",
    "    startTime=dfName['Time'].min()\n",
    "    endTime=startTime+windowLength\n",
    "\n",
    "    while startTime<24*3600*1000:\n",
    "        dfTemp=dfName[dfName['Time']>=startTime]\n",
    "        dfTemp=dfTemp[dfTemp['Time']<endTime]\n",
    "        if len(dfTemp)>5*15:\n",
    "            features=[]\n",
    "            f1=abs(dfTemp['Yaw'].values)+abs(dfTemp['Roll'].values)+abs(dfTemp['Pitch'].values)\n",
    "            f2=abs(dfTemp['X'].values)+abs(dfTemp['Y'].values)+abs(dfTemp['Z'].values)\n",
    "            f2+=0.0001\n",
    "            f1=f1/f2\n",
    "            f1=np.mean(f1)\n",
    "            f2=np.mean(f2)\n",
    "            if np.isnan(f1):\n",
    "                print('Nan F1 Value')\n",
    "                continue\n",
    "            features.append(f1)\n",
    "            features.append(f2)\n",
    "            for axe in dfTemp.columns:\n",
    "                if axe=='Time' or axe=='Name':\n",
    "                    continue\n",
    "                tempVal=np.mean(abs(dfTemp[axe].values))\n",
    "                features.append(tempVal)\n",
    "\n",
    "                tempVal=np.std(abs(dfTemp[axe].values))\n",
    "                features.append(tempVal)\n",
    "\n",
    "                tempVal=np.mean(dfTemp[axe].values)\n",
    "                features.append(tempVal)\n",
    "\n",
    "                tempVal=np.std(dfTemp[axe].values)\n",
    "                features.append(tempVal)\n",
    "            features.extend([name,startTime,endTime])\n",
    "            featureData.append(features)\n",
    "        startTime+=windowLength\n",
    "        endTime+=windowLength\n",
    "    return featureData\n",
    "\n",
    "def labelExtractor(dfMeal,features):\n",
    "    dataTotal=[]\n",
    "\n",
    "    for feature in features:\n",
    "        dataTemp=[]\n",
    "        windowName=feature[-3]\n",
    "        windowStart=feature[-2]\n",
    "        windowEnd=feature[-1]\n",
    "        dfTemp=dfMeal[dfMeal['Name']==windowName]\n",
    "        if len(dfTemp)==0:\n",
    "            print('skipped',windowName)\n",
    "            break\n",
    "        eatingFlag=False\n",
    "        for counter in range(0,len(dfTemp)):\n",
    "            if dfTemp.iloc[counter,1]<windowEnd and dfTemp.iloc[counter,2]>windowStart:\n",
    "                eatingFlag=True\n",
    "                break\n",
    "        dataTemp.extend(feature[:len(feature)-3])\n",
    "        dataTemp.extend([windowName,eatingFlag])\n",
    "        dataTotal.append(dataTemp)\n",
    "\n",
    "    return dataTotal\n",
    "\n",
    "def callerFunc(element,dfMeal,dfTime):\n",
    "\n",
    "    dfSensor=shimmerReader(element)\n",
    "    dfSensor=timeFinder(dfSensor,dfTime)\n",
    "    featureData=featureExtractor(dfSensor)\n",
    "    allData=labelExtractor(dfMeal,featureData)\n",
    "\n",
    "    return allData\n",
    "\n",
    "def main(addressPrefix):\n",
    "    shimmerFiles=[]\n",
    "    dfMeal,dfTime=labelReader(os.path.join(addressPrefix,'EVENTfiles'))\n",
    "\n",
    "    for root, dirs, files in os.walk(os.path.join(addressPrefix,'SHMfiles'), topdown=False):\n",
    "       for name in files:\n",
    "           if '.shm' in name:\n",
    "               shimmerFiles.append([os.path.join(root,name),name[:-4]])\n",
    "    print(num_cores)\n",
    "    # shimmerFiles=shimmerFiles[0:10]\n",
    "    allData=Parallel(n_jobs=num_cores)(delayed(callerFunc)(i, dfMeal,dfTime) for i in tqdm(shimmerFiles))\n",
    "\n",
    "    headers=['f1','f2']\n",
    "    for counter in range(5,29):\n",
    "        headers.append(('f'+str(counter)))\n",
    "    headers.extend(['Name','EatingFlag'])\n",
    "\n",
    "    allData = [ item for elem in allData for item in elem]\n",
    "    dfAllData=pd.DataFrame(allData,columns=headers)\n",
    "    dfAllData.to_csv(os.path.join(addressPrefix,'AllDataParallel.csv'),index=False)\n",
    "    return dfAllData\n",
    "\n",
    "dfAllData=main(addressPrefix)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "36\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 354/354 [08:35<00:00,  1.46s/it]\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def modelVisualizer(testData,testLabels,modelBest):\n",
    "    slidingWindowPrediction = modelBest.predict(testData)\n",
    "    confMatrix=sklearn.metrics.confusion_matrix(testLabels,slidingWindowPrediction,normalize='all')\n",
    "    accuracy=sklearn.metrics.accuracy_score(testLabels,slidingWindowPrediction)\n",
    "    recall=sklearn.metrics.recall_score(testLabels,slidingWindowPrediction)\n",
    "    precision=sklearn.metrics.precision_score(testLabels,slidingWindowPrediction)\n",
    "\n",
    "    print('Testing on test dataset:')\n",
    "    print(confMatrix)\n",
    "    print('Accuracy',np.round(100*accuracy,0),'Recall',np.round(100*recall,0),'Precision',np.round(100*precision,0))\n",
    "\n",
    "    titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                      (\"Normalized confusion matrix\", 'true')]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(modelBest, testData, testLabels,\n",
    "                                     display_labels=['Non Eating','Eating'],\n",
    "                                     cmap=plt.cm.Blues,\n",
    "                                     normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def xgClassifier(dataList, labelList,randomSeed):\n",
    "    trainData, testData, trainLabels, testLabels = train_test_split(dataList, labelList, test_size=0.25,random_state=randomSeed)\n",
    "    trainData, valData, trainLabels, valLabels = train_test_split(trainData, trainLabels, test_size=0.33,random_state=randomSeed)\n",
    "    oversample = SMOTE()\n",
    "    trainData,trainLabels = oversample.fit_resample(trainData,trainLabels)\n",
    "    f1Best=0\n",
    "    for maxDepth in np.arange(2,7):\n",
    "        for estimator in np.arange(20,30,200):\n",
    "            clf = xgb.XGBClassifier(n_estimators=estimator,max_depth=maxDepth,objective = \"binary:logistic\",\n",
    "                                    eval_metric = \"logloss\",use_label_encoder =False,scale_pos_weight=1,random_state=randomSeed)\n",
    "            clf.fit(trainData, trainLabels)\n",
    "            slidingWindowPrediction = clf.predict(valData)\n",
    "            accuracy=sklearn.metrics.accuracy_score(valLabels,slidingWindowPrediction)\n",
    "            recall=sklearn.metrics.recall_score(valLabels,slidingWindowPrediction)\n",
    "            precision=sklearn.metrics.precision_score(valLabels,slidingWindowPrediction)\n",
    "            f1=sklearn.metrics.f1_score(valLabels,slidingWindowPrediction,average='weighted')\n",
    "\n",
    "            if f1>f1Best:\n",
    "                f1Best=f1\n",
    "                maxDepthBest=maxDepth\n",
    "                estimatorBest=estimator\n",
    "                accuracyBest=accuracy\n",
    "                modelBest=clf\n",
    "                recallBest=recall\n",
    "                precisionBest=precision\n",
    "    print(modelBest.feature_importances_)\n",
    "    modelVisualizer(testData,testLabels,modelBest)\n",
    "\n",
    "def randomForestClassifier(dataList,labelList,randomSeed):\n",
    "    trainData, testData, trainLabels, testLabels = train_test_split(dataList, labelList, test_size=0.25,random_state=randomSeed)\n",
    "    trainData, valData, trainLabels, valLabels = train_test_split(trainData, trainLabels, test_size=0.33,random_state=randomSeed)\n",
    "    oversample = SMOTE()\n",
    "    trainData,trainLabels = oversample.fit_resample(trainData,trainLabels)\n",
    "    f1Best=0\n",
    "    for treeNum in np.arange(10,100,10):\n",
    "        for maxDepth in np.arange(3,10):\n",
    "            clf=RandomForestClassifier(n_estimators=treeNum,criterion='entropy',random_state=0,max_depth=maxDepth)\n",
    "            clf.fit(trainData,trainLabels)\n",
    "            slidingWindowPrediction=clf.predict(valData)\n",
    "            accuracy=sklearn.metrics.accuracy_score(valLabels,slidingWindowPrediction)\n",
    "            recall=sklearn.metrics.recall_score(valLabels,slidingWindowPrediction)\n",
    "            precision=sklearn.metrics.precision_score(valLabels,slidingWindowPrediction)\n",
    "            f1=sklearn.metrics.f1_score(valLabels,slidingWindowPrediction,average='weighted')\n",
    "\n",
    "            if f1>f1Best:\n",
    "                f1Best=f1\n",
    "                maxDepthBest=maxDepth\n",
    "                treeNumBest=treeNum\n",
    "                accuracyBest=accuracy\n",
    "                modelBest=clf\n",
    "                recallBest=recall\n",
    "                precisionBest=precision\n",
    "\n",
    "    modelVisualizer(testData,testLabels,modelBest)\n",
    "\n",
    "data=pd.read_csv(os.path.join(addressPrefix,'AllDataParallel.csv'))\n",
    "allLabel=data['EatingFlag'].values\n",
    "allLabel=np.asarray(allLabel,dtype=int)\n",
    "\n",
    "data.drop(columns=['Name','EatingFlag'],inplace=True)\n",
    "allData=data.values\n",
    "allData=np.asarray(allData,dtype=float)\n",
    "for axis in range(allData.shape[1]):\n",
    "    allData[:,axis]-=np.mean(allData[:,axis])\n",
    "    allData[:,axis]/=np.std(allData[:,axis])\n",
    "\n",
    "xgClassifier(allData, allLabel,randomSeed=random.randrange(0,100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.20525041 0.03441921 0.0931453  0.05008665 0.01736302 0.02832308\n",
      " 0.04803561 0.06378374 0.01454042 0.0315385  0.02543925 0.01339464\n",
      " 0.01741818 0.01705613 0.02123758 0.02225391 0.02220359 0.017065\n",
      " 0.05264009 0.04521772 0.01800485 0.04056862 0.04329865 0.02797338\n",
      " 0.01300489 0.01673748]\n",
      "Testing on test dataset:\n",
      "[[0.72406918 0.21497407]\n",
      " [0.02081979 0.04013697]]\n",
      "Accuracy 76.0 Recall 66.0 Precision 16.0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d32c1ca2beb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mallData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mxgClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallLabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandomSeed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-d32c1ca2beb1>\u001b[0m in \u001b[0;36mxgClassifier\u001b[0;34m(dataList, labelList, randomSeed)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mprecisionBest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelBest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mmodelVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestLabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelBest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandomSeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-d32c1ca2beb1>\u001b[0m in \u001b[0;36mmodelVisualizer\u001b[0;34m(testData, testLabels, modelBest)\u001b[0m\n\u001b[1;32m     13\u001b[0m                       (\"Normalized confusion matrix\", 'true')]\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtitles_options\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         disp = plot_confusion_matrix(modelBest, testData, testLabels,\n\u001b[0m\u001b[1;32m     16\u001b[0m                                      \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Non Eating'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Eating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                      \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(estimator, X, y_true, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     cm = confusion_matrix(y_true, y_pred, sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    265\u001b[0m                           labels=labels, normalize=normalize)\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# convert yt, yp into index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;31m# intersect y_pred, y_true with labels, eliminate items not in labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# convert yt, yp into index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;31m# intersect y_pred, y_true with labels, eliminate items not in labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "from sklearn import preprocessing\n",
    "print(preprocessing.normalize([[0, 1,2,3,4], [5,6,7,8,9]]))\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.         0.18257419 0.36514837 0.54772256 0.73029674]\n",
      " [0.31311215 0.37573457 0.438357   0.50097943 0.56360186]]\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}