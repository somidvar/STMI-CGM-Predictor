{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pytz\n",
    "from datetime import datetime,timedelta,timezone\n",
    "from dateutil.tz import tzutc\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import pearsonr, mode,skew,kurtosis\n",
    "from scipy.signal import savgol_filter\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error,plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "addDataPrefix='/Users/sorush/My Drive/Documents/Educational/TAMU/Research/Trial/Data/11-5-21-11-15-21'\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix='/home/grads/s/sorush.omidvar/CGMDataset/Trial/Data/11-5-21-11-15-21'\n",
    "addUserInput=os.path.join(addDataPrefix,'User inputted')\n",
    "addHKCM=os.path.join(addDataPrefix,'hk+cm')\n",
    "addCGM=os.path.join(addDataPrefix,'CGM')\n",
    "addE4=os.path.join(addDataPrefix,'E4')\n",
    "\n",
    "exempts=['p2']\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({'figure.facecolor':'white'})\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemption... p2Meals.csv\n",
      "Reading ... p4Meals.csv\n",
      "Reading ... p3Meals.csv\n",
      "Reading ... p1Meals.csv\n",
      "reading is done\n",
      "Meal database is limited to the trial period\n",
      "Reading ... p3_fl.txt\n",
      "Exemption... p2_fl.txt\n",
      "Reading ... p1_fl.txt\n",
      "Reading ... p4_fl.txt\n",
      "reading is done\n",
      "CGM database is limited to the trial period\n",
      "Reading ... p4_cm_all_modified.csv\n",
      "File is read\n",
      "modified\n",
      "sorted\n",
      "Reading ... p1_cm_all_modified.csv\n",
      "File is read\n",
      "modified\n",
      "sorted\n",
      "Exemption... p2_cm_all_modified.csv\n",
      "Reading ... p3_cm_all_modified.csv\n",
      "File is read\n",
      "modified\n",
      "sorted\n",
      "Processing is done\n",
      "CM database is limited to the trial period\n",
      "File name does not comply with analyzed fields tags.csv\n",
      "File name does not comply with analyzed fields IBI.csv\n",
      "p4 TEMP\n",
      "Reading ... TEMP.csv\n",
      "p4 HR\n",
      "Reading ... HR.csv\n",
      "p4 BVP\n",
      "Reading ... BVP.csv\n",
      "p4 EDA\n",
      "Reading ... EDA.csv\n",
      "File name does not comply with analyzed fields ACC.csv\n",
      "File name does not comply with analyzed fields tags.csv\n",
      "File name does not comply with analyzed fields IBI.csv\n",
      "p4 TEMP\n",
      "Reading ... TEMP.csv\n",
      "p4 HR\n",
      "Reading ... HR.csv\n",
      "p4 BVP\n",
      "Reading ... BVP.csv\n",
      "p4 EDA\n",
      "Reading ... EDA.csv\n",
      "File name does not comply with analyzed fields ACC.csv\n",
      "File name does not comply with analyzed fields tags.csv\n",
      "File name does not comply with analyzed fields IBI.csv\n",
      "p4 TEMP\n",
      "Reading ... TEMP.csv\n",
      "p4 HR\n",
      "Reading ... HR.csv\n",
      "p4 BVP\n",
      "Reading ... BVP.csv\n",
      "p4 EDA\n",
      "Reading ... EDA.csv\n",
      "File name does not comply with analyzed fields ACC.csv\n",
      "File name does not comply with analyzed fields tags.csv\n",
      "File name does not comply with analyzed fields IBI.csv\n",
      "p4 TEMP\n",
      "Reading ... TEMP.csv\n",
      "p4 HR\n",
      "Reading ... HR.csv\n",
      "p4 BVP\n",
      "Reading ... BVP.csv\n",
      "p4 EDA\n",
      "Reading ... EDA.csv\n",
      "File name does not comply with analyzed fields ACC.csv\n",
      "File name does not comply with analyzed fields tags.csv\n",
      "File name does not comply with analyzed fields IBI.csv\n",
      "p4 TEMP\n",
      "Reading ... TEMP.csv\n",
      "p4 HR\n",
      "Reading ... HR.csv\n",
      "p4 BVP\n",
      "Reading ... BVP.csv\n",
      "p4 EDA\n",
      "Reading ... EDA.csv\n",
      "File name does not comply with analyzed fields ACC.csv\n",
      "File name does not comply with analyzed fields tags.csv\n",
      "File name does not comply with analyzed fields IBI.csv\n",
      "p4 TEMP\n",
      "Reading ... TEMP.csv\n",
      "p4 HR\n",
      "Reading ... HR.csv\n",
      "p4 BVP\n",
      "Reading ... BVP.csv\n",
      "p4 EDA\n",
      "Reading ... EDA.csv\n",
      "File name does not comply with analyzed fields ACC.csv\n",
      "File name does not comply with analyzed fields tags.csv\n",
      "File name does not comply with analyzed fields IBI.csv\n",
      "p4 TEMP\n",
      "Reading ... TEMP.csv\n",
      "p4 HR\n",
      "Reading ... HR.csv\n",
      "p4 BVP\n",
      "Reading ... BVP.csv\n",
      "p4 EDA\n",
      "Reading ... EDA.csv\n",
      "File name does not comply with analyzed fields ACC.csv\n",
      "File name does not comply with analyzed fields tags.csv\n",
      "File name does not comply with analyzed fields IBI.csv\n",
      "p4 TEMP\n",
      "Reading ... TEMP.csv\n",
      "p4 HR\n",
      "Reading ... HR.csv\n",
      "p4 BVP\n",
      "Reading ... BVP.csv\n",
      "p4 EDA\n",
      "Reading ... EDA.csv\n",
      "File name does not comply with analyzed fields ACC.csv\n",
      "File name does not comply with analyzed fields tags.csv\n",
      "File name does not comply with analyzed fields IBI.csv\n",
      "p3 TEMP\n",
      "Reading ... TEMP.csv\n",
      "p3 HR\n",
      "Reading ... HR.csv\n",
      "p3 BVP\n",
      "Reading ... BVP.csv\n",
      "p3 EDA\n",
      "Reading ... EDA.csv\n",
      "File name does not comply with analyzed fields ACC.csv\n",
      "File name does not comply with analyzed fields tags.csv\n",
      "File name does not comply with analyzed fields IBI.csv\n",
      "p3 TEMP\n",
      "Reading ... TEMP.csv\n"
     ]
    }
   ],
   "source": [
    "START_OF_TRIAL = datetime.strptime('11 06 2021-02:00:00', '%m %d %Y-%H:%M:%S')#to handle the daylight saving issue in apple watches\n",
    "END_OF_TRIAL = datetime.strptime('11 15 2021-00:00:00', '%m %d %Y-%H:%M:%S')  \n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix,'All_meals.pkl')):\n",
    "    os.remove(os.path.join(addDataPrefix,'All_meals.pkl'))\n",
    "os.chdir(addUserInput)\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_meals.pkl')):    \n",
    "    df=[]\n",
    "    for root, dirs, files in os.walk(addUserInput):\n",
    "        for file in files:\n",
    "            if '.csv' in file.lower():\n",
    "                if 'meals' in file.lower():\n",
    "                    participantName=file[:file.find('Meals')]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\",file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\",file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    dfTemp.insert(0,'Participant',participantName)\n",
    "                    dfTemp.rename(columns={'startTime':'StartTime'}, inplace=True)\n",
    "                    dfTemp['StartTime']=pd.to_datetime(dfTemp['StartTime'])\n",
    "                    dfTemp['FinishTime']=pd.to_datetime(dfTemp['FinishTime'])\n",
    "\n",
    "                    dfTemp['StartTime']-=pd.DateOffset(hours=5)#fixing the time zone issue\n",
    "                    dfTemp['FinishTime']-=pd.DateOffset(hours=5)#fixing the time zone issue            \n",
    "                    dfTemp.sort_values([\"Participant\",'StartTime'],ascending = (True, True),inplace=True)\n",
    "                    if len(dfTemp.columns)!=10:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    if len(df)!=0:\n",
    "                        frames=[dfTemp,df]\n",
    "                        df=pd.concat(frames)\n",
    "                    else:\n",
    "                        df=dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfMeal=df    \n",
    "    dfMeal=dfMeal[dfMeal['StartTime']>=START_OF_TRIAL]\n",
    "    dfMeal=dfMeal[dfMeal['FinishTime']<END_OF_TRIAL]\n",
    "    print(\"Meal database is limited to the trial period\")\n",
    "    dfMeal.to_pickle(os.path.join(addDataPrefix,'All_meals.pkl')) \n",
    "else:\n",
    "    dfMeal=pd.read_pickle(os.path.join(addDataPrefix,'All_meals.pkl')) \n",
    "\n",
    "def pdInterpolation(dfTemp):\n",
    "    index=dfTemp['Time']\n",
    "    seriesParticipant = pd.Series(dfTemp['Abbot'].to_list(), index=index)\n",
    "    seriesParticipant=seriesParticipant.resample('1T').asfreq()\n",
    "    seriesParticipant.interpolate(method='polynomial',order=3,inplace=True)\n",
    "    tempTime=seriesParticipant.index\n",
    "    tempVal=seriesParticipant.values\n",
    "    dfTemp=pd.DataFrame(zip(tempTime,tempVal),columns=['Time','Abbot'])\n",
    "    return dfTemp\n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix,'All_cgm.pkl')):\n",
    "    os.remove(os.path.join(addDataPrefix,'All_cgm.pkl'))\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_cgm.pkl')):\n",
    "    os.chdir(addCGM)\n",
    "    dfCGM=[]\n",
    "    for root, dirs, files in os.walk(addCGM):\n",
    "        for file in files:\n",
    "            if '.txt' in file.lower():\n",
    "                if '_fl' in file.lower():\n",
    "                    participantName=file[:file.find('_fl')]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\",file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\",file)\n",
    "                    dfTemp = pd.read_csv(file,sep=\"\\t\",skiprows=1)\n",
    "                    if len(dfTemp.columns)!=4:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break               \n",
    "                    dfTemp.columns.values[0] = \"ID\"\n",
    "                    dfTemp.columns.values[1] = \"Time\"\n",
    "                    dfTemp.columns.values[2] = \"Record\"\n",
    "                    dfTemp.columns.values[3] = \"Abbot\"\n",
    "                    dfTemp.drop(columns=[\"ID\",'Record'],inplace=True)                \n",
    "                    dfTemp['Time']=pd.to_datetime(dfTemp['Time'])\n",
    "                    dfTemp['Abbot']=pd.to_numeric(dfTemp['Abbot'])\n",
    "                    dfTemp.sort_values([\"Time\"],ascending = (True),inplace=True)\n",
    "                    dfTemp=pdInterpolation(dfTemp)\n",
    "                    dfTemp.insert(0,'Participant',participantName)\n",
    "                    if len(dfTemp.columns)!=3:\n",
    "                        print(\"MAYDAY. Error in processing csv\")\n",
    "                        break                    \n",
    "                    if len(dfCGM)!=0:\n",
    "                        frames=[dfTemp,dfCGM]\n",
    "                        dfCGM=pd.concat(frames)\n",
    "                    else:\n",
    "                        dfCGM=dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfCGM=dfCGM[dfCGM['Time']>=START_OF_TRIAL]\n",
    "    dfCGM=dfCGM[dfCGM['Time']<END_OF_TRIAL]\n",
    "    print(\"CGM database is limited to the trial period\")\n",
    "    dfCGM.to_pickle(os.path.join(addDataPrefix,'All_cgm.pkl')) \n",
    "else:\n",
    "    dfCGM=pd.read_pickle(os.path.join(addDataPrefix,'All_cgm.pkl'))\n",
    "\n",
    "\n",
    "  \n",
    "if os.path.exists(os.path.join(addDataPrefix,'All_cm.pkl')):\n",
    "    os.remove(os.path.join(addDataPrefix,'All_cm.pkl'))\n",
    "os.chdir(addHKCM)\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_cm.pkl')):\n",
    "    df=[]\n",
    "    for root, dirs, files in os.walk(addHKCM):\n",
    "        for file in files:\n",
    "            if '.csv' in file.lower():\n",
    "                if 'cm' in file.lower() and 'modified' in file.lower():\n",
    "                    participantName=file[:file.find('_cm')]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\",file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\",file)\n",
    "                    dfTemp=pd.read_csv(file)\n",
    "                    print(\"File is read\")\n",
    "                    dfTemp['Time']=pd.to_datetime(dfTemp['Time'])\n",
    "                    dfTemp.insert(0,'Participant',participantName)\n",
    "                    dfTemp.insert(len(dfTemp.columns),'|Ax|+|Ay|+|Az|',dfTemp['Ax'].abs()+dfTemp['Ay'].abs()+dfTemp['Az'].abs()+0.001)#this is to avoid 0 later on for feature calculation\n",
    "                    dfTemp.insert(len(dfTemp.columns),'|Yaw|+|Roll|+|Pitch|',dfTemp['Yaw'].abs()+dfTemp['Roll'].abs()+dfTemp['Pitch'].abs())\n",
    "                    dfTemp.insert(len(dfTemp.columns),'RotationalToLinear',dfTemp['|Yaw|+|Roll|+|Pitch|']/dfTemp['|Ax|+|Ay|+|Az|'])\n",
    "                    print(\"modified\")\n",
    "                    dfTemp.sort_values(['Time'],ascending = (True),inplace=True)\n",
    "                    print(\"sorted\")\n",
    "                    if len(dfTemp.columns)!=14:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        print(dfTemp.columns)\n",
    "                        break\n",
    "                    if len(df)!=0:\n",
    "                        frames=[dfTemp,df]\n",
    "                        df=pd.concat(frames)\n",
    "                    else:\n",
    "                        df=dfTemp\n",
    "    dfCM=df\n",
    "    print(\"Processing is done\")\n",
    "    dfCM=dfCM[dfCM['Time']>=START_OF_TRIAL]\n",
    "    dfCM=dfCM[dfCM['Time']<END_OF_TRIAL]\n",
    "    print(\"CM database is limited to the trial period\")\n",
    "    dfCM.to_pickle(os.path.join(addDataPrefix,'All_cm.pkl')) \n",
    "else:\n",
    "    dfCM = pd.read_pickle(os.path.join(addDataPrefix,'All_cm.pkl'))\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix,'All_E4.pkl')):\n",
    "    os.remove(os.path.join(addDataPrefix,'All_E4.pkl'))\n",
    "os.chdir(addE4)\n",
    "# fields=['ACC','BVP','EDA','HR','IBI','TEMP']\n",
    "fields=['BVP','EDA','HR','TEMP']\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_E4.pkl')):    \n",
    "    dfE4=[]\n",
    "    for root, dirs, files in os.walk(addE4):\n",
    "        for file in files:\n",
    "            if '.csv' in file.lower():\n",
    "                participantName=root[root.find('/E4/')+4:]\n",
    "                participantName=participantName[:participantName.find('/')]\n",
    "                field=file[:file.find('.csv')]\n",
    "                if field not in fields:\n",
    "                    print(\"File name does not comply with analyzed fields\",file)\n",
    "                    continue\n",
    "                print(participantName,field)\n",
    "                if participantName in exempts:\n",
    "                    print(\"Exemption...\",file)\n",
    "                    continue\n",
    "                print(\"Reading ...\",file)\n",
    "                os.chdir(root)\n",
    "                dfTemp = pd.read_csv(file,header=None)\n",
    "                timeStep=-1\n",
    "                skipRow=-1\n",
    "                # if field=='ACC':\n",
    "                #     assert len(dfTemp.columns)==3\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     timeStep=1/dfTemp.iloc[1,0]\n",
    "                #     dfTemp.drop([0,1],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Data1',1:'Data2',2:'Data3'}, inplace=True)#x,y,z for data1,data2,data3\n",
    "                #     timeTemp=[]\n",
    "                #     for counter in range(len(dfTemp)):\n",
    "                #         timeTemp.append(timeBase+counter*timeStep)\n",
    "                #     dfTemp.insert(0,'Time',timeTemp)\n",
    "                #     dfTemp.insert(0,'Field',\"Acceleration\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                if field=='BVP':\n",
    "                    assert len(dfTemp.columns)==1\n",
    "                    timeBase=dfTemp.iloc[0,0]\n",
    "                    timeStep=1/dfTemp.iloc[1,0]\n",
    "                    dfTemp.drop([0,1],inplace=True)\n",
    "                    dfTemp.rename(columns={0:'Data1'}, inplace=True)\n",
    "                    dfTemp[\"Data2\"]=\"\"\n",
    "                    dfTemp[\"Data3\"]=\"\"\n",
    "                    timeTemp=[]\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase+counter*timeStep)\n",
    "                    dfTemp.insert(0,'Time',timeTemp)\n",
    "                    dfTemp.insert(0,'Field',\"BVP\")\n",
    "                    dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                elif field=='HR':\n",
    "                    assert len(dfTemp.columns)==1\n",
    "                    timeBase=dfTemp.iloc[0,0]\n",
    "                    timeStep=1/dfTemp.iloc[1,0]\n",
    "                    dfTemp.drop([0,1],inplace=True)\n",
    "                    dfTemp.rename(columns={0:'Data1'}, inplace=True)\n",
    "                    dfTemp[\"Data2\"]=\"\"\n",
    "                    dfTemp[\"Data3\"]=\"\"\n",
    "                    timeTemp=[]\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase+counter*timeStep)\n",
    "                    dfTemp.insert(0,'Time',timeTemp)\n",
    "                    dfTemp.insert(0,'Field',\"HR\")\n",
    "                    dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')                \n",
    "                elif field=='EDA':\n",
    "                    assert len(dfTemp.columns)==1\n",
    "                    timeBase=dfTemp.iloc[0,0]\n",
    "                    timeStep=1/dfTemp.iloc[1,0]\n",
    "                    dfTemp.drop([0,1],inplace=True)\n",
    "                    dfTemp.rename(columns={0:'Data1'}, inplace=True)\n",
    "                    dfTemp[\"Data2\"]=\"\"\n",
    "                    dfTemp[\"Data3\"]=\"\"                    \n",
    "                    timeTemp=[]\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase+counter*timeStep)\n",
    "                    dfTemp.insert(0,'Time',timeTemp)\n",
    "                    dfTemp.insert(0,'Field',\"EDA\")\n",
    "                    dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                # elif field=='IBI':\n",
    "                #     assert len(dfTemp.columns)==2\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     dfTemp.drop([0],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Time',1:'Data1'}, inplace=True)\n",
    "                #     dfTemp[\"Data2\"]=\"\"\n",
    "                #     dfTemp[\"Data3\"]=\"\"\n",
    "                #     timeTemp=[]\n",
    "                #     dfTemp['Time']+=timeBase\n",
    "                #     dfTemp.insert(0,'Field',\"IBI\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                elif field=='TEMP':\n",
    "                    assert len(dfTemp.columns)==1\n",
    "                    timeBase=dfTemp.iloc[0,0]\n",
    "                    timeStep=1/dfTemp.iloc[1,0]\n",
    "                    dfTemp.drop([0,1],inplace=True)\n",
    "                    dfTemp.rename(columns={0:'Data1'}, inplace=True)\n",
    "                    dfTemp[\"Data2\"]=\"\"\n",
    "                    dfTemp[\"Data3\"]=\"\"                    \n",
    "                    timeTemp=[]\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase+counter*timeStep)\n",
    "                    dfTemp.insert(0,'Time',timeTemp)\n",
    "                    dfTemp.insert(0,'Field',\"Temperature\")\n",
    "                    dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')             \n",
    "                dfTemp.insert(0,'Participant',participantName)\n",
    "\n",
    "                dfTemp['Time']-=pd.DateOffset(hours=6)#Empatica records in GMT and also during the trial we had daylight saving\n",
    "                dfTemp.sort_values([\"Participant\",'Field',\"Time\"],ascending = (True,True, True),inplace=True)\n",
    "                if len(dfTemp.columns)!=6:\n",
    "                    print(\"MAYDAY. Error in reading csv\")\n",
    "                    break\n",
    "                if len(dfE4)!=0:\n",
    "                    frames=[dfTemp,dfE4]\n",
    "                    dfE4=pd.concat(frames)\n",
    "                else:\n",
    "                    dfE4=dfTemp\n",
    "                \n",
    "    print(\"reading is done\")  \n",
    "    dfE4=dfE4[dfE4['Time']>=START_OF_TRIAL]\n",
    "    dfE4=dfE4[dfE4['Time']<END_OF_TRIAL]\n",
    "    print(\"E4 database is limited to the trial period\")\n",
    "    dfE4.to_pickle(os.path.join(addDataPrefix,'All_E4.pkl')) \n",
    "else:\n",
    "    dfE4=pd.read_pickle(os.path.join(addDataPrefix,'All_E4.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant  p3  is started\n",
      "CM size for participant 7567184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:19<00:00,  9.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant  p1  is started\n",
      "CM size for participant 7643165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:19<00:00,  9.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant  p4  is started\n",
      "CM size for participant 7191513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:01<01:01, 61.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-746a1f43caec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mtempListCM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotionCalculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfTempCM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mdfTempE4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdfParticipantE4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfParticipantE4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0minnerWindowStart\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdfParticipantE4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0minnerWindowEnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfTempE4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mMINIMUM_POINT_CM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mtempListE4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Nan'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Nan'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Nan'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Nan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__lt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__lt__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__lt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__le__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5500\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5501\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5503\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    268\u001b[0m     ):\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# Call the method on lvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__lt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__lt__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__lt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__le__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0mother_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# GH#37462 comparison on i8 values is almost 2x faster than M8/m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0mo_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def e4Reporter(df):\n",
    "    topics=['BVP','EDA','HR','Temperature']\n",
    "    report=[]\n",
    "    for topic in topics:\n",
    "        dfTemp=df[df['Field']==topic]\n",
    "        val=dfTemp['Data1'].mean()\n",
    "        report.append(val)\n",
    "    return report\n",
    "\n",
    "def motionCalculator(df):\n",
    "    f1=df['RotationalToLinear'].mean()\n",
    "    f2=df['|Ax|+|Ay|+|Az|'].mean()\n",
    "    f5=df['|Yaw|+|Roll|+|Pitch|'].mean()\n",
    "    return [f1,f2,f5]\n",
    "\n",
    "def featureExtractor(dataList):\n",
    "    dataList=np.asarray(dataList).astype(float)\n",
    "    result=[]\n",
    "    dataDim=dataList.ndim\n",
    "    if dataDim>1:\n",
    "        for counter in range(dataList.shape[1]):\n",
    "            meanVal=np.nanmean(dataList[:,counter],axis=0)\n",
    "            stdVal=np.nanstd(dataList[:,counter],axis=0)\n",
    "            minVal=np.nanmin(dataList[:,counter],axis=0)\n",
    "            maxVal=np.nanmax(dataList[:,counter],axis=0)\n",
    "            rangeVal=maxVal-minVal\n",
    "            skewnessVal=skew(dataList[:,counter],nan_policy='omit',axis=0)\n",
    "            kurtosisVal=kurtosis(dataList[:,counter],nan_policy='omit',axis=0)\n",
    "            result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal])\n",
    "    else:\n",
    "        meanVal=np.nanmean(dataList)\n",
    "        stdVal=np.nanstd(dataList)\n",
    "        minVal=np.nanmin(dataList)\n",
    "        maxVal=np.nanmax(dataList)\n",
    "        rangeVal=maxVal-minVal\n",
    "        skewnessVal=skew(dataList,nan_policy='omit')\n",
    "        kurtosisVal=kurtosis(dataList,nan_policy='omit')\n",
    "        result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal])        \n",
    "    return result\n",
    "\n",
    "MINIMUM_POINT_CM=100\n",
    "OUTTER_WINDOW_LENGTH=timedelta(minutes=180)\n",
    "OUTTER_WINDOW_STEP=timedelta(minutes=90)\n",
    "EATING_PORTION=timedelta(minutes=90)\n",
    "INNER_WINDOW_LENGTH=timedelta(minutes=1)\n",
    "\n",
    "participants=dfCM['Participant'].to_list()\n",
    "participants=list(set(participants))\n",
    "participantDataList=[]\n",
    "skippedWindows=0\n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix,'Features.pkl')):\n",
    "    os.remove(os.path.join(addDataPrefix,'Features.pkl'))\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'Features.pkl')):\n",
    "    for participant in participants:\n",
    "        outterWindowStart=START_OF_TRIAL\n",
    "        outterWindowEnd=outterWindowStart+OUTTER_WINDOW_LENGTH        \n",
    "        print(\"Participant \",participant,\" is started\")\n",
    "        dfParticipantCM=dfCM[dfCM['Participant']==participant]\n",
    "        dfParticipantMeal=dfMeal[dfMeal['Participant']==participant]\n",
    "        dfParticipantCGM=dfCGM[dfCGM['Participant']==participant]\n",
    "        dfParticipantE4=dfE4[dfE4['Participant']==participant]\n",
    "        print(\"CM size for participant\",len(dfParticipantCM))\n",
    "        innerWindowStart=outterWindowStart\n",
    "        innerWindowEnd=innerWindowStart+INNER_WINDOW_LENGTH        \n",
    "        for i in tqdm(range(0,int(((END_OF_TRIAL-START_OF_TRIAL).total_seconds())/(OUTTER_WINDOW_LENGTH.total_seconds())),1)):\n",
    "            dfTempMeal=dfParticipantMeal[(dfParticipantMeal['StartTime']>=outterWindowStart) & (dfParticipantMeal['StartTime']<=outterWindowStart+EATING_PORTION)]\n",
    "            tempList=[]\n",
    "            tempListCM=[]\n",
    "            tempListE4=[]\n",
    "            tempListCGM=[]\n",
    "            tempListInfo=[outterWindowStart,outterWindowEnd,participant[1:]]\n",
    "            skippedFlag=True\n",
    "            for j in range(0,int((OUTTER_WINDOW_LENGTH.total_seconds())/(INNER_WINDOW_LENGTH.total_seconds())),1):\n",
    "                dfTempCM=dfParticipantCM[(dfParticipantCM['Time']>=innerWindowStart) & (dfParticipantCM['Time']<innerWindowEnd)]\n",
    "                if(len(dfTempCM)<MINIMUM_POINT_CM):\n",
    "                    tempListCM.append(['Nan','Nan','Nan'])\n",
    "                else:\n",
    "                    tempListCM.append(motionCalculator(dfTempCM))\n",
    "\n",
    "                dfTempE4=dfParticipantE4[(dfParticipantE4['Time']>=innerWindowStart) & (dfParticipantE4['Time']<innerWindowEnd)]\n",
    "                if(len(dfTempE4)<MINIMUM_POINT_CM):\n",
    "                    tempListE4.append(['Nan','Nan','Nan','Nan'])\n",
    "                else:\n",
    "                    tempListE4.append(e4Reporter(dfTempE4))\n",
    "                \n",
    "                if(len(dfTempCM)>MINIMUM_POINT_CM and len(dfTempE4)>MINIMUM_POINT_CM):\n",
    "                    skippedFlag=False\n",
    "                innerWindowStart+=INNER_WINDOW_LENGTH\n",
    "                innerWindowEnd+=INNER_WINDOW_LENGTH\n",
    "            if len(dfTempMeal)>0:\n",
    "                mealFlag=1\n",
    "            else:\n",
    "                mealFlag=0\n",
    "                \n",
    "            carbs=dfTempMeal['Carbs'].sum()\n",
    "            protein=dfTempMeal['Protein'].sum()\n",
    "            fat=dfTempMeal['Fat'].sum()\n",
    "\n",
    "            if skippedFlag:\n",
    "                skippedWindows+=1\n",
    "            else:\n",
    "                assert len(tempListCM)==int((OUTTER_WINDOW_LENGTH.total_seconds())/(INNER_WINDOW_LENGTH.total_seconds()))\n",
    "                tempListCM=featureExtractor(tempListCM)\n",
    "                tempList.extend(tempListCM) #7*3=21\n",
    "\n",
    "                assert len(tempListE4)==int((OUTTER_WINDOW_LENGTH.total_seconds())/(INNER_WINDOW_LENGTH.total_seconds()))\n",
    "                tempListE4=featureExtractor(tempListE4)\n",
    "                tempList.extend(tempListE4) #7*4=28\n",
    "\n",
    "                dfTempCGM=dfParticipantCGM[(dfParticipantCGM['Time']>=outterWindowStart) & (dfParticipantCGM['Time']<outterWindowEnd)]\n",
    "                tempListCGM=dfTempCGM['Abbot'].to_list()\n",
    "                tempListCGM=featureExtractor(tempListCGM)\n",
    "                tempList.extend(tempListCGM) #7\n",
    "\n",
    "                tempList.extend(tempListInfo) #3\n",
    "                tempList.extend([mealFlag]) #1\n",
    "                assert len(tempList)==7*3+7*4+7+3+1\n",
    "                participantDataList.append(tempList)\n",
    "            outterWindowStart+=OUTTER_WINDOW_STEP\n",
    "            outterWindowEnd+=OUTTER_WINDOW_STEP\n",
    "    participantDataArray=np.asarray(participantDataList)\n",
    "    columnTopics=['F1','F2','F5','BVP','EDA','HR','Temperature','CGM']\n",
    "    columnStats=['Range','Mean','Std','Min','Max','Skew','Kurtosis']\n",
    "    columns=[]\n",
    "    for topic in columnTopics:\n",
    "        for stat in columnStats:\n",
    "            columns.append(topic+stat)\n",
    "    columns.extend(['Start','End','Participant','MealLabel'])\n",
    "    dfFeatures=pd.DataFrame(participantDataArray,columns=columns)\n",
    "    dfFeatures.to_pickle(os.path.join(addDataPrefix,'Features.pkl')) \n",
    "else:\n",
    "    dfFeatures = pd.read_pickle(os.path.join(addDataPrefix,'Features.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Combination: ['CGM']\n",
      "['4']\n",
      "----------------------\n",
      "Combination: ['CGM', 'F1', 'F2', 'F5']\n",
      "['4']\n",
      "----------------------\n",
      "Combination: ['CGM', 'BVP', 'EDA', 'HR', 'Temperature']\n",
      "['4']\n",
      "----------------------\n",
      "Combination: ['CGM', 'BVP', 'EDA', 'HR', 'Temperature', 'F1', 'F2', 'F3']\n",
      "['4']\n"
     ]
    }
   ],
   "source": [
    "def STMI_XGBoost(xTrain,xVal,xTest,yTrain,yVal,yTest):\n",
    "    f1ScoreBest=-1\n",
    "    for maxDepth in tqdm(np.arange(2,8,1)):\n",
    "        for estimator in np.arange(50,200,50):\n",
    "            for posWeight in np.arange(1,50,5):\n",
    "                clf = xgb.XGBClassifier(scale_pos_weight = posWeight, n_jobs=18,n_estimators=estimator,max_depth=maxDepth, objective = \"binary:logistic\", eval_metric = \"error\")\n",
    "                clf.fit(xTrain,yTrain)\n",
    "                predictionsVal = clf.predict(xVal)\n",
    "                # predictionsVal = clf.predict_proba(xVal)\n",
    "                # predictionsVal=predictionsVal[:,1]\n",
    "                # predictionsVal[predictionsVal>=threshold]=1\n",
    "                # predictionsVal[predictionsVal<threshold]=0\n",
    "                \n",
    "                confMatrix=sklearn.metrics.confusion_matrix(yVal,predictionsVal)\n",
    "                accuracy=sklearn.metrics.accuracy_score(yVal,predictionsVal)\n",
    "                recall=sklearn.metrics.recall_score(yVal,predictionsVal)\n",
    "                precision=sklearn.metrics.precision_score(yVal,predictionsVal)\n",
    "                f1Score=sklearn.metrics.f1_score(yVal,predictionsVal)\n",
    "\n",
    "                if f1Score>f1ScoreBest:\n",
    "                    confMatrixBest=confMatrix\n",
    "                    accuracyBest=accuracy\n",
    "                    modelBest=clf\n",
    "                    recallBest=recall\n",
    "                    precisionBest=precision\n",
    "                    f1ScoreBest=f1Score\n",
    "    # print(\"***********Val:\")\n",
    "    # print(confMatrixBest)\n",
    "    # print(\"Accuracy:\",np.round(100*accuracyBest,0),\"Recall:\",np.round(100*recallBest,0),\"Precision:\",np.round(100*precisionBest,0))\n",
    "    # print(\"***********Test:\")\n",
    "    predictionsTest=modelBest.predict(xTest)\n",
    "    # predictionsTest=modelBest.predict_proba(xTest)\n",
    "    # predictionsTest=predictionsTest[:,1]\n",
    "    # predictionsTest[predictionsTest>=thresholdBest]=1\n",
    "    # predictionsTest[predictionsTest<thresholdBest]=0    \n",
    "    \n",
    "    confMatrix=sklearn.metrics.confusion_matrix(yTest,predictionsTest)\n",
    "    accuracy=sklearn.metrics.accuracy_score(yTest,predictionsTest)\n",
    "    recall=sklearn.metrics.recall_score(yTest,predictionsTest)\n",
    "    precision=sklearn.metrics.precision_score(yTest,predictionsTest)\n",
    "    \n",
    "    print(confMatrix)\n",
    "    print(\"Accuracy:\",np.round(100*accuracy,0),\"Recall:\",np.round(100*recall,0),\"Precision:\",np.round(100*precision,0))\n",
    "    plot_confusion_matrix(modelBest, xTest, yTest,cmap='bone') \n",
    "\n",
    "def dataBalancer(xTrain,xVal,yTrain,yVal):\n",
    "    oversample = SMOTE()\n",
    "    xVal, yVal = oversample.fit_resample(xVal, yVal)\n",
    "    xTrain, yTrain = oversample.fit_resample(xTrain, yTrain)\n",
    "\n",
    "    return xTrain,xVal,yTrain,yVal\n",
    "\n",
    "def testTrainSplitFunc(data,randomSeed,normalFlag):\n",
    "    participants=data[:,data.shape[1]-2]\n",
    "    participants=list(set(participants))\n",
    "    print(participants)\n",
    "    for participant in participants:\n",
    "        if participant !=3:\n",
    "            continue\n",
    "        \n",
    "        print(\"Participant:\",participant)\n",
    "        indxList=[]\n",
    "        for counter in range(data.shape[0]):\n",
    "            if(data[counter,data.shape[1]-2]==participant):\n",
    "                indxList.append(counter)\n",
    "        dataParticipant=data[indxList,:]\n",
    "\n",
    "        windowStarts=dataParticipant[:,dataParticipant.shape[1]-4]\n",
    "        windowEnds=dataParticipant[:,dataParticipant.shape[1]-3]\n",
    "        \n",
    "        dataX=dataParticipant[:,0:dataParticipant.shape[1]-4]\n",
    "        dataY=dataParticipant[:,dataParticipant.shape[1]-1]\n",
    "        dataY=dataY.astype(float)\n",
    "        dataX=dataX.astype(float)\n",
    "        if(normalFlag):\n",
    "            dataX=dataX-dataX.mean(axis=0)\n",
    "            dataX/=dataX.std(axis=0)\n",
    "        \n",
    "        stratidiedSampling = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=randomSeed)\n",
    "        for trainIndex, testIndex in stratidiedSampling.split(dataX, dataY):\n",
    "            xTrain,xTest=dataX[trainIndex],dataX[testIndex]\n",
    "            yTrain,yTest=dataY[trainIndex],dataY[testIndex]\n",
    "\n",
    "        stratidiedSampling = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=randomSeed)\n",
    "        for trainIndex, valIndex in stratidiedSampling.split(xTrain, yTrain):\n",
    "            xTrain,xVal=dataX[trainIndex],dataX[valIndex]\n",
    "            yTrain,yVal=dataY[trainIndex],dataY[valIndex]\n",
    "        print(np.sum(yTrain),np.sum(yVal),np.sum(yTest))\n",
    "        # xTrain,xVal,yTrain,yVal=dataBalancer(xTrain,xVal,yTrain,yVal)\n",
    "        STMI_XGBoost(xTrain,xVal,xTest,yTrain,yVal,yTest)\n",
    "\n",
    "combinations=[['CGM'],['CGM','F1','F2','F5'],['CGM','BVP','EDA','HR','Temperature'],['CGM','BVP','EDA','HR','Temperature','F1','F2','F3']]\n",
    "columns=dfFeatures.columns\n",
    "for combination in combinations:\n",
    "    columnList=['Start','End','Participant','MealLabel']\n",
    "    for topic in combination:\n",
    "        for column in columns:\n",
    "            if topic in column:\n",
    "                columnList.append(column)\n",
    "                \n",
    "    dfCombination = dfFeatures[dfFeatures.columns.intersection(columnList)]\n",
    "    participantDataArray=dfCombination.to_numpy()\n",
    "    randomSeed=random.randrange(50)\n",
    "    print(\"----------------------\")\n",
    "    print(\"Combination:\",combination)\n",
    "    NORMALIZED_FLAG=False\n",
    "    testTrainSplitFunc(participantDataArray,randomSeed,NORMALIZED_FLAG)\n",
    "\n",
    "# print(\"**********************************\")\n",
    "# print(\"**********************************\")\n",
    "# print(\"With NORMALIZATION\")\n",
    "# NORMALIZED_FLAG=True\n",
    "# testTrainSplitFunc(participantDataArray,randomSeed,NORMALIZED_FLAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[687.2829089137258 168.68650370397307 98.83966310830473 ...\n",
      "  Timestamp('2021-11-06 05:00:00') '4' 0]\n",
      " [482.6004579160706 140.61388523537758 75.80792819238005 ...\n",
      "  Timestamp('2021-11-06 08:00:00') '4' 0]\n",
      " [71.42178362865398 83.85014024322537 16.676863826240215 ...\n",
      "  Timestamp('2021-11-06 09:30:00') '4' 0]\n",
      " ...\n",
      " [581.6409072966463 115.22322109314646 93.15313306545019 ...\n",
      "  Timestamp('2021-11-10 11:00:00') '4' 0]\n",
      " [443.7409960708389 108.21050720669687 73.26694998392072 ...\n",
      "  Timestamp('2021-11-10 12:30:00') '4' 0]\n",
      " [592.6413400297446 161.40631496902296 102.23773446400212 ...\n",
      "  Timestamp('2021-11-10 14:00:00') '4' 0]]\n"
     ]
    }
   ],
   "source": [
    "print(participantDataArray)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65e249be015da37cfe4cfdd1da028fe4cb475c26be679b9e3e34696278a17c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
