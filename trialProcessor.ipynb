{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pytz\n",
    "from datetime import datetime,timedelta,timezone\n",
    "from dateutil.tz import tzutc\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import pearsonr, mode\n",
    "from scipy.signal import savgol_filter\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error,plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "addDataPrefix='/Users/sorush/My Drive/Documents/Educational/TAMU/Research/Trial/Data/11-5-21-11-15-21'\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix='/home/grads/s/sorush.omidvar/CGMDataset/Trial/Data/11-5-21-11-15-21'\n",
    "addUserInput=os.path.join(addDataPrefix,'User inputted')\n",
    "addHKCM=os.path.join(addDataPrefix,'hk+cm')\n",
    "addCGM=os.path.join(addDataPrefix,'CGM')\n",
    "addE4=os.path.join(addDataPrefix,'E4')\n",
    "\n",
    "exempts=['p2']\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({'figure.facecolor':'white'})\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(os.path.join(addDataPrefix,'All_meals.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,'All_meals.pkl'))\n",
    "os.chdir(addUserInput)\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_meals.pkl')):    \n",
    "    df=[]\n",
    "    for root, dirs, files in os.walk(addUserInput):\n",
    "        for file in files:\n",
    "            if '.csv' in file.lower():\n",
    "                if 'meals' in file.lower():\n",
    "                    participantName=file[:file.find('Meals')]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\",file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\",file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    dfTemp.insert(0,'Participant',participantName)\n",
    "                    dfTemp.rename(columns={'startTime':'StartTime'}, inplace=True)\n",
    "                    dfTemp['StartTime']=pd.to_datetime(dfTemp['StartTime'])\n",
    "                    dfTemp['FinishTime']=pd.to_datetime(dfTemp['FinishTime'])\n",
    "\n",
    "                    dfTemp['StartTime']-=pd.DateOffset(hours=5)#fixing the time zone issue\n",
    "                    dfTemp['FinishTime']-=pd.DateOffset(hours=5)#fixing the time zone issue            \n",
    "                    dfTemp.sort_values([\"Participant\",'StartTime'],ascending = (True, True),inplace=True)\n",
    "                    if len(dfTemp.columns)!=10:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    if len(df)!=0:\n",
    "                        frames=[dfTemp,df]\n",
    "                        df=pd.concat(frames)\n",
    "                    else:\n",
    "                        df=dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfMeal=df    \n",
    "    dfMeal.to_pickle(os.path.join(addDataPrefix,'All_meals.pkl')) \n",
    "else:\n",
    "    dfMeal=pd.read_pickle(os.path.join(addDataPrefix,'All_meals.pkl'))\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addDataPrefix,'All_cgm.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,'All_cgm.pkl'))\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_cgm.pkl')):\n",
    "    os.chdir(addCGM)\n",
    "    df=[]\n",
    "    for root, dirs, files in os.walk(addCGM):\n",
    "        for file in files:\n",
    "            if '.csv' in file.lower():\n",
    "                if 'processed' in file.lower():\n",
    "                    participantName=file[:file.find('Processed')]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\",file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\",file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    dfTemp.insert(0,'Participant',participantName)\n",
    "                    dfTemp['Time']=pd.to_datetime(dfTemp['Time'])\n",
    "                    dfTemp.sort_values([\"Participant\",\"Time\"],ascending = (True,True),inplace=True)\n",
    "                    if len(dfTemp.columns)!=4:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    if len(df)!=0:\n",
    "                        frames=[dfTemp,df]\n",
    "                        df=pd.concat(frames)\n",
    "                    else:\n",
    "                        df=dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfCGM=df\n",
    "    dfCGM['Abbot'].interpolate(method='linear',limit_direction='both',axis=0,inplace=True)\n",
    "    dfCGM['Dexcom'].interpolate(method='linear',limit_direction='both',axis=0,inplace=True)\n",
    "    dfCGM.to_pickle(os.path.join(addDataPrefix,'All_cgm.pkl')) \n",
    "else:\n",
    "    dfCGM=pd.read_pickle(os.path.join(addDataPrefix,'All_cgm.pkl'))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "if os.path.exists(os.path.join(addDataPrefix,'All_cm.pkl')):\n",
    "    os.remove(os.path.join(addDataPrefix,'All_cm.pkl'))\n",
    "os.chdir(addHKCM)\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_cm.pkl')):\n",
    "    df=[]\n",
    "    for root, dirs, files in os.walk(addHKCM):\n",
    "        for file in files:\n",
    "            if '.csv' in file.lower():\n",
    "                if 'cm' in file.lower() and 'modified' in file.lower():\n",
    "                    participantName=file[:file.find('_cm')]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\",file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\",file)\n",
    "                    dfTemp=pd.read_csv(file)\n",
    "                    print(\"File is read\")\n",
    "                    dfTemp['Time']=pd.to_datetime(dfTemp['Time'])\n",
    "                    dfTemp.insert(0,'Participant',participantName)\n",
    "                    dfTemp.insert(len(dfTemp.columns),'|Ax|+|Ay|+|Az|',dfTemp['Ax'].abs()+dfTemp['Ay'].abs()+dfTemp['Az'].abs()+0.001)#this is to avoid 0 later on for feature calculation\n",
    "                    dfTemp.insert(len(dfTemp.columns),'|Yaw|+|Roll|+|Pitch|',dfTemp['Yaw'].abs()+dfTemp['Roll'].abs()+dfTemp['Pitch'].abs())\n",
    "                    dfTemp.insert(len(dfTemp.columns),'RotationalToLinear',dfTemp['|Yaw|+|Roll|+|Pitch|']/dfTemp['|Ax|+|Ay|+|Az|'])\n",
    "                    print(\"modified\")\n",
    "                    dfTemp.sort_values(['Time'],ascending = (True),inplace=True)\n",
    "                    print(\"sorted\")\n",
    "                    if len(dfTemp.columns)!=14:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        print(dfTemp.columns)\n",
    "                        break\n",
    "                    if len(df)!=0:\n",
    "                        frames=[dfTemp,df]\n",
    "                        df=pd.concat(frames)\n",
    "                    else:\n",
    "                        df=dfTemp\n",
    "    dfCM=df\n",
    "    print(\"Processing is done\")\n",
    "    dfCM.to_pickle(os.path.join(addDataPrefix,'All_cm.pkl')) \n",
    "else:\n",
    "    dfCM = pd.read_pickle(os.path.join(addDataPrefix,'All_cm.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractorMotion(df):\n",
    "    f1=df['RotationalToLinear'].mean()\n",
    "    f2=df['|Ax|+|Ay|+|Az|'].mean()\n",
    "    f5=df['|Yaw|+|Roll|+|Pitch|'].mean()\n",
    "    return [f1,f2,f5]\n",
    "\n",
    "def featureExtractorCGM(df):\n",
    "    mean=df['Abbot'].mean()\n",
    "    std=df['Abbot'].std()\n",
    "    max=df['Abbot'].max()\n",
    "    min=df['Abbot'].min()\n",
    "    return mean, std, min,max\n",
    "\n",
    "MINIMUM_POINT_CM=10\n",
    "WINDOW_LENGTH=timedelta(minutes=2)\n",
    "MEAL_MAX_TIME=timedelta(minutes=30)\n",
    "MEAL_PORTION_RELAXATION=timedelta(seconds=10)\n",
    "START_OF_TRIAL = datetime.strptime('11 06 2021-02:00:00', '%m %d %Y-%H:%M:%S')#to handle the daylight saving issue in apple watches\n",
    "END_OF_TRIAL = datetime.strptime('11 15 2021-00:00:00', '%m %d %Y-%H:%M:%S')\n",
    "\n",
    "\n",
    "dfMeal=dfMeal[dfMeal['StartTime']>=START_OF_TRIAL]\n",
    "dfMeal=dfMeal[dfMeal['FinishTime']<END_OF_TRIAL]\n",
    "print(\"Meal database is limited to the trial period\")\n",
    "\n",
    "dfCM=dfCM[dfCM['Time']>=START_OF_TRIAL]\n",
    "dfCM=dfCM[dfCM['Time']<END_OF_TRIAL]\n",
    "print(\"CM databse is limited to the trial period\")\n",
    "\n",
    "participants=dfCM['Participant'].to_list()\n",
    "participants=list(set(participants))\n",
    "participantDataList=[]\n",
    "skippedWindows=0\n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix,'Features.pkl')):\n",
    "    os.remove(os.path.join(addDataPrefix,'Features.pkl'))\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'Features.pkl')):\n",
    "    for participant in participants:\n",
    "        windowStart=START_OF_TRIAL\n",
    "        windowEnd=windowStart+WINDOW_LENGTH        \n",
    "        print(\"Participant \",participant,\" is started\")\n",
    "        dfParticipantCM=dfCM[dfCM['Participant']==participant]\n",
    "        dfParticipantMeal=dfMeal[dfMeal['Participant']==participant]\n",
    "        print(\"CM size for participant\",len(dfParticipantCM))\n",
    "        for counter in tqdm(range(0,int((END_OF_TRIAL-START_OF_TRIAL).total_seconds()/WINDOW_LENGTH.total_seconds()),1)):\n",
    "            dfTempCM=dfParticipantCM[(dfParticipantCM['Time']>=windowStart) & (dfParticipantCM['Time']<=windowEnd)]\n",
    "            dfTempMeal=dfParticipantMeal[(dfParticipantMeal['StartTime']-MEAL_PORTION_RELAXATION<=windowStart) & (dfParticipantMeal['FinishTime']+MEAL_PORTION_RELAXATION>=windowEnd)]\n",
    "            dfTempMeal=dfTempMeal[dfTempMeal['StartTime']+MEAL_MAX_TIME>=dfTempMeal['FinishTime']]\n",
    "            if(len(dfTempCM)<MINIMUM_POINT_CM):\n",
    "                windowStart+=WINDOW_LENGTH\n",
    "                windowEnd+=WINDOW_LENGTH\n",
    "                skippedWindows+=1\n",
    "                continue\n",
    "            tempList=featureExtractorMotion(dfTempCM)\n",
    "            if(len(dfTempMeal)!=0):\n",
    "                tempList.append(1)\n",
    "            else:\n",
    "                tempList.append(0)\n",
    "            tempList.append(participant[1:])           \n",
    "            if(len(tempList)!=5):\n",
    "                print(\"MAYDAY. The length is not right\")\n",
    "                print(windowStart,windowEnd)\n",
    "                break\n",
    "            participantDataList.append(tempList)\n",
    "            windowStart+=WINDOW_LENGTH\n",
    "            windowEnd+=WINDOW_LENGTH\n",
    "    participantDataArray=np.asarray(participantDataList)\n",
    "    np.save(os.path.join(addDataPrefix,'Features.pkl'),participantDataArray)\n",
    "else:\n",
    "    participantDataArray = np.load(os.path.join(addDataPrefix,'Features.pkl'))\n",
    "\n",
    "print(\"Total number of skipped windows:\",skippedWindows, \" the shape of the data:\",participantDataArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STMI_XGBoost(xTrain,xVal,xTest,yTrain,yVal,yTest):\n",
    "    f1ScoreBest=0\n",
    "    for maxDepth in tqdm(np.arange(3,60,2)):\n",
    "        for estimator in np.arange(5,50,2):\n",
    "            for threshold in np.arange(0.2,0.9,0.2):\n",
    "                clf = xgb.XGBClassifier(n_jobs=24,n_estimators=estimator,max_depth=maxDepth,objective = \"binary:logistic\",eval_metric = \"logloss\",use_label_encoder =False)\n",
    "                clf.fit(xTrain,yTrain)\n",
    "                predictionsVal = clf.predict_proba(xVal)\n",
    "                predictionsVal=predictionsVal[:,1]\n",
    "                predictionsVal[predictionsVal>=threshold]=1\n",
    "                predictionsVal[predictionsVal<threshold]=0\n",
    "\n",
    "                confMatrix=sklearn.metrics.confusion_matrix(yVal,predictionsVal)\n",
    "                accuracy=sklearn.metrics.accuracy_score(yVal,predictionsVal)\n",
    "                recall=sklearn.metrics.recall_score(yVal,predictionsVal)\n",
    "                precision=sklearn.metrics.precision_score(yVal,predictionsVal)\n",
    "                f1Score=sklearn.metrics.f1_score(yVal,predictionsVal)\n",
    "\n",
    "                if f1Score>f1ScoreBest:\n",
    "                    confMatrixBest=confMatrix\n",
    "                    accuracyBest=accuracy\n",
    "                    modelBest=clf\n",
    "                    recallBest=recall\n",
    "                    precisionBest=precision\n",
    "                    thresholdBest=threshold\n",
    "                    f1ScoreBest=f1Score\n",
    "    print(\"***********Val:\")\n",
    "    print(confMatrixBest)\n",
    "    print(\"Accuracy:\",np.round(100*accuracyBest,0),\"Recall:\",np.round(100*recallBest,0),\"Precision:\",np.round(100*precisionBest,0))\n",
    "    print(\"***********Test:\")\n",
    "    predictionsTest=modelBest.predict_proba(xTest)\n",
    "    predictionsTest=predictionsTest[:,1]\n",
    "    predictionsTest[predictionsTest>=thresholdBest]=1\n",
    "    predictionsTest[predictionsTest<thresholdBest]=0    \n",
    "    \n",
    "    confMatrix=sklearn.metrics.confusion_matrix(yTest,predictionsTest)\n",
    "    accuracy=sklearn.metrics.accuracy_score(yTest,predictionsTest)\n",
    "    recall=sklearn.metrics.recall_score(yTest,predictionsTest)\n",
    "    precision=sklearn.metrics.precision_score(yTest,predictionsTest)\n",
    "    \n",
    "    print(confMatrix)\n",
    "    print(\"Accuracy:\",np.round(100*accuracy,0),\"Recall:\",np.round(100*recall,0),\"Precision:\",np.round(100*precision,0))\n",
    "    plot_confusion_matrix(modelBest, xTest, yTest,cmap='bone') \n",
    "\n",
    "    return modelBest\n",
    "\n",
    "def dataBalancer(xTrain,xVal,yTrain,yVal):\n",
    "    oversample = SMOTE()\n",
    "    xVal, yVal = oversample.fit_resample(xVal, yVal)\n",
    "    xTrain, yTrain = oversample.fit_resample(xTrain, yTrain)\n",
    "\n",
    "    return xTrain,xVal,yTrain,yVal\n",
    "\n",
    "def testTrainSplitFunc(data,randomSeed,normalFlag):\n",
    "    data=data.astype(float)\n",
    "    participants=data[:,data.shape[1]-1]\n",
    "    participants=list(set(participants))\n",
    "    for participant in participants:\n",
    "        print(\"Participant:\",participant)\n",
    "        indxList=[]\n",
    "        for counter in range(len(data)):\n",
    "            if(data[counter,data.shape[1]-1]==participant):\n",
    "                indxList.append(counter)\n",
    "        dataTemp=data[indxList,:]\n",
    "        dataX=dataTemp[:,0:dataTemp.shape[1]-2]\n",
    "        dataY=dataTemp[:,dataTemp.shape[1]-2]\n",
    "\n",
    "        random.seed(randomSeed)\n",
    "        np.random.shuffle(data)\n",
    "        if(normalFlag):\n",
    "            dataX=dataX-dataX.mean(axis=0)\n",
    "            dataX/=dataX.std(axis=0)\n",
    "        \n",
    "        stratidiedSampling = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=randomSeed)\n",
    "        for trainIndex, testIndex in stratidiedSampling.split(dataX, dataY):\n",
    "            xTrain,xTest=dataX[trainIndex],dataX[testIndex]\n",
    "            yTrain,yTest=dataY[trainIndex],dataY[testIndex]\n",
    "\n",
    "        stratidiedSampling = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=randomSeed)\n",
    "        for trainIndex, valIndex in stratidiedSampling.split(xTrain, yTrain):\n",
    "            xTrain,xVal=dataX[trainIndex],dataX[valIndex]\n",
    "            yTrain,yVal=dataY[trainIndex],dataY[valIndex]\n",
    "\n",
    "        return xTrain,xVal,xTest,yTrain,yVal,yTest\n",
    "\n",
    "\n",
    "print(\"Without NORMALIZATION\")\n",
    "NORMALIZED_FLAG=False\n",
    "randomSeed=random.randrange(100)\n",
    "xTrain,xVal,xTest,yTrain,yVal,yTest=testTrainSplitFunc(participantDataArray,randomSeed,NORMALIZED_FLAG)\n",
    "xTrain,xVal,yTrain,yVal=dataBalancer(xTrain,xVal,yTrain,yVal)\n",
    "modelBest=STMI_XGBoost(xTrain,xVal,xTest,yTrain,yVal,yTest)\n",
    "\n",
    "print(\"With NORMALIZATION\")\n",
    "NORMALIZED_FLAG=True\n",
    "xTrain,xVal,xTest,yTrain,yVal,yTest=testTrainSplitFunc(participantDataArray,randomSeed,NORMALIZED_FLAG)\n",
    "xTrain,xVal,yTrain,yVal=dataBalancer(xTrain,xVal,yTrain,yVal)\n",
    "modelBest=STMI_XGBoost(xTrain,xVal,xTest,yTrain,yVal,yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65e249be015da37cfe4cfdd1da028fe4cb475c26be679b9e3e34696278a17c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
