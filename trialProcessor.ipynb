{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pytz\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from dateutil.tz import tzutc\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from joblib import Parallel, delayed\n",
    "import csv\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import pearsonr, mode, skew, kurtosis\n",
    "from scipy.signal import savgol_filter\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "addDataPrefix = \"/Users/sorush/My Drive/Documents/Educational/TAMU/Research/Trial/Data/11-5-21-11-15-21\"\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"/home/grads/s/sorush.omidvar/CGMDataset/Trial/Data/11-5-21-11-15-21\"\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"C:\\\\GDrive\\\\Documents\\\\Educational\\\\TAMU\\\\Research\\\\Trial\\\\Data\\\\11-5-21-11-15-21\"\n",
    "\n",
    "addUserInput = os.path.join(addDataPrefix, \"User inputted\")\n",
    "addHKCM = os.path.join(addDataPrefix, \"hk+cm\")\n",
    "addCGM = os.path.join(addDataPrefix, \"CGM\")\n",
    "addE4 = os.path.join(addDataPrefix, \"E4\")\n",
    "\n",
    "exempts = [\"p2\", \"p4\"]\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({\"figure.facecolor\": \"white\"})\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ... p3Meals-Modified.xlsx\n",
      "Reading ... p1Meals-Modified.xlsx\n",
      "reading is done\n",
      "Meal database is limited to the trial period\n"
     ]
    }
   ],
   "source": [
    "START_OF_TRIAL = datetime.strptime(\"11 06 2021-02:00:00\", \"%m %d %Y-%H:%M:%S\")  # to handle the daylight saving issue in apple watches\n",
    "END_OF_TRIAL = datetime.strptime(\"11 15 2021-00:00:00\", \"%m %d %Y-%H:%M:%S\")\n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix, \"All_meals.pkl\")):\n",
    "    os.remove(os.path.join(addDataPrefix, \"All_meals.pkl\"))\n",
    "os.chdir(addUserInput)\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"All_meals.pkl\")):\n",
    "    dfMeal = []\n",
    "    for root, dirs, files in os.walk(addUserInput):\n",
    "        for file in files:\n",
    "            if \".xlsx\" in file.lower():\n",
    "                if \"meals-modified\" in file.lower():\n",
    "                    participantName = file[: file.find(\"Meals\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_excel(file)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    dfTemp.drop(columns=[\"startTime\", \"FinishTime\", \"Duration\"], inplace=True)\n",
    "                    dfTemp.rename(columns={\"startTimeModified\": \"StartTime\"}, inplace=True)\n",
    "                    dfTemp.rename(columns={\"FinishTimeModified\": \"FinishTime\"}, inplace=True)\n",
    "                    dfTemp[\"StartTime\"] = pd.to_datetime(dfTemp[\"StartTime\"])\n",
    "                    dfTemp[\"FinishTime\"] = pd.to_datetime(dfTemp[\"FinishTime\"])\n",
    "                    dfTemp = dfTemp[dfTemp[\"StartTime\"].notna()]\n",
    "                    # dfTemp['StartTime']-=pd.DateOffset(hours=5)#fixing the time zone issue\n",
    "                    # dfTemp['FinishTime']-=pd.DateOffset(hours=5)#fixing the time zone issue\n",
    "                    dfTemp.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "                    for counter in range(1, len(dfTemp)):\n",
    "                        if dfTemp[\"StartTime\"].iloc[counter] == dfTemp[\"StartTime\"].iloc[counter - 1]:\n",
    "                            dfTemp[\"Carbs\"].iloc[counter] += dfTemp[\"Carbs\"].iloc[counter - 1]\n",
    "                            dfTemp[\"Fat\"].iloc[counter] += dfTemp[\"Fat\"].iloc[counter - 1]\n",
    "                            dfTemp[\"Protein\"].iloc[counter] += dfTemp[\"Protein\"].iloc[counter - 1]\n",
    "                            dfTemp[\"StartTime\"].iloc[counter] = \"\"\n",
    "                    dfTemp = dfTemp[dfTemp[\"StartTime\"].notna()]\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "                    for counter in range(1, len(dfTemp)):\n",
    "                        if dfTemp[\"StartTime\"].iloc[counter] - dfTemp[\"StartTime\"].iloc[counter - 1] <= timedelta(hours=1):\n",
    "                            print(\"The meals are not compressed:\", dfTemp[\"StartTime\"].iloc[counter], dfTemp[\"StartTime\"].iloc[counter - 1])\n",
    "                            os._exit()\n",
    "                    if len(dfMeal) != 0:\n",
    "                        frames = [dfTemp, dfMeal]\n",
    "                        dfMeal = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfMeal = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfMeal = dfMeal[dfMeal[\"StartTime\"] >= START_OF_TRIAL]\n",
    "    dfMeal = dfMeal[dfMeal[\"FinishTime\"] < END_OF_TRIAL]\n",
    "    dfMeal.reset_index(drop=True, inplace=True)\n",
    "    print(\"Meal database is limited to the trial period\")\n",
    "    dfMeal.to_pickle(os.path.join(addDataPrefix, \"All_meals.pkl\"))\n",
    "else:\n",
    "    dfMeal = pd.read_pickle(os.path.join(addDataPrefix, \"All_meals.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdInterpolation(dfTemp):\n",
    "    index = dfTemp[\"Time\"]\n",
    "    seriesParticipant = pd.Series(dfTemp[\"Abbot\"].to_list(), index=index)\n",
    "    seriesParticipant = seriesParticipant.resample(\"1T\").asfreq()\n",
    "    seriesParticipant.interpolate(method=\"polynomial\", order=3, inplace=True)\n",
    "    tempTime = seriesParticipant.index\n",
    "    tempVal = seriesParticipant.values\n",
    "    dfTemp = pd.DataFrame(zip(tempTime, tempVal), columns=[\"Time\", \"Abbot\"])\n",
    "    return dfTemp\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addDataPrefix,'All_cgm.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,'All_cgm.pkl'))\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"All_cgm.pkl\")):\n",
    "    os.chdir(addCGM)\n",
    "    dfCGM = []\n",
    "    for root, dirs, files in os.walk(addCGM):\n",
    "        for file in files:\n",
    "            if \".txt\" in file.lower():\n",
    "                if \"_fl\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_fl\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file, sep=\"\\t\", skiprows=1)\n",
    "                    if len(dfTemp.columns) != 4:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    dfTemp.columns.values[0] = \"ID\"\n",
    "                    dfTemp.columns.values[1] = \"Time\"\n",
    "                    dfTemp.columns.values[2] = \"Record\"\n",
    "                    dfTemp.columns.values[3] = \"Abbot\"\n",
    "                    dfTemp.drop(columns=[\"ID\", \"Record\"], inplace=True)\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"])\n",
    "                    dfTemp[\"Abbot\"] = pd.to_numeric(dfTemp[\"Abbot\"])\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                    dfTemp = pdInterpolation(dfTemp)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    if len(dfTemp.columns) != 3:\n",
    "                        print(\"MAYDAY. Error in processing csv\")\n",
    "                        break\n",
    "                    if len(dfCGM) != 0:\n",
    "                        frames = [dfTemp, dfCGM]\n",
    "                        dfCGM = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfCGM = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfCGM = dfCGM[dfCGM[\"Time\"] >= START_OF_TRIAL]\n",
    "    dfCGM = dfCGM[dfCGM[\"Time\"] < END_OF_TRIAL]\n",
    "    print(\"CGM database is limited to the trial period\")\n",
    "    dfCGM.to_pickle(os.path.join(addDataPrefix, \"All_cgm.pkl\"))\n",
    "else:\n",
    "    dfCGM = pd.read_pickle(os.path.join(addDataPrefix, \"All_cgm.pkl\"))\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addDataPrefix,'All_cm.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,'All_cm.pkl'))\n",
    "os.chdir(addHKCM)\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"All_cm.pkl\")):\n",
    "    df = []\n",
    "    for root, dirs, files in os.walk(addHKCM):\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                if \"cm\" in file.lower() and \"modified\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_cm\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    print(\"File is read\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"])\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    dfTemp.insert(\n",
    "                        len(dfTemp.columns), \"|Ax|+|Ay|+|Az|\", dfTemp[\"Ax\"].abs() + dfTemp[\"Ay\"].abs() + dfTemp[\"Az\"].abs() + 0.001\n",
    "                    )  # this is to avoid 0 later on for feature calculation\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Yaw|+|Roll|+|Pitch|\", dfTemp[\"Yaw\"].abs() + dfTemp[\"Roll\"].abs() + dfTemp[\"Pitch\"].abs())\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"RotationalToLinear\", dfTemp[\"|Yaw|+|Roll|+|Pitch|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"])\n",
    "                    print(\"modified\")\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                    print(\"sorted\")\n",
    "                    if len(dfTemp.columns) != 14:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        print(dfTemp.columns)\n",
    "                        break\n",
    "                    if len(df) != 0:\n",
    "                        frames = [dfTemp, df]\n",
    "                        df = pd.concat(frames)\n",
    "                    else:\n",
    "                        df = dfTemp\n",
    "    dfCM = df\n",
    "    print(\"Processing is done\")\n",
    "    dfCM = dfCM[dfCM[\"Time\"] >= START_OF_TRIAL]\n",
    "    dfCM = dfCM[dfCM[\"Time\"] < END_OF_TRIAL]\n",
    "    print(\"CM database is limited to the trial period\")\n",
    "    dfCM.to_pickle(os.path.join(addDataPrefix, \"All_cm.pkl\"))\n",
    "else:\n",
    "    dfCM = pd.read_pickle(os.path.join(addDataPrefix, \"All_cm.pkl\"))\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addDataPrefix,'All_E4.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,'All_E4.pkl'))\n",
    "os.chdir(addE4)\n",
    "# fields=['ACC','BVP','EDA','HR','IBI','TEMP']\n",
    "fields = [\"BVP\", \"EDA\", \"HR\", \"TEMP\"]\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"All_E4.pkl\")):\n",
    "    dfE4 = []\n",
    "    for root, dirs, files in os.walk(addE4):\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                participantName = root[root.find(\"E4\") + 3 :]\n",
    "                participantName = participantName[:2]\n",
    "                field = file[: file.find(\".csv\")]\n",
    "                if field not in fields:\n",
    "                    print(\"File name does not comply with analyzed fields\", file)\n",
    "                    continue\n",
    "                print(participantName, field)\n",
    "                if participantName in exempts:\n",
    "                    print(\"Exemption...\", file)\n",
    "                    continue\n",
    "                print(\"Reading ...\", file)\n",
    "                os.chdir(root)\n",
    "                dfTemp = pd.read_csv(file, header=None)\n",
    "                # if field=='ACC':\n",
    "                #     assert len(dfTemp.columns)==3\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     timeStep=1/dfTemp.iloc[1,0]\n",
    "                #     dfTemp.drop([0,1],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Data1',1:'Data2',2:'Data3'}, inplace=True)#x,y,z for data1,data2,data3\n",
    "                #     timeTemp=[]\n",
    "                #     for counter in range(len(dfTemp)):\n",
    "                #         timeTemp.append(timeBase+counter*timeStep)\n",
    "                #     dfTemp.insert(0,'Time',timeTemp)\n",
    "                #     dfTemp.insert(0,'Field',\"Acceleration\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                if field == \"BVP\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"BVP\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                elif field == \"HR\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"HR\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                elif field == \"EDA\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"EDA\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                # elif field=='IBI':\n",
    "                #     assert len(dfTemp.columns)==2\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     dfTemp.drop([0],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Time',1:'Data1'}, inplace=True)\n",
    "                #     dfTemp[\"Data2\"]=\"\"\n",
    "                #     dfTemp[\"Data3\"]=\"\"\n",
    "                #     timeTemp=[]\n",
    "                #     dfTemp['Time']+=timeBase\n",
    "                #     dfTemp.insert(0,'Field',\"IBI\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                elif field == \"TEMP\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"Temperature\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                dfTemp.insert(0, \"Participant\", participantName)\n",
    "\n",
    "                dfTemp[\"Time\"] -= pd.DateOffset(hours=6)  # Empatica records in GMT and also during the trial we had daylight saving\n",
    "                dfTemp.sort_values([\"Participant\", \"Field\", \"Time\"], ascending=(True, True, True), inplace=True)\n",
    "                if len(dfTemp.columns) != 6:\n",
    "                    print(\"MAYDAY. Error in reading csv\")\n",
    "                    break\n",
    "                if len(dfE4) != 0:\n",
    "                    frames = [dfTemp, dfE4]\n",
    "                    dfE4 = pd.concat(frames)\n",
    "                else:\n",
    "                    dfE4 = dfTemp\n",
    "\n",
    "    print(\"reading is done\")\n",
    "    dfE4 = dfE4[dfE4[\"Time\"] >= START_OF_TRIAL]\n",
    "    dfE4 = dfE4[dfE4[\"Time\"] < END_OF_TRIAL]\n",
    "    print(\"E4 database is limited to the trial period\")\n",
    "    dfE4.to_pickle(os.path.join(addDataPrefix, \"All_E4.pkl\"))\n",
    "else:\n",
    "    dfE4 = pd.read_pickle(os.path.join(addDataPrefix, \"All_E4.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant  p3  is started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 35/39 [12:15<01:23, 20.95s/it]"
     ]
    }
   ],
   "source": [
    "OUTTER_WINDOW_LENGTH = timedelta(minutes=60)\n",
    "OUTTER_WINDOW_STEP = timedelta(minutes=60)\n",
    "INNER_WINDOW_LENGTH = timedelta(minutes=1)\n",
    "COMPLEX_MEAL_LENGTH = timedelta(minutes=1800)\n",
    "MINIMUM_POINT = INNER_WINDOW_LENGTH.total_seconds()\n",
    "\n",
    "\n",
    "def e4Reporter(df):\n",
    "    topics = [\"BVP\", \"EDA\", \"HR\", \"Temperature\"]\n",
    "    report = []\n",
    "    for topic in topics:\n",
    "        dfTemp = df[df[\"Field\"] == topic]\n",
    "        if topic == \"BVP\":\n",
    "            MIN_POINT = MINIMUM_POINT * 64 * 0.3\n",
    "        elif topic == \"EDA\":\n",
    "            MIN_POINT = MINIMUM_POINT * 4 * 0.3\n",
    "        elif topic == \"HR\":\n",
    "            MIN_POINT = MINIMUM_POINT / 10 * 0.3\n",
    "        elif topic == \"Temperature\":\n",
    "            MIN_POINT = MINIMUM_POINT * 4 * 0.3\n",
    "        else:\n",
    "            print(\"MAYDAY at sensor reader\")\n",
    "            os._exit()\n",
    "\n",
    "        if len(dfTemp) < MIN_POINT:\n",
    "            report.append(\"Nan\")\n",
    "        else:\n",
    "            val = dfTemp[\"Data1\"].mean()\n",
    "            report.append(val)\n",
    "    return report\n",
    "\n",
    "\n",
    "def motionCalculator(df):\n",
    "    f1 = df[\"RotationalToLinear\"].mean()\n",
    "    f2 = df[\"|Ax|+|Ay|+|Az|\"].mean()\n",
    "    f5 = df[\"|Yaw|+|Roll|+|Pitch|\"].mean()\n",
    "    return [f1, f2, f5]\n",
    "\n",
    "\n",
    "def statFeature(dataList):\n",
    "    dataList = np.asarray(dataList).astype(float)\n",
    "    result = []\n",
    "    dataDim = dataList.ndim\n",
    "    if dataDim > 1:\n",
    "        for counter in range(dataList.shape[1]):\n",
    "            meanVal = np.nanmean(dataList[:, counter], axis=0)\n",
    "            stdVal = np.nanstd(dataList[:, counter], axis=0)\n",
    "            minVal = np.nanmin(dataList[:, counter], axis=0)\n",
    "            maxVal = np.nanmax(dataList[:, counter], axis=0)\n",
    "            rangeVal = maxVal - minVal\n",
    "            # skewnessVal=skew(dataList[:,counter],nan_policy='omit',axis=0)\n",
    "            # kurtosisVal=kurtosis(dataList[:,counter],nan_policy='omit',axis=0)\n",
    "            result.extend([rangeVal, meanVal, stdVal, minVal, maxVal])\n",
    "    else:\n",
    "        meanVal = np.nanmean(dataList)\n",
    "        stdVal = np.nanstd(dataList)\n",
    "        minVal = np.nanmin(dataList)\n",
    "        maxVal = np.nanmax(dataList)\n",
    "        rangeVal = maxVal - minVal\n",
    "        # skewnessVal=skew(dataList,nan_policy='omit')\n",
    "        # kurtosisVal=kurtosis(dataList,nan_policy='omit')\n",
    "        result.extend([rangeVal, meanVal, stdVal, minVal, maxVal])\n",
    "    return result\n",
    "\n",
    "\n",
    "def innerWindowExtractor(outterWindowStart, innerWindowNumber, dfParticipantCM, dfParticipantE4):\n",
    "    tempListCM = []\n",
    "    tempListE4 = []\n",
    "    for counterInner in range(0, innerWindowNumber, 1):\n",
    "        innerWindowStart = outterWindowStart + counterInner * INNER_WINDOW_LENGTH\n",
    "        innerWindowEnd = innerWindowStart + INNER_WINDOW_LENGTH\n",
    "        dfTempCM = dfParticipantCM[(dfParticipantCM[\"Time\"] >= innerWindowStart) & (dfParticipantCM[\"Time\"] < innerWindowEnd)]\n",
    "\n",
    "        if len(dfTempCM) < MINIMUM_POINT * 10 * 0.3:\n",
    "            tempListCM.append([\"Nan\", \"Nan\", \"Nan\"])\n",
    "        else:\n",
    "            tempListCM.append(motionCalculator(dfTempCM))\n",
    "\n",
    "        dfTempE4 = dfParticipantE4[(dfParticipantE4[\"Time\"] >= innerWindowStart) & (dfParticipantE4[\"Time\"] < innerWindowEnd)]\n",
    "        if len(dfTempE4) < MINIMUM_POINT * 32 * 0.3:\n",
    "            tempListE4.append([\"Nan\", \"Nan\", \"Nan\", \"Nan\"])\n",
    "        else:\n",
    "            tempListE4.append(e4Reporter(dfTempE4))\n",
    "\n",
    "    return tempListCM, tempListE4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def outterWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant):\n",
    "    participantDataList = []\n",
    "    for counterOuter in tqdm(range(0, len(dfParticipantMeal))):\n",
    "        outterWindowStart = dfParticipantMeal[\"StartTime\"].iloc[counterOuter]\n",
    "        outterWindowEnd = outterWindowStart + OUTTER_WINDOW_LENGTH\n",
    "        innerWindowNumber = int(OUTTER_WINDOW_LENGTH.total_seconds() / INNER_WINDOW_LENGTH.total_seconds())\n",
    "        tempListInfo = [outterWindowStart, outterWindowEnd, participant]\n",
    "        tempList = []\n",
    "        tempListCM, tempListE4 = innerWindowExtractor(outterWindowStart, innerWindowNumber, dfParticipantCM, dfParticipantE4)\n",
    "\n",
    "        carbs = dfParticipantMeal[\"Carbs\"].iloc[counterOuter]\n",
    "        protein = dfParticipantMeal[\"Protein\"].iloc[counterOuter]\n",
    "        fat = dfParticipantMeal[\"Fat\"].iloc[counterOuter]\n",
    "\n",
    "        tempListCM = statFeature(tempListCM)\n",
    "        tempList.extend(tempListCM)  # 5*3=15\n",
    "\n",
    "        tempListE4 = statFeature(tempListE4)\n",
    "        tempList.extend(tempListE4)  # 5*4=20\n",
    "\n",
    "        dfTempCGM = dfParticipantCGM[(dfParticipantCGM[\"Time\"] >= outterWindowStart) & (dfParticipantCGM[\"Time\"] < outterWindowEnd)]\n",
    "        tempListCGM = dfTempCGM[\"Abbot\"].to_list()\n",
    "        tempListCGM = statFeature(tempListCGM)\n",
    "        tempList.extend(tempListCGM)  # 5\n",
    "        tempList.extend(tempListInfo)  # 3\n",
    "\n",
    "        tempList.append(carbs)\n",
    "        tempList.append(fat)\n",
    "        tempList.append(protein)\n",
    "        tempList.append(1)  # mealFlag\n",
    "        assert len(tempList) == 5 * 3 + 5 * 4 + 5 + 3 + 4\n",
    "        participantDataList.append(tempList)\n",
    "    return participantDataList\n",
    "\n",
    "\n",
    "def participantFeatureWriter(participantDataList):\n",
    "    participantDataArray = np.asarray(participantDataList)\n",
    "    columnTopics = [\"F1\", \"F2\", \"F5\", \"BVP\", \"EDA\", \"HR\", \"Temperature\", \"CGM\"]\n",
    "    columnStats = [\"Range\", \"Mean\", \"Std\", \"Min\", \"Max\"]\n",
    "    columns = []\n",
    "    for topic in columnTopics:\n",
    "        for stat in columnStats:\n",
    "            columns.append(topic + \"-\" + stat)\n",
    "    columns.extend([\"StartTime\", \"EndTime\", \"Participant\", \"Carb\", \"Fat\", \"Protein\", \"MealLabel\"])\n",
    "    dfFeatures = pd.DataFrame(participantDataArray, columns=columns)\n",
    "    dfFeatures.sort_values([\"Participant\", \"Start\"], ascending=(True, True), inplace=True)\n",
    "    dfFeatures.reset_index(drop=True, inplace=True)\n",
    "    dfFeatures.insert(len(dfFeatures.columns), \"ComplexFlag\", 0)\n",
    "    for counter in range(1, len(dfFeatures)):\n",
    "        if dfFeatures[\"StartTime\"].iloc[counter] <= dfFeatures[\"StartTime\"].iloc[counter - 1] + COMPLEX_MEAL_LENGTH:\n",
    "            dfFeatures[\"StartTime\"].iloc[counter - 1] = 1\n",
    "    dfFeatures.to_csv(os.path.join(addDataPrefix, participant + \"-Features.csv\"), index=False)\n",
    "\n",
    "\n",
    "def allFeatureWriter(participants):\n",
    "    dfFeatures = []\n",
    "    for participant in participants:\n",
    "        if participant in exempts:\n",
    "            continue\n",
    "        if not os.path.exists(os.path.join(addDataPrefix, participant + \"-Features.csv\")):\n",
    "            print(\"MAYDAY, no feature for participant:\", participant)\n",
    "            os._exit()\n",
    "        dfTemp = pd.DataFrame(os.path.join(addDataPrefix, participant + \"-Features.csv\"))\n",
    "        if len(dfFeatures) == 0:\n",
    "            dfFeatures = dfTemp\n",
    "        else:\n",
    "            frames = [dfTemp, dfFeatures]\n",
    "            dfFeatures = pd.concat(frames)\n",
    "    dfFeatures.to_csv(os.path.join(addDataPrefix, \"All-Features.csv\"), index=False)\n",
    "\n",
    "participants = dfCM[\"Participant\"].to_list()\n",
    "participants = list(set(participants))\n",
    "if os.path.exists(os.path.join(addDataPrefix, \"All-Features.csv\")):\n",
    "    os.remove(os.path.join(addDataPrefix, \"All-Features.csv\"))\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"All-Features.csv\")):\n",
    "    for participant in participants:\n",
    "        if participant != \"p3\":  ############################################\n",
    "            continue\n",
    "        if participant in exempts:\n",
    "            continue\n",
    "        if os.path.exists(os.path.join(addDataPrefix, participant + \"-Features.csv\")):\n",
    "            os.remove(os.path.join(addDataPrefix, participant + \"-Features.csv\"))\n",
    "        if not os.path.exists(os.path.join(addDataPrefix, participant + \"-Features.csv\")):\n",
    "            print(\"Participant \", participant, \" is started\")\n",
    "            dfParticipantCM = dfCM[dfCM[\"Participant\"] == participant]\n",
    "            dfParticipantMeal = dfMeal[dfMeal[\"Participant\"] == participant]\n",
    "            dfParticipantCGM = dfCGM[dfCGM[\"Participant\"] == participant]\n",
    "            dfParticipantE4 = dfE4[dfE4[\"Participant\"] == participant]\n",
    "\n",
    "            participantDataList = outterWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant)\n",
    "            participantFeatureWriter(participantDataList)\n",
    "            allFeatureWriter(participants)\n",
    "else:\n",
    "    dfFeatures = pd.DataFrame(os.path.join(addDataPrefix, \"All-Features.csv\"))\n",
    "print(dfFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgRegressor(xTrain, xVal, xTest, yTrain, yVal, yTest):\n",
    "    rmseBest = 100000000000\n",
    "    for maxDepth in tqdm(np.arange(2, 8, 2)):\n",
    "        for estimator in np.arange(50, 200, 50):\n",
    "            clf = xgb.XGBClassifier(n_jobs=36, n_estimators=estimator, max_depth=maxDepth, objective=\"reg:squarederror\", eval_metric=\"rmse\",)\n",
    "            clf.fit(xTrain, yTrain)\n",
    "            predictionsVal = clf.predict(xVal)\n",
    "            rmse = np.sqrt(MSE(yVal, predictionsVal))\n",
    "            if rmse < rmseBest:\n",
    "                rmseBest = rmse\n",
    "                modelBest = clf\n",
    "\n",
    "    predictionsTest = modelBest.predict(xTest)\n",
    "    rmse = np.sqrt(MSE(yTest, predictionsTest))\n",
    "    # print(\"For \",parameter,\" we have RMSE:\",rmse, \"Relative RMSE:\",rmse/np.sum(yTest))\n",
    "    return rmse, rmse / np.sum(yTest), np.sum(yTest)\n",
    "    # plot_confusion_matrix(modelBest, xTest, yTest,cmap='bone')\n",
    "\n",
    "\n",
    "def xgClassifier(xTrain, xVal, xTest, yTrain, yVal, yTest):\n",
    "    f1ScoreBest = -1\n",
    "    for maxDepth in tqdm(np.arange(2, 8, 2)):\n",
    "        for estimator in np.arange(50, 200, 50):\n",
    "            for posWeight in np.arange(1, 10, 2):\n",
    "                clf = xgb.XGBClassifier(\n",
    "                    scale_pos_weight=posWeight, n_jobs=36, n_estimators=estimator, max_depth=maxDepth, objective=\"binary:logistic\", eval_metric=\"error\",\n",
    "                )\n",
    "                clf.fit(xTrain, yTrain)\n",
    "                predictionsVal = clf.predict(xVal)\n",
    "\n",
    "                accuracy = sklearn.metrics.accuracy_score(yVal, predictionsVal)\n",
    "                recall = sklearn.metrics.recall_score(yVal, predictionsVal)\n",
    "                precision = sklearn.metrics.precision_score(yVal, predictionsVal)\n",
    "                f1Score = sklearn.metrics.f1_score(yVal, predictionsVal)\n",
    "\n",
    "                if f1Score > f1ScoreBest:\n",
    "                    modelBest = clf\n",
    "                    f1ScoreBest = f1Score\n",
    "    predictionsTest = modelBest.predict(xTest)\n",
    "    confMatrix = sklearn.metrics.confusion_matrix(yTest, predictionsTest)\n",
    "    accuracy = sklearn.metrics.accuracy_score(yTest, predictionsTest)\n",
    "    recall = sklearn.metrics.recall_score(yTest, predictionsTest)\n",
    "    precision = sklearn.metrics.precision_score(yTest, predictionsTest)\n",
    "    f1Score = sklearn.metrics.f1_score(yTest, predictionsTest)\n",
    "\n",
    "    return accuracy, recall, precision, f1Score\n",
    "    # plot_confusion_matrix(modelBest, xTest, yTest,cmap='bone')\n",
    "\n",
    "\n",
    "def dataBalancer(xTrain, xVal, yTrain, yVal):\n",
    "    oversample = SMOTE()\n",
    "    xVal, yVal = oversample.fit_resample(xVal, yVal)\n",
    "    xTrain, yTrain = oversample.fit_resample(xTrain, yTrain)\n",
    "\n",
    "    return xTrain, xVal, yTrain, yVal\n",
    "\n",
    "\n",
    "def reportFormatter(\n",
    "    reportTemp, classifierFlag, classifierReports, regressorReports, participant, combination, component,\n",
    "):\n",
    "    reportTemp = np.asarray(reportTemp)\n",
    "    reportTemp = np.mean(reportTemp, axis=0)\n",
    "    reportTemp = list(reportTemp)\n",
    "    if classifierFlag:\n",
    "        reportTemp.append(participant)\n",
    "        reportTemp.append(combination)\n",
    "        reportTemp.append(\"Nan\")\n",
    "        reportTemp = np.asarray(reportTemp)\n",
    "        classifierReports.append(reportTemp)\n",
    "    else:\n",
    "        reportTemp.append(\"Nan\")\n",
    "        reportTemp.append(participant)\n",
    "        reportTemp.append(combination)\n",
    "        reportTemp.append(component)\n",
    "        reportTemp = np.asarray(reportTemp)\n",
    "        regressorReports.append(reportTemp)\n",
    "\n",
    "\n",
    "def testTrainSplitFunc(data, randomSeed, normalFlag, combination):\n",
    "    participants = data[:, data.shape[1] - 5]\n",
    "    participants = list(set(participants))\n",
    "    regressorReports = []\n",
    "    classifierReports = []\n",
    "    for participantCounter in range(len(participants) + 1):\n",
    "\n",
    "        indxList = []\n",
    "        if participantCounter < len(participants):\n",
    "            participant = participants[participantCounter]\n",
    "            print(\"Participant:\", participant)\n",
    "            for counter in range(data.shape[0]):\n",
    "                if data[counter, data.shape[1] - 5] == participant:\n",
    "                    indxList.append(counter)\n",
    "            dataParticipant = data[indxList, :]\n",
    "        else:  # all participant\n",
    "            participant = \"All\"\n",
    "            dataParticipant = data\n",
    "\n",
    "        # windowStarts=dataParticipant[:,dataParticipant.shape[1]-7]\n",
    "        # windowEnds=dataParticipant[:,dataParticipant.shape[1]-6]\n",
    "\n",
    "        dataXBinary = dataParticipant[:, 0 : dataParticipant.shape[1] - 7]\n",
    "        dataXBinary = dataXBinary.astype(float)\n",
    "        dataXRegression = dataXBinary\n",
    "\n",
    "        dataYBinary = dataParticipant[:, dataParticipant.shape[1] - 1]\n",
    "        dataYBinary = dataYBinary.astype(float)\n",
    "\n",
    "        dataYRegression = dataParticipant[:, dataParticipant.shape[1] - 4 : dataParticipant.shape[1] - 1]  # -4, -3 and -2 are carb, fat and protein\n",
    "        dataYRegression = dataYRegression.astype(float)\n",
    "\n",
    "        if normalFlag:\n",
    "            dataXBinary -= -dataXBinary.mean(axis=0)\n",
    "            dataXBinary /= dataXBinary.std(axis=0)\n",
    "            dataXRegression = dataXBinary\n",
    "\n",
    "        reportClassifierTemp = []\n",
    "        reportFatTemp = []\n",
    "        reportCarbTemp = []\n",
    "        reportProteinTemp = []\n",
    "        splitterOuter = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=randomSeed)\n",
    "        for trainIndex, testIndex in splitterOuter.split(dataXBinary, dataYBinary):\n",
    "            xTrainBinary, xTestBinary = (\n",
    "                dataXBinary[trainIndex, :],\n",
    "                dataXBinary[testIndex, :],\n",
    "            )\n",
    "            yTrainBinary, yTestBinary = dataYBinary[trainIndex], dataYBinary[testIndex]\n",
    "\n",
    "            xTrainRegression, xTestRegression = (\n",
    "                dataXRegression[trainIndex, :],\n",
    "                dataXRegression[testIndex, :],\n",
    "            )\n",
    "            yTrainRegression, yTestRegression = (\n",
    "                dataYRegression[trainIndex, :],\n",
    "                dataYRegression[testIndex, :],\n",
    "            )\n",
    "\n",
    "            splitterInner = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=randomSeed)\n",
    "            for trainIndex, valIndex in splitterInner.split(xTrainBinary, yTrainBinary):\n",
    "                xTrainBinary, xValBinary = (\n",
    "                    dataXBinary[trainIndex, :],\n",
    "                    dataXBinary[valIndex, :],\n",
    "                )\n",
    "                yTrainBinary, yValBinary = (\n",
    "                    dataYBinary[trainIndex],\n",
    "                    dataYBinary[valIndex],\n",
    "                )\n",
    "\n",
    "                xTrainRegression, xValRegression = (\n",
    "                    dataXRegression[trainIndex, :],\n",
    "                    dataXRegression[valIndex, :],\n",
    "                )\n",
    "                yTrainRegression, yValRegression = (\n",
    "                    dataYRegression[trainIndex, :],\n",
    "                    dataYRegression[valIndex, :],\n",
    "                )\n",
    "\n",
    "            tempFilter = []\n",
    "            print(len(xTrainRegression), xTrainRegression.shape)\n",
    "            os._exit()\n",
    "            for counter in range(len(xTrainRegression)):\n",
    "                print(\"\")\n",
    "\n",
    "            counter = 0\n",
    "            reportCarbTemp.append(\n",
    "                xgRegressor(\n",
    "                    xTrainRegression, xValRegression, xTestRegression, yTrainRegression[:, counter], yValRegression[:, counter], yTestRegression[:, counter],\n",
    "                )\n",
    "            )\n",
    "            counter = 1\n",
    "            reportFatTemp.append(\n",
    "                xgRegressor(\n",
    "                    xTrainRegression, xValRegression, xTestRegression, yTrainRegression[:, counter], yValRegression[:, counter], yTestRegression[:, counter],\n",
    "                )\n",
    "            )\n",
    "            counter = 2\n",
    "            reportProteinTemp.append(\n",
    "                xgRegressor(\n",
    "                    xTrainRegression, xValRegression, xTestRegression, yTrainRegression[:, counter], yValRegression[:, counter], yTestRegression[:, counter],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            reportClassifierTemp.append(xgClassifier(xTrainBinary, xValBinary, xTestBinary, yTrainBinary, yValBinary, yTestBinary,))\n",
    "\n",
    "        reportFormatter(\n",
    "            reportClassifierTemp, True, classifierReports, regressorReports, participant, combination, \"Nan\",\n",
    "        )\n",
    "        reportFormatter(\n",
    "            reportCarbTemp, False, classifierReports, regressorReports, participant, combination, \"Carb\",\n",
    "        )\n",
    "        reportFormatter(\n",
    "            reportFatTemp, False, classifierReports, regressorReports, participant, combination, \"Fat\",\n",
    "        )\n",
    "        reportFormatter(\n",
    "            reportProteinTemp, False, classifierReports, regressorReports, participant, combination, \"Protein\",\n",
    "        )\n",
    "    classifierReports = np.asarray(classifierReports)\n",
    "    regressorReports = np.asarray(regressorReports)\n",
    "    comboReport = np.vstack((classifierReports, regressorReports))\n",
    "    return comboReport\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix, \"FinalReport2.csv\")):\n",
    "    os.remove(os.path.join(addDataPrefix, \"FinalReport2.csv\"))\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"FinalReport2.csv\")):\n",
    "    combinations = [\n",
    "        [\"CGM\"],\n",
    "        [\"CGM\", \"F1\", \"F2\", \"F5\"],\n",
    "        [\"CGM\", \"BVP\", \"EDA\", \"HR\", \"Temperature\"],\n",
    "        [\"CGM\", \"BVP\", \"EDA\", \"HR\", \"Temperature\", \"F1\", \"F2\", \"F3\"],\n",
    "    ]\n",
    "    columns = dfFeatures.columns\n",
    "    reportHeaders = [\n",
    "        \"Accuracy-RMSE\",\n",
    "        \"Recall-RMSERelative\",\n",
    "        \"Precision-Macro\",\n",
    "        \"F1-NAN\",\n",
    "        \"Participant\",\n",
    "        \"Combination\",\n",
    "        \"Component\",\n",
    "    ]\n",
    "    dfReports = []\n",
    "    for combination in combinations:\n",
    "        columnList = [\n",
    "            \"Start\",\n",
    "            \"End\",\n",
    "            \"Participant\",\n",
    "            \"Carb\",\n",
    "            \"Fat\",\n",
    "            \"Protein\",\n",
    "            \"MealLabel\",\n",
    "        ]\n",
    "        for topic in combination:\n",
    "            for column in columns:\n",
    "                if topic in column:\n",
    "                    columnList.append(column)\n",
    "\n",
    "        dfCombination = dfFeatures[dfFeatures.columns.intersection(columnList)]\n",
    "        participantDataArray = dfCombination.to_numpy()\n",
    "        randomSeed = random.randrange(50)\n",
    "        print(\"----------------------\")\n",
    "        print(\"Combination:\", \"+\".join(combination))\n",
    "        NORMALIZED_FLAG = False\n",
    "        dfTemp = testTrainSplitFunc(participantDataArray, randomSeed, NORMALIZED_FLAG, \"+\".join(combination))\n",
    "        dfTemp = pd.DataFrame(dfTemp, columns=reportHeaders)\n",
    "        if len(dfReports) > 0:\n",
    "            frames = [dfTemp, dfReports]\n",
    "            dfReports = pd.concat(frames)\n",
    "        else:\n",
    "            dfReports = dfTemp\n",
    "    dfReports.reset_index(drop=True, inplace=True)\n",
    "    print(dfReports)\n",
    "    dfReports.to_csv(os.path.join(addDataPrefix, \"FinalReport2.csv\"), index=False)\n",
    "else:\n",
    "    dfReports = pd.read_csv(os.path.join(addDataPrefix, \"FinalReport2.csv\"))\n",
    "# print(\"**********************************\")\n",
    "# print(\"**********************************\")\n",
    "# print(\"With NORMALIZATION\")\n",
    "# NORMALIZED_FLAG=True\n",
    "# testTrainSplitFunc(participantDataArray,randomSeed,NORMALIZED_FLAG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReports = pd.read_csv(os.path.join(addDataPrefix, \"FinalReport.csv\"))\n",
    "dfReports.reset_index(drop=True, inplace=True)\n",
    "dfReports.replace(\"Nan\", np.nan, inplace=True)\n",
    "dfReports.replace(\"CGM+BVP+EDA+HR+Temperature\", \"C\", inplace=True)\n",
    "dfReports.replace(\"CGM+BVP+EDA+HR+Temperature\", \"CE\", inplace=True)\n",
    "dfReports.replace(\"CGM+F1+F2+F5\", \"CM\", inplace=True)\n",
    "dfReports.replace(\"CGM+BVP+EDA+HR+Temperature+F1+F2+F3\", \"CEM\", inplace=True)\n",
    "\n",
    "\n",
    "dfRegression = dfReports.copy(deep=True)\n",
    "dfRegression.drop([\"Precision-Macro\", \"F1-NAN\"], axis=1, inplace=True)\n",
    "dfRegression.dropna(inplace=True)\n",
    "\n",
    "dfCarb = dfRegression.copy(deep=True)\n",
    "dfProtein = dfRegression.copy(deep=True)\n",
    "dfFat = dfRegression.copy(deep=True)\n",
    "\n",
    "dfCarb = dfCarb[dfCarb[\"Component\"] == \"Carb\"]\n",
    "dfFat = dfFat[dfFat[\"Component\"] == \"Fat\"]\n",
    "dfProtein = dfProtein[dfProtein[\"Component\"] == \"Protein\"]\n",
    "\n",
    "dfCarb.sort_values([\"Comboniation\", \"Participant\"], ascending=(True, True), inplace=True)\n",
    "dfFat.sort_values([\"Comboniation\", \"Participant\"], ascending=(True, True), inplace=True)\n",
    "dfProtein.sort_values([\"Comboniation\", \"Participant\"], ascending=(True, True), inplace=True)\n",
    "\n",
    "dfCarb.reset_index(drop=True, inplace=True)\n",
    "dfFat.reset_index(drop=True, inplace=True)\n",
    "dfProtein.reset_index(drop=True, inplace=True)\n",
    "\n",
    "assert len(dfCarb) == len(dfFat)\n",
    "assert len(dfCarb) == len(dfProtein)\n",
    "\n",
    "dfCarb.insert(len(dfCarb.columns), \"CarbRMSE\", -1)\n",
    "dfCarb.insert(len(dfCarb.columns), \"CarbRMSERelative\", -1)\n",
    "\n",
    "dfCarb.insert(len(dfCarb.columns), \"FatRMSE\", -1)\n",
    "dfCarb.insert(len(dfCarb.columns), \"FatRMSERelative\", -1)\n",
    "\n",
    "dfCarb.insert(len(dfCarb.columns), \"ProteinRMSE\", -1)\n",
    "dfCarb.insert(len(dfCarb.columns), \"ProteinRMSERelative\", -1)\n",
    "\n",
    "# for counter in range(len(dfCarb)):\n",
    "dfCarb[\"CarbRMSE\"] = dfCarb[\"Accuracy-RMSE\"]\n",
    "dfCarb[\"CarbRMSERelative\"] = dfCarb[\"Recall-RMSERelative\"]\n",
    "\n",
    "dfCarb[\"FatRMSE\"] = dfFat[\"Accuracy-RMSE\"]\n",
    "dfCarb[\"FatRMSERelative\"] = dfFat[\"Recall-RMSERelative\"]\n",
    "\n",
    "dfCarb[\"ProteinRMSE\"] = dfProtein[\"Accuracy-RMSE\"]\n",
    "dfCarb[\"ProteinRMSERelative\"] = dfProtein[\"Recall-RMSERelative\"]\n",
    "\n",
    "dfCarb.drop([\"Recall-RMSERelative\", \"Accuracy-RMSE\", \"Component\"], axis=1, inplace=True)\n",
    "dfCarb = dfCarb[dfCarb[\"Participant\"] != \"All\"]\n",
    "\n",
    "\n",
    "# dfCarb=dfCarb.groupby(['Comboniation']).mean()\n",
    "# print(dfCarb)\n",
    "# dfCarb.plot(kind='bar',x='Comboniation',y=['CarbRMSERelative','FatRMSERelative','ProteinRMSERelative'])\n",
    "# print(dfCarb.groupby(['Participant']).mean())\n",
    "print(dfCarb.groupby([\"Comboniation\"]).mean())\n",
    "\n",
    "\n",
    "# dfTemp=dfCarb[dfCarb['Participant']=='p3']\n",
    "# participants=dfCarb['Participant'].to_list()\n",
    "# participants=set(list(participants))\n",
    "# for participant in participants:\n",
    "\n",
    "\n",
    "# carb=dfTemp['CarbRMSERelative'].to_list()\n",
    "# fat=dfTemp['FatRMSERelative'].to_list()\n",
    "# protein=dfTemp['ProteinRMSERelative'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = list(set(dfMeal[\"Participant\"].to_list()))\n",
    "for participant in participants:\n",
    "    print(participant, \"---------\")\n",
    "    dfTemp = dfMeal[dfMeal[\"Participant\"] == participant]\n",
    "    duration = dfTemp[\"FinishTime\"] - dfTemp[\"StartTime\"]\n",
    "    duration = duration.dt.seconds\n",
    "\n",
    "    print(dfTemp[\"Carbs\"].max(), dfTemp[\"Carbs\"].min())\n",
    "    # print(duration.mean()/60,duration.std()/60)\n",
    "    # print(dfTemp['Carbs'].mean(),dfTemp['Carbs'].std())\n",
    "    # print(dfTemp['Fat'].mean(),dfTemp['Fat'].std())\n",
    "    # print(dfTemp['Protein'].mean(),dfTemp['Protein'].std())\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65e249be015da37cfe4cfdd1da028fe4cb475c26be679b9e3e34696278a17c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
