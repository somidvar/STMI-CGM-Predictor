{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from dateutil.tz import tzutc\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from scipy.stats import pearsonr, mode, skew, kurtosis\n",
    "from scipy.signal import savgol_filter\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, ShuffleSplit\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "OUTTER_WINDOW_LENGTH = timedelta(minutes=60)\n",
    "INNER_WINDOW_LENGTH = timedelta(seconds=60)\n",
    "COMPLEX_MEAL_LENGTH = timedelta(minutes=180)\n",
    "FASTING_LENGTH = timedelta(minutes=30)\n",
    "MINIMUM_POINT = INNER_WINDOW_LENGTH.total_seconds()\n",
    "\n",
    "START_OF_TRIAL = datetime.strptime(\"11 06 2021-02:00:00\", \"%m %d %Y-%H:%M:%S\")  # to handle the daylight saving issue in apple watches\n",
    "END_OF_TRIAL = datetime.strptime(\"11 15 2021-00:00:00\", \"%m %d %Y-%H:%M:%S\")\n",
    "\n",
    "\n",
    "addDataPrefix = \"/Users/sorush/My Drive/Documents/Educational/TAMU/Research/Trial/Data/11-5-21-11-15-21\"\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"/home/grads/s/sorush.omidvar/CGMDataset/Trial/Data/11-5-21-11-15-21\"\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"C:\\\\GDrive\\\\Documents\\\\Educational\\\\TAMU\\\\Research\\\\Trial\\\\Data\\\\11-5-21-11-15-21\"\n",
    "\n",
    "addUserInput = os.path.join(addDataPrefix, \"User inputted\")\n",
    "addHKCM = os.path.join(addDataPrefix, \"hk+cm\")\n",
    "addCGM = os.path.join(addDataPrefix, \"CGM\")\n",
    "addE4 = os.path.join(addDataPrefix, \"E4\")\n",
    "\n",
    "exempts = [\"p2\"]\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({\"figure.facecolor\": \"white\"})\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # no GPU\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ... p3Meals-Modified.xlsx\n",
      "Reading ... p4Meals-Modified.xlsx\n",
      "Reading ... p1Meals-Modified.xlsx\n",
      "reading is done\n",
      "Meal database is limited to the trial period\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(os.path.join(addDataPrefix, \"Results\", \"All_meals.pkl\")):\n",
    "    os.remove(os.path.join(addDataPrefix, \"Results\", \"All_meals.pkl\"))\n",
    "os.chdir(addUserInput)\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"Results\", \"All_meals.pkl\")):\n",
    "    dfMeal = []\n",
    "    for root, dirs, files in os.walk(addUserInput):\n",
    "        for file in files:\n",
    "            if \".xlsx\" in file.lower():\n",
    "                if \"meals-modified\" in file.lower():\n",
    "                    participantName = file[: file.find(\"Meals\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_excel(file)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    dfTemp.drop(columns=[\"startTime\", \"FinishTime\", \"Duration\"], inplace=True)\n",
    "                    dfTemp.rename(columns={\"startTimeModified\": \"StartTime\"}, inplace=True)\n",
    "                    dfTemp.rename(columns={\"FinishTimeModified\": \"FinishTime\"}, inplace=True)\n",
    "                    dfTemp[\"StartTime\"] = pd.to_datetime(dfTemp[\"StartTime\"])\n",
    "                    dfTemp[\"FinishTime\"] = pd.to_datetime(dfTemp[\"FinishTime\"])\n",
    "                    dfTemp = dfTemp[dfTemp[\"StartTime\"].notna()]\n",
    "                    # dfTemp['StartTime']-=pd.DateOffset(hours=5)#fixing the time zone issue\n",
    "                    # dfTemp['FinishTime']-=pd.DateOffset(hours=5)#fixing the time zone issue\n",
    "                    dfTemp.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "                    for counter in range(1, len(dfTemp)):\n",
    "                        if dfTemp[\"StartTime\"].iloc[counter] == dfTemp[\"StartTime\"].iloc[counter - 1]:\n",
    "                            dfTemp[\"Carbs\"].iloc[counter] += dfTemp[\"Carbs\"].iloc[counter - 1]\n",
    "                            dfTemp[\"Fat\"].iloc[counter] += dfTemp[\"Fat\"].iloc[counter - 1]\n",
    "                            dfTemp[\"Protein\"].iloc[counter] += dfTemp[\"Protein\"].iloc[counter - 1]\n",
    "                            dfTemp[\"StartTime\"].iloc[counter] = \"\"\n",
    "                    dfTemp = dfTemp[dfTemp[\"StartTime\"].notna()]\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "                    for counter in range(1, len(dfTemp)):\n",
    "                        if dfTemp[\"StartTime\"].iloc[counter] - dfTemp[\"StartTime\"].iloc[counter - 1] <= timedelta(hours=1):\n",
    "                            print(\"The meals are not compressed for participant:\", participantName, dfTemp[\"StartTime\"].iloc[counter], dfTemp[\"StartTime\"].iloc[counter - 1])\n",
    "                            print(dfTemp)\n",
    "                            os._exit()\n",
    "                    if len(dfMeal) != 0:\n",
    "                        frames = [dfTemp, dfMeal]\n",
    "                        dfMeal = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfMeal = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfMeal = dfMeal[dfMeal[\"StartTime\"] >= START_OF_TRIAL]\n",
    "    dfMeal = dfMeal[dfMeal[\"FinishTime\"] < END_OF_TRIAL]\n",
    "    dfMeal.reset_index(drop=True, inplace=True)\n",
    "    print(\"Meal database is limited to the trial period\")\n",
    "    dfMeal.to_pickle(os.path.join(addDataPrefix, \"Results\", \"All_meals.pkl\"))\n",
    "else:\n",
    "    dfMeal = pd.read_pickle(os.path.join(addDataPrefix, \"Results\", \"All_meals.pkl\"))\n",
    "\n",
    "\n",
    "def pdInterpolation(dfTemp):\n",
    "    index = dfTemp[\"Time\"]\n",
    "    seriesParticipant = pd.Series(dfTemp[\"Abbot\"].to_list(), index=index)\n",
    "    seriesParticipant = seriesParticipant.resample(\"1T\").asfreq()\n",
    "    seriesParticipant.interpolate(method=\"polynomial\", order=3, inplace=True)\n",
    "    tempTime = seriesParticipant.index\n",
    "    tempVal = seriesParticipant.values\n",
    "    dfTemp = pd.DataFrame(zip(tempTime, tempVal), columns=[\"Time\", \"Abbot\"])\n",
    "    return dfTemp\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addDataPrefix,\"Results\",'All_cgm.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,\"Results\",'All_cgm.pkl'))\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"Results\", \"All_cgm.pkl\")):\n",
    "    os.chdir(addCGM)\n",
    "    dfCGM = []\n",
    "    for root, dirs, files in os.walk(addCGM):\n",
    "        for file in files:\n",
    "            if \".txt\" in file.lower():\n",
    "                if \"_fl\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_fl\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file, sep=\"\\t\", skiprows=1)\n",
    "                    if len(dfTemp.columns) != 4:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    dfTemp.columns.values[0] = \"ID\"\n",
    "                    dfTemp.columns.values[1] = \"Time\"\n",
    "                    dfTemp.columns.values[2] = \"Record\"\n",
    "                    dfTemp.columns.values[3] = \"Abbot\"\n",
    "                    dfTemp.drop(columns=[\"ID\", \"Record\"], inplace=True)\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"])\n",
    "                    dfTemp[\"Abbot\"] = pd.to_numeric(dfTemp[\"Abbot\"])\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                    dfTemp = pdInterpolation(dfTemp)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    if len(dfTemp.columns) != 3:\n",
    "                        print(\"MAYDAY. Error in processing csv\")\n",
    "                        break\n",
    "                    if len(dfCGM) != 0:\n",
    "                        frames = [dfTemp, dfCGM]\n",
    "                        dfCGM = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfCGM = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfCGM = dfCGM[dfCGM[\"Time\"] >= START_OF_TRIAL]\n",
    "    dfCGM = dfCGM[dfCGM[\"Time\"] < END_OF_TRIAL]\n",
    "    print(\"CGM database is limited to the trial period\")\n",
    "    dfCGM.to_pickle(os.path.join(addDataPrefix, \"Results\", \"All_cgm.pkl\"))\n",
    "else:\n",
    "    dfCGM = pd.read_pickle(os.path.join(addDataPrefix, \"Results\", \"All_cgm.pkl\"))\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addDataPrefix,\"Results\",'All_cm.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,\"Results\",'All_cm.pkl'))\n",
    "os.chdir(addHKCM)\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"Results\", \"All_cm.pkl\")):\n",
    "    df = []\n",
    "    for root, dirs, files in os.walk(addHKCM):\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                if \"cm\" in file.lower() and \"modified\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_cm\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    print(\"File is read\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"])\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Ax|+|Ay|+|Az|\", dfTemp[\"Ax\"].abs() + dfTemp[\"Ay\"].abs() + dfTemp[\"Az\"].abs() + 0.001)  # this is to avoid 0 later on for feature calculation\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Yaw|+|Roll|+|Pitch|\", dfTemp[\"Yaw\"].abs() + dfTemp[\"Roll\"].abs() + dfTemp[\"Pitch\"].abs())\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\", dfTemp[\"Rx\"].abs() + dfTemp[\"Ry\"].abs() + dfTemp[\"Rz\"].abs())\n",
    "                    dfTemp[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"] = dfTemp[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"]\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"RotationalToLinear\", dfTemp[\"|Yaw|+|Roll|+|Pitch|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"])\n",
    "                    print(\"modified\")\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                    print(\"sorted\")\n",
    "                    if len(dfTemp.columns) != 15:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        print(dfTemp.columns)\n",
    "                        break\n",
    "                    if len(df) != 0:\n",
    "                        frames = [dfTemp, df]\n",
    "                        df = pd.concat(frames)\n",
    "                    else:\n",
    "                        df = dfTemp\n",
    "    dfCM = df\n",
    "    print(\"Processing is done\")\n",
    "    dfCM = dfCM[dfCM[\"Time\"] >= START_OF_TRIAL]\n",
    "    dfCM = dfCM[dfCM[\"Time\"] < END_OF_TRIAL]\n",
    "    print(\"CM database is limited to the trial period\")\n",
    "    dfCM.to_pickle(os.path.join(addDataPrefix, \"Results\", \"All_cm.pkl\"))\n",
    "else:\n",
    "    dfCM = pd.read_pickle(os.path.join(addDataPrefix, \"Results\", \"All_cm.pkl\"))\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addDataPrefix, \"Results\",'All_E4.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix, \"Results\",'All_E4.pkl'))\n",
    "os.chdir(addE4)\n",
    "# fields=['ACC','BVP','EDA','HR','IBI','TEMP']\n",
    "fields = [\"BVP\", \"EDA\", \"HR\", \"TEMP\"]\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"Results\", \"All_E4.pkl\")):\n",
    "    dfE4 = []\n",
    "    for root, dirs, files in os.walk(addE4):\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                participantName = root[root.find(\"E4\") + 3 :]\n",
    "                participantName = participantName[:2]\n",
    "                field = file[: file.find(\".csv\")]\n",
    "                if field not in fields:\n",
    "                    print(\"File name does not comply with analyzed fields\", file)\n",
    "                    continue\n",
    "                print(participantName, field)\n",
    "                if participantName in exempts:\n",
    "                    print(\"Exemption...\", file)\n",
    "                    continue\n",
    "                print(\"Reading ...\", file)\n",
    "                os.chdir(root)\n",
    "                dfTemp = pd.read_csv(file, header=None)\n",
    "                # if field=='ACC':\n",
    "                #     assert len(dfTemp.columns)==3\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     timeStep=1/dfTemp.iloc[1,0]\n",
    "                #     dfTemp.drop([0,1],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Data1',1:'Data2',2:'Data3'}, inplace=True)#x,y,z for data1,data2,data3\n",
    "                #     timeTemp=[]\n",
    "                #     for counter in range(len(dfTemp)):\n",
    "                #         timeTemp.append(timeBase+counter*timeStep)\n",
    "                #     dfTemp.insert(0,'Time',timeTemp)\n",
    "                #     dfTemp.insert(0,'Field',\"Acceleration\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                if field == \"BVP\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"BVP\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                elif field == \"HR\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"HR\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                elif field == \"EDA\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"EDA\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                # elif field=='IBI':\n",
    "                #     assert len(dfTemp.columns)==2\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     dfTemp.drop([0],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Time',1:'Data1'}, inplace=True)\n",
    "                #     dfTemp[\"Data2\"]=\"\"\n",
    "                #     dfTemp[\"Data3\"]=\"\"\n",
    "                #     timeTemp=[]\n",
    "                #     dfTemp['Time']+=timeBase\n",
    "                #     dfTemp.insert(0,'Field',\"IBI\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                elif field == \"TEMP\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"Temperature\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                dfTemp.insert(0, \"Participant\", participantName)\n",
    "\n",
    "                dfTemp[\"Time\"] -= pd.DateOffset(hours=6)  # Empatica records in GMT and also during the trial we had daylight saving\n",
    "                dfTemp.sort_values([\"Participant\", \"Field\", \"Time\"], ascending=(True, True, True), inplace=True)\n",
    "                if len(dfTemp.columns) != 6:\n",
    "                    print(\"MAYDAY. Error in reading csv\")\n",
    "                    break\n",
    "                if len(dfE4) != 0:\n",
    "                    frames = [dfTemp, dfE4]\n",
    "                    dfE4 = pd.concat(frames)\n",
    "                else:\n",
    "                    dfE4 = dfTemp\n",
    "\n",
    "    print(\"reading is done\")\n",
    "    dfE4 = dfE4[dfE4[\"Time\"] >= START_OF_TRIAL]\n",
    "    dfE4 = dfE4[dfE4[\"Time\"] < END_OF_TRIAL]\n",
    "    print(\"E4 database is limited to the trial period\")\n",
    "    dfE4.to_pickle(os.path.join(addDataPrefix, \"Results\", \"All_E4.pkl\"))\n",
    "else:\n",
    "    dfE4 = pd.read_pickle(os.path.join(addDataPrefix, \"Results\", \"All_E4.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619\n",
      "590\n"
     ]
    }
   ],
   "source": [
    "def e4Reporter(df):\n",
    "    topics = [\"BVP\", \"EDA\", \"HR\", \"Temperature\"]\n",
    "    report = []\n",
    "    for topic in topics:\n",
    "        dfTemp = df[df[\"Field\"] == topic]\n",
    "        if topic == \"BVP\":\n",
    "            MIN_POINT = MINIMUM_POINT * 64 * 0.3\n",
    "        elif topic == \"EDA\":\n",
    "            MIN_POINT = MINIMUM_POINT * 4 * 0.3\n",
    "        elif topic == \"HR\":\n",
    "            MIN_POINT = MINIMUM_POINT / 10 * 0.3\n",
    "        elif topic == \"Temperature\":\n",
    "            MIN_POINT = MINIMUM_POINT * 4 * 0.3\n",
    "        else:\n",
    "            print(\"MAYDAY at sensor reader\")\n",
    "            os._exit()\n",
    "        if len(dfTemp) < MIN_POINT:\n",
    "            report.append(\"Nan\")\n",
    "        else:\n",
    "            val = dfTemp[\"Data1\"].mean()\n",
    "            report.append(val)\n",
    "    return report\n",
    "\n",
    "\n",
    "def motionCalculator(df):\n",
    "    f1 = df[\"RotationalToLinear\"].mean()\n",
    "    f2 = df[\"|Ax|+|Ay|+|Az|\"].mean()\n",
    "    f3 = df[\"|Yaw|+|Roll|+|Pitch|\"].mean()\n",
    "    f4 = df[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"].mean()\n",
    "    return [f1, f2, f3, f4]\n",
    "\n",
    "\n",
    "def statFeatures(dataList):\n",
    "    dataList = np.asarray(dataList).astype(float)\n",
    "    result = []\n",
    "    dataDim = dataList.ndim\n",
    "    if dataDim > 1:\n",
    "        for counter in range(dataList.shape[1]):\n",
    "            if not np.isnan(dataList[:, counter]).all():\n",
    "                meanVal = np.nanmean(dataList[:, counter], axis=0)\n",
    "                stdVal = np.nanstd(dataList[:, counter], axis=0)\n",
    "                minVal = np.nanmin(dataList[:, counter], axis=0)\n",
    "                maxVal = np.nanmax(dataList[:, counter], axis=0)\n",
    "                rangeVal = maxVal - minVal\n",
    "                skewnessVal = skew(dataList[:, counter], nan_policy=\"omit\", axis=0)\n",
    "                kurtosisVal = kurtosis(dataList[:, counter], nan_policy=\"omit\", axis=0)\n",
    "                result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal])\n",
    "            else:\n",
    "                result.extend([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    else:\n",
    "        if not np.isnan(dataList).all():\n",
    "            meanVal = np.nanmean(dataList)\n",
    "            stdVal = np.nanstd(dataList)\n",
    "            minVal = np.nanmin(dataList)\n",
    "            maxVal = np.nanmax(dataList)\n",
    "            rangeVal = maxVal - minVal\n",
    "            skewnessVal = skew(dataList, nan_policy=\"omit\")\n",
    "            kurtosisVal = kurtosis(dataList, nan_policy=\"omit\")\n",
    "            result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal])\n",
    "        else:\n",
    "            result.extend([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    return result\n",
    "\n",
    "\n",
    "# def dataframeQuerry(df,start,end):\n",
    "#     dfTemp=\n",
    "\n",
    "\n",
    "def innerWindowExtractor(outterWindowStart, outterWindowEnd, innerWindowNumber, dfParticipantCM, dfParticipantE4):\n",
    "    tempListCM = []\n",
    "    tempListE4 = []\n",
    "    dfParticipantCMTemp = dfParticipantCM[dfParticipantCM[\"Time\"] >= outterWindowStart]\n",
    "    dfParticipantCMTemp = dfParticipantCMTemp[dfParticipantCMTemp[\"Time\"] < outterWindowEnd]\n",
    "\n",
    "    dfParticipantE4Temp = dfParticipantE4[dfParticipantE4[\"Time\"] >= outterWindowStart]\n",
    "    dfParticipantE4Temp = dfParticipantE4Temp[dfParticipantE4Temp[\"Time\"] < outterWindowEnd]\n",
    "    for counterInner in range(0, innerWindowNumber, 1):\n",
    "        innerWindowStart = outterWindowStart + counterInner * INNER_WINDOW_LENGTH\n",
    "        innerWindowEnd = innerWindowStart + INNER_WINDOW_LENGTH\n",
    "        dfTempCM = dfParticipantCMTemp[dfParticipantCMTemp[\"Time\"] >= innerWindowStart]\n",
    "        dfTempCM = dfTempCM[dfTempCM[\"Time\"] < innerWindowEnd]\n",
    "        if len(dfTempCM) < MINIMUM_POINT * 10 * 0.3:\n",
    "            tempListCM.append([\"Nan\", \"Nan\", \"Nan\", \"Nan\"])\n",
    "        else:\n",
    "            tempListCM.append(motionCalculator(dfTempCM))\n",
    "\n",
    "        dfTempE4 = dfParticipantE4Temp[dfParticipantE4Temp[\"Time\"] >= innerWindowStart]\n",
    "        dfTempE4 = dfTempE4[dfTempE4[\"Time\"] < innerWindowEnd]\n",
    "        if len(dfTempE4) < MINIMUM_POINT * 32 * 0.3:\n",
    "            tempListE4.append([\"Nan\", \"Nan\", \"Nan\", \"Nan\"])\n",
    "        else:\n",
    "            tempListE4.append(e4Reporter(dfTempE4))\n",
    "\n",
    "    return tempListCM, tempListE4\n",
    "\n",
    "\n",
    "def outterPosWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant):\n",
    "    print(\"Positive windows:\")\n",
    "    participantDataList = []\n",
    "    lagBeforeMeals = [timedelta(minutes=-30), timedelta(minutes=-15), timedelta(minutes=0), timedelta(minutes=15)]\n",
    "    for counterOuter in tqdm(range(0, len(dfParticipantMeal))):\n",
    "        for lagBeforeMeal in lagBeforeMeals:\n",
    "            outterWindowStart = dfParticipantMeal[\"StartTime\"].iloc[counterOuter] + lagBeforeMeal\n",
    "            outterWindowEnd = outterWindowStart + OUTTER_WINDOW_LENGTH\n",
    "            innerWindowNumber = int(OUTTER_WINDOW_LENGTH.total_seconds() / INNER_WINDOW_LENGTH.total_seconds())\n",
    "            tempListInfo = [outterWindowStart, outterWindowEnd, participant]\n",
    "            tempList = []\n",
    "\n",
    "            tempListCM, tempListE4 = innerWindowExtractor(outterWindowStart, outterWindowEnd, innerWindowNumber, dfParticipantCM, dfParticipantE4)\n",
    "\n",
    "            carbs = dfParticipantMeal[\"Carbs\"].iloc[counterOuter]\n",
    "            protein = dfParticipantMeal[\"Protein\"].iloc[counterOuter]\n",
    "            fat = dfParticipantMeal[\"Fat\"].iloc[counterOuter]\n",
    "\n",
    "            tempListCM = statFeatures(tempListCM)\n",
    "            tempList.extend(tempListCM)  # 7*4=28\n",
    "\n",
    "            tempListE4 = statFeatures(tempListE4)\n",
    "            tempList.extend(tempListE4)  # 7*4=28\n",
    "\n",
    "            dfTempCGM = dfParticipantCGM[(dfParticipantCGM[\"Time\"] >= outterWindowStart) & (dfParticipantCGM[\"Time\"] < outterWindowEnd)]\n",
    "            tempListCGM = dfTempCGM[\"Abbot\"].to_list()\n",
    "            tempListCGM = statFeatures(tempListCGM)\n",
    "            tempList.extend(tempListCGM)  # 7\n",
    "            tempList.extend(tempListInfo)  # 3\n",
    "            tempList.append(carbs)\n",
    "            tempList.append(fat)\n",
    "            tempList.append(protein)\n",
    "            tempList.append(1)  # mealFlag\n",
    "            assert len(tempList) == 7 * 4 + 7 * 4 + 7 + 3 + 4\n",
    "            participantDataList.append(tempList)\n",
    "    return participantDataList\n",
    "\n",
    "\n",
    "def outterNegWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant):\n",
    "    print(\"Negative windows:\")\n",
    "    participantDataList = []\n",
    "    gaps = []\n",
    "\n",
    "    for counterOuter in range(1, len(dfParticipantMeal)):\n",
    "        if dfParticipantMeal[\"StartTime\"].iloc[counterOuter] - dfParticipantMeal[\"StartTime\"].iloc[counterOuter - 1] >= FASTING_LENGTH:\n",
    "            gaps.append([dfParticipantMeal[\"StartTime\"].iloc[counterOuter - 1], dfParticipantMeal[\"StartTime\"].iloc[counterOuter]])\n",
    "\n",
    "    if participant == \"p1\":  # to avoid CGM have a santizied data, I am throwing more negative winodws\n",
    "        P1_FASTING_DAY = datetime.strptime(\"11 14 2021-08:00:00\", \"%m %d %Y-%H:%M:%S\")\n",
    "        gaps.append([P1_FASTING_DAY, P1_FASTING_DAY + timedelta(hours=10)])\n",
    "\n",
    "    for counterOuter in tqdm(range(len(gaps))):\n",
    "        querryTemp = gaps[counterOuter]\n",
    "        querryStart = querryTemp[0] + FASTING_LENGTH\n",
    "        querryEnd = querryTemp[1] - FASTING_LENGTH\n",
    "        querryWindNum = datetime.timestamp(querryEnd) - datetime.timestamp(querryStart)\n",
    "        querryWindNum = int(querryWindNum / OUTTER_WINDOW_LENGTH.total_seconds())\n",
    "\n",
    "        for counter in range(querryWindNum):\n",
    "            outterWindowStart = querryStart + counter * OUTTER_WINDOW_LENGTH\n",
    "            outterWindowEnd = outterWindowStart + OUTTER_WINDOW_LENGTH\n",
    "\n",
    "            dfTempE4 = dfParticipantE4[dfParticipantE4[\"Time\"] >= outterWindowStart]\n",
    "            dfTempE4 = dfTempE4[dfTempE4[\"Time\"] < outterWindowEnd]\n",
    "            if len(dfTempE4) < OUTTER_WINDOW_LENGTH.total_seconds() * (64 + 4 + 4) * 0.3:\n",
    "                print(\"Not enough data for E4\", outterWindowStart, outterWindowEnd)\n",
    "                continue\n",
    "\n",
    "            dfTempCM = dfParticipantCM[dfParticipantCM[\"Time\"] >= outterWindowStart]\n",
    "            dfTempCM = dfTempCM[dfTempCM[\"Time\"] < outterWindowEnd]\n",
    "            if len(dfTempCM) < OUTTER_WINDOW_LENGTH.total_seconds() * 10 * 0.3:\n",
    "                print(\"Not enough data for Apple\", outterWindowStart, outterWindowEnd)\n",
    "                continue\n",
    "\n",
    "            innerWindowNumber = int(OUTTER_WINDOW_LENGTH.total_seconds() / INNER_WINDOW_LENGTH.total_seconds())\n",
    "            tempListInfo = [outterWindowStart, outterWindowEnd, participant]\n",
    "            tempList = []\n",
    "            tempListCM, tempListE4 = innerWindowExtractor(outterWindowStart, outterWindowEnd, innerWindowNumber, dfParticipantCM, dfParticipantE4)\n",
    "\n",
    "            carbs = 0\n",
    "            protein = 0\n",
    "            fat = 0\n",
    "\n",
    "            tempListCM = statFeatures(tempListCM)\n",
    "            tempList.extend(tempListCM)  # 7*4=28\n",
    "\n",
    "            tempListE4 = statFeatures(tempListE4)\n",
    "            tempList.extend(tempListE4)  # 7*4=28\n",
    "\n",
    "            dfTempCGM = dfParticipantCGM[(dfParticipantCGM[\"Time\"] >= outterWindowStart) & (dfParticipantCGM[\"Time\"] < outterWindowEnd)]\n",
    "            tempListCGM = dfTempCGM[\"Abbot\"].to_list()\n",
    "            tempListCGM = statFeatures(tempListCGM)\n",
    "            tempList.extend(tempListCGM)  # 7\n",
    "            tempList.extend(tempListInfo)  # 3\n",
    "\n",
    "            tempList.append(carbs)\n",
    "            tempList.append(fat)\n",
    "            tempList.append(protein)\n",
    "            tempList.append(0)  # mealFlag\n",
    "            assert len(tempList) == 7 * 4 + 7 * 4 + 7 + 3 + 4\n",
    "            participantDataList.append(tempList)\n",
    "            # if counter==2:\n",
    "            #     break  # Making sure that each positive window has two negative window afterward at max and also the negative window is located close to a positive one\n",
    "    return participantDataList\n",
    "\n",
    "\n",
    "def participantFeatureWriter(participantDataList, participant):\n",
    "    participantDataArray = np.asarray(participantDataList)\n",
    "    columnTopics = [\"F1\", \"F2\", \"F3\", \"F4\", \"BVP\", \"EDA\", \"HR\", \"Temperature\", \"CGM\"]\n",
    "    columnStats = [\"Range\", \"Mean\", \"Std\", \"Min\", \"Max\", \"Skewness\", \"Kurtosis\"]\n",
    "    columns = []\n",
    "    for topic in columnTopics:\n",
    "        for stat in columnStats:\n",
    "            columns.append(topic + \"-\" + stat)\n",
    "    columns.extend([\"StartTime\", \"EndTime\", \"Participant\", \"Carb\", \"Fat\", \"Protein\", \"MealLabel\"])\n",
    "    dfFeatures = pd.DataFrame(participantDataArray, columns=columns)\n",
    "    dfFeatures.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    dfFeatures.reset_index(drop=True, inplace=True)\n",
    "    dfFeatures.insert(len(dfFeatures.columns), \"ComplexFlag\", 0)\n",
    "    for counter in range(1, len(dfFeatures)):\n",
    "        if dfFeatures[\"StartTime\"].iloc[counter] <= dfFeatures[\"StartTime\"].iloc[counter - 1] + COMPLEX_MEAL_LENGTH:\n",
    "            dfFeatures[\"ComplexFlag\"].iloc[counter - 1] = 1\n",
    "    dfFeatures.to_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + participant + \"-Features.xlsx\")), index=False)\n",
    "\n",
    "\n",
    "def allFeatureWriter(participants):\n",
    "    dfFeatures = []\n",
    "    for participant in participants:\n",
    "        if participant in exempts:\n",
    "            continue\n",
    "        if not os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + participant + \"-Features.xlsx\"))):\n",
    "            print(\"MAYDAY, no feature for participant:\", participant)\n",
    "            continue\n",
    "        dfTemp = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + participant + \"-Features.xlsx\")))\n",
    "        if len(dfFeatures) == 0:\n",
    "            dfFeatures = dfTemp\n",
    "        else:\n",
    "            frames = [dfTemp, dfFeatures]\n",
    "            dfFeatures = pd.concat(frames)\n",
    "    dfFeatures.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    dfFeatures.reset_index(drop=True, inplace=True)\n",
    "    dfFeatures.to_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\")), index=False)\n",
    "    return dfFeatures\n",
    "\n",
    "\n",
    "participants = dfCM[\"Participant\"].to_list()\n",
    "participants = list(set(participants))\n",
    "# if os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\"))):\n",
    "#     os.remove(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\")))\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\"))):\n",
    "    for participant in participants:\n",
    "        if participant in exempts:\n",
    "            continue\n",
    "        # if os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + participant+\"-Features.xlsx\"))):\n",
    "        #     os.remove(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + participant+\"-Features.xlsx\")))\n",
    "        if not os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + participant + \"-Features.xlsx\"))):\n",
    "            print(\"Participant \", participant, \" is started\")\n",
    "            dfParticipantCM = dfCM[dfCM[\"Participant\"] == participant]\n",
    "            dfParticipantMeal = dfMeal[dfMeal[\"Participant\"] == participant]\n",
    "            dfParticipantCGM = dfCGM[dfCGM[\"Participant\"] == participant]\n",
    "            dfParticipantE4 = dfE4[dfE4[\"Participant\"] == participant]\n",
    "\n",
    "            participantDataList = outterPosWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant)\n",
    "            participantDataList.extend(outterNegWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant))\n",
    "            participantFeatureWriter(participantDataList, participant)\n",
    "    dfFeatures = allFeatureWriter(participants)\n",
    "else:\n",
    "    dfFeatures = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\")))\n",
    "print(len(dfFeatures))\n",
    "dfFeatures.dropna(inplace=True)\n",
    "print(len(dfFeatures))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Combination: CGM+F1+F2+F3+F4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: p1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 0.8048117940935444\n",
      "p1 0.6381898007429924\n",
      "Participant: p4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:01<00:01,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p4 0.4237167277167277\n",
      "p4 0.2667810831426392\n",
      "Participant: p3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:02<00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p3 0.5018910680138765\n",
      "p3 0.6667826369543641\n",
      "Participant: All\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 0.575210136924276\n",
      "All 0.432923500761554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def rmseCalculator(trueGround, prediction):\n",
    "    rmse = 0\n",
    "    assert len(trueGround) == len(prediction)\n",
    "    for counter in range(len(trueGround)):\n",
    "        tempVal = trueGround[counter] - prediction[counter]\n",
    "        tempVal *= tempVal\n",
    "        rmse += tempVal\n",
    "    rmse /= len(trueGround)\n",
    "    rmse = np.sqrt(rmse)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def rmsleCalculator(trueGround, prediction):\n",
    "    rmsle = 0\n",
    "    assert len(trueGround) == len(prediction)\n",
    "    for counter in range(len(trueGround)):\n",
    "        tempVal = np.log(1 + prediction[counter]) - np.log(1 + trueGround[counter])\n",
    "        tempVal *= tempVal\n",
    "        rmsle += tempVal\n",
    "    rmsle /= len(trueGround)\n",
    "    rmsle = np.sqrt(rmsle)\n",
    "    return rmsle\n",
    "\n",
    "\n",
    "def randomForester(xTrain, xTest, yTrain, yTest):\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=3)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    predictionsTest = clf.predict(xTest)\n",
    "\n",
    "    confMatrix = sklearn.metrics.confusion_matrix(yTest, predictionsTest)\n",
    "    accuracy = sklearn.metrics.accuracy_score(yTest, predictionsTest)\n",
    "    recall = sklearn.metrics.recall_score(yTest, predictionsTest)\n",
    "    precision = sklearn.metrics.precision_score(yTest, predictionsTest)\n",
    "    f1Score = sklearn.metrics.f1_score(yTest, predictionsTest)\n",
    "    return [accuracy, recall, precision, f1Score]\n",
    "\n",
    "\n",
    "# def xgRegressor(xTrain, xVal, xTest, yTrain, yVal, yTest, headerNames):\n",
    "#     rmseBest = 100000000000\n",
    "#     for maxDepth in np.arange(2, 8, 1):\n",
    "#         for estimator in np.arange(50, 200, 50):\n",
    "#             clf = xgb.XGBRegressor(n_jobs=24, n_estimators=estimator, max_depth=maxDepth, objective=\"reg:squarederror\")\n",
    "#             # clf = xgb.XGBRegressor(n_jobs=24, n_estimators=estimator, max_depth=maxDepth, objective=\"reg:squaredlogerror\")\n",
    "#             clf.fit(xTrain, yTrain)\n",
    "#             predictionsVal = clf.predict(xVal)\n",
    "#             rmse = rmseCalculator(yVal, predictionsVal)\n",
    "#             rmsle = rmsleCalculator(yVal, predictionsVal)\n",
    "#             if rmse < rmseBest:\n",
    "#                 rmseBest = rmse\n",
    "#                 modelBest = clf\n",
    "\n",
    "#     predictionsTest = modelBest.predict(xTest)\n",
    "#     rmse = rmseCalculator(yTest, predictionsTest)\n",
    "#     rmsle = rmsleCalculator(yTest, predictionsTest)\n",
    "#     featureImportance = modelBest.feature_importances_\n",
    "#     return [rmse, rmsle, headerNames, featureImportance, yTest, predictionsTest]\n",
    "\n",
    "\n",
    "# def xgClassifier(xTrain, xVal, xTest, yTrain, yVal, yTest):\n",
    "#     f1ScoreBest = -1\n",
    "#     for maxDepth in np.arange(2, 6, 1):\n",
    "#         for estimator in np.arange(50, 200, 50):\n",
    "#             for posWeight in np.arange(1, 3, 0.5):\n",
    "#                 for featureLength in [8]:\n",
    "#                     clf = xgb.XGBClassifier(scale_pos_weight=posWeight, n_jobs=18, n_estimators=estimator, max_depth=maxDepth, objective=\"binary:logistic\", eval_metric=\"error\")\n",
    "#                     clf.fit(xTrain, yTrain)\n",
    "#                     featureImportanceTemp = clf.feature_importances_\n",
    "#                     featureImportanceTemp *= -1\n",
    "#                     sortedIndex = np.argsort(featureImportanceTemp)\n",
    "#                     if len(sortedIndex) > featureLength:\n",
    "#                         sortedIndex = sortedIndex[:featureLength]\n",
    "#                     xTrainTransform = xTrain[:, sortedIndex]\n",
    "#                     clf.fit(xTrainTransform, yTrain)\n",
    "#                     xValTransfore = xVal[:, sortedIndex]\n",
    "#                     predictionsVal = clf.predict(xValTransfore)\n",
    "\n",
    "#                     accuracy = sklearn.metrics.accuracy_score(yVal, predictionsVal)\n",
    "#                     recall = sklearn.metrics.recall_score(yVal, predictionsVal)\n",
    "#                     precision = sklearn.metrics.precision_score(yVal, predictionsVal)\n",
    "#                     f1Score = sklearn.metrics.f1_score(yVal, predictionsVal)\n",
    "\n",
    "#                     if f1Score > f1ScoreBest:\n",
    "#                         modelBest = clf\n",
    "#                         f1ScoreBest = f1Score\n",
    "#                         sortedIndexBest = sortedIndex\n",
    "#     xTestTransform = xTest[:, sortedIndexBest]\n",
    "#     predictionsTest = modelBest.predict(xTestTransform)\n",
    "#     confMatrix = sklearn.metrics.confusion_matrix(yTest, predictionsTest)\n",
    "#     accuracy = sklearn.metrics.accuracy_score(yTest, predictionsTest)\n",
    "#     recall = sklearn.metrics.recall_score(yTest, predictionsTest)\n",
    "#     precision = sklearn.metrics.precision_score(yTest, predictionsTest)\n",
    "#     f1Score = sklearn.metrics.f1_score(yTest, predictionsTest)\n",
    "#     return [accuracy, recall, precision, f1Score]\n",
    "\n",
    "\n",
    "def xgClassifier(xTrain, yTrain, xVal):\n",
    "    f1ScoreBest = -1\n",
    "    featureLength = 8\n",
    "\n",
    "    clf = xgb.XGBClassifier(scale_pos_weight=len(yTrain) / np.sum(yTrain), n_jobs=18, n_estimators=250, max_depth=4, objective=\"binary:logistic\", eval_metric=\"error\")\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    # featureImportanceTemp = clf.feature_importances_\n",
    "    # featureImportanceTemp *= -1\n",
    "    # sortedIndex = np.argsort(featureImportanceTemp)\n",
    "    # if len(sortedIndex) > featureLength:\n",
    "    #     sortedIndex = sortedIndex[:featureLength]\n",
    "    # xValTransform = xVal[:, sortedIndex]\n",
    "    predictionsVal = clf.predict_proba(xVal)\n",
    "    predictionsVal = predictionsVal[:, 0]\n",
    "\n",
    "    # confMatrix = sklearn.metrics.confusion_matrix(yTest, predictionsTest)\n",
    "    # accuracy = sklearn.metrics.accuracy_score(yTest, predictionsTest)\n",
    "    # recall = sklearn.metrics.recall_score(yTest, predictionsTest)\n",
    "    # precision = sklearn.metrics.precision_score(yTest, predictionsTest)\n",
    "    # f1Score = sklearn.metrics.f1_score(yTest, predictionsTest)\n",
    "\n",
    "    return predictionsVal\n",
    "\n",
    "\n",
    "def dataBalancer(xTrain, xVal, yTrain, yVal):\n",
    "    oversample = SMOTE()\n",
    "    xVal, yVal = oversample.fit_resample(xVal, yVal)\n",
    "    xTrain, yTrain = oversample.fit_resample(xTrain, yTrain)\n",
    "\n",
    "    return xTrain, xVal, yTrain, yVal\n",
    "\n",
    "\n",
    "def testTrainSplitFunc(dfCombination, randomSeed, normalFlag, combination):\n",
    "    participants = list(set(dfCombination[\"Participant\"].to_list()))\n",
    "    regressorReports = []\n",
    "    classifierReports = []\n",
    "    for participantCounter in tqdm(range(len(participants) + 1)):\n",
    "    # for participantCounter in tqdm(range(len(participants))):\n",
    "        if participantCounter == len(participants):  # General Model (one model for all participants)\n",
    "            dfParticipant = dfCombination\n",
    "            participant = \"All\"\n",
    "        else:  # Personal Model (each participant have a his/her own model)\n",
    "            participant = participants[participantCounter]\n",
    "            dfParticipant = dfCombination[dfCombination[\"Participant\"] == participant]\n",
    "\n",
    "        print(\"Participant:\", participant)\n",
    "\n",
    "        dfParticipant.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "        dfParticipant.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        positiveInd = dfParticipant[dfParticipant[\"MealLabel\"] == 1].index\n",
    "        negativeInd = dfParticipant[dfParticipant[\"MealLabel\"] == 0].index\n",
    "\n",
    "        positiveInd = positiveInd.to_list()\n",
    "        negativeInd = negativeInd.to_list()\n",
    "\n",
    "        positiveInd = np.asarray(positiveInd)\n",
    "        negativeInd = np.asarray(negativeInd)\n",
    "\n",
    "        kfPos = KFold(n_splits=5, shuffle=False)\n",
    "        setData = []\n",
    "        fSetData = []\n",
    "        for train_index, test_index in kfPos.split(positiveInd):\n",
    "            trainSet = positiveInd[train_index]\n",
    "            testSet = positiveInd[test_index]\n",
    "            trainTemp, testTemp, a, b = train_test_split(negativeInd, negativeInd, test_size=0.20, shuffle=False)\n",
    "            trainSet = list(trainSet)\n",
    "            testSet = list(testSet)\n",
    "            trainSet.extend(trainTemp)\n",
    "            testSet.extend(testTemp)\n",
    "\n",
    "            allColumns = dfParticipant.columns\n",
    "            columnToDrop = []\n",
    "            dfCGMCombo = dfParticipant.copy(deep=True)\n",
    "            for allColumn in allColumns:\n",
    "                if \"F1\" in allColumn or \"F2\" in allColumn or \"F3\" in allColumn or \"F4\" in allColumn:\n",
    "                    columnToDrop.append(allColumn)\n",
    "            dfCGMCombo.drop(columns=columnToDrop, inplace=True)\n",
    "            dataColumnIndex = dfCGMCombo.columns.get_loc(\"StartTime\")\n",
    "\n",
    "            dataX = dfCGMCombo[dfCGMCombo.columns[0:dataColumnIndex]].to_numpy()\n",
    "            dataY = dfCGMCombo[\"MealLabel\"].to_numpy()\n",
    "            dataX = dataX.astype(float)\n",
    "            dataY = dataY.astype(float)\n",
    "\n",
    "            trainXTemp = dataX[trainSet, :]\n",
    "            testXTemp = dataX[testSet, :]\n",
    "            trainYTemp = dataY[trainSet]\n",
    "            testYTemp = dataY[testSet]\n",
    "\n",
    "            valIndex = np.arange(1, len(trainXTemp), 2)\n",
    "            trainIndex = np.arange(0, len(trainXTemp), 2)\n",
    "\n",
    "            valXTemp = trainXTemp[valIndex, :]\n",
    "            valYTemp = trainYTemp[valIndex]\n",
    "            trainXTemp = trainXTemp[trainIndex, :]\n",
    "            trainYTemp = trainYTemp[trainIndex]\n",
    "            # probablityCGM = xgClassifier(trainXTemp, trainYTemp, valXTemp,)\n",
    "            \n",
    "            clf1 = xgb.XGBClassifier(scale_pos_weight=len(trainYTemp) / np.sum(trainYTemp), n_jobs=18, n_estimators=250, max_depth=4, objective=\"binary:logistic\", eval_metric=\"error\")\n",
    "            clf1.fit(trainXTemp, trainYTemp, verbose=3)\n",
    "            \n",
    "            predictionsValCGM = clf1.predict_proba(valXTemp)\n",
    "            predictionsValCGM = predictionsValCGM[:, 0] \n",
    "\n",
    "            predictionsTestCGM = clf1.predict_proba(testXTemp)\n",
    "            predictionsTestCGM = predictionsTestCGM[:, 0] \n",
    "\n",
    "            fTestCGM = clf1.predict(testXTemp)\n",
    "            fTest = sklearn.metrics.f1_score(testYTemp, fTestCGM)\n",
    "            fSetData.append(fTest)\n",
    "\n",
    "\n",
    "            allColumns = dfParticipant.columns\n",
    "            columnToDrop = []\n",
    "            dfWatchCombo = dfParticipant.copy(deep=True)\n",
    "            for allColumn in allColumns:\n",
    "                if \"CGM\" in allColumn:\n",
    "                    columnToDrop.append(allColumn)\n",
    "\n",
    "            dfWatchCombo.drop(columns=columnToDrop, inplace=True)\n",
    "            dataColumnIndex = dfWatchCombo.columns.get_loc(\"StartTime\")\n",
    "\n",
    "            dataX = dfWatchCombo[dfWatchCombo.columns[0:dataColumnIndex]].to_numpy()\n",
    "            dataY = dfWatchCombo[\"MealLabel\"].to_numpy()\n",
    "            dataX = dataX.astype(float)\n",
    "            dataY = dataY.astype(float)\n",
    "\n",
    "            trainXTemp = dataX[trainSet, :]\n",
    "            testXTemp = dataX[testSet, :]\n",
    "            trainYTemp = dataY[trainSet]\n",
    "            testYTemp = dataY[testSet]\n",
    "\n",
    "            valIndex = np.arange(1, len(trainXTemp), 2)\n",
    "            trainIndex = np.arange(0, len(trainXTemp), 2)\n",
    "\n",
    "            valXTemp = trainXTemp[valIndex, :]\n",
    "            valYTemp = trainYTemp[valIndex]\n",
    "            trainXTemp = trainXTemp[trainIndex, :]\n",
    "            trainYTemp = trainYTemp[trainIndex]\n",
    "            # probablityWatch = xgClassifier(trainXTemp, trainYTemp, valXTemp)\n",
    "\n",
    "            clf2 = xgb.XGBClassifier(scale_pos_weight=len(trainYTemp) / np.sum(trainYTemp), n_jobs=18, n_estimators=250, max_depth=4, objective=\"binary:logistic\", eval_metric=\"error\")\n",
    "            clf2.fit(trainXTemp, trainYTemp)\n",
    "            predictionsValWatch = clf2.predict_proba(valXTemp)\n",
    "            predictionsValWatch = predictionsValWatch[:, 0] \n",
    "\n",
    "            predictionsTestWatch = clf2.predict_proba(testXTemp)\n",
    "            predictionsTestWatch = predictionsTestWatch[:, 0] \n",
    "\n",
    "\n",
    "            predictionsValWatch = np.expand_dims(predictionsValWatch, axis=1)\n",
    "            predictionsValCGM = np.expand_dims(predictionsValCGM, axis=1)\n",
    "            allData=np.concatenate((predictionsValWatch, predictionsValCGM), axis=1)\n",
    "\n",
    "            clf = LogisticRegression(random_state=0).fit(allData, valYTemp)\n",
    "            \n",
    "            predictionsTestWatch = np.expand_dims(predictionsTestWatch, axis=1)\n",
    "            predictionsTestCGM = np.expand_dims(predictionsTestCGM, axis=1)\n",
    "            allData=np.concatenate((predictionsTestWatch, predictionsTestCGM), axis=1) \n",
    "            \n",
    "            LRPred=clf.predict(allData)\n",
    "            f1Score = sklearn.metrics.f1_score(testYTemp, LRPred)\n",
    "            setData.append(f1Score)\n",
    "        print(participant,np.mean(np.asarray(fSetData)))\n",
    "        print(participant,np.mean(np.asarray(setData)))\n",
    "\n",
    "\n",
    "    return classifierReports, regressorReports\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\"))):\n",
    "    os.remove(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\")))\n",
    "    os.remove(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Regressor.xlsx\")))\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\"))):\n",
    "    combinations = [\n",
    "        [\"CGM\", \"F1\", \"F2\", \"F3\", \"F4\"],\n",
    "        # [\"F1\", \"F2\", \"F3\", \"F4\"]\n",
    "        # [\"CGM\", \"F1\", \"F2\", \"Temperature\"],\n",
    "        # [\"CGM\", \"BVP\", \"EDA\", \"HR\", \"Temperature\", \"F1\", \"F2\", \"F5\"],\n",
    "    ]\n",
    "    columns = dfFeatures.columns\n",
    "    headersClassifier = [\n",
    "        \"Accuracy\",\n",
    "        \"Recall\",\n",
    "        \"Precision\",\n",
    "        \"F1\",\n",
    "        \"Participant\",\n",
    "        \"Combination\",\n",
    "        \"StartTime\",\n",
    "        \"EndTime\",\n",
    "        \"SetNumber\",\n",
    "        \"Component\",\n",
    "    ]\n",
    "    headersRegressor = [\n",
    "        \"RMSquaredError\",\n",
    "        \"RMSquaredLogError\",\n",
    "        \"Features\",\n",
    "        \"FeatureImportance\",\n",
    "        \"TrueMacro\",\n",
    "        \"PredictedMacro\",\n",
    "        \"Participant\",\n",
    "        \"Combination\",\n",
    "        \"StartTime\",\n",
    "        \"EndTime\",\n",
    "        \"SetNumber\",\n",
    "        \"Component\",\n",
    "    ]\n",
    "    dfClassifier = []\n",
    "    dfRegressor = []\n",
    "    for combination in combinations:\n",
    "        columnList = [\"StartTime\", \"EndTime\", \"Participant\", \"Carb\", \"Fat\", \"Protein\", \"MealLabel\"]\n",
    "        for topic in combination:\n",
    "            for column in columns:\n",
    "                # if topic in column and not 'Kurtosis' in column and not 'Skewness' in column and not 'Min' in column and not 'Max' in column:\n",
    "                if topic in column:\n",
    "                    columnList.append(column)\n",
    "\n",
    "        dfCombination = dfFeatures[dfFeatures.columns.intersection(columnList)]\n",
    "\n",
    "        randomSeed = 60\n",
    "        print(\"----------------------\")\n",
    "        print(\"Combination:\", \"+\".join(combination))\n",
    "        NORMALIZED_FLAG = False\n",
    "        classifierReports, regressorReports = testTrainSplitFunc(dfCombination, randomSeed, NORMALIZED_FLAG, \"+\".join(combination))\n",
    "        dfTempClassifier = pd.DataFrame(classifierReports, columns=headersClassifier)\n",
    "        dfTempRegressor = pd.DataFrame(regressorReports, columns=headersRegressor)\n",
    "        if len(dfClassifier) > 0:\n",
    "            frames = [dfTempClassifier, dfClassifier]\n",
    "            dfClassifier = pd.concat(frames)\n",
    "\n",
    "            frames = [dfTempRegressor, dfRegressor]\n",
    "            dfRegressor = pd.concat(frames)\n",
    "        else:\n",
    "            dfClassifier = dfTempClassifier\n",
    "            dfRegressor = dfTempRegressor\n",
    "    dfClassifier.reset_index(drop=True, inplace=True)\n",
    "    dfRegressor.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    dfClassifier.to_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\")), index=False)\n",
    "    dfRegressor.to_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Regressor.xlsx\")), index=False)\n",
    "else:\n",
    "    dfClassifier = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\")))\n",
    "    dfRegressor = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Regressor.xlsx\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/grads/s/sorush.omidvar/CGMDataset/Trial/Data/11-5-21-11-15-21/Results/1:00:00-0:30:00-Final-Regressor.xlsx'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Regressor.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringFixer(df):\n",
    "    dfColumns = [\"TrueMacro\", \"PredictedMacro\"]\n",
    "    for dfColumn in dfColumns:\n",
    "        for counter in range(len(df)):\n",
    "            tempVal = df[dfColumn].iloc[counter]\n",
    "            tempVal = tempVal.replace(\"[\", \"\")\n",
    "            tempVal = tempVal.replace(\"]\", \"\")\n",
    "            tempVal = list(tempVal.split(\" \"))\n",
    "            tempVal = list(filter(None, tempVal))\n",
    "            tempVal = np.asarray(tempVal).astype(float)\n",
    "            df[dfColumn].iloc[counter] = tempVal\n",
    "    return df\n",
    "\n",
    "\n",
    "dfRegressor = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Regressor.xlsx\")))\n",
    "dfRegressor = stringFixer(dfRegressor)\n",
    "\n",
    "dfRegressor.reset_index(drop=True, inplace=True)\n",
    "# dfRegressor.replace(\"CGM\", \"C\", inplace=True)\n",
    "# dfRegressor.replace(\"CGM+F1+F2+F5\", \"CM\", inplace=True)\n",
    "# dfRegressor.replace(\"CGM+BVP+EDA+HR+Temperature\", \"CE\", inplace=True)\n",
    "# dfRegressor.replace(\"CGM+BVP+EDA+HR+Temperature+F1+F2+F5\", \"CEM\", inplace=True)\n",
    "components = [\"Carb\", \"Fat\", \"Protein\"]\n",
    "colors = [\"red\", \"green\", \"blue\", \"magenta\"]\n",
    "participants = list(set(dfRegressor[\"Participant\"].to_list()))\n",
    "combinations = list(set(dfRegressor[\"Combination\"].to_list()))\n",
    "\n",
    "dfPearson = []\n",
    "for participant in participants:\n",
    "    dfParticipant = dfRegressor[dfRegressor[\"Participant\"] == participant]\n",
    "    for component in components:\n",
    "        dfComponent = dfParticipant[dfParticipant[\"Component\"] == component]\n",
    "        # myFig = plt.figure(figsize=(10, 10))\n",
    "        for counter in range(len(combinations)):\n",
    "            dfCombination = dfComponent[dfComponent[\"Combination\"] == combinations[counter]]\n",
    "            trueVal = dfCombination[\"TrueMacro\"].to_list()\n",
    "            trueVal = np.asarray(trueVal).astype(float)\n",
    "            trueVal = trueVal.flatten()\n",
    "\n",
    "            predVal = dfCombination[\"PredictedMacro\"].to_list()\n",
    "            predVal = np.asarray(predVal).astype(float)\n",
    "            predVal = predVal.flatten()\n",
    "\n",
    "            figName = \"Participant:\" + participant + \", Macro:\" + component\n",
    "            # plt.scatter(x=trueVal, y=predVal, c=colors[counter], label=combinations[counter], alpha=0.5, s=20)\n",
    "            # plt.title(figName)\n",
    "            # plt.plot([0, np.max(trueVal)], [0, np.max(trueVal)], \"k--\")\n",
    "            tempVal = pearsonr(trueVal, predVal)[0]\n",
    "            dfPearson.append([participant, component, combinations[counter], tempVal])\n",
    "            # plt.xlabel(\"True\")\n",
    "            # plt.ylabel(\"Pred\")\n",
    "        # plt.legend(loc=\"upper left\")\n",
    "        # plt.savefig(os.path.join(addDataPrefix, \"Results\", figName + \".png\"), dpi=600)\n",
    "        # plt.show()\n",
    "dfPearson = pd.DataFrame(dfPearson, columns=[\"Participant\", \"Component\", \"Combination\", \"Pearson\"])\n",
    "dfPearson.insert(len(dfPearson.columns), \"RelativePearson\", -100)\n",
    "dfPearson[\"RelativePearson\"] = dfPearson[\"Pearson\"]\n",
    "for participant in participants:  # Finding the difference of C with other Combinations\n",
    "    for component in components:\n",
    "        dfTemp = dfPearson[dfPearson[\"Participant\"] == participant]\n",
    "        dfTemp = dfTemp[dfTemp[\"Component\"] == component]\n",
    "        baseLine = dfTemp[dfTemp[\"Combination\"] == \"C\"]\n",
    "        baseLine = baseLine[\"RelativePearson\"].sum()\n",
    "        for counter in range(len(dfPearson)):\n",
    "            if dfPearson[\"Participant\"].iloc[counter] == participant and dfPearson[\"Component\"].iloc[counter] == component:\n",
    "                dfPearson[\"RelativePearson\"].iloc[counter] -= baseLine\n",
    "dfPearson.to_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Pearson.xlsx\")), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRegressor = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Regressor.xlsx\")))\n",
    "for root, dirs, files in os.walk(os.path.join(addDataPrefix, \"Results\")):\n",
    "    for file in files:\n",
    "        if \".xlsx\" in file.lower():\n",
    "            if \"classifier\" in file.lower() and not \"summary\" in file.lower():\n",
    "                dfClassifier = pd.read_excel(os.path.join(root, file))\n",
    "                newFileName = \"Summary-\" + file[: file.find(\".xlsx\")] + \".xlsx\"\n",
    "                newFileName = os.path.join(root, newFileName)\n",
    "                newFileData = []\n",
    "                participants = list(set(dfClassifier[\"Participant\"].to_list()))\n",
    "                combinations = list(set(dfClassifier[\"Combination\"].to_list()))\n",
    "                components = list(set(dfClassifier[\"Component\"].to_list()))\n",
    "                for participant in participants:\n",
    "                    dfParticipant = dfClassifier[dfClassifier[\"Participant\"] == participant]\n",
    "                    for combination in combinations:\n",
    "                        dfCombination = dfParticipant[dfParticipant[\"Combination\"] == combination]\n",
    "                        for component in components:\n",
    "                            dfComponent = dfCombination[dfCombination[\"Component\"] == component]\n",
    "                            assert len(dfComponent) == 5\n",
    "                            accuracyTemp = dfComponent[\"Accuracy\"].mean()\n",
    "                            recallTemp = dfComponent[\"Recall\"].mean()\n",
    "                            precisionTemp = dfComponent[\"Precision\"].mean()\n",
    "                            f1Temp = 2 * recallTemp * precisionTemp / (precisionTemp + recallTemp)\n",
    "                            newFileData.append([accuracyTemp, recallTemp, precisionTemp, f1Temp, participant, combination, component])\n",
    "                dfNewFile = pd.DataFrame(newFileData, columns=[\"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"Participant\", \"Combination\", \"Component\"])\n",
    "                dfNewFile.sort_values([\"Participant\", \"F1\"], ascending=(True, True), inplace=True)\n",
    "                dfNewFile.to_excel(newFileName, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Pearson.xlsx\"))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65e249be015da37cfe4cfdd1da028fe4cb475c26be679b9e3e34696278a17c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
