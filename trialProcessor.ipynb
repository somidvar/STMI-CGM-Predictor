{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This program is developed by Sorush Omidvar to process the dataset collected at Texas A&M University May 2022\n",
    "# This cell imports the required library and set some parameters to configure the code\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, mode, skew, kurtosis, linregress\n",
    "import xgboost as xgb\n",
    "from joblib import Parallel, delayed\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, roc_curve, roc_auc_score, recall_score, precision_score, accuracy_score, precision_recall_curve, auc, f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, ShuffleSplit, StratifiedKFold, KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import zipfile\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import multiprocessing as mp\n",
    "from matplotlib import patches\n",
    "import sys\n",
    "import shap\n",
    "import neurokit2 as nk\n",
    "\n",
    "# For plotting the seaborn with latex\n",
    "# sns.set_style(\"white\")\n",
    "# plt.rcParams[\"text.usetex\"] = True\n",
    "# font = {\"family\": \"normal\", \"weight\": \"bold\", \"size\": 22}\n",
    "# plt.rc(\"font\", **font)\n",
    "\n",
    "# Considering the existing lag in Apple Watch data (partially the day-light saving), this value aligns the timming of the apple watch to Texas Central time.\n",
    "MOTION_LAG_CORRECTION = [\n",
    "    (\"p1\", timedelta(minutes=2 * 60 + 36)),\n",
    "    (\"p3\", timedelta(minutes=2 * 60)),\n",
    "    (\"p5\", timedelta(minutes=-360)),\n",
    "    (\"p6\", timedelta(minutes=-360)),\n",
    "    (\"p7\", timedelta(minutes=-360)),\n",
    "    (\"p8\", timedelta(minutes=-360)),\n",
    "    # (\"p8\", datetime.strptime(\"02 02 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\"),datetime.strptime(\"02 06 2022-07:20:00\", \"%m %d %Y-%H:%M:%S\"),timedelta(minutes=-165)),\n",
    "    # (\"p8\", datetime.strptime(\"02 06 2022-07:20:00\", \"%m %d %Y-%H:%M:%S\"),datetime.strptime(\"02 09 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\"),timedelta(minutes=-165-190)),\n",
    "    # (\"p8\", datetime.strptime(\"02 09 2022-07:20:00\", \"%m %d %Y-%H:%M:%S\"),datetime.strptime(\"02 14 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\"),timedelta(minutes=93)),\n",
    "]\n",
    "# CGM_LAG_IMPOSING_STR = sys.argv[1]# ONLY TO IMPOSE A TIME LAG BETWEEN CGM READINGS AND CORE MOTION DATA!!!! WATCH OUT AND USE IT CAUTIOUSLY\n",
    "CGM_LAG_IMPOSING_STR = \"0\"  # This value can be used to lag the CGM response forward or backward to handle the fact that PPGR is not instantaneous so use it cautiously\n",
    "\n",
    "CGM_LAG_IMPOSING = timedelta(minutes=int(CGM_LAG_IMPOSING_STR))\n",
    "AVERAGING_BLOCK = timedelta(minutes=5)  # Averaging the results of detection performed by XGBoost. So, if we are using the window of 30 seconds and average over 5 minutes, we can remove false postivies/negatives by voting.\n",
    "OUTTER_WINDOW_LENGTH = timedelta(minutes=30)  # Length of CGM window\n",
    "INNER_WINDOW_LENGTH = timedelta(seconds=30)  # Length of Apple Watch, E4 window\n",
    "OUTTER_WINDOW_STEP = timedelta(seconds=30)  # Step of windows\n",
    "\n",
    "# OUTTER_WINDOW_LENGTH = timedelta(minutes=int(sys.argv[1]))\n",
    "# OUTTER_WINDOW_STEP = timedelta(seconds=int(sys.argv[2]))\n",
    "# INNER_WINDOW_LENGTH = timedelta(seconds=int(sys.argv[2]))\n",
    "# print(\"Outter Step:\", str(OUTTER_WINDOW_STEP), \"Inner Length:\", str(INNER_WINDOW_LENGTH))\n",
    "\n",
    "EDA_FLAG = \"PHASIC\"  # TOTAL, TONIC, PHASIC for EDA\n",
    "FASTING_LENGTH = timedelta(minutes=30)  # This option is not used during the code but left here\n",
    "BIG_MEAL_CALORIE = 200  # This option is not used during the code but left here\n",
    "COMPLEX_MEAL_DURATION = timedelta(minutes=60)  # This option is not used during the code but left here\n",
    "FOLD_NUMBER = 5  # Fold number for eating detection as we are using k-fold (NOT-STRATIFIED)\n",
    "MINIMUM_POINT = INNER_WINDOW_LENGTH.total_seconds()  # This will be used toward the minimum points required for sensor readings\n",
    "\n",
    "\n",
    "START_OF_TRIAL = [datetime.strptime(\"11 06 2021-04:00:00\", \"%m %d %Y-%H:%M:%S\"), datetime.strptime(\"02 03 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\")]  # Each round has a start date (2 rounds and 2 start dates)\n",
    "END_OF_TRIAL = [datetime.strptime(\"11 15 2021-00:00:00\", \"%m %d %Y-%H:%M:%S\"), datetime.strptime(\"02 13 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\")]  # Each round has a end date (2 rounds and 2 end dates)\n",
    "DAY_LIGHT_SAVING = datetime.strptime(\"11 06 2021-02:00:00\", \"%m %d %Y-%H:%M:%S\")  # Date at which day-light saving comes in place\n",
    "coreNumber = 90  # Number of cores for parallel processing.\n",
    "\n",
    "addDataPrefix = \"/Users/sorush/My Drive/Documents/Educational/TAMU/Research/TAMU/\"  # Result folder\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"/home/grads/s/sorush.omidvar/CGMDataset/TAMU/\"\n",
    "\n",
    "addUserInput = os.path.join(addDataPrefix, \"User inputted\")  # Input directory for Apple watch user diary\n",
    "addHKMotion = os.path.join(addDataPrefix, \"hk+cm\")  # Input directory for healthkit and core motion Apple Watch data\n",
    "addCGM = os.path.join(addDataPrefix, \"CGM\")  # Input directory for CGM data\n",
    "addE4 = os.path.join(addDataPrefix, \"E4\")  # Input directory for Empatica E4 data\n",
    "addResults = os.path.join(addDataPrefix, \"Results\" + str(CGM_LAG_IMPOSING_STR))  # Result address based on the CGM_Lag time defined earlier\n",
    "if not os.path.exists(addResults):\n",
    "    os.mkdir(addResults)\n",
    "\n",
    "exempts = [\"p2\", \"p4\"]  # Discarded users\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({\"figure.facecolor\": \"white\"})\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # no GPU\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This cell unzips the E4 data from zip files.\n",
    "# def unzipperE4(participantFolder):\n",
    "#     for root, dirs, files in os.walk(participantFolder):\n",
    "#         for file in files:\n",
    "#             if not '.zip' in file:\n",
    "#                 continue\n",
    "#             with zipfile.ZipFile(os.path.join(root,file), 'r') as zip_ref:\n",
    "#                 destFile=file[:file.find('.zip')]\n",
    "#                 destFile=os.path.join(root,destFile)\n",
    "#                 if not os.path.exists(destFile):\n",
    "#                     os.mkdir(destFile)\n",
    "#                 zip_ref.extractall(destFile)\n",
    "# def zipCleanerE4(E4Folder):\n",
    "#     for root, dirs, files in os.walk(E4Folder):\n",
    "#         for file in files:\n",
    "#             if '.zip' in file:\n",
    "#                 os.remove(os.path.join(root,file))\n",
    "\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p5')\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p6')\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p7')\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p8')\n",
    "# zipCleanerE4('/Users/sorush/Desktop/Round2E4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell forms the dfMeal which contains all the info for participants' meals (time and content)\n",
    "def trialTimeLimitter(df, columnName):  # Limiting the dataframe to the trial date ranges defined in START_OF_TRIAL and END_OF_TRIAL\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    dfTotal = []\n",
    "    for participant in participants:\n",
    "        if participant == \"p1\" or participant == \"p2\" or participant == \"p3\" or participant == \"p4\":\n",
    "            startOfTrial = START_OF_TRIAL[0]\n",
    "            endOfTrial = END_OF_TRIAL[0]\n",
    "        elif participant == \"p5\" or participant == \"p6\" or participant == \"p7\" or participant == \"p8\":\n",
    "            startOfTrial = START_OF_TRIAL[1]\n",
    "            endOfTrial = END_OF_TRIAL[1]\n",
    "        else:\n",
    "            print(\"Mayday in trialTimeLimitter\")\n",
    "            print(participant)\n",
    "            raise\n",
    "        dfTemp = df[df[\"Participant\"] == participant]\n",
    "        dfTemp = dfTemp[(dfTemp[columnName] >= startOfTrial) & (dfTemp[columnName] <= endOfTrial)]\n",
    "        if len(dfTotal) == 0:\n",
    "            dfTotal = dfTemp\n",
    "        else:\n",
    "            frames = [dfTotal, dfTemp]\n",
    "            dfTotal = pd.concat(frames)\n",
    "    return dfTotal\n",
    "\n",
    "\n",
    "def mealMarker(df):  # Marking the meal (big and complex) which are not used later on\n",
    "    df.insert(len(df.columns), \"BigMeal\", False)\n",
    "    for counter in range(0, len(df)):\n",
    "        if df[\"Calories\"].iloc[counter] >= BIG_MEAL_CALORIE:\n",
    "            df[\"BigMeal\"].iloc[counter] = True\n",
    "\n",
    "    df.insert(len(df.columns), \"ComplexMeal\", False)\n",
    "    participants = df[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    for participant in participants:\n",
    "        dfTemp = df[df[\"Participant\"] == participant]\n",
    "        for counter in range(1, len(dfTemp)):\n",
    "            if dfTemp[\"StartTime\"].iloc[counter - 1] + COMPLEX_MEAL_DURATION >= dfTemp[\"StartTime\"].iloc[counter]:\n",
    "                dfTemp[\"ComplexMeal\"].iloc[counter] = True\n",
    "                dfTemp[\"ComplexMeal\"].iloc[counter - 1] = True\n",
    "        indexs = dfTemp.index[dfTemp[\"ComplexMeal\"] == True]\n",
    "        df[\"ComplexMeal\"][indexs] = True\n",
    "    return df\n",
    "\n",
    "\n",
    "def dfMealReader():  # Reading the participants' diaries and forming dfMeal\n",
    "    os.chdir(addUserInput)\n",
    "    dfMeal = []\n",
    "    for root, dirs, files in os.walk(addUserInput):\n",
    "        print(root)\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                if \"meals\" in file.lower() and \"modified\" not in file.lower():\n",
    "                    participantName = file[: file.find(\"Meals\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    dfTemp.rename(columns={\"startTime\": \"StartTime\"}, inplace=True)\n",
    "                    dfTemp[\"StartTime\"] = pd.to_datetime(dfTemp[\"StartTime\"])\n",
    "                    dfTemp[\"FinishTime\"] = pd.to_datetime(dfTemp[\"FinishTime\"])\n",
    "                    dfTemp.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                    if len(dfMeal) != 0:\n",
    "                        frames = [dfTemp, dfMeal]\n",
    "                        dfMeal = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfMeal = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfMeal = trialTimeLimitter(dfMeal, \"StartTime\")\n",
    "    dfMeal = trialTimeLimitter(dfMeal, \"FinishTime\")\n",
    "    dfMeal.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    dfMeal.reset_index(drop=True, inplace=True)\n",
    "    # dfMeal.insert(4, \"MealDuration\", -1)\n",
    "    # dfMeal[\"MealDuration\"] = dfMeal[\"FinishTime\"] - dfMeal[\"StartTime\"]\n",
    "    # dfMeal[\"MealDuration\"] = dfMeal[\"MealDuration\"].dt.total_seconds()\n",
    "    print(\"Meal database is limited to the trial period\")\n",
    "    dfMeal.to_pickle(os.path.join(addResults, \"All_meals.pkl\"))\n",
    "    return dfMeal\n",
    "\n",
    "\n",
    "dfMeal = dfMealReader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeZoneFixer(df, LocalizeFlag, columnName):  # Fixing the time zone for wearables and CGM. It fixes the daylight based on the date.\n",
    "    if LocalizeFlag:\n",
    "        df[columnName] -= timedelta(hours=5)\n",
    "    tempColumn = df[columnName]\n",
    "    tempColumn[tempColumn >= DAY_LIGHT_SAVING] -= timedelta(hours=1)\n",
    "    df[columnName] = tempColumn\n",
    "    return df\n",
    "\n",
    "\n",
    "def pdInterpolation(dfTemp):  # Interpolating the Abbot from 15 min resolution to 1-min\n",
    "    index = dfTemp[\"Time\"]\n",
    "    seriesParticipant = pd.Series(dfTemp[\"Abbot\"].to_list(), index=index)\n",
    "    seriesParticipant = seriesParticipant.resample(\"1T\").asfreq()\n",
    "    seriesParticipant.interpolate(method=\"polynomial\", order=3, inplace=True)\n",
    "    tempTime = seriesParticipant.index\n",
    "    tempVal = seriesParticipant.values\n",
    "    dfTemp = pd.DataFrame(zip(tempTime, tempVal), columns=[\"Time\", \"Abbot\"])\n",
    "    return dfTemp\n",
    "\n",
    "\n",
    "def motionLagCorrector(df):  # Fix the Apple Watch lag based on MOTION_LAG_CORRECTION defined earlier for each participant\n",
    "    participants = df[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    dfTotal = []\n",
    "\n",
    "    for element in MOTION_LAG_CORRECTION:\n",
    "        participant = element[0]\n",
    "        timeLag = element[1]\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        if len(dfParticipant) == 0:\n",
    "            continue\n",
    "        dfParticipant[\"Time\"] += timeLag\n",
    "        if len(dfTotal) == 0:\n",
    "            dfTotal = dfParticipant\n",
    "        else:\n",
    "            frames = [dfTotal, dfParticipant]\n",
    "            dfTotal = pd.concat(frames)\n",
    "\n",
    "    return dfTotal\n",
    "\n",
    "\n",
    "def motionSmoother(df):  # Smoothing the Apple Watch data using an exponential mov-mean\n",
    "    columnLabels = df.columns\n",
    "    for columnLabel in columnLabels:\n",
    "        if columnLabel == \"Time\":\n",
    "            continue\n",
    "        tempSerie = df[columnLabel]\n",
    "        tempSerie = tempSerie.ewm(span=10).mean()  # Considering the frequency of 10 Hz\n",
    "        df[columnLabel] = tempSerie\n",
    "    return df\n",
    "\n",
    "\n",
    "def CGMLagImposer(df):  # If there is a lag imposing to CGM\n",
    "    df[\"Time\"] += CGM_LAG_IMPOSING\n",
    "    return df\n",
    "\n",
    "\n",
    "def CGMNormalizer(df):  # Normalizing CGM using min/max or mean/std\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    participants.sort()\n",
    "    dfResult = []\n",
    "    for participant in participants:\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        dates = list(set(dfParticipant[\"Time\"].dt.date.to_list()))\n",
    "        dates.sort()\n",
    "        for date in dates:\n",
    "            dfDate = dfParticipant[dfParticipant[\"Time\"].dt.date == date]\n",
    "            if len(dfDate) <= 10:\n",
    "                continue\n",
    "            minBG = dfDate[\"Abbot\"].min()\n",
    "            maxBG = dfDate[\"Abbot\"].max()\n",
    "\n",
    "            meanBG = dfDate[\"Abbot\"].mean()\n",
    "            stdBG = dfDate[\"Abbot\"].std()\n",
    "            dfDate[\"Abbot\"] -= minBG\n",
    "            dfDate[\"Abbot\"] /= maxBG - minBG\n",
    "            # dfDate[\"Abbot\"] -= meanBG\n",
    "            # dfDate[\"Abbot\"] /= stdBG\n",
    "\n",
    "            assert not np.isnan(minBG)\n",
    "            assert not np.isnan(maxBG)\n",
    "            assert not np.isnan(meanBG)\n",
    "            assert not np.isnan(stdBG)\n",
    "            if len(dfResult) == 0:\n",
    "                dfResult = dfDate.copy()\n",
    "            else:\n",
    "                frames = [dfResult, dfDate]\n",
    "                dfResult = pd.concat(frames)\n",
    "    return dfResult\n",
    "\n",
    "\n",
    "def CGMLowPass(df):  # Filter the CGM using low-pass\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    participants.sort()\n",
    "    dfResult = []\n",
    "    for participant in participants:\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        cgmVals = dfParticipant[\"Abbot\"].to_list()\n",
    "        cgmVals = np.asarray(cgmVals)\n",
    "        lowPassFilter = signal.butter(3, 12, \"lp\", fs=60 * 24, output=\"sos\")  # high pass of period of 2 hours (12 per day)\n",
    "        cgmVals = signal.sosfilt(lowPassFilter, cgmVals)\n",
    "        dfParticipant[\"Abbot\"] = cgmVals\n",
    "        if len(dfResult) == 0:\n",
    "            dfResult = dfParticipant.copy()\n",
    "        else:\n",
    "            frames = [dfResult, dfParticipant]\n",
    "            dfResult = pd.concat(frames)\n",
    "    return dfResult\n",
    "\n",
    "\n",
    "def CGMReader():  # Reading the CGM Data for each participant\n",
    "    os.chdir(addCGM)\n",
    "    dfCGM = []\n",
    "    for root, dirs, files in os.walk(addCGM):\n",
    "        for file in files:\n",
    "            if \".txt\" in file.lower():\n",
    "                if \"_libre\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_libre\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file, sep=\"\\t\", skiprows=1)\n",
    "                    if len(dfTemp.columns) != 4:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    dfTemp.columns.values[0] = \"ID\"\n",
    "                    dfTemp.columns.values[1] = \"Time\"\n",
    "                    dfTemp.columns.values[2] = \"Record\"\n",
    "                    dfTemp.columns.values[3] = \"Abbot\"\n",
    "                    dfTemp.drop(columns=[\"ID\", \"Record\"], inplace=True)\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"])\n",
    "                    if participantName == \"p1\" or participantName == \"p2\" or participantName == \"p3\" or participantName == \"p4\":\n",
    "                        dfTemp[\"Time\"] += timedelta(hours=-1)  # This fixes the daylight saving for the first round\n",
    "                    dfTemp[\"Abbot\"] = pd.to_numeric(dfTemp[\"Abbot\"])\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "                    dfTemp = pdInterpolation(dfTemp)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    if len(dfTemp.columns) != 3:\n",
    "                        print(\"MAYDAY. Error in processing csv\")\n",
    "                        break\n",
    "                    if len(dfCGM) != 0:\n",
    "                        frames = [dfTemp, dfCGM]\n",
    "                        dfCGM = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfCGM = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfCGM = CGMLagImposer(dfCGM)\n",
    "    dfCGM = trialTimeLimitter(dfCGM, \"Time\")\n",
    "    dfCGM.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfCGM.reset_index(drop=True, inplace=True)\n",
    "    # dfCGM = CGMLowPass(dfCGM)\n",
    "    # dfCGM = CGMNormalizer(dfCGM)\n",
    "    dfCGM.reset_index(drop=True, inplace=True)\n",
    "    print(\"CGM database is limited to the trial period\")\n",
    "    dfCGM.to_pickle(os.path.join(addResults, \"All_cgm.pkl\"))\n",
    "    return dfCGM\n",
    "\n",
    "\n",
    "dfCGM = CGMReader()\n",
    "\n",
    "\n",
    "def motionReader():  # Reading the Apple Watch motion data\n",
    "    # if os.path.exists(os.path.join(addResults, \"All_motion.pkl\")):\n",
    "    #     os.remove(os.path.join(addResults, \"All_motion.pkl\"))\n",
    "    os.chdir(addHKMotion)\n",
    "    if not os.path.exists(os.path.join(addResults, \"All_motion.pkl\")):\n",
    "        dfMotion = []\n",
    "        for root, dirs, files in os.walk(addHKMotion):\n",
    "            for file in files:\n",
    "                if \".csv\" in file.lower():\n",
    "                    if \"corrected_cm_all\" in file.lower():\n",
    "                        participantName = file[: file.find(\"_corrected\")]\n",
    "                        if participantName in exempts:\n",
    "                            print(\"Exemption...\", file)\n",
    "                            continue\n",
    "                        print(\"Reading ...\", file)\n",
    "                        dfTemp = pd.read_csv(file)\n",
    "                        print(\"File is read\")\n",
    "                        dfTemp[\"UnixTime\"] = pd.to_datetime(dfTemp[\"UnixTime\"], unit=\"s\")\n",
    "\n",
    "                        dfTemp.rename(columns={\"UnixTime\": \"Time\"}, inplace=True)\n",
    "                        dfTemp.drop(columns=[\"UID\", \"Date\"], inplace=True)\n",
    "                        dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                        dfTemp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                        dfTemp = motionSmoother(dfTemp)\n",
    "                        dfTemp[\"Yaw\"] *= 180 / np.pi\n",
    "                        dfTemp[\"Pitch\"] *= 180 / np.pi\n",
    "                        dfTemp[\"Roll\"] *= 180 / np.pi\n",
    "\n",
    "                        dfTemp.insert(0, \"Participant\", participantName)\n",
    "                        # this is to avoid 0 later on for feature calculation\n",
    "                        dfTemp.insert(len(dfTemp.columns), \"|Ax|+|Ay|+|Az|\", dfTemp[\"Ax\"].abs() + dfTemp[\"Ay\"].abs() + dfTemp[\"Az\"].abs() + 0.0001)\n",
    "                        dfTemp.insert(len(dfTemp.columns), \"|Yaw|+|Roll|+|Pitch|\", dfTemp[\"Yaw\"].abs() + dfTemp[\"Roll\"].abs() + dfTemp[\"Pitch\"].abs())\n",
    "                        dfTemp.insert(len(dfTemp.columns), \"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\", dfTemp[\"Rx\"].abs() + dfTemp[\"Ry\"].abs() + dfTemp[\"Rz\"].abs())\n",
    "                        dfTemp[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"] = dfTemp[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"]\n",
    "                        dfTemp.insert(len(dfTemp.columns), \"RotationalToLinear\", dfTemp[\"|Yaw|+|Roll|+|Pitch|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"])\n",
    "                        print(\"modified\")\n",
    "\n",
    "                        if len(dfTemp.columns) != 15:\n",
    "                            print(\"MAYDAY. Error in reading csv\")\n",
    "                            print(dfTemp.columns)\n",
    "                            break\n",
    "                        if len(dfMotion) != 0:\n",
    "                            frames = [dfTemp, dfMotion]\n",
    "                            dfMotion = pd.concat(frames)\n",
    "                        else:\n",
    "                            dfMotion = dfTemp\n",
    "        print(\"Processing is done\")\n",
    "        dfMotion = motionLagCorrector(dfMotion)\n",
    "        dfMotion = trialTimeLimitter(dfMotion, \"Time\")\n",
    "        dfMotion.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "        dfMotion.reset_index(drop=True, inplace=True)\n",
    "        print(\"Motion database is limited to the trial period\")\n",
    "        dfMotion.to_pickle(os.path.join(addResults, \"All_motion.pkl\"))\n",
    "    else:\n",
    "        dfMotion = pd.read_pickle(os.path.join(addResults, \"All_motion.pkl\"))\n",
    "    return dfMotion\n",
    "\n",
    "\n",
    "dfMotion = motionReader()\n",
    "\n",
    "\n",
    "def E4Smoother(df):  # Smoothing E4 data using exponential moving average\n",
    "    dfE4EDA = df[df[\"Field\"] == \"EDA\"]\n",
    "    dfE4HR = df[df[\"Field\"] == \"HR\"]\n",
    "    dfE4Temperature = df[df[\"Field\"] == \"Temperature\"]\n",
    "\n",
    "    tempSerie = dfE4EDA[\"Data1\"]\n",
    "    tempSerie = tempSerie.ewm(span=5 * 4).mean()  # Considering the frequency of 4 Hz\n",
    "    dfE4EDA[\"Data1\"] = tempSerie\n",
    "\n",
    "    tempSerie = dfE4HR[\"Data1\"]\n",
    "    tempSerie = tempSerie.ewm(span=5).mean()  # Considering the frequency of 1 Hz\n",
    "    dfE4HR[\"Data1\"] = tempSerie\n",
    "\n",
    "    tempSerie = dfE4Temperature[\"Data1\"]\n",
    "    tempSerie = tempSerie.ewm(span=5 * 4).mean()  # Considering the frequency of 4 Hz\n",
    "    dfE4Temperature[\"Data1\"] = tempSerie\n",
    "    frames = [dfE4EDA, dfE4HR, dfE4Temperature]\n",
    "    df = pd.concat(frames)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def E4Reader():  # Reading Empatica E4 data\n",
    "    # if os.path.exists(os.path.join(addResults, \"All_E4.pkl\")):\n",
    "    #     os.remove(os.path.join(addResults, \"All_E4.pkl\"))\n",
    "    os.chdir(addE4)\n",
    "    # fields=['ACC','BVP','EDA','HR','IBI','TEMP']\n",
    "    fields = [\"HR\", \"TEMP\", \"EDA\"]\n",
    "    if not os.path.exists(os.path.join(addResults, \"All_E4.pkl\")):\n",
    "        dfE4 = []\n",
    "        for root, dirs, files in os.walk(addE4):\n",
    "            for file in files:\n",
    "                if \".csv\" in file.lower():\n",
    "                    participantName = root[root.find(\"E4\") + 3 :]\n",
    "                    participantName = participantName[:2]\n",
    "                    field = file[: file.find(\".csv\")]\n",
    "                    if field not in fields:\n",
    "                        print(\"File name does not comply with analyzed fields\", file)\n",
    "                        continue\n",
    "                    print(participantName, field)\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    os.chdir(root)\n",
    "                    dfTemp = pd.read_csv(file, header=None)\n",
    "                    # if field=='ACC':\n",
    "                    #     assert len(dfTemp.columns)==3\n",
    "                    #     timeBase=dfTemp.iloc[0,0]\n",
    "                    #     timeStep=1/dfTemp.iloc[1,0]\n",
    "                    #     dfTemp.drop([0,1],inplace=True)\n",
    "                    #     dfTemp.rename(columns={0:'Data1',1:'Data2',2:'Data3'}, inplace=True)#x,y,z for data1,data2,data3\n",
    "                    #     timeTemp=[]\n",
    "                    #     for counter in range(len(dfTemp)):\n",
    "                    #         timeTemp.append(timeBase+counter*timeStep)\n",
    "                    #     dfTemp.insert(0,'Time',timeTemp)\n",
    "                    #     dfTemp.insert(0,'Field',\"Acceleration\")\n",
    "                    #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                    # if field == \"BVP\":\n",
    "                    #     assert len(dfTemp.columns) == 1\n",
    "                    #     timeBase = dfTemp.iloc[0, 0]\n",
    "                    #     timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    #     dfTemp.drop([0, 1], inplace=True)\n",
    "                    #     dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    #     dfTemp[\"Data2\"] = \"\"\n",
    "                    #     dfTemp[\"Data3\"] = \"\"\n",
    "                    #     timeTemp = []\n",
    "                    #     for counter in range(len(dfTemp)):\n",
    "                    #         timeTemp.append(timeBase + counter * timeStep)\n",
    "                    #     dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    #     dfTemp.insert(0, \"Field\", \"BVP\")\n",
    "                    #     dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                    if field == \"HR\":\n",
    "                        assert len(dfTemp.columns) == 1\n",
    "                        timeBase = dfTemp.iloc[0, 0]\n",
    "                        timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                        dfTemp.drop([0, 1], inplace=True)\n",
    "                        dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                        dfTemp[\"Data2\"] = \"\"\n",
    "                        dfTemp[\"Data3\"] = \"\"\n",
    "                        timeTemp = []\n",
    "                        for counter in range(len(dfTemp)):\n",
    "                            timeTemp.append(timeBase + counter * timeStep)\n",
    "                        dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                        dfTemp.insert(0, \"Field\", \"HR\")\n",
    "                        dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                    elif field == \"EDA\":\n",
    "                        assert len(dfTemp.columns) == 1\n",
    "                        timeBase = dfTemp.iloc[0, 0]\n",
    "                        timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                        dfTemp.drop([0, 1], inplace=True)\n",
    "                        dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                        dfTemp[\"Data2\"] = \"\"\n",
    "                        dfTemp[\"Data3\"] = \"\"\n",
    "                        timeTemp = []\n",
    "                        for counter in range(len(dfTemp)):\n",
    "                            timeTemp.append(timeBase + counter * timeStep)\n",
    "                        dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                        dfTemp.insert(0, \"Field\", \"EDA\")\n",
    "                        dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                        dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                        if EDA_FLAG == \"TONIC\":\n",
    "                            edaDecomposition = nk.eda_phasic(nk.standardize(dfTemp[\"Data1\"]), sampling_rate=4)\n",
    "                            dfTemp[\"Data1\"] = edaDecomposition[\"EDA_Tonic\"]\n",
    "                        elif EDA_FLAG == \"PHASIC\":\n",
    "                            edaDecomposition = nk.eda_phasic(nk.standardize(dfTemp[\"Data1\"]), sampling_rate=4)\n",
    "                            dfTemp[\"Data1\"] = edaDecomposition[\"EDA_Phasic\"]\n",
    "                        elif EDA_FLAG == \"TOTAL\":\n",
    "                            dfTemp[\"Data1\"] = dfTemp[\"Data1\"]\n",
    "                        else:\n",
    "                            print(\"The EDA flag is not recognized\")\n",
    "                            raise\n",
    "                    # elif field=='IBI':\n",
    "                    #     assert len(dfTemp.columns)==2\n",
    "                    #     timeBase=dfTemp.iloc[0,0]\n",
    "                    #     dfTemp.drop([0],inplace=True)\n",
    "                    #     dfTemp.rename(columns={0:'Time',1:'Data1'}, inplace=True)\n",
    "                    #     dfTemp[\"Data2\"]=\"\"\n",
    "                    #     dfTemp[\"Data3\"]=\"\"\n",
    "                    #     timeTemp=[]\n",
    "                    #     dfTemp['Time']+=timeBase\n",
    "                    #     dfTemp.insert(0,'Field',\"IBI\")\n",
    "                    #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                    elif field == \"TEMP\":\n",
    "                        assert len(dfTemp.columns) == 1\n",
    "                        timeBase = dfTemp.iloc[0, 0]\n",
    "                        timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                        dfTemp.drop([0, 1], inplace=True)\n",
    "                        dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                        dfTemp[\"Data2\"] = \"\"\n",
    "                        dfTemp[\"Data3\"] = \"\"\n",
    "                        timeTemp = []\n",
    "                        for counter in range(len(dfTemp)):\n",
    "                            timeTemp.append(timeBase + counter * timeStep)\n",
    "                        dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                        dfTemp.insert(0, \"Field\", \"Temperature\")\n",
    "                        dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    dfTemp.sort_values([\"Participant\", \"Field\", \"Time\"], ascending=(True, True, True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "                    dfTemp = E4Smoother(dfTemp)\n",
    "                    if len(dfTemp.columns) != 6:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    if len(dfE4) != 0:\n",
    "                        frames = [dfTemp, dfE4]\n",
    "                        dfE4 = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfE4 = dfTemp\n",
    "        print(\"reading is done\")\n",
    "        dfE4 = timeZoneFixer(dfE4, True, \"Time\")\n",
    "        dfE4.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "        dfE4.reset_index(drop=True, inplace=True)\n",
    "        dfE4 = trialTimeLimitter(dfE4, \"Time\")\n",
    "        dfE4.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "        dfE4.reset_index(drop=True, inplace=True)\n",
    "        print(\"E4 database is limited to the trial period\")\n",
    "        dfE4.to_pickle(os.path.join(addResults, \"All_E4.pkl\"))\n",
    "    else:\n",
    "        dfE4 = pd.read_pickle(os.path.join(addResults, \"All_E4.pkl\"))\n",
    "    dfE4 = E4Reader()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motionCalculator(df):  # Extracting features from Apple Motion data\n",
    "    f1 = np.asarray(df[\"RotationalToLinear\"].to_list())\n",
    "    f2 = np.asarray(df[\"|Ax|+|Ay|+|Az|\"].to_list())\n",
    "\n",
    "    aX = np.asarray(df[\"Ax\"].to_list())\n",
    "    aY = np.asarray(df[\"Ay\"].to_list())\n",
    "    aZ = np.asarray(df[\"Az\"].to_list())\n",
    "\n",
    "    yaw = np.asarray(df[\"Yaw\"].to_list())\n",
    "    pitch = np.asarray(df[\"Pitch\"].to_list())\n",
    "    roll = np.asarray(df[\"Roll\"].to_list())\n",
    "\n",
    "    # featureData = [f1.mean(skipna=True), f1.std(skipna=True), f1.max(skipna=True) - f1.min(skipna=True), f2.mean(skipna=True), f2.std(skipna=True), f2.max(skipna=True) - f2.min(skipna=True)]\n",
    "    featureData = [\n",
    "        np.nanmean(f1),\n",
    "        np.nanstd(f1),\n",
    "        np.nanmax(f1),\n",
    "        np.nanmin(f1),\n",
    "        np.nanmax(f1) - np.nanmin(f1),\n",
    "        np.nanmean(f2),\n",
    "        np.nanstd(f2),\n",
    "        np.nanmax(f2),\n",
    "        np.nanmin(f2),\n",
    "        np.nanmax(f1) - np.nanmin(f1),\n",
    "        np.nanmean(aX),\n",
    "        np.nanstd(aX),\n",
    "        np.nanmax(aX),\n",
    "        np.nanmin(aX),\n",
    "        np.nanmax(aX) - np.nanmin(aX),\n",
    "        np.nanmean(aY),\n",
    "        np.nanstd(aY),\n",
    "        np.nanmax(aY),\n",
    "        np.nanmin(aY),\n",
    "        np.nanmax(aY) - np.nanmin(aY),\n",
    "        np.nanmean(aZ),\n",
    "        np.nanstd(aZ),\n",
    "        np.nanmax(aZ),\n",
    "        np.nanmin(aZ),\n",
    "        np.nanmax(aZ) - np.nanmin(aZ),\n",
    "        np.nanmean(yaw),\n",
    "        np.nanstd(yaw),\n",
    "        np.nanmax(yaw),\n",
    "        np.nanmin(yaw),\n",
    "        np.nanmax(yaw) - np.nanmin(yaw),\n",
    "        np.nanmean(pitch),\n",
    "        np.nanstd(pitch),\n",
    "        np.nanmax(pitch),\n",
    "        np.nanmin(pitch),\n",
    "        np.nanmax(pitch) - np.nanmin(pitch),\n",
    "        np.nanmean(roll),\n",
    "        np.nanstd(roll),\n",
    "        np.nanmax(roll),\n",
    "        np.nanmin(roll),\n",
    "        np.nanmax(roll) - np.nanmin(roll),\n",
    "    ]\n",
    "    assert len(featureData) == 40\n",
    "    return featureData\n",
    "\n",
    "\n",
    "def CGMStatFeatures(dataList):  # Extracting features from CGM data\n",
    "    assert len(dataList) >= 10\n",
    "\n",
    "    dataList = np.asarray(dataList).astype(float)\n",
    "    result = []\n",
    "    dataDim = dataList.ndim\n",
    "    assert dataDim == 1\n",
    "    assert len(dataList) == len(dataList[~np.isnan(dataList)])\n",
    "    dataList = dataList[~np.isnan(dataList)]\n",
    "\n",
    "    meanVal = np.nanmean(dataList)\n",
    "    stdVal = np.nanstd(dataList)\n",
    "    minVal = np.nanmin(dataList)\n",
    "    maxVal = np.nanmax(dataList)\n",
    "    rangeVal = maxVal - minVal\n",
    "    skewnessVal = skew(dataList, nan_policy=\"omit\")\n",
    "    kurtosisVal = kurtosis(dataList, nan_policy=\"omit\")\n",
    "\n",
    "    tempSize = int(len(dataList) / 4)\n",
    "    firstFourthSlopeVal = np.mean(dataList[0:tempSize])\n",
    "    secondFourthSlopeVal = np.mean(dataList[tempSize : 2 * tempSize])\n",
    "    thirdFourthSlopeVal = np.mean(dataList[2 * tempSize : 3 * tempSize])\n",
    "    forthFourthSlopeVal = np.mean(dataList[3 * tempSize :])\n",
    "    firstHalfSlopeVal = np.mean(dataList[0 : 2 * tempSize])\n",
    "    secondHalfSlopeVal = np.mean(dataList[2 * tempSize :])\n",
    "\n",
    "    dataListDiff = np.diff(dataList)\n",
    "    meanDiff = np.nanmean(dataListDiff)\n",
    "    stdDiff = np.nanstd(dataListDiff)\n",
    "    minDiff = np.nanmin(dataListDiff)\n",
    "    maxDiff = np.nanmax(dataListDiff)\n",
    "    rangeDiff = maxDiff - minDiff\n",
    "    skewnessDiff = skew(dataListDiff, nan_policy=\"omit\")\n",
    "    kurtosisDiff = kurtosis(dataListDiff, nan_policy=\"omit\")\n",
    "\n",
    "    tempSize = int(len(dataListDiff) / 4)\n",
    "    firstFourthSlopeDiff = np.mean(dataListDiff[0:tempSize])\n",
    "    secondFourthSlopeDiff = np.mean(dataListDiff[tempSize : 2 * tempSize])\n",
    "    thirdFourthSlopeDiff = np.mean(dataListDiff[2 * tempSize : 3 * tempSize])\n",
    "    forthFourthSlopeDiff = np.mean(dataListDiff[3 * tempSize :])\n",
    "    firstHalfSlopeDiff = np.mean(dataList[0 : 2 * tempSize])\n",
    "    secondHalfSlopeDiff = np.mean(dataList[2 * tempSize :])\n",
    "\n",
    "    result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal, firstFourthSlopeVal, secondFourthSlopeVal, thirdFourthSlopeVal, forthFourthSlopeVal, secondHalfSlopeVal - firstHalfSlopeVal])\n",
    "    result.extend([rangeDiff, meanDiff, stdDiff, minDiff, maxDiff, skewnessDiff, kurtosisDiff, firstFourthSlopeDiff, secondFourthSlopeDiff, thirdFourthSlopeDiff, forthFourthSlopeDiff, secondHalfSlopeDiff - firstHalfSlopeDiff])\n",
    "    assert len(result) == 24\n",
    "    return result\n",
    "\n",
    "\n",
    "def E4StatFeatures(df, sensor):  # Extracting E4 features\n",
    "    nanList = []\n",
    "    for counter in range(14 * 1):\n",
    "        nanList.extend([np.nan])\n",
    "\n",
    "    dfTemp = df[df[\"Field\"] == sensor]\n",
    "    tempVal = dfTemp[\"Data1\"].to_list()\n",
    "\n",
    "    if len(tempVal) < 10:\n",
    "        return nanList\n",
    "    else:\n",
    "        tempVal = np.asarray(tempVal).astype(float)\n",
    "        tempVal = tempVal[~np.isnan(tempVal)]\n",
    "\n",
    "        meanVal = np.nanmean(tempVal)\n",
    "        stdVal = np.nanstd(tempVal)\n",
    "        minVal = np.nanmin(tempVal)\n",
    "        maxVal = np.nanmax(tempVal)\n",
    "        rangeVal = maxVal - minVal\n",
    "        skewnessVal = skew(tempVal, nan_policy=\"omit\")\n",
    "        kurtosisVal = kurtosis(tempVal, nan_policy=\"omit\")\n",
    "\n",
    "        dataTempDiff = np.diff(tempVal)\n",
    "        meanDiff = np.nanmean(dataTempDiff)\n",
    "        stdDiff = np.nanstd(dataTempDiff)\n",
    "        minDiff = np.nanmin(dataTempDiff)\n",
    "        maxDiff = np.nanmax(dataTempDiff)\n",
    "        rangeDiff = maxDiff - minDiff\n",
    "        skewnessDiff = skew(dataTempDiff, nan_policy=\"omit\")\n",
    "        kurtosisDiff = kurtosis(dataTempDiff, nan_policy=\"omit\")\n",
    "        return [rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal, rangeDiff, meanDiff, stdDiff, minDiff, maxDiff, skewnessDiff, kurtosisDiff]\n",
    "\n",
    "\n",
    "def parallelCall(windowData):  # Converting each windowDatas to feature based elements.\n",
    "    tempList = []\n",
    "    outterWindowStart = windowData[0]\n",
    "    outterWindowEnd = windowData[1]\n",
    "    mealFlag = windowData[2]\n",
    "    participant = windowData[3]\n",
    "    mealStartList = windowData[4]\n",
    "    mealEndList = windowData[5]\n",
    "\n",
    "    nanList = []\n",
    "    for counter in range(40 * 1):\n",
    "        nanList.extend([np.nan])\n",
    "\n",
    "    dfTempMotion = dfParticipantMotion[(dfParticipantMotion[\"Time\"] >= outterWindowStart) & (dfParticipantMotion[\"Time\"] < outterWindowEnd)]\n",
    "    dfTempE4 = dfParticipantE4[(dfParticipantE4[\"Time\"] >= outterWindowStart) & (dfParticipantE4[\"Time\"] < outterWindowEnd)]\n",
    "    dfTempCGM = dfParticipantCGM[\n",
    "        (dfParticipantCGM[\"Time\"] >= outterWindowStart) & (dfParticipantCGM[\"Time\"] < outterWindowEnd + OUTTER_WINDOW_LENGTH)\n",
    "    ]  # We are looking forward. For example if the meal is started at 12.10 we are interested to see the data from 12.10 to 12.40 (assuming that the outer window length is 30 min)\n",
    "    if len(dfTempMotion) >= MINIMUM_POINT * 10 * 0.5:  # Minimum point is the length of inner window per sec and this results in 50% of data\n",
    "        listMotion = motionCalculator(dfTempMotion)\n",
    "    else:\n",
    "        listMotion = nanList\n",
    "\n",
    "    listEDA = E4StatFeatures(dfTempE4, \"EDA\")\n",
    "    listHR = E4StatFeatures(dfTempE4, \"HR\")\n",
    "    listTemperature = E4StatFeatures(dfTempE4, \"Temperature\")\n",
    "\n",
    "    listCGM = CGMStatFeatures(dfTempCGM[\"Abbot\"].to_list())\n",
    "\n",
    "    tempList.append(listMotion)  # 1\n",
    "    tempList.append(listEDA)  # 1\n",
    "    tempList.append(listHR)  # 1\n",
    "    tempList.append(listTemperature)  # 1\n",
    "\n",
    "    tempList.append(listCGM)  # 1\n",
    "\n",
    "    tempList.append(outterWindowStart)  # 1\n",
    "    tempList.append(outterWindowEnd)  # 1\n",
    "    tempList.append(participant)  # 1\n",
    "\n",
    "    tempList.append(mealFlag)  # mealFlag\n",
    "    tempList.append(mealStartList)  # mealStarts\n",
    "    tempList.append(mealEndList)  # mealEnds\n",
    "\n",
    "    assert len(tempList) == 11\n",
    "    return tempList\n",
    "\n",
    "\n",
    "def outterWindowExtractorTotal(participant):  # Forming winodwDatas for each participant\n",
    "    participantDataList = []\n",
    "    windowDatas = []\n",
    "    experimentStart = dfParticipantMotion[\"Time\"].min()\n",
    "    experimentEnd = dfParticipantMotion[\"Time\"].max()\n",
    "\n",
    "    startQuerry = experimentStart\n",
    "    endQuerry = startQuerry + OUTTER_WINDOW_STEP\n",
    "    mealPartCounter = 0  # This shows the relation between the window and the part of the eating window.\n",
    "    while endQuerry <= experimentEnd:\n",
    "        # dfTempMeal = dfParticipantMeal[(dfParticipantMeal[\"StartTime\"] <= startQuerry) & (dfParticipantMeal[\"StartTime\"] + timedelta(minutes=15) >= startQuerry)]  #################  ATTENTION, I CHANGED THE RULE OF 15 MIN MEAL\n",
    "        dfTempMeal = dfParticipantMeal[(dfParticipantMeal[\"StartTime\"] <= startQuerry) & (dfParticipantMeal[\"FinishTime\"] >= startQuerry)]\n",
    "        mealFlag = min(len(dfTempMeal), 1)\n",
    "        if mealFlag == 1:  # if the meal is 15 min and window is 1 minute, we get max of 15\n",
    "            mealPartCounter += 1\n",
    "        else:\n",
    "            mealPartCounter = 0\n",
    "        mealStartList = dfTempMeal[\"StartTime\"].to_list()\n",
    "        mealEndList = dfTempMeal[\"FinishTime\"].to_list()\n",
    "\n",
    "        windowDatas.append([startQuerry, endQuerry, mealPartCounter, participant, mealStartList, mealEndList])\n",
    "        startQuerry += OUTTER_WINDOW_STEP\n",
    "        endQuerry += OUTTER_WINDOW_STEP\n",
    "    skipNumber = int(OUTTER_WINDOW_LENGTH.seconds / INNER_WINDOW_LENGTH.seconds)\n",
    "    windowDatas = windowDatas[: len(windowDatas) - skipNumber]  # Skipping the last 30 windows (assuming outter of 30 and inner of 1 min) because the last window has not enough points for looking back and this causes issues in stat calculation\n",
    "    # for counterOuter in tqdm(range(int(len(windowDatas)))):\n",
    "    #     windowData = windowDatas[counterOuter]\n",
    "    #     participantDataList.append(parallelCall(windowData))\n",
    "\n",
    "    pool = mp.Pool(coreNumber)\n",
    "    participantDataList = pool.map(parallelCall, tqdm(windowDatas), chunksize=coreNumber)\n",
    "    pool.close()\n",
    "    return participantDataList\n",
    "\n",
    "\n",
    "# This cell extracts the features for each participant as follows: First there is a loop over each participant where dfParticipantMeal, dfParticipantMotion, dfParticipantE4 and dfParticipantCGM are formed.\n",
    "# Then the outterWindowExtractorTotal forms windowDatas which consists query start, query end mealPartCounter (to see which part of the meal we are looking at such as begining, middle or end), participantName, mealStartList and mealEndList(which meal happens during this query).\n",
    "# Then the formed windowDatas are processed by parallelCall function using parallel processing where each query is translated to features of each window.\n",
    "if os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-All-Features.pkl\"))):\n",
    "    os.remove(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-All-Features.pkl\")))\n",
    "if os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-All-Features.pkl\"))):\n",
    "    dfAllFeatures = pd.read_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-All-Features.pkl\")))\n",
    "else:\n",
    "    dfAllFeatures = []\n",
    "    participants = dfMeal[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    participants.sort()\n",
    "\n",
    "    columnHeaderList = [\"Motion\", \"EDA\", \"HR\", \"Temperature\", \"CGM\", \"StartTime\", \"FinishTime\", \"Participant\", \"MealLabel\", \"MealStartList\", \"MealEndList\"]\n",
    "    for participant in participants:\n",
    "        print(\"Participant:\", participant)\n",
    "        if participant in exempts:\n",
    "            continue\n",
    "        dfParticipantMeal = dfMeal[dfMeal[\"Participant\"] == participant]\n",
    "        dfParticipantMotion = dfMotion[dfMotion[\"Participant\"] == participant]\n",
    "        dfParticipantE4 = dfE4[dfE4[\"Participant\"] == participant]\n",
    "        dfParticipantCGM = dfCGM[dfCGM[\"Participant\"] == participant]\n",
    "        participantDataList = outterWindowExtractorTotal(participant)\n",
    "\n",
    "        participantDataList = pd.DataFrame(participantDataList, columns=columnHeaderList)\n",
    "        if len(dfAllFeatures) == 0:\n",
    "            dfAllFeatures = participantDataList\n",
    "        else:\n",
    "            frames = [dfAllFeatures, participantDataList]\n",
    "            dfAllFeatures = pd.concat(frames)\n",
    "    dfAllFeatures.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    dfAllFeatures.reset_index(drop=True, inplace=True)\n",
    "    dfAllFeatures.to_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-All-Features.pkl\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgClassifier(xTrain, xTest, yTrain, yTest, featturesName, combinationElement, foldNumber):  # Training model based on the extracted features for each sensor and returning the probability of eating\n",
    "    thresholdBest = np.nan\n",
    "    clf = xgb.XGBClassifier(scale_pos_weight=len(yTrain) / np.sum(yTrain), n_jobs=coreNumber, n_estimators=250, max_depth=3, objective=\"binary:logistic\", eval_metric=\"error\")\n",
    "    clf.fit(xTrain, yTrain)\n",
    "\n",
    "    predictionsTest = clf.predict_proba(xTest)\n",
    "    predictionsTest = predictionsTest[:, 1]\n",
    "\n",
    "    # itemIndex = np.where(yTest == 1)\n",
    "    # itemIndex = itemIndex[0]\n",
    "    # itemIndex = itemIndex[0]\n",
    "\n",
    "    # predictionsTest = clf.predict_proba(xTest)\n",
    "    # predictionsTest = predictionsTest[:, 1]\n",
    "    # mamad=np.copy(predictionsTest)\n",
    "    # for counter in range(len(mamad)-5):\n",
    "    #     mamad[counter]=np.mean(predictionsTest[counter:counter+5])\n",
    "    # plt.figure(figsize=(20, 10))\n",
    "    # plt.plot(yTest[itemIndex: itemIndex + 2500], color=\"r\")\n",
    "    # plt.plot(predictionsTest[itemIndex: itemIndex + 2500], color=\"b\")\n",
    "    # plt.plot(mamad[itemIndex: itemIndex + 2500], color=\"g\",linewidth=7)\n",
    "\n",
    "    # plt.show()\n",
    "    # raise\n",
    "\n",
    "    # explainer = shap.Explainer(clf, xTrain, feature_names=featturesName)\n",
    "    # shap_values = explainer(xTest)\n",
    "    # shap.plots.beeswarm(shap_values, show=False)\n",
    "    # plt.savefig(os.path.join(addResults, combinationElement + str(foldNumber) + \".png\"), dpi=600, bbox_inches=\"tight\")\n",
    "    # plt.clf()\n",
    "\n",
    "    featureImportance = clf.feature_importances_\n",
    "    featureImportance = dict(zip(featturesName, featureImportance))\n",
    "\n",
    "    return [thresholdBest, np.sum(yTest), len(yTest) - np.sum(yTest), featureImportance, yTest, predictionsTest]\n",
    "\n",
    "\n",
    "def xDataGetter(dfParticipant, sensor):  # Getting the features from the defined combination\n",
    "    tempList = dfParticipant[sensor].to_list()\n",
    "    tempList = np.asarray(tempList)\n",
    "    return tempList\n",
    "\n",
    "\n",
    "def testTrainSplit(dfParticipant, combinationList, NORMAL_FLAG, HOOVER_FLAG):  # Splitting the data into k-fold which is NOT stratified to assure there is a minimal data leak\n",
    "    dfParticipant.insert(len(dfParticipant.columns), \"MultiModalProb\", np.nan)\n",
    "    dfParticipant.insert(len(dfParticipant.columns), \"Threshold\", np.nan)\n",
    "    dfParticipant.insert(len(dfParticipant.columns), \"MealPart\", np.nan)\n",
    "\n",
    "    dfParticipant.reset_index(drop=True, inplace=True)\n",
    "    yData = dfParticipant[\"MealLabel\"].to_list()\n",
    "    yData = np.asarray(yData).astype(int)\n",
    "    mealPartCounterData = np.copy(yData)\n",
    "    yData[yData >= 1] = 1  # this converts the mealPartCounter to meal flag\n",
    "    for combinationElement in combinationList:\n",
    "        if combinationElement == \"Motion\" and HOOVER_FLAG:\n",
    "            continue  # Already handled by HooverModel\n",
    "        xData = xDataGetter(dfParticipant, combinationElement)\n",
    "\n",
    "        if NORMAL_FLAG:\n",
    "            xData -= np.nanmean(xData, axis=0)\n",
    "            xData /= np.nanstd(xData, axis=0)\n",
    "        kf = KFold(n_splits=FOLD_NUMBER, shuffle=False)\n",
    "        predictionTests = []\n",
    "        featuresName = featuresNameGetter(combinationElement)\n",
    "        foldCounter = 1\n",
    "        for trainIndex, testIndex in kf.split(xData, yData):\n",
    "            xTrain, xTest = xData[trainIndex, :], xData[testIndex, :]\n",
    "            yTrain, yTest = yData[trainIndex], yData[testIndex]\n",
    "\n",
    "            tempListReport = xgClassifier(xTrain, xTest, yTrain, yTest, featuresName, combinationElement, foldCounter)\n",
    "\n",
    "            predictionTests.extend(tempListReport[-1])\n",
    "            foldCounter += 1\n",
    "        predictionTests = np.asarray(predictionTests)\n",
    "        dfParticipant[combinationElement] = predictionTests\n",
    "    dfParticipant[\"MealPart\"] = mealPartCounterData\n",
    "    blockAverager(dfParticipant, combinationList)\n",
    "    multiModalModel(dfParticipant, combinationList)\n",
    "\n",
    "\n",
    "def multiModalModel(df, combinationList):  # Fusing the probabilities from sensors using a logistic regression model\n",
    "    xData = []\n",
    "    yData = df[\"MealLabel\"].to_list()\n",
    "    yData = np.asarray(yData)\n",
    "\n",
    "    xData = df[combinationList].values\n",
    "    xData = np.asarray(xData)\n",
    "\n",
    "    kf = KFold(n_splits=FOLD_NUMBER, shuffle=False)\n",
    "    predictionsTests = []\n",
    "    thresholds = []\n",
    "    print(\"LR intercepts and coeff:\")\n",
    "    print(\"Intercept\", combinationList)\n",
    "    foldCounter = 1\n",
    "    for trainIndex, testIndex in kf.split(xData, yData):\n",
    "        xTrain, xTest = xData[trainIndex, :], xData[testIndex, :]\n",
    "        yTrain, yTest = yData[trainIndex], yData[testIndex]\n",
    "\n",
    "        xVal = xTrain[int(0.8 * len(xTrain)) :, :]\n",
    "        yVal = yTrain[int(0.8 * len(yTrain)) :]\n",
    "\n",
    "        xTrain = xTrain[: int(0.8 * len(xTrain)), :]\n",
    "        yTrain = yTrain[: int(0.8 * len(yTrain))]\n",
    "\n",
    "        clf = LogisticRegression(class_weight=\"balanced\", n_jobs=coreNumber)\n",
    "        clf.fit(xTrain, yTrain)\n",
    "        print(\"Fold\", foldCounter, clf.intercept_, clf.coef_)\n",
    "\n",
    "        thresholdBest = -1\n",
    "        f1Best = -1\n",
    "        for threshold in np.arange(0, 1, 0.01):\n",
    "            predVal = clf.predict_proba(xVal)\n",
    "            predVal = predVal[:, 1]\n",
    "            predVal[predVal >= threshold] = 1\n",
    "            predVal[predVal < threshold] = 0\n",
    "            f1Score = sklearn.metrics.f1_score(yVal, predVal)\n",
    "            if f1Score >= f1Best:\n",
    "                thresholdBest = threshold\n",
    "                f1Best = f1Score\n",
    "\n",
    "        predictionsTest = clf.predict_proba(xTest)\n",
    "        predictionsTest = predictionsTest[:, 1]\n",
    "\n",
    "        for counter in range(len(yTest)):\n",
    "            thresholds.append(thresholdBest)\n",
    "\n",
    "        predictionsTests.extend(predictionsTest)\n",
    "        foldCounter += 1\n",
    "    df[\"MultiModalProb\"] = predictionsTests\n",
    "    df[\"Threshold\"] = thresholds\n",
    "\n",
    "\n",
    "def featuresNameGetter(sensorName):  # Setting the combination for the fusion\n",
    "    CGMStat = [\"-Range\", \"-Mean\", \"-STD\", \"-Min\", \"-Max\", \"-Skewness\", \"-Kurtosis\", \"-FirstFourthSlope\", \"-SecondFourthSlope\", \"-ThirdFourthSlope\", \"-FourthFourthSlope\", \"-HalvesSlope\"]\n",
    "    CGMStat.extend([\"-RangeDiff\", \"-MeanDiff\", \"-STDDiff\", \"-MinDiff\", \"-MaxDiff\", \"-SkewnessDiff\", \"-KurtosisDiff\", \"-FirstFourthSlopeDiff\", \"-SecondFourthSlopeDiff\", \"-ThirdFourthSlopeDiff\", \"-FourthFourthSlopeDiff\", \"-HalvesSlopeDiff\"])\n",
    "    E4Stat = [\"-RangeVal\", \"-MeanVal\", \"-StdVal\", \"-MinVal\", \"-MaxVal\", \"-SkewnessVal\", \"-KurtosisVal\", \"-RangeDiff\", \"-MeanDiff\", \"-StdDiff\", \"-MinDiff\", \"-MaxDiff\", \"-SkewnessDiff\", \"-KurtosisDiff\"]\n",
    "    motionParameters = [\"F1\", \"F1\", \"Ax\", \"Ay\", \"Az\", \"Yaw\", \"Pitch\", \"Roll\"]\n",
    "    motionStat = [\"-Mean\", \"-Std\", \"-Max\", \"-Min\", \"-Range\"]\n",
    "    motionStats = []\n",
    "    for motionParameter in motionParameters:\n",
    "        for element in motionStat:\n",
    "            motionStats.append(motionParameter + element)\n",
    "\n",
    "    if \"CGM\" in sensorName:\n",
    "        return [\"CGM\" + element for element in CGMStat]\n",
    "\n",
    "    if \"Motion\" in sensorName:\n",
    "        return motionStats\n",
    "\n",
    "    if \"EDA\" in sensorName:\n",
    "        return [\"EDA\" + element for element in E4Stat]\n",
    "\n",
    "    if \"HR\" in sensorName:\n",
    "        return [\"HR\" + element for element in E4Stat]\n",
    "\n",
    "    if \"Temperature\" in sensorName:\n",
    "        return [\"Temperature\" + element for element in E4Stat]\n",
    "    raise\n",
    "\n",
    "\n",
    "def hooverPredictor(dfAllFeatures, NORMAL_FLAG):  # If pre-trained Hoover model is used for the motion data\n",
    "    xData = dfAllFeatures[\"Motion\"].to_list()\n",
    "    xData = np.asarray(xData)\n",
    "    if NORMAL_FLAG:\n",
    "        xData -= np.nanmean(xData, axis=0)\n",
    "        xData /= np.nanstd(xData, axis=0)\n",
    "\n",
    "    hooverModelAdd = \"/home/grads/s/sorush.omidvar/CGMDataset/Hoover/HooverModel-0.5.sav\"\n",
    "    hooverModel = pickle.load(open(hooverModelAdd, \"rb\"))\n",
    "    hooverModel.n_jobs = coreNumber\n",
    "\n",
    "    hooverPredictions = hooverModel.predict_proba(xData)\n",
    "    hooverPredictions = hooverPredictions[:, 1]\n",
    "\n",
    "    hooverPredictions = np.asarray(hooverPredictions)\n",
    "    dfAllFeatures[\"Motion\"] = hooverPredictions\n",
    "\n",
    "\n",
    "def dfReader():  # Reading the feature dataframe\n",
    "    dfAllFeatures = pd.read_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-All-Features.pkl\")))\n",
    "    dfAllFeatures = dfAllFeatures.dropna()\n",
    "    return dfAllFeatures\n",
    "\n",
    "\n",
    "def blockAverager(df, combinationList):  # Taking the average of each sensor individually. The probability will be averaged over the length of AVERAGING_BLOCK and the label is the majority of all inner windows.\n",
    "    for counter in tqdm(range(len(df))):\n",
    "        startTime = df[\"StartTime\"].iloc[counter]\n",
    "        dfTemp = df[(df[\"StartTime\"] >= startTime) & (df[\"FinishTime\"] <= startTime + AVERAGING_BLOCK)]\n",
    "\n",
    "        mealLabel = dfTemp[\"MealLabel\"].mean()\n",
    "        if mealLabel >= 0.5:\n",
    "            mealLabel = 1\n",
    "        else:\n",
    "            mealLabel = 0\n",
    "        df[\"MealLabel\"].iloc[counter] = mealLabel\n",
    "        for combinationElement in combinationList:\n",
    "            df[combinationElement].iloc[counter] = dfTemp[combinationElement].mean()\n",
    "        # df[\"MealPart\"].iloc[counter] = dfTemp[\"MealPart\"].mean()\n",
    "\n",
    "\n",
    "def metricCalc(df, combinationList):  # Summarizing the performance of each fusion on all folds. Each fold is in the test set exactly one time and to summarize we need to collect all folds together.\n",
    "    participants = df[\"Participant\"].unique()\n",
    "    combinationSummary = []\n",
    "    for participant in participants:\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        yTrues = dfParticipant[\"MealLabel\"].to_list()\n",
    "        yPreds = dfParticipant[\"MultiModalProb\"].to_list()\n",
    "        thresholds = dfParticipant[\"Threshold\"].to_list()\n",
    "        mealParts = dfParticipant[\"MealPart\"].to_list()\n",
    "\n",
    "        yTrues = np.asarray(yTrues).astype(int)\n",
    "        yPreds = np.asarray(yPreds)\n",
    "        thresholds = np.asarray(thresholds)\n",
    "        mealParts = np.asarray(mealParts)\n",
    "\n",
    "        rocAuc = roc_auc_score(yTrues, yPreds)\n",
    "        precisionTemp, recallTemp, thresholdsTemp = precision_recall_curve(yTrues, yPreds)\n",
    "        prAuc = auc(recallTemp, precisionTemp)\n",
    "\n",
    "        for counter in range(len(yTrues)):\n",
    "            if yPreds[counter] >= thresholds[counter]:\n",
    "                yPreds[counter] = 1\n",
    "            else:\n",
    "                yPreds[counter] = 0\n",
    "\n",
    "        accuracy = accuracy_score(yTrues, yPreds)\n",
    "        recall = recall_score(yTrues, yPreds)\n",
    "        precision = precision_score(yTrues, yPreds)\n",
    "        f1Score = f1_score(yTrues, yPreds)\n",
    "\n",
    "        # mealParts = (mealParts * yPreds)\n",
    "        # mealParts = (mealParts * yTrues)\n",
    "        # mealParts = mealParts[mealParts > 0]\n",
    "        # plt.figure()\n",
    "        # plt.hist(mealParts)\n",
    "        # plt.xlabel(\"Meal Part (left and right sides are beginning and end of the meal)\")\n",
    "        # plt.ylabel(\"# of Correctly positive windows\")\n",
    "        # plt.title(\"+\".join(combinationList) + \" for:\" + participant)\n",
    "\n",
    "        combinationSummary.append([participant, \"+\".join(combinationList), rocAuc, prAuc, accuracy, recall, precision, f1Score])\n",
    "    combinationSummary = pd.DataFrame(combinationSummary, columns=[\"Participant\", \"Combination\", \"ROC-AUC\", \"PR-AUC\", \"Accuracy\", \"Recall\", \"Precision\", \"F1\"])\n",
    "    return combinationSummary\n",
    "\n",
    "\n",
    "def predictionMain(dfCombination, combinationList, NORMAL_FLAG, HOOVER_FLAG):  # Reading the features for each participant and send the data to testTrainSplit to use k-fold. The result is stored at classifierReports\n",
    "    participants = dfCombination[\"Participant\"].unique()\n",
    "    participants.sort()\n",
    "    classifierReports = []\n",
    "    for participant in participants:\n",
    "        dfParticipant = dfCombination[dfCombination[\"Participant\"] == participant]\n",
    "        dfParticipant.sort_values([\"StartTime\"], ascending=(True), inplace=True)\n",
    "        print(\"*************************\", \"Participant:\", participant)\n",
    "        testTrainSplit(dfParticipant, combinationList, NORMAL_FLAG, HOOVER_FLAG)\n",
    "        if len(classifierReports) == 0:\n",
    "            classifierReports = dfParticipant\n",
    "        else:\n",
    "            frames = [classifierReports, dfParticipant]\n",
    "            classifierReports = pd.concat(frames)\n",
    "    return classifierReports\n",
    "\n",
    "\n",
    "# Reading the extracted features, training model for each sensor, applying an averager block to remove false detections, fusing probabilities of a sensor combination using LR.\n",
    "NORMAL_FLAG = True\n",
    "HOOVER_FLAG = False\n",
    "if os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-Final-Classifier.xlsx\"))):\n",
    "    os.remove(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-Final-Classifier.xlsx\")))\n",
    "if not os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-Final-Classifier.xlsx\"))):\n",
    "    dfClassifier = []\n",
    "    combinationLists = [\n",
    "        [\"Motion\"],\n",
    "        [\"CGM\"],\n",
    "        [\"EDA\"],\n",
    "        [\"HR\"],\n",
    "        [\"Temperature\"],\n",
    "        [\"Motion\", \"CGM\"],\n",
    "        [\"Motion\", \"CGM\", \"EDA\"],\n",
    "        [\"Motion\", \"CGM\", \"EDA\", \"HR\"],\n",
    "        [\"Motion\", \"EDA\", \"HR\", \"Temperature\"],\n",
    "        [\"EDA\", \"HR\", \"Temperature\"],\n",
    "        [\"CGM\", \"EDA\", \"HR\", \"Temperature\"],\n",
    "        [\"Motion\", \"CGM\", \"EDA\", \"HR\", \"Temperature\"],\n",
    "    ]\n",
    "\n",
    "    combinationSummary = []\n",
    "    for combinationList in combinationLists:\n",
    "        dfAllFeatures = dfReader()\n",
    "        print(\"Total Number of Samples:\", len(dfAllFeatures), \"for combination:\", combinationList)\n",
    "        if \"Motion\" in combinationList and HOOVER_FLAG:\n",
    "            hooverPredictor(dfAllFeatures, NORMAL_FLAG)\n",
    "        dfAllFeatures = predictionMain(dfAllFeatures, combinationList, NORMAL_FLAG, HOOVER_FLAG)\n",
    "        dfAllFeatures.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "        dfAllFeatures.reset_index(drop=True, inplace=True)\n",
    "        combinationSummaryTemp = metricCalc(dfAllFeatures, combinationList)\n",
    "        if len(combinationSummary) == 0:\n",
    "            combinationSummary = combinationSummaryTemp\n",
    "        else:\n",
    "            frames = [combinationSummary, combinationSummaryTemp]\n",
    "            combinationSummary = pd.concat(frames)\n",
    "\n",
    "    combinationSummary.to_excel(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-Final-Classifier.xlsx\")), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricSummarizer(metricName):\n",
    "    dfResult = pd.read_excel(os.path.join(addResults, (\"FINAL-\" + str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-Final-Classifier.xlsx\")))\n",
    "    # combinationList = ['Motion','CGM','EDA','HR','Temperature']\n",
    "    # dfSummary = dfSummary[dfSummary['Combination'].isin(combinationList)]\n",
    "\n",
    "    # metricMean = dfSummary.groupby([\"Combination\"], as_index=False).mean()\n",
    "    # metricMin = dfSummary.groupby([\"Combination\"], as_index=False).min()\n",
    "    # metricMax = dfSummary.groupby([\"Combination\"], as_index=False).max()\n",
    "\n",
    "    # combinations = np.asarray(metricMean[\"Combination\"].to_list())\n",
    "    # metricMin = np.asarray(metricMin[metricName].to_list())\n",
    "    # metricMax = np.asarray(metricMax[metricName].to_list())\n",
    "    # metricMean = np.asarray(metricMean[metricName].to_list())\n",
    "\n",
    "    # sort_index = np.argsort(metricMean)\n",
    "    # metricMin = metricMin[sort_index]\n",
    "    # metricMax = metricMax[sort_index]\n",
    "    # metricMean = metricMean[sort_index]\n",
    "    # combinations = combinations[sort_index]\n",
    "\n",
    "    # asymmetric_error = np.array(list(zip(metricMean - metricMin, metricMax - metricMean))).T\n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    # plt.errorbar(combinations, metricMean, asymmetric_error, fmt=\".\", ecolor=\"red\")\n",
    "    # plt.ylabel(metricName)\n",
    "    # plt.xlabel(\"Combinations\")\n",
    "    # ax = plt.gca()\n",
    "    # ax.set_xticklabels(combinations, rotation=90)\n",
    "\n",
    "    combinationList = [[\"Motion\"], [\"CGM\"], [\"Motion\", \"CGM\"], [\"EDA\", \"HR\", \"Temperature\"], [\"CGM\", \"EDA\", \"HR\", \"Temperature\"], [\"Motion\", \"CGM\", \"EDA\", \"HR\", \"Temperature\"]]\n",
    "    dfSummary = []\n",
    "    for combination in combinationList:\n",
    "        dfTemp = dfResult[dfResult[\"Combination\"] == \"+\".join(combination)]\n",
    "        if len(dfSummary) == 0:\n",
    "            dfSummary = dfTemp.copy(deep=True)\n",
    "        else:\n",
    "            frames = [dfSummary, dfTemp]\n",
    "            dfSummary = pd.concat(frames)\n",
    "\n",
    "    sns.catplot(x=\"Participant\", y=metricName, data=dfSummary, kind=\"bar\", hue=\"Combination\", legend=True)\n",
    "\n",
    "\n",
    "metricSummarizer(\"ROC-AUC\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(30, 10))\n",
    "#     gs = GridSpec(2, 5)\n",
    "#     colors = plt.cm.get_cmap(\"tab10\")\n",
    "\n",
    "#     ax_calibration_curve = fig.add_subplot(gs[:2, :2])\n",
    "#     calibration_displays = {}\n",
    "\n",
    "\n",
    "#     display = CalibrationDisplay.from_estimator(\n",
    "#         clf,\n",
    "#         xVal,\n",
    "#         yVal,\n",
    "#         n_bins=10,\n",
    "#         name='testmodel',\n",
    "#         ax=ax_calibration_curve,\n",
    "#         color=colors(0),\n",
    "#         strategy='quantile'\n",
    "#     )\n",
    "#     calibration_displays['testmodel'] = display\n",
    "\n",
    "#     ax_calibration_curve.grid()\n",
    "#     ax_calibration_curve.set_title(\"Calibration plots\")\n",
    "\n",
    "#     # Add histogram\n",
    "#     grid_positions = [(0, 2)]\n",
    "#     # for i, m in enumerate(models):\n",
    "#     name = 'CLF'\n",
    "#     row, col = grid_positions[0]\n",
    "#     ax = fig.add_subplot(gs[row, col])\n",
    "\n",
    "#     ax.hist(\n",
    "#         calibration_displays['testmodel'].y_prob,\n",
    "#         range=(0, 1),\n",
    "#         bins=10,\n",
    "#         label=name,\n",
    "#         color=colors(0)\n",
    "#     )\n",
    "#     ax.set(title=name, xlabel=\"Mean predicted probability\", ylabel=\"Count\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     ax_calibration_curve.legend(loc='upper left')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(os.path.join(addResults))\n",
    "\n",
    "\n",
    "# def summaryPlotter(participant, metricType):\n",
    "#     metricMotionList = []\n",
    "#     metricCGMList = []\n",
    "#     metricCGMMotionList = []\n",
    "#     metricAllList = []\n",
    "#     windowLenList = []\n",
    "#     for root, dirs, files in os.walk(os.path.join(addResults)):\n",
    "#         for file in sorted(files):\n",
    "#             if \".xlsx\" in file.lower() and \"classifier\" in file.lower() and str(INNER_WINDOW_LENGTH) in file:\n",
    "#                 windowLen = file[: file.find(\"-\")]\n",
    "\n",
    "#                 dfTemp = pd.read_excel(file)\n",
    "\n",
    "#                 metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"Motion\")]\n",
    "#                 metricVal = metricVal[metricType].to_list()\n",
    "#                 assert len(metricVal) == 1\n",
    "#                 metricVal = metricVal[0]\n",
    "#                 metricMotionList.append(metricVal)\n",
    "\n",
    "#                 metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM\")]\n",
    "#                 metricVal = metricVal[metricType].to_list()\n",
    "#                 assert len(metricVal) == 1\n",
    "#                 metricVal = metricVal[0]\n",
    "#                 metricCGMList.append(metricVal)\n",
    "\n",
    "#                 metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM+Motion\")]\n",
    "#                 metricVal = metricVal[metricType].to_list()\n",
    "#                 assert len(metricVal) == 1\n",
    "#                 metricVal = metricVal[0]\n",
    "#                 metricCGMMotionList.append(metricVal)\n",
    "\n",
    "#                 metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"Motion+CGM+EDA+HR+Temperature\")]\n",
    "#                 metricVal = metricVal[metricType].to_list()\n",
    "#                 assert len(metricVal) == 1\n",
    "#                 metricVal = metricVal[0]\n",
    "#                 metricAllList.append(metricVal)\n",
    "#                 windowLenList.append(windowLen)\n",
    "\n",
    "#     for counter in range(len(windowLenList)):\n",
    "#         tempVal = datetime.strptime(windowLenList[counter], \"%H:%M:%S\")\n",
    "#         tempVal = tempVal.time().hour * 60 + tempVal.time().minute\n",
    "#         windowLenList[counter] = tempVal\n",
    "#     return metricMotionList, metricCGMList, metricCGMMotionList, metricAllList, windowLenList\n",
    "\n",
    "\n",
    "# def metricPlotter(metricName):\n",
    "#     participants = [\"p1\", \"p3\", \"p5\", \"p6\", \"p7\", \"p8\"]\n",
    "#     subplotCounter = 1\n",
    "#     fig = plt.figure(figsize=(10, 15))\n",
    "#     colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"]\n",
    "#     for participant in participants:\n",
    "#         metricMotionList, metricCGMList, metricCGMMotionList, metricAllList, windowLenList = summaryPlotter(participant, metricName)\n",
    "#         slopeCGM, interceptCGM, r_valueCGM, p_valueCGM, std_errCGM = linregress(windowLenList, metricCGMList)\n",
    "#         slopeMotion, interceptMotion, r_valueMotion, p_valueMotion, std_errMotion = linregress(windowLenList, metricMotionList)\n",
    "#         slopeCGMMotion, interceptCGMMotion, r_valueCGMMotion, p_valueCGMMotion, std_errCGMMotion = linregress(windowLenList, metricCGMMotionList)\n",
    "#         slopeAll, interceptAll, r_valueAll, p_valueAll, std_errAll = linregress(windowLenList, metricAllList)\n",
    "\n",
    "#         print(participant, (30 * slopeCGM + interceptCGM - interceptAll) / slopeAll)\n",
    "#         # print(participant,slopeCGM,slopeCGMMotion)\n",
    "#         # print(participant,interceptCGM,interceptCGMMotion)\n",
    "\n",
    "#         plt.subplot(3, 2, subplotCounter)\n",
    "#         sns.regplot(x=windowLenList, y=metricMotionList, marker=\"+\", color=colors[0], label=\"Motion\")\n",
    "#         sns.regplot(x=windowLenList, y=metricCGMList, marker=\"s\", color=colors[1], label=\"CGM\")\n",
    "#         sns.regplot(x=windowLenList, y=metricCGMMotionList, marker=\"d\", color=colors[2], label=\"CGM+Motion\")\n",
    "#         sns.regplot(x=windowLenList, y=metricAllList, marker=\"d\", color=colors[3], label=\"All\")\n",
    "#         # plt.plot(windowLenList, metricCGMMotionTempList, \"--o\", color=colors[3], label=\"CGM+Motion+Temperature\")\n",
    "#         # plt.plot(windowLenList, metricCGMMotionTempHREDAList, \":s\", color=colors[4], label=\"CGM+Motion+Temperature+HR+EDA\")\n",
    "#         plt.text(20, 0.9, participant.capitalize())\n",
    "#         plt.ylim([0, 1])\n",
    "#         if subplotCounter == 3:\n",
    "#             plt.ylabel(metricName, labelpad=30)\n",
    "#         if subplotCounter == 5:\n",
    "#             # plt.xlabel(\"Window Length [min]\",labelpad=30)\n",
    "#             frame1 = plt.gca()\n",
    "#             frame1.axes.set_xlabel(\"Window Length [min]\", labelpad=30, x=1)\n",
    "#         if subplotCounter == 2:\n",
    "#             plt.legend(loc=\"upper right\")\n",
    "#         if subplotCounter % 2 == 1:\n",
    "#             plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [\"0.0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"])\n",
    "#         else:\n",
    "#             plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [])\n",
    "#         if subplotCounter >= 5:\n",
    "#             plt.xticks([15, 30, 45, 60, 75, 90], [\"15\", \"30\", \"45\", \"60\", \"75\", \"90\"])\n",
    "#         else:\n",
    "#             plt.xticks([15, 30, 45, 60, 75, 90], [])\n",
    "\n",
    "#         subplotCounter += 1\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     fig.savefig(os.path.join(addResults, \"Eating-ROC-AUC Summary-\" + metricName + \"-\" + str(INNER_WINDOW_LENGTH) + \".jpg\"), dpi=600)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# raise\n",
    "# metricPlotter(metricName=\"Recall\")\n",
    "# metricPlotter(metricName=\"Precision\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noNormal=[{'-MaxDiff': 0.1078463, '-SecondFourthSlopeDiff': 0.103150845, '-FourthFourthSlopeDiff': 0.07462696, '-ThirdFourthSlope': 0.06913031, '-Skewness': 0.056625057, '-SkewnessDiff': 0.050760787, '-STDDiff': 0.048788596, '-FirstFourthSlopeDiff': 0.046131063, '-RangeDiff': 0.04021073, '-HalvesSlopeDiff': 0.04018015, '-MinDiff': 0.033765636, '-HalvesSlope': 0.03357451, '-SecondFourthSlope': 0.033038698, '-FourthFourthSlope': 0.029650774, '-FirstFourthSlope': 0.02836506, '-Min': 0.025608739, '-Max': 0.024943182, '-STD': 0.024530888, '-Mean': 0.02407294, '-Range': 0.023151893, '-MeanDiff': 0.022112701, '-KurtosisDiff': 0.02190013, '-ThirdFourthSlopeDiff': 0.02160139, '-Kurtosis': 0.016232677},\n",
    "# {'-MinDiff': 0.05836166, '-Max': 0.05825951, '-Mean': 0.056890287, '-FirstFourthSlopeDiff': 0.054751, '-SecondFourthSlope': 0.05199795, '-FirstFourthSlope': 0.051083237, '-RangeDiff': 0.047590412, '-FourthFourthSlopeDiff': 0.046937533, '-ThirdFourthSlope': 0.04655046, '-HalvesSlope': 0.044784807, '-Min': 0.043269206, '-SkewnessDiff': 0.042040505, '-MaxDiff': 0.041865278, '-HalvesSlopeDiff': 0.041717757, '-Skewness': 0.037697215, '-FourthFourthSlope': 0.034438096, '-MeanDiff': 0.03392487, '-STDDiff': 0.033244412, '-Range': 0.032868195, '-SecondFourthSlopeDiff': 0.031723518, '-KurtosisDiff': 0.029031616, '-Kurtosis': 0.028224358, '-ThirdFourthSlopeDiff': 0.027494926, '-STD': 0.025253225},\n",
    "# {'-Range': 0.07485981, '-MaxDiff': 0.07235001, '-FourthFourthSlope': 0.061106034, '-Min': 0.06102726, '-ThirdFourthSlope': 0.05558133, '-SkewnessDiff': 0.054457445, '-HalvesSlope': 0.051805902, '-RangeDiff': 0.050594293, '-FirstFourthSlope': 0.04973889, '-FourthFourthSlopeDiff': 0.049186327, '-Mean': 0.046296857, '-Kurtosis': 0.04171118, '-SecondFourthSlopeDiff': 0.03683889, '-MeanDiff': 0.034761127, '-Max': 0.03353867, '-MinDiff': 0.03286376, '-SecondFourthSlope': 0.03176475, '-STDDiff': 0.028456414, '-KurtosisDiff': 0.028452437, '-ThirdFourthSlopeDiff': 0.024667135, '-FirstFourthSlopeDiff': 0.022733245, '-Skewness': 0.021999788, '-STD': 0.020657314, '-HalvesSlopeDiff': 0.014551135},\n",
    "# {'-ThirdFourthSlope': 0.116321504, '-FourthFourthSlope': 0.06946923, '-MaxDiff': 0.06276192, '-Max': 0.059627842, '-Mean': 0.052711405, '-Range': 0.050306994, '-MinDiff': 0.049013417, '-RangeDiff': 0.048471592, '-Skewness': 0.047412317, '-FourthFourthSlopeDiff': 0.046264015, '-STDDiff': 0.040881716, '-SkewnessDiff': 0.038825456, '-SecondFourthSlope': 0.037260063, '-Min': 0.033757806, '-MeanDiff': 0.033217307, '-HalvesSlope': 0.031427175, '-KurtosisDiff': 0.03128091, '-FirstFourthSlope': 0.028787797, '-STD': 0.027287915, '-FirstFourthSlopeDiff': 0.024499362, '-Kurtosis': 0.021792239, '-SecondFourthSlopeDiff': 0.01951169, '-ThirdFourthSlopeDiff': 0.01877995, '-HalvesSlopeDiff': 0.010330347},\n",
    "# {'-MaxDiff': 0.06764946, '-STD': 0.056324393, '-FourthFourthSlopeDiff': 0.055581857, '-Mean': 0.051104046, '-Range': 0.0502673, '-SkewnessDiff': 0.049853936, '-RangeDiff': 0.044252936, '-Min': 0.043754313, '-Max': 0.04371197, '-MinDiff': 0.042753506, '-KurtosisDiff': 0.039921276, '-HalvesSlopeDiff': 0.03888581, '-FirstFourthSlope': 0.038707566, '-FourthFourthSlope': 0.03850367, '-STDDiff': 0.038403533, '-Skewness': 0.038231872, '-SecondFourthSlope': 0.03812664, '-SecondFourthSlopeDiff': 0.037757747, '-Kurtosis': 0.037050135, '-ThirdFourthSlopeDiff': 0.03525641, '-ThirdFourthSlope': 0.032925814, '-MeanDiff': 0.031699583, '-HalvesSlope': 0.028091868, '-FirstFourthSlopeDiff': 0.021184346},\n",
    "# {'-FourthFourthSlopeDiff': 0.07831435, '-SkewnessDiff': 0.06162001, '-Min': 0.050464742, '-SecondFourthSlopeDiff': 0.049488824, '-RangeDiff': 0.049330417, '-Range': 0.04861606, '-MaxDiff': 0.04708212, '-FourthFourthSlope': 0.046744823, '-KurtosisDiff': 0.046689652, '-STDDiff': 0.04431532, '-FirstFourthSlopeDiff': 0.042319566, '-MeanDiff': 0.041090157, '-MinDiff': 0.039877523, '-Skewness': 0.039017998, '-SecondFourthSlope': 0.038478997, '-Max': 0.03784959, '-Mean': 0.03724398, '-FirstFourthSlope': 0.037229583, '-ThirdFourthSlopeDiff': 0.033134893, '-Kurtosis': 0.031625576, '-HalvesSlope': 0.030476, '-ThirdFourthSlope': 0.026068594, '-STD': 0.023853524, '-HalvesSlopeDiff': 0.01906771}]\n",
    "\n",
    "# for counter in range(len(noNormal)):\n",
    "#     temp=noNormal[counter]\n",
    "#     noNormal[counter]=dict(sorted(temp.items(), key=lambda item: item[0],reverse=True))\n",
    "# y=[]\n",
    "# for counter in range(len(noNormal)):\n",
    "#     temp=noNormal[counter]\n",
    "#     x=temp.keys()\n",
    "#     y.append(list(temp.values()))\n",
    "# y=np.asarray(y)\n",
    "# x=list(x)\n",
    "\n",
    "# y=y.mean(axis=0)\n",
    "# indexSorted=np.argsort(y)\n",
    "# x=np.asarray(x)\n",
    "# x=x[indexSorted.astype(int)]\n",
    "# y=np.sort(y)\n",
    "# print(\"********\")\n",
    "\n",
    "# plt.figure(figsize=(15,15))\n",
    "# plt.bar(x,y)\n",
    "# plt.xticks(x, rotation='vertical')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4eb26d83fe05250b5b83f543d3d7d3642bdb5ef6b331e9a41899d2131d4858f3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
