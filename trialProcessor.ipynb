{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pytz\n",
    "from datetime import datetime,timedelta,timezone\n",
    "from dateutil.tz import tzutc\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import pearsonr, mode,skew,kurtosis\n",
    "from scipy.signal import savgol_filter\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error,plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "addDataPrefix='/Users/sorush/My Drive/Documents/Educational/TAMU/Research/Trial/Data/11-5-21-11-15-21'\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix='/home/grads/s/sorush.omidvar/CGMDataset/Trial/Data/11-5-21-11-15-21'\n",
    "if not os.path.exists(addDataPrefix):\n",
    "   addDataPrefix = 'C:\\\\GDrive\\\\Documents\\\\Educational\\\\TAMU\\\\Research\\\\Trial\\\\Data\\\\11-5-21-11-15-21'\n",
    "\n",
    "addUserInput=os.path.join(addDataPrefix,'User inputted')\n",
    "addHKCM=os.path.join(addDataPrefix,'hk+cm')\n",
    "addCGM=os.path.join(addDataPrefix,'CGM')\n",
    "addE4=os.path.join(addDataPrefix,'E4')\n",
    "\n",
    "exempts=['p2']\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({'figure.facecolor':'white'})\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "START_OF_TRIAL = datetime.strptime('11 06 2021-02:00:00', '%m %d %Y-%H:%M:%S')#to handle the daylight saving issue in apple watches\n",
    "END_OF_TRIAL = datetime.strptime('11 15 2021-00:00:00', '%m %d %Y-%H:%M:%S')  \n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix,'All_meals.pkl')):\n",
    "    os.remove(os.path.join(addDataPrefix,'All_meals.pkl'))\n",
    "os.chdir(addUserInput)\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_meals.pkl')):    \n",
    "    df=[]\n",
    "    for root, dirs, files in os.walk(addUserInput):\n",
    "        for file in files:\n",
    "            if '.csv' in file.lower():\n",
    "                if 'meals' in file.lower():\n",
    "                    participantName=file[:file.find('Meals')]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\",file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\",file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    dfTemp.insert(0,'Participant',participantName)\n",
    "                    dfTemp.rename(columns={'startTime':'StartTime'}, inplace=True)\n",
    "                    dfTemp['StartTime']=pd.to_datetime(dfTemp['StartTime'])\n",
    "                    dfTemp['FinishTime']=pd.to_datetime(dfTemp['FinishTime'])\n",
    "\n",
    "                    dfTemp['StartTime']-=pd.DateOffset(hours=5)#fixing the time zone issue\n",
    "                    dfTemp['FinishTime']-=pd.DateOffset(hours=5)#fixing the time zone issue            \n",
    "                    dfTemp.sort_values([\"Participant\",'StartTime'],ascending = (True, True),inplace=True)\n",
    "                    if len(dfTemp.columns)!=10:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    if len(df)!=0:\n",
    "                        frames=[dfTemp,df]\n",
    "                        df=pd.concat(frames)\n",
    "                    else:\n",
    "                        df=dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfMeal=df    \n",
    "    dfMeal=dfMeal[dfMeal['StartTime']>=START_OF_TRIAL]\n",
    "    dfMeal=dfMeal[dfMeal['FinishTime']<END_OF_TRIAL]\n",
    "    print(\"Meal database is limited to the trial period\")\n",
    "    dfMeal.to_pickle(os.path.join(addDataPrefix,'All_meals.pkl')) \n",
    "else:\n",
    "    dfMeal=pd.read_pickle(os.path.join(addDataPrefix,'All_meals.pkl')) \n",
    "\n",
    "def pdInterpolation(dfTemp):\n",
    "    index=dfTemp['Time']\n",
    "    seriesParticipant = pd.Series(dfTemp['Abbot'].to_list(), index=index)\n",
    "    seriesParticipant=seriesParticipant.resample('1T').asfreq()\n",
    "    seriesParticipant.interpolate(method='polynomial',order=3,inplace=True)\n",
    "    tempTime=seriesParticipant.index\n",
    "    tempVal=seriesParticipant.values\n",
    "    dfTemp=pd.DataFrame(zip(tempTime,tempVal),columns=['Time','Abbot'])\n",
    "    return dfTemp\n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix,'All_cgm.pkl')):\n",
    "    os.remove(os.path.join(addDataPrefix,'All_cgm.pkl'))\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_cgm.pkl')):\n",
    "    os.chdir(addCGM)\n",
    "    dfCGM=[]\n",
    "    for root, dirs, files in os.walk(addCGM):\n",
    "        for file in files:\n",
    "            if '.txt' in file.lower():\n",
    "                if '_fl' in file.lower():\n",
    "                    participantName=file[:file.find('_fl')]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\",file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\",file)\n",
    "                    dfTemp = pd.read_csv(file,sep=\"\\t\",skiprows=1)\n",
    "                    if len(dfTemp.columns)!=4:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break               \n",
    "                    dfTemp.columns.values[0] = \"ID\"\n",
    "                    dfTemp.columns.values[1] = \"Time\"\n",
    "                    dfTemp.columns.values[2] = \"Record\"\n",
    "                    dfTemp.columns.values[3] = \"Abbot\"\n",
    "                    dfTemp.drop(columns=[\"ID\",'Record'],inplace=True)                \n",
    "                    dfTemp['Time']=pd.to_datetime(dfTemp['Time'])\n",
    "                    dfTemp['Abbot']=pd.to_numeric(dfTemp['Abbot'])\n",
    "                    dfTemp.sort_values([\"Time\"],ascending = (True),inplace=True)\n",
    "                    dfTemp=pdInterpolation(dfTemp)\n",
    "                    dfTemp.insert(0,'Participant',participantName)\n",
    "                    if len(dfTemp.columns)!=3:\n",
    "                        print(\"MAYDAY. Error in processing csv\")\n",
    "                        break                    \n",
    "                    if len(dfCGM)!=0:\n",
    "                        frames=[dfTemp,dfCGM]\n",
    "                        dfCGM=pd.concat(frames)\n",
    "                    else:\n",
    "                        dfCGM=dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfCGM=dfCGM[dfCGM['Time']>=START_OF_TRIAL]\n",
    "    dfCGM=dfCGM[dfCGM['Time']<END_OF_TRIAL]\n",
    "    print(\"CGM database is limited to the trial period\")\n",
    "    dfCGM.to_pickle(os.path.join(addDataPrefix,'All_cgm.pkl')) \n",
    "else:\n",
    "    dfCGM=pd.read_pickle(os.path.join(addDataPrefix,'All_cgm.pkl'))\n",
    "\n",
    "\n",
    "  \n",
    "if os.path.exists(os.path.join(addDataPrefix,'All_cm.pkl')):\n",
    "    os.remove(os.path.join(addDataPrefix,'All_cm.pkl'))\n",
    "os.chdir(addHKCM)\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_cm.pkl')):\n",
    "    df=[]\n",
    "    for root, dirs, files in os.walk(addHKCM):\n",
    "        for file in files:\n",
    "            if '.csv' in file.lower():\n",
    "                if 'cm' in file.lower() and 'modified' in file.lower():\n",
    "                    participantName=file[:file.find('_cm')]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\",file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\",file)\n",
    "                    dfTemp=pd.read_csv(file)\n",
    "                    print(\"File is read\")\n",
    "                    dfTemp['Time']=pd.to_datetime(dfTemp['Time'])\n",
    "                    dfTemp.insert(0,'Participant',participantName)\n",
    "                    dfTemp.insert(len(dfTemp.columns),'|Ax|+|Ay|+|Az|',dfTemp['Ax'].abs()+dfTemp['Ay'].abs()+dfTemp['Az'].abs()+0.001)#this is to avoid 0 later on for feature calculation\n",
    "                    dfTemp.insert(len(dfTemp.columns),'|Yaw|+|Roll|+|Pitch|',dfTemp['Yaw'].abs()+dfTemp['Roll'].abs()+dfTemp['Pitch'].abs())\n",
    "                    dfTemp.insert(len(dfTemp.columns),'RotationalToLinear',dfTemp['|Yaw|+|Roll|+|Pitch|']/dfTemp['|Ax|+|Ay|+|Az|'])\n",
    "                    print(\"modified\")\n",
    "                    dfTemp.sort_values(['Time'],ascending = (True),inplace=True)\n",
    "                    print(\"sorted\")\n",
    "                    if len(dfTemp.columns)!=14:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        print(dfTemp.columns)\n",
    "                        break\n",
    "                    if len(df)!=0:\n",
    "                        frames=[dfTemp,df]\n",
    "                        df=pd.concat(frames)\n",
    "                    else:\n",
    "                        df=dfTemp\n",
    "    dfCM=df\n",
    "    print(\"Processing is done\")\n",
    "    dfCM=dfCM[dfCM['Time']>=START_OF_TRIAL]\n",
    "    dfCM=dfCM[dfCM['Time']<END_OF_TRIAL]\n",
    "    print(\"CM database is limited to the trial period\")\n",
    "    dfCM.to_pickle(os.path.join(addDataPrefix,'All_cm.pkl')) \n",
    "else:\n",
    "    dfCM = pd.read_pickle(os.path.join(addDataPrefix,'All_cm.pkl'))\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix,'All_E4.pkl')):\n",
    "    os.remove(os.path.join(addDataPrefix,'All_E4.pkl'))\n",
    "os.chdir(addE4)\n",
    "# fields=['ACC','BVP','EDA','HR','IBI','TEMP']\n",
    "fields=['BVP','EDA','HR','TEMP']\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_E4.pkl')):    \n",
    "    dfE4=[]\n",
    "    for root, dirs, files in os.walk(addE4):\n",
    "        for file in files:\n",
    "            if '.csv' in file.lower():\n",
    "                participantName=root[root.find('E4')+3:]\n",
    "                participantName=participantName[:2]\n",
    "                field=file[:file.find('.csv')]\n",
    "                if field not in fields:\n",
    "                    print(\"File name does not comply with analyzed fields\",file)\n",
    "                    continue\n",
    "                print(participantName,field)\n",
    "                if participantName in exempts:\n",
    "                    print(\"Exemption...\",file)\n",
    "                    continue\n",
    "                print(\"Reading ...\",file)\n",
    "                os.chdir(root)\n",
    "                dfTemp = pd.read_csv(file,header=None)\n",
    "                # if field=='ACC':\n",
    "                #     assert len(dfTemp.columns)==3\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     timeStep=1/dfTemp.iloc[1,0]\n",
    "                #     dfTemp.drop([0,1],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Data1',1:'Data2',2:'Data3'}, inplace=True)#x,y,z for data1,data2,data3\n",
    "                #     timeTemp=[]\n",
    "                #     for counter in range(len(dfTemp)):\n",
    "                #         timeTemp.append(timeBase+counter*timeStep)\n",
    "                #     dfTemp.insert(0,'Time',timeTemp)\n",
    "                #     dfTemp.insert(0,'Field',\"Acceleration\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                if field=='BVP':\n",
    "                    assert len(dfTemp.columns)==1\n",
    "                    timeBase=dfTemp.iloc[0,0]\n",
    "                    timeStep=1/dfTemp.iloc[1,0]\n",
    "                    dfTemp.drop([0,1],inplace=True)\n",
    "                    dfTemp.rename(columns={0:'Data1'}, inplace=True)\n",
    "                    dfTemp[\"Data2\"]=\"\"\n",
    "                    dfTemp[\"Data3\"]=\"\"\n",
    "                    timeTemp=[]\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase+counter*timeStep)\n",
    "                    dfTemp.insert(0,'Time',timeTemp)\n",
    "                    dfTemp.insert(0,'Field',\"BVP\")\n",
    "                    dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                elif field=='HR':\n",
    "                    assert len(dfTemp.columns)==1\n",
    "                    timeBase=dfTemp.iloc[0,0]\n",
    "                    timeStep=1/dfTemp.iloc[1,0]\n",
    "                    dfTemp.drop([0,1],inplace=True)\n",
    "                    dfTemp.rename(columns={0:'Data1'}, inplace=True)\n",
    "                    dfTemp[\"Data2\"]=\"\"\n",
    "                    dfTemp[\"Data3\"]=\"\"\n",
    "                    timeTemp=[]\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase+counter*timeStep)\n",
    "                    dfTemp.insert(0,'Time',timeTemp)\n",
    "                    dfTemp.insert(0,'Field',\"HR\")\n",
    "                    dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')                \n",
    "                elif field=='EDA':\n",
    "                    assert len(dfTemp.columns)==1\n",
    "                    timeBase=dfTemp.iloc[0,0]\n",
    "                    timeStep=1/dfTemp.iloc[1,0]\n",
    "                    dfTemp.drop([0,1],inplace=True)\n",
    "                    dfTemp.rename(columns={0:'Data1'}, inplace=True)\n",
    "                    dfTemp[\"Data2\"]=\"\"\n",
    "                    dfTemp[\"Data3\"]=\"\"                    \n",
    "                    timeTemp=[]\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase+counter*timeStep)\n",
    "                    dfTemp.insert(0,'Time',timeTemp)\n",
    "                    dfTemp.insert(0,'Field',\"EDA\")\n",
    "                    dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                # elif field=='IBI':\n",
    "                #     assert len(dfTemp.columns)==2\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     dfTemp.drop([0],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Time',1:'Data1'}, inplace=True)\n",
    "                #     dfTemp[\"Data2\"]=\"\"\n",
    "                #     dfTemp[\"Data3\"]=\"\"\n",
    "                #     timeTemp=[]\n",
    "                #     dfTemp['Time']+=timeBase\n",
    "                #     dfTemp.insert(0,'Field',\"IBI\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                elif field=='TEMP':\n",
    "                    assert len(dfTemp.columns)==1\n",
    "                    timeBase=dfTemp.iloc[0,0]\n",
    "                    timeStep=1/dfTemp.iloc[1,0]\n",
    "                    dfTemp.drop([0,1],inplace=True)\n",
    "                    dfTemp.rename(columns={0:'Data1'}, inplace=True)\n",
    "                    dfTemp[\"Data2\"]=\"\"\n",
    "                    dfTemp[\"Data3\"]=\"\"                    \n",
    "                    timeTemp=[]\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase+counter*timeStep)\n",
    "                    dfTemp.insert(0,'Time',timeTemp)\n",
    "                    dfTemp.insert(0,'Field',\"Temperature\")\n",
    "                    dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')             \n",
    "                dfTemp.insert(0,'Participant',participantName)\n",
    "\n",
    "                dfTemp['Time']-=pd.DateOffset(hours=6)#Empatica records in GMT and also during the trial we had daylight saving\n",
    "                dfTemp.sort_values([\"Participant\",'Field',\"Time\"],ascending = (True,True, True),inplace=True)\n",
    "                if len(dfTemp.columns)!=6:\n",
    "                    print(\"MAYDAY. Error in reading csv\")\n",
    "                    break\n",
    "                if len(dfE4)!=0:\n",
    "                    frames=[dfTemp,dfE4]\n",
    "                    dfE4=pd.concat(frames)\n",
    "                else:\n",
    "                    dfE4=dfTemp\n",
    "                \n",
    "    print(\"reading is done\")  \n",
    "    dfE4=dfE4[dfE4['Time']>=START_OF_TRIAL]\n",
    "    dfE4=dfE4[dfE4['Time']<END_OF_TRIAL]\n",
    "    print(\"E4 database is limited to the trial period\")\n",
    "    dfE4.to_pickle(os.path.join(addDataPrefix,'All_E4.pkl')) \n",
    "else:\n",
    "    dfE4=pd.read_pickle(os.path.join(addDataPrefix,'All_E4.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMUM_POINT_CM=100\n",
    "OUTTER_WINDOW_LENGTH=timedelta(minutes=180)\n",
    "OUTTER_WINDOW_STEP=timedelta(minutes=90)\n",
    "EATING_PORTION=timedelta(minutes=90)\n",
    "INNER_WINDOW_LENGTH=timedelta(minutes=1)\n",
    "\n",
    "\n",
    "def e4Reporter(df):\n",
    "    topics=['BVP','EDA','HR','Temperature']\n",
    "    report=[]\n",
    "    for topic in topics:\n",
    "        dfTemp=df[df['Field']==topic]\n",
    "        if(len(dfTemp)<MINIMUM_POINT_CM):\n",
    "            report.append('Nan')\n",
    "        else:\n",
    "            val=dfTemp['Data1'].mean()\n",
    "            report.append(val)\n",
    "    return report\n",
    "\n",
    "def motionCalculator(df):\n",
    "    f1=df['RotationalToLinear'].mean()\n",
    "    f2=df['|Ax|+|Ay|+|Az|'].mean()\n",
    "    f5=df['|Yaw|+|Roll|+|Pitch|'].mean()\n",
    "    return [f1,f2,f5]\n",
    "\n",
    "def featureExtractor(dataList):\n",
    "    dataList=np.asarray(dataList).astype(float)\n",
    "    result=[]\n",
    "    dataDim=dataList.ndim\n",
    "    if dataDim>1:\n",
    "        for counter in range(dataList.shape[1]):\n",
    "            meanVal=np.nanmean(dataList[:,counter],axis=0)\n",
    "            stdVal=np.nanstd(dataList[:,counter],axis=0)\n",
    "            minVal=np.nanmin(dataList[:,counter],axis=0)\n",
    "            maxVal=np.nanmax(dataList[:,counter],axis=0)\n",
    "            rangeVal=maxVal-minVal\n",
    "            # skewnessVal=skew(dataList[:,counter],nan_policy='omit',axis=0)\n",
    "            # kurtosisVal=kurtosis(dataList[:,counter],nan_policy='omit',axis=0)\n",
    "            result.extend([rangeVal, meanVal, stdVal, minVal, maxVal])\n",
    "    else:\n",
    "        meanVal=np.nanmean(dataList)\n",
    "        stdVal=np.nanstd(dataList)\n",
    "        minVal=np.nanmin(dataList)\n",
    "        maxVal=np.nanmax(dataList)\n",
    "        rangeVal=maxVal-minVal\n",
    "        # skewnessVal=skew(dataList,nan_policy='omit')\n",
    "        # kurtosisVal=kurtosis(dataList,nan_policy='omit')\n",
    "        result.extend([rangeVal, meanVal, stdVal, minVal, maxVal])        \n",
    "    return result\n",
    "\n",
    "\n",
    "participants=dfCM['Participant'].to_list()\n",
    "participants=list(set(participants))\n",
    "participantDataList=[]\n",
    "skippedWindows=0\n",
    "\n",
    "# if os.path.exists(os.path.join(addDataPrefix,'Features.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,'Features.pkl'))\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'Features.pkl')):\n",
    "    for participant in participants:\n",
    "        outterWindowStart=START_OF_TRIAL\n",
    "        outterWindowEnd=outterWindowStart+OUTTER_WINDOW_LENGTH        \n",
    "        print(\"Participant \",participant,\" is started\")\n",
    "        dfParticipantCM=dfCM[dfCM['Participant']==participant]\n",
    "        dfParticipantMeal=dfMeal[dfMeal['Participant']==participant]\n",
    "        dfParticipantCGM=dfCGM[dfCGM['Participant']==participant]\n",
    "        dfParticipantE4=dfE4[dfE4['Participant']==participant]\n",
    "        print(\"CM size for participant\",len(dfParticipantCM))\n",
    "        innerWindowStart=outterWindowStart\n",
    "        innerWindowEnd=innerWindowStart+INNER_WINDOW_LENGTH        \n",
    "        for i in tqdm(range(0,int(((END_OF_TRIAL-START_OF_TRIAL).total_seconds())/(OUTTER_WINDOW_LENGTH.total_seconds())),1)):\n",
    "            dfTempMeal=dfParticipantMeal[(dfParticipantMeal['StartTime']>=outterWindowStart) & (dfParticipantMeal['StartTime']<=outterWindowStart+EATING_PORTION)]\n",
    "            tempList=[]\n",
    "            tempListCM=[]\n",
    "            tempListE4=[]\n",
    "            tempListCGM=[]\n",
    "            tempListInfo=[outterWindowStart,outterWindowEnd,participant]\n",
    "            skippedFlag=True\n",
    "            for j in range(0,int((OUTTER_WINDOW_LENGTH.total_seconds())/(INNER_WINDOW_LENGTH.total_seconds())),1):\n",
    "                dfTempCM=dfParticipantCM[(dfParticipantCM['Time']>=innerWindowStart) & (dfParticipantCM['Time']<innerWindowEnd)]\n",
    "                if(len(dfTempCM)<MINIMUM_POINT_CM):\n",
    "                    tempListCM.append(['Nan','Nan','Nan'])\n",
    "                else:\n",
    "                    tempListCM.append(motionCalculator(dfTempCM))\n",
    "\n",
    "                dfTempE4=dfParticipantE4[(dfParticipantE4['Time']>=innerWindowStart) & (dfParticipantE4['Time']<innerWindowEnd)]\n",
    "                if(len(dfTempE4)<MINIMUM_POINT_CM):\n",
    "                    tempListE4.append(['Nan','Nan','Nan','Nan'])\n",
    "                else:\n",
    "                    tempListE4.append(e4Reporter(dfTempE4))\n",
    "                \n",
    "                if(len(dfTempCM)>MINIMUM_POINT_CM and len(dfTempE4)>MINIMUM_POINT_CM):\n",
    "                    skippedFlag=False\n",
    "                innerWindowStart+=INNER_WINDOW_LENGTH\n",
    "                innerWindowEnd+=INNER_WINDOW_LENGTH\n",
    "            if len(dfTempMeal)>0:\n",
    "                mealFlag=1\n",
    "            else:\n",
    "                mealFlag=0\n",
    "                \n",
    "            carbs=dfTempMeal['Carbs'].sum()\n",
    "            protein=dfTempMeal['Protein'].sum()\n",
    "            fat=dfTempMeal['Fat'].sum()\n",
    "\n",
    "            if skippedFlag:\n",
    "                skippedWindows+=1\n",
    "            else:\n",
    "                assert len(tempListCM)==int((OUTTER_WINDOW_LENGTH.total_seconds())/(INNER_WINDOW_LENGTH.total_seconds()))\n",
    "                tempListCM=featureExtractor(tempListCM)\n",
    "                tempList.extend(tempListCM) #5*3=15\n",
    "\n",
    "                assert len(tempListE4)==int((OUTTER_WINDOW_LENGTH.total_seconds())/(INNER_WINDOW_LENGTH.total_seconds()))\n",
    "                tempListE4=featureExtractor(tempListE4)\n",
    "                tempList.extend(tempListE4) #5*4=20\n",
    "\n",
    "                dfTempCGM=dfParticipantCGM[(dfParticipantCGM['Time']>=outterWindowStart) & (dfParticipantCGM['Time']<outterWindowEnd)]\n",
    "                tempListCGM=dfTempCGM['Abbot'].to_list()\n",
    "                tempListCGM=featureExtractor(tempListCGM)\n",
    "                tempList.extend(tempListCGM) #5\n",
    "\n",
    "                tempList.extend(tempListInfo) #3\n",
    "                tempList.append(carbs)\n",
    "                tempList.append(fat)\n",
    "                tempList.append(protein)\n",
    "                tempList.append(mealFlag) #1\n",
    "                assert len(tempList)==5*3+5*4+5+3+4\n",
    "                participantDataList.append(tempList)\n",
    "            outterWindowStart+=OUTTER_WINDOW_STEP\n",
    "            outterWindowEnd+=OUTTER_WINDOW_STEP\n",
    "    participantDataArray=np.asarray(participantDataList)\n",
    "    columnTopics=['F1','F2','F5','BVP','EDA','HR','Temperature','CGM']\n",
    "    columnStats=['Range','Mean','Std','Min','Max']\n",
    "    columns=[]\n",
    "    for topic in columnTopics:\n",
    "        for stat in columnStats:\n",
    "            columns.append(topic+stat)\n",
    "    columns.extend(['Start','End','Participant','Carb','Fat','Protein','MealLabel'])\n",
    "    dfFeatures=pd.DataFrame(participantDataArray,columns=columns)\n",
    "    dfFeatures.to_pickle(os.path.join(addDataPrefix,'Features.pkl')) \n",
    "else:\n",
    "    dfFeatures = pd.read_pickle(os.path.join(addDataPrefix,'Features.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfFeatures['Participant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Combination: CGM\n",
      "Participant: p4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:04<00:09,  2.44s/it]"
     ]
    }
   ],
   "source": [
    "def xgRegressor(xTrain,xVal,xTest,yTrain,yVal,yTest):\n",
    "    rmseBest=100000000000\n",
    "    for maxDepth in tqdm(np.arange(2,8,1)):\n",
    "        for estimator in np.arange(50,200,25):\n",
    "            clf = xgb.XGBClassifier(n_jobs=24,n_estimators=estimator,max_depth=maxDepth, objective = \"reg:squarederror\", eval_metric = \"rmse\")\n",
    "            clf.fit(xTrain,yTrain)\n",
    "            predictionsVal = clf.predict(xVal)\n",
    "            rmse = np.sqrt(MSE(yVal, predictionsVal))\n",
    "            if rmse<rmseBest:\n",
    "                rmseBest=rmse\n",
    "                modelBest=clf\n",
    "\n",
    "    predictionsTest=modelBest.predict(xTest)\n",
    "    rmse = np.sqrt(MSE(yTest, predictionsTest))\n",
    "    # print(\"For \",parameter,\" we have RMSE:\",rmse, \"Relative RMSE:\",rmse/np.sum(yTest))\n",
    "    return rmse,rmse/np.sum(yTest)\n",
    "    # plot_confusion_matrix(modelBest, xTest, yTest,cmap='bone') \n",
    "\n",
    "\n",
    "def xgClassifier(xTrain,xVal,xTest,yTrain,yVal,yTest):\n",
    "    f1ScoreBest=-1\n",
    "    for maxDepth in tqdm(np.arange(2,8,1)):\n",
    "        for estimator in np.arange(50,200,25):\n",
    "            for posWeight in np.arange(1,50,5):\n",
    "                clf = xgb.XGBClassifier(scale_pos_weight = posWeight, n_jobs=24,n_estimators=estimator,max_depth=maxDepth, objective = \"binary:logistic\", eval_metric = \"error\")\n",
    "                clf.fit(xTrain,yTrain)\n",
    "                predictionsVal = clf.predict(xVal)\n",
    "        \n",
    "                accuracy=sklearn.metrics.accuracy_score(yVal,predictionsVal)\n",
    "                recall=sklearn.metrics.recall_score(yVal,predictionsVal)\n",
    "                precision=sklearn.metrics.precision_score(yVal,predictionsVal)\n",
    "                f1Score=sklearn.metrics.f1_score(yVal,predictionsVal)\n",
    "\n",
    "                if f1Score>f1ScoreBest:\n",
    "                    modelBest=clf\n",
    "                    f1ScoreBest=f1Score\n",
    "    predictionsTest=modelBest.predict(xTest)\n",
    "    confMatrix=sklearn.metrics.confusion_matrix(yTest,predictionsTest)\n",
    "    accuracy=sklearn.metrics.accuracy_score(yTest,predictionsTest)\n",
    "    recall=sklearn.metrics.recall_score(yTest,predictionsTest)\n",
    "    precision=sklearn.metrics.precision_score(yTest,predictionsTest)\n",
    "    f1Score=sklearn.metrics.f1_score(yTest,predictionsTest)\n",
    "    \n",
    "    return accuracy,recall,precision,f1Score\n",
    "    # plot_confusion_matrix(modelBest, xTest, yTest,cmap='bone') \n",
    "\n",
    "def dataBalancer(xTrain,xVal,yTrain,yVal):\n",
    "    oversample = SMOTE()\n",
    "    xVal, yVal = oversample.fit_resample(xVal, yVal)\n",
    "    xTrain, yTrain = oversample.fit_resample(xTrain, yTrain)\n",
    "\n",
    "    return xTrain,xVal,yTrain,yVal\n",
    "\n",
    "def reportFormatter(reportTemp,classifierFlag,classifierReports,regressorReports,participant,combination,component):\n",
    "    reportTemp=np.asarray(reportTemp)\n",
    "    reportTemp=np.mean(reportTemp,axis=0)\n",
    "    reportTemp=list(reportTemp)\n",
    "    if classifierFlag:\n",
    "        reportTemp.append(participant)\n",
    "        reportTemp.append(combination)\n",
    "        reportTemp.append('Nan')\n",
    "        reportTemp=np.asarray(reportTemp)\n",
    "        classifierReports.append(reportTemp)\n",
    "    else:\n",
    "        reportTemp.append('Nan')\n",
    "        reportTemp.append('Nan')\n",
    "        reportTemp.append(participant)\n",
    "        reportTemp.append(combination)\n",
    "        reportTemp.append(component)\n",
    "        reportTemp=np.asarray(reportTemp)\n",
    "        regressorReports.append(reportTemp)        \n",
    "\n",
    "def testTrainSplitFunc(data,randomSeed,normalFlag,combination):\n",
    "    participants=data[:,data.shape[1]-5]\n",
    "    participants=list(set(participants))\n",
    "    regressorReports=[]\n",
    "    classifierReports=[]   \n",
    "    for participantCounter in range(len(participants)+1):       \n",
    "        \n",
    "        indxList=[]\n",
    "        if participantCounter<len(participants):\n",
    "            participant=participants[participantCounter]\n",
    "            print(\"Participant:\",participant)\n",
    "            for counter in range(data.shape[0]):\n",
    "                if(data[counter,data.shape[1]-5]==participant):\n",
    "                    indxList.append(counter)\n",
    "            dataParticipant=data[indxList,:]\n",
    "        else:#all participant\n",
    "            participant=\"All\"\n",
    "            dataParticipant=data\n",
    "            \n",
    "        # windowStarts=dataParticipant[:,dataParticipant.shape[1]-7]\n",
    "        # windowEnds=dataParticipant[:,dataParticipant.shape[1]-6]\n",
    "        \n",
    "        dataXBinary=dataParticipant[:,0:dataParticipant.shape[1]-7]\n",
    "        dataXBinary=dataXBinary.astype(float)\n",
    "        dataXRegression=dataXBinary\n",
    "\n",
    "        dataYBinary=dataParticipant[:,dataParticipant.shape[1]-1]\n",
    "        dataYBinary=dataYBinary.astype(float)\n",
    "\n",
    "        dataYRegression=dataParticipant[:,dataParticipant.shape[1]-4:dataParticipant.shape[1]-1]#-4, -3 and -2 are carb, fat and protein\n",
    "        dataYRegression=dataYRegression.astype(float)\n",
    "\n",
    "        if(normalFlag):\n",
    "            dataXBinary-=-dataXBinary.mean(axis=0)\n",
    "            dataXBinary/=dataXBinary.std(axis=0)\n",
    "            dataXRegression=dataXBinary        \n",
    "\n",
    "        reportClassifierTemp=[]\n",
    "        reportFatTemp=[]\n",
    "        reportCarbTemp=[]\n",
    "        reportProteinTemp=[]\n",
    "        splitterOuter = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=randomSeed)\n",
    "        for trainIndex, testIndex in splitterOuter.split(dataXBinary, dataYBinary):\n",
    "            xTrainBinary,xTestBinary=dataXBinary[trainIndex,:],dataXBinary[testIndex,:]\n",
    "            yTrainBinary,yTestBinary=dataYBinary[trainIndex],dataYBinary[testIndex]\n",
    "\n",
    "            xTrainRegression,xTestRegression=dataXRegression[trainIndex,:],dataXRegression[testIndex,:]\n",
    "            yTrainRegression,yTestRegression=dataYRegression[trainIndex,:],dataYRegression[testIndex,:]\n",
    "\n",
    "            splitterInner = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=randomSeed)\n",
    "            for trainIndex, valIndex in splitterInner.split(xTrainBinary, yTrainBinary):\n",
    "                xTrainBinary,xValBinary=dataXBinary[trainIndex,:],dataXBinary[valIndex,:]\n",
    "                yTrainBinary,yValBinary=dataYBinary[trainIndex],dataYBinary[valIndex]\n",
    "\n",
    "                xTrainRegression,xValRegression=dataXRegression[trainIndex,:],dataXRegression[valIndex,:]\n",
    "                yTrainRegression,yValRegression=dataYRegression[trainIndex,:],dataYRegression[valIndex,:]\n",
    "\n",
    "            reportClassifierTemp.append(xgClassifier(xTrainBinary,xValBinary,xTestBinary,yTrainBinary,yValBinary,yTestBinary))\n",
    "\n",
    "            counter=0\n",
    "            reportCarbTemp.append(xgRegressor(xTrainRegression,xValRegression,xTestRegression,yTrainRegression[:,counter],yValRegression[:,counter],yTestRegression[:,counter]))\n",
    "            counter=1\n",
    "            reportFatTemp.append(xgRegressor(xTrainRegression,xValRegression,xTestRegression,yTrainRegression[:,counter],yValRegression[:,counter],yTestRegression[:,counter]))\n",
    "            counter=2\n",
    "            reportProteinTemp.append(xgRegressor(xTrainRegression,xValRegression,xTestRegression,yTrainRegression[:,counter],yValRegression[:,counter],yTestRegression[:,counter]))            \n",
    "        reportFormatter(reportClassifierTemp,True,classifierReports,regressorReports,participant,combination,'Nan')\n",
    "        reportFormatter(reportCarbTemp,False,classifierReports,regressorReports,participant,combination,'Carb')\n",
    "        reportFormatter(reportFatTemp,False,classifierReports,regressorReports,participant,combination,'Fat')\n",
    "        reportFormatter(reportProteinTemp,False,classifierReports,regressorReports,participant,combination,'Protein')\n",
    "    classifierReports=np.asarray(classifierReports)\n",
    "    regressorReports=np.asarray(regressorReports)\n",
    "    comboReport=np.vstack((classifierReports,regressorReports))\n",
    "    return comboReport\n",
    "\n",
    "\n",
    "combinations=[['CGM'],['CGM','F1','F2','F5'],['CGM','BVP','EDA','HR','Temperature'],['CGM','BVP','EDA','HR','Temperature','F1','F2','F3']]\n",
    "columns=dfFeatures.columns\n",
    "reportHeaders=['Accuracy-RMSE','Recall-RMSERelative','Precision-NAN','F1-NAN','Participant','Comboniation','Component']\n",
    "dfReports=[]\n",
    "for combination in combinations:\n",
    "    columnList=['Start','End','Participant','Carb','Fat','Protein','MealLabel']\n",
    "    for topic in combination:\n",
    "        for column in columns:\n",
    "            if topic in column:\n",
    "                columnList.append(column)\n",
    "                \n",
    "    dfCombination = dfFeatures[dfFeatures.columns.intersection(columnList)]\n",
    "    participantDataArray=dfCombination.to_numpy()\n",
    "    randomSeed=random.randrange(50)\n",
    "    print(\"----------------------\")\n",
    "    print(\"Combination:\",'+'.join(combination))\n",
    "    NORMALIZED_FLAG=False\n",
    "    dfTemp=testTrainSplitFunc(participantDataArray,randomSeed,NORMALIZED_FLAG,'+'.join(combination))    \n",
    "    dfTemp=pd.DataFrame(dfTemp,columns=reportHeaders)\n",
    "    if len(dfReports)>0:\n",
    "        frames=[dfTemp,dfReports]\n",
    "        dfReports=pd.concat(frames)\n",
    "    else:\n",
    "        dfReports=dfTemp\n",
    "dfReports.reset_index(drop=True, inplace=True)\n",
    "print(dfReports)\n",
    "\n",
    "\n",
    "# print(\"**********************************\")\n",
    "# print(\"**********************************\")\n",
    "# print(\"With NORMALIZATION\")\n",
    "# NORMALIZED_FLAG=True\n",
    "# testTrainSplitFunc(participantDataArray,randomSeed,NORMALIZED_FLAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfReports['Participant'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65e249be015da37cfe4cfdd1da028fe4cb475c26be679b9e3e34696278a17c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
