{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, mode, skew, kurtosis, linregress\n",
    "import xgboost as xgb\n",
    "from joblib import Parallel, delayed\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, roc_curve, roc_auc_score, recall_score, precision_score, accuracy_score, precision_recall_curve, auc, f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, ShuffleSplit, StratifiedKFold, KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import zipfile\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import multiprocessing as mp\n",
    "from matplotlib import patches\n",
    "\n",
    "# sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "# plt.rcParams[\"text.usetex\"] = True\n",
    "# font = {\"family\": \"normal\", \"weight\": \"bold\", \"size\": 22}\n",
    "\n",
    "# plt.rc(\"font\", **font)\n",
    "\n",
    "CM_LAG_CORRECTION = [\n",
    "    (\"p1\", timedelta(minutes=2 * 60 + 36)),\n",
    "    (\"p3\", timedelta(minutes=2 * 60)),\n",
    "    (\"p5\", timedelta(minutes=-360)),\n",
    "    (\"p6\", timedelta(minutes=-360)),\n",
    "    (\"p7\", timedelta(minutes=-360)),\n",
    "    (\"p8\", timedelta(minutes=-360)),\n",
    "    # (\"p8\", datetime.strptime(\"02 02 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\"),datetime.strptime(\"02 06 2022-07:20:00\", \"%m %d %Y-%H:%M:%S\"),timedelta(minutes=-165)),\n",
    "    # (\"p8\", datetime.strptime(\"02 06 2022-07:20:00\", \"%m %d %Y-%H:%M:%S\"),datetime.strptime(\"02 09 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\"),timedelta(minutes=-165-190)),\n",
    "    # (\"p8\", datetime.strptime(\"02 09 2022-07:20:00\", \"%m %d %Y-%H:%M:%S\"),datetime.strptime(\"02 14 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\"),timedelta(minutes=93)),\n",
    "]\n",
    "# CGM_LAG_IMPOSING_STR = sys.argv[1]# ONLY TO IMPOSE A TIME LAG BETWEEN CGM READINGS AND CORE MOTION DATA!!!! WATCH OUT AND USE IT CAUTIOUSLY\n",
    "CGM_LAG_IMPOSING_STR = \"0\"\n",
    "# OUTTER_WINDOW_LENGTH = timedelta(minutes=int(sys.argv[2]))\n",
    "\n",
    "\n",
    "CGM_LAG_IMPOSING = timedelta(minutes=int(CGM_LAG_IMPOSING_STR))  # ONLY TO IMPOSE A TIME LAG BETWEEN CGM READINGS AND CORE MOTION DATA!!!! WATCH OUT AND USE IT CAUTIOUSLY\n",
    "AVERAGING_BLOCK = timedelta(minutes=5)\n",
    "OUTTER_WINDOW_LENGTH = timedelta(minutes=30)\n",
    "OUTTER_WINDOW_STEP = timedelta(seconds=30)\n",
    "INNER_WINDOW_LENGTH = timedelta(seconds=30)\n",
    "\n",
    "\n",
    "FASTING_LENGTH = timedelta(minutes=30)\n",
    "BIG_MEAL_CALORIE = 200\n",
    "FOLD_NUMBER = 5\n",
    "MINIMUM_POINT = INNER_WINDOW_LENGTH.total_seconds()\n",
    "COMPLEX_MEAL_DURATION = timedelta(minutes=60)\n",
    "\n",
    "\n",
    "START_OF_TRIAL = [datetime.strptime(\"11 06 2021-04:00:00\", \"%m %d %Y-%H:%M:%S\"), datetime.strptime(\"02 03 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\")]\n",
    "END_OF_TRIAL = [datetime.strptime(\"11 15 2021-00:00:00\", \"%m %d %Y-%H:%M:%S\"), datetime.strptime(\"02 13 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\")]\n",
    "DAY_LIGHT_SAVING = datetime.strptime(\"11 06 2021-02:00:00\", \"%m %d %Y-%H:%M:%S\")\n",
    "coreNumber = 100\n",
    "\n",
    "addDataPrefix = \"/Users/sorush/My Drive/Documents/Educational/TAMU/Research/TAMU/\"\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"/home/grads/s/sorush.omidvar/CGMDataset/TAMU/\"\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"C:\\\\GDrive\\\\Documents\\\\Educational\\\\TAMU\\\\Research\\\\Trial\\\\Data\\\\11-5-21-11-15-21\"\n",
    "\n",
    "addUserInput = os.path.join(addDataPrefix, \"User inputted\")\n",
    "addHKCM = os.path.join(addDataPrefix, \"hk+cm\")\n",
    "addCGM = os.path.join(addDataPrefix, \"CGM\")\n",
    "addE4 = os.path.join(addDataPrefix, \"E4\")\n",
    "addResults = os.path.join(addDataPrefix, \"Results\" + str(CGM_LAG_IMPOSING_STR))\n",
    "if not os.path.exists(addResults):\n",
    "    os.mkdir(addResults)\n",
    "\n",
    "exempts = [\"p2\", \"p4\"]\n",
    "# exempts = [\"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"p6\"]\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({\"figure.facecolor\": \"white\"})\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # no GPU\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unzipperE4(participantFolder):\n",
    "#     for root, dirs, files in os.walk(participantFolder):\n",
    "#         for file in files:\n",
    "#             if not '.zip' in file:\n",
    "#                 continue\n",
    "#             with zipfile.ZipFile(os.path.join(root,file), 'r') as zip_ref:\n",
    "#                 destFile=file[:file.find('.zip')]\n",
    "#                 destFile=os.path.join(root,destFile)\n",
    "#                 if not os.path.exists(destFile):\n",
    "#                     os.mkdir(destFile)\n",
    "#                 zip_ref.extractall(destFile)\n",
    "# def zipCleanerE4(E4Folder):\n",
    "#     for root, dirs, files in os.walk(E4Folder):\n",
    "#         for file in files:\n",
    "#             if '.zip' in file:\n",
    "#                 os.remove(os.path.join(root,file))\n",
    "\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p5')\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p6')\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p7')\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p8')\n",
    "# zipCleanerE4('/Users/sorush/Desktop/Round2E4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeZoneFixer(df, LocalizeFlag, columnName):\n",
    "    if LocalizeFlag:\n",
    "        df[columnName] -= timedelta(hours=5)\n",
    "    tempColumn = df[columnName]\n",
    "    tempColumn[tempColumn >= DAY_LIGHT_SAVING] -= timedelta(hours=1)\n",
    "    df[columnName] = tempColumn\n",
    "    return df\n",
    "\n",
    "\n",
    "def trialTimeLimitter(df, columnName):\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    dfTotal = []\n",
    "    for participant in participants:\n",
    "        if participant == \"p1\" or participant == \"p2\" or participant == \"p3\" or participant == \"p4\":\n",
    "            startOfTrial = START_OF_TRIAL[0]\n",
    "            endOfTrial = END_OF_TRIAL[0]\n",
    "        elif participant == \"p5\" or participant == \"p6\" or participant == \"p7\" or participant == \"p8\":\n",
    "            startOfTrial = START_OF_TRIAL[1]\n",
    "            endOfTrial = END_OF_TRIAL[1]\n",
    "        else:\n",
    "            print(\"Mayday in trialTimeLimitter\")\n",
    "            print(participant)\n",
    "            raise\n",
    "        dfTemp = df[df[\"Participant\"] == participant]\n",
    "        dfTemp = dfTemp[(dfTemp[columnName] >= startOfTrial) & (dfTemp[columnName] <= endOfTrial)]\n",
    "        if len(dfTotal) == 0:\n",
    "            dfTotal = dfTemp\n",
    "        else:\n",
    "            frames = [dfTotal, dfTemp]\n",
    "            dfTotal = pd.concat(frames)\n",
    "    return dfTotal\n",
    "\n",
    "\n",
    "def mealMarker(df):\n",
    "    df.insert(len(df.columns), \"BigMeal\", False)\n",
    "    for counter in range(0, len(df)):\n",
    "        if df[\"Calories\"].iloc[counter] >= BIG_MEAL_CALORIE:\n",
    "            df[\"BigMeal\"].iloc[counter] = True\n",
    "\n",
    "    df.insert(len(df.columns), \"ComplexMeal\", False)\n",
    "    participants = df[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    for participant in participants:\n",
    "        dfTemp = df[df[\"Participant\"] == participant]\n",
    "        for counter in range(1, len(dfTemp)):\n",
    "            if dfTemp[\"StartTime\"].iloc[counter - 1] + COMPLEX_MEAL_DURATION >= dfTemp[\"StartTime\"].iloc[counter]:\n",
    "                dfTemp[\"ComplexMeal\"].iloc[counter] = True\n",
    "                dfTemp[\"ComplexMeal\"].iloc[counter - 1] = True\n",
    "        indexs = dfTemp.index[dfTemp[\"ComplexMeal\"] == True]\n",
    "        df[\"ComplexMeal\"][indexs] = True\n",
    "    return df\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addResults, \"All_meals.pkl\")):\n",
    "    os.remove(os.path.join(addResults, \"All_meals.pkl\"))\n",
    "os.chdir(addUserInput)\n",
    "if not os.path.exists(os.path.join(addResults, \"All_meals.pkl\")):\n",
    "    dfMeal = []\n",
    "    for root, dirs, files in os.walk(addUserInput):\n",
    "        print(root)\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                if \"meals\" in file.lower() and \"modified\" not in file.lower():\n",
    "                    participantName = file[: file.find(\"Meals\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    dfTemp.rename(columns={\"startTime\": \"StartTime\"}, inplace=True)\n",
    "                    dfTemp[\"StartTime\"] = pd.to_datetime(dfTemp[\"StartTime\"])\n",
    "                    dfTemp[\"FinishTime\"] = pd.to_datetime(dfTemp[\"FinishTime\"])\n",
    "                    dfTemp.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                    if len(dfMeal) != 0:\n",
    "                        frames = [dfTemp, dfMeal]\n",
    "                        dfMeal = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfMeal = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfMeal = trialTimeLimitter(dfMeal, \"StartTime\")\n",
    "    dfMeal = trialTimeLimitter(dfMeal, \"FinishTime\")\n",
    "    dfMeal.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    dfMeal.reset_index(drop=True, inplace=True)\n",
    "    # dfMeal.insert(4, \"MealDuration\", -1)\n",
    "    # dfMeal[\"MealDuration\"] = dfMeal[\"FinishTime\"] - dfMeal[\"StartTime\"]\n",
    "    # dfMeal[\"MealDuration\"] = dfMeal[\"MealDuration\"].dt.total_seconds()\n",
    "    print(\"Meal database is limited to the trial period\")\n",
    "    dfMeal.to_pickle(os.path.join(addResults, \"All_meals.pkl\"))\n",
    "else:\n",
    "    dfMeal = pd.read_pickle(os.path.join(addResults, \"All_meals.pkl\"))\n",
    "dfMeal = mealMarker(dfMeal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdInterpolation(dfTemp):\n",
    "    index = dfTemp[\"Time\"]\n",
    "    seriesParticipant = pd.Series(dfTemp[\"Abbot\"].to_list(), index=index)\n",
    "    seriesParticipant = seriesParticipant.resample(\"1T\").asfreq()\n",
    "    seriesParticipant.interpolate(method=\"polynomial\", order=3, inplace=True)\n",
    "    tempTime = seriesParticipant.index\n",
    "    tempVal = seriesParticipant.values\n",
    "    dfTemp = pd.DataFrame(zip(tempTime, tempVal), columns=[\"Time\", \"Abbot\"])\n",
    "    return dfTemp\n",
    "\n",
    "\n",
    "def cmLagCorrector(df):\n",
    "    participants = df[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    dfTotal = []\n",
    "\n",
    "    for element in CM_LAG_CORRECTION:\n",
    "        participant = element[0]\n",
    "        timeLag = element[1]\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        if len(dfParticipant) == 0:\n",
    "            continue\n",
    "        dfParticipant[\"Time\"] += timeLag\n",
    "        if len(dfTotal) == 0:\n",
    "            dfTotal = dfParticipant\n",
    "        else:\n",
    "            frames = [dfTotal, dfParticipant]\n",
    "            dfTotal = pd.concat(frames)\n",
    "\n",
    "    return dfTotal\n",
    "\n",
    "\n",
    "def cmSmoother(df):\n",
    "    columnLabels = df.columns\n",
    "    for columnLabel in columnLabels:\n",
    "        if columnLabel == \"Time\":\n",
    "            continue\n",
    "        tempSerie = df[columnLabel]\n",
    "        tempSerie = tempSerie.ewm(span=10).mean()  # Considering the frequency of 10 Hz\n",
    "        df[columnLabel] = tempSerie\n",
    "    return df\n",
    "\n",
    "\n",
    "def CGMLagImposer(df):\n",
    "    df[\"Time\"] += CGM_LAG_IMPOSING\n",
    "    return df\n",
    "\n",
    "\n",
    "def CGMNormalizer(df):\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    participants.sort()\n",
    "    dfResult = []\n",
    "    for participant in participants:\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        dates = list(set(dfParticipant[\"Time\"].dt.date.to_list()))\n",
    "        dates.sort()\n",
    "        for date in dates:\n",
    "            dfDate = dfParticipant[dfParticipant[\"Time\"].dt.date == date]\n",
    "            if len(dfDate) <= 10:\n",
    "                continue\n",
    "            minBG = dfDate[\"Abbot\"].min()\n",
    "            maxBG = dfDate[\"Abbot\"].max()\n",
    "\n",
    "            meanBG = dfDate[\"Abbot\"].mean()\n",
    "            stdBG = dfDate[\"Abbot\"].std()\n",
    "            dfDate[\"Abbot\"] -= minBG\n",
    "            dfDate[\"Abbot\"] /= maxBG - minBG\n",
    "            # dfDate[\"Abbot\"] -= meanBG\n",
    "            # dfDate[\"Abbot\"] /= stdBG\n",
    "\n",
    "            assert not np.isnan(minBG)\n",
    "            assert not np.isnan(maxBG)\n",
    "            assert not np.isnan(meanBG)\n",
    "            assert not np.isnan(stdBG)\n",
    "            if len(dfResult) == 0:\n",
    "                dfResult = dfDate.copy()\n",
    "            else:\n",
    "                frames = [dfResult, dfDate]\n",
    "                dfResult = pd.concat(frames)\n",
    "    return dfResult\n",
    "\n",
    "\n",
    "def CGMLowPass(df):\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    participants.sort()\n",
    "    dfResult = []\n",
    "    for participant in participants:\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        cgmVals = dfParticipant[\"Abbot\"].to_list()\n",
    "        cgmVals = np.asarray(cgmVals)\n",
    "        lowPassFilter = signal.butter(3, 12, \"lp\", fs=60 * 24, output=\"sos\")  # high pass of period of 2 hours (12 per day)\n",
    "        cgmVals = signal.sosfilt(lowPassFilter, cgmVals)\n",
    "        dfParticipant[\"Abbot\"] = cgmVals\n",
    "        if len(dfResult) == 0:\n",
    "            dfResult = dfParticipant.copy()\n",
    "        else:\n",
    "            frames = [dfResult, dfParticipant]\n",
    "            dfResult = pd.concat(frames)\n",
    "    return dfResult\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addResults, \"All_cgm.pkl\")):\n",
    "    os.remove(os.path.join(addResults, \"All_cgm.pkl\"))\n",
    "if not os.path.exists(os.path.join(addResults, \"All_cgm.pkl\")):\n",
    "    os.chdir(addCGM)\n",
    "    dfCGM = []\n",
    "    for root, dirs, files in os.walk(addCGM):\n",
    "        for file in files:\n",
    "            if \".txt\" in file.lower():\n",
    "                if \"_libre\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_libre\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file, sep=\"\\t\", skiprows=1)\n",
    "                    if len(dfTemp.columns) != 4:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    dfTemp.columns.values[0] = \"ID\"\n",
    "                    dfTemp.columns.values[1] = \"Time\"\n",
    "                    dfTemp.columns.values[2] = \"Record\"\n",
    "                    dfTemp.columns.values[3] = \"Abbot\"\n",
    "                    dfTemp.drop(columns=[\"ID\", \"Record\"], inplace=True)\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"])\n",
    "                    if participantName == \"p1\" or participantName == \"p2\" or participantName == \"p3\" or participantName == \"p4\":\n",
    "                        dfTemp[\"Time\"] += timedelta(hours=-1)  # This fixes the daylight saving for the first round\n",
    "                    dfTemp[\"Abbot\"] = pd.to_numeric(dfTemp[\"Abbot\"])\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "                    dfTemp = pdInterpolation(dfTemp)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    if len(dfTemp.columns) != 3:\n",
    "                        print(\"MAYDAY. Error in processing csv\")\n",
    "                        break\n",
    "                    if len(dfCGM) != 0:\n",
    "                        frames = [dfTemp, dfCGM]\n",
    "                        dfCGM = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfCGM = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfCGM = CGMLagImposer(dfCGM)\n",
    "    dfCGM = trialTimeLimitter(dfCGM, \"Time\")\n",
    "    dfCGM.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfCGM.reset_index(drop=True, inplace=True)\n",
    "    # dfCGM = CGMLowPass(dfCGM)\n",
    "    # dfCGM = CGMNormalizer(dfCGM)\n",
    "    dfCGM.reset_index(drop=True, inplace=True)\n",
    "    print(\"CGM database is limited to the trial period\")\n",
    "    dfCGM.to_pickle(os.path.join(addResults, \"All_cgm.pkl\"))\n",
    "else:\n",
    "    dfCGM = pd.read_pickle(os.path.join(addResults, \"All_cgm.pkl\"))\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addResults, \"All_cm.pkl\")):\n",
    "#     os.remove(os.path.join(addResults, \"All_cm.pkl\"))\n",
    "os.chdir(addHKCM)\n",
    "if not os.path.exists(os.path.join(addResults, \"All_cm.pkl\")):\n",
    "    dfCM = []\n",
    "    for root, dirs, files in os.walk(addHKCM):\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                if \"corrected_cm_all\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_corrected\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    print(\"File is read\")\n",
    "                    dfTemp[\"UnixTime\"] = pd.to_datetime(dfTemp[\"UnixTime\"], unit=\"s\")\n",
    "\n",
    "                    dfTemp.rename(columns={\"UnixTime\": \"Time\"}, inplace=True)\n",
    "                    dfTemp.drop(columns=[\"UID\", \"Date\"], inplace=True)\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                    dfTemp = cmSmoother(dfTemp)\n",
    "                    dfTemp[\"Yaw\"] *= 180 / np.pi\n",
    "                    dfTemp[\"Pitch\"] *= 180 / np.pi\n",
    "                    dfTemp[\"Roll\"] *= 180 / np.pi\n",
    "\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    # this is to avoid 0 later on for feature calculation\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Ax|+|Ay|+|Az|\", dfTemp[\"Ax\"].abs() + dfTemp[\"Ay\"].abs() + dfTemp[\"Az\"].abs() + 0.0001)\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Yaw|+|Roll|+|Pitch|\", dfTemp[\"Yaw\"].abs() + dfTemp[\"Roll\"].abs() + dfTemp[\"Pitch\"].abs())\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\", dfTemp[\"Rx\"].abs() + dfTemp[\"Ry\"].abs() + dfTemp[\"Rz\"].abs())\n",
    "                    dfTemp[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"] = dfTemp[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"]\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"RotationalToLinear\", dfTemp[\"|Yaw|+|Roll|+|Pitch|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"])\n",
    "                    print(\"modified\")\n",
    "\n",
    "                    if len(dfTemp.columns) != 15:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        print(dfTemp.columns)\n",
    "                        break\n",
    "                    if len(dfCM) != 0:\n",
    "                        frames = [dfTemp, dfCM]\n",
    "                        dfCM = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfCM = dfTemp\n",
    "    print(\"Processing is done\")\n",
    "    dfCM = cmLagCorrector(dfCM)\n",
    "    dfCM = trialTimeLimitter(dfCM, \"Time\")\n",
    "    dfCM.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfCM.reset_index(drop=True, inplace=True)\n",
    "    print(\"CM database is limited to the trial period\")\n",
    "    dfCM.to_pickle(os.path.join(addResults, \"All_cm.pkl\"))\n",
    "else:\n",
    "    dfCM = pd.read_pickle(os.path.join(addResults, \"All_cm.pkl\"))\n",
    "\n",
    "\n",
    "def E4Smoother(df):\n",
    "    dfE4EDA = df[df[\"Field\"] == \"EDA\"]\n",
    "    dfE4HR = df[df[\"Field\"] == \"HR\"]\n",
    "    dfE4Temperature = df[df[\"Field\"] == \"Temperature\"]\n",
    "\n",
    "    tempSerie = dfE4EDA[\"Data1\"]\n",
    "    tempSerie = tempSerie.ewm(span=5 * 4).mean()  # Considering the frequency of 4 Hz\n",
    "    dfE4EDA[\"Data1\"] = tempSerie\n",
    "\n",
    "    tempSerie = dfE4HR[\"Data1\"]\n",
    "    tempSerie = tempSerie.ewm(span=5).mean()  # Considering the frequency of 1 Hz\n",
    "    dfE4HR[\"Data1\"] = tempSerie\n",
    "\n",
    "    tempSerie = dfE4Temperature[\"Data1\"]\n",
    "    tempSerie = tempSerie.ewm(span=5 * 4).mean()  # Considering the frequency of 4 Hz\n",
    "    dfE4Temperature[\"Data1\"] = tempSerie\n",
    "    frames = [dfE4EDA, dfE4HR, dfE4Temperature]\n",
    "    df = pd.concat(frames)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addResults, \"All_E4.pkl\")):\n",
    "#     os.remove(os.path.join(addResults, \"All_E4.pkl\"))\n",
    "os.chdir(addE4)\n",
    "# fields=['ACC','BVP','EDA','HR','IBI','TEMP']\n",
    "fields = [\"HR\", \"TEMP\", \"EDA\"]\n",
    "if not os.path.exists(os.path.join(addResults, \"All_E4.pkl\")):\n",
    "    dfE4 = []\n",
    "    for root, dirs, files in os.walk(addE4):\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                participantName = root[root.find(\"E4\") + 3 :]\n",
    "                participantName = participantName[:2]\n",
    "                field = file[: file.find(\".csv\")]\n",
    "                if field not in fields:\n",
    "                    print(\"File name does not comply with analyzed fields\", file)\n",
    "                    continue\n",
    "                print(participantName, field)\n",
    "                if participantName in exempts:\n",
    "                    print(\"Exemption...\", file)\n",
    "                    continue\n",
    "                print(\"Reading ...\", file)\n",
    "                os.chdir(root)\n",
    "                dfTemp = pd.read_csv(file, header=None)\n",
    "                # if field=='ACC':\n",
    "                #     assert len(dfTemp.columns)==3\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     timeStep=1/dfTemp.iloc[1,0]\n",
    "                #     dfTemp.drop([0,1],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Data1',1:'Data2',2:'Data3'}, inplace=True)#x,y,z for data1,data2,data3\n",
    "                #     timeTemp=[]\n",
    "                #     for counter in range(len(dfTemp)):\n",
    "                #         timeTemp.append(timeBase+counter*timeStep)\n",
    "                #     dfTemp.insert(0,'Time',timeTemp)\n",
    "                #     dfTemp.insert(0,'Field',\"Acceleration\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                # if field == \"BVP\":\n",
    "                #     assert len(dfTemp.columns) == 1\n",
    "                #     timeBase = dfTemp.iloc[0, 0]\n",
    "                #     timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                #     dfTemp.drop([0, 1], inplace=True)\n",
    "                #     dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                #     dfTemp[\"Data2\"] = \"\"\n",
    "                #     dfTemp[\"Data3\"] = \"\"\n",
    "                #     timeTemp = []\n",
    "                #     for counter in range(len(dfTemp)):\n",
    "                #         timeTemp.append(timeBase + counter * timeStep)\n",
    "                #     dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                #     dfTemp.insert(0, \"Field\", \"BVP\")\n",
    "                #     dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                if field == \"HR\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"HR\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                elif field == \"EDA\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"EDA\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                # elif field=='IBI':\n",
    "                #     assert len(dfTemp.columns)==2\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     dfTemp.drop([0],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Time',1:'Data1'}, inplace=True)\n",
    "                #     dfTemp[\"Data2\"]=\"\"\n",
    "                #     dfTemp[\"Data3\"]=\"\"\n",
    "                #     timeTemp=[]\n",
    "                #     dfTemp['Time']+=timeBase\n",
    "                #     dfTemp.insert(0,'Field',\"IBI\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                elif field == \"TEMP\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"Temperature\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                dfTemp.insert(0, \"Participant\", participantName)\n",
    "                dfTemp.sort_values([\"Participant\", \"Field\", \"Time\"], ascending=(True, True, True), inplace=True)\n",
    "                dfTemp.reset_index(drop=True, inplace=True)\n",
    "                dfTemp = E4Smoother(dfTemp)\n",
    "                if len(dfTemp.columns) != 6:\n",
    "                    print(\"MAYDAY. Error in reading csv\")\n",
    "                    break\n",
    "                if len(dfE4) != 0:\n",
    "                    frames = [dfTemp, dfE4]\n",
    "                    dfE4 = pd.concat(frames)\n",
    "                else:\n",
    "                    dfE4 = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfE4 = timeZoneFixer(dfE4, True, \"Time\")\n",
    "    dfE4.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfE4.reset_index(drop=True, inplace=True)\n",
    "    dfE4 = trialTimeLimitter(dfE4, \"Time\")\n",
    "    dfE4.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfE4.reset_index(drop=True, inplace=True)\n",
    "    print(\"E4 database is limited to the trial period\")\n",
    "    dfE4.to_pickle(os.path.join(addResults, \"All_E4.pkl\"))\n",
    "else:\n",
    "    dfE4 = pd.read_pickle(os.path.join(addResults, \"All_E4.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motionCalculator(df):\n",
    "    f1 = np.asarray(df[\"RotationalToLinear\"].to_list())\n",
    "    f2 = np.asarray(df[\"|Ax|+|Ay|+|Az|\"].to_list())\n",
    "\n",
    "    aX = np.asarray(df[\"Ax\"].to_list())\n",
    "    aY = np.asarray(df[\"Ay\"].to_list())\n",
    "    aZ = np.asarray(df[\"Az\"].to_list())\n",
    "\n",
    "    yaw = np.asarray(df[\"Yaw\"].to_list())\n",
    "    pitch = np.asarray(df[\"Pitch\"].to_list())\n",
    "    roll = np.asarray(df[\"Roll\"].to_list())\n",
    "\n",
    "    # featureData = [f1.mean(skipna=True), f1.std(skipna=True), f1.max(skipna=True) - f1.min(skipna=True), f2.mean(skipna=True), f2.std(skipna=True), f2.max(skipna=True) - f2.min(skipna=True)]\n",
    "    featureData = [\n",
    "        np.nanmean(f1),\n",
    "        np.nanstd(f1),\n",
    "        np.nanmax(f1),\n",
    "        np.nanmin(f1),\n",
    "        np.nanmax(f1) - np.nanmin(f1),\n",
    "        np.nanmean(f2),\n",
    "        np.nanstd(f2),\n",
    "        np.nanmax(f2),\n",
    "        np.nanmin(f2),\n",
    "        np.nanmax(f1) - np.nanmin(f1),\n",
    "        np.nanmean(aX),\n",
    "        np.nanstd(aX),\n",
    "        np.nanmax(aX),\n",
    "        np.nanmin(aX),\n",
    "        np.nanmax(aX) - np.nanmin(aX),\n",
    "        np.nanmean(aY),\n",
    "        np.nanstd(aY),\n",
    "        np.nanmax(aY),\n",
    "        np.nanmin(aY),\n",
    "        np.nanmax(aY) - np.nanmin(aY),\n",
    "        np.nanmean(aZ),\n",
    "        np.nanstd(aZ),\n",
    "        np.nanmax(aZ),\n",
    "        np.nanmin(aZ),\n",
    "        np.nanmax(aZ) - np.nanmin(aZ),\n",
    "        np.nanmean(yaw),\n",
    "        np.nanstd(yaw),\n",
    "        np.nanmax(yaw),\n",
    "        np.nanmin(yaw),\n",
    "        np.nanmax(yaw) - np.nanmin(yaw),\n",
    "        np.nanmean(pitch),\n",
    "        np.nanstd(pitch),\n",
    "        np.nanmax(pitch),\n",
    "        np.nanmin(pitch),\n",
    "        np.nanmax(pitch) - np.nanmin(pitch),\n",
    "        np.nanmean(roll),\n",
    "        np.nanstd(roll),\n",
    "        np.nanmax(roll),\n",
    "        np.nanmin(roll),\n",
    "        np.nanmax(roll) - np.nanmin(roll),\n",
    "    ]\n",
    "    assert len(featureData) == 40\n",
    "    return featureData\n",
    "\n",
    "\n",
    "def CGMStatFeatures(dataList):\n",
    "    # nanList = []\n",
    "    # for counter in range(24):\n",
    "    #     nanList.extend([-1000])\n",
    "    # return nanList\n",
    "    # assert len(dataList) >= int(OUTTER_WINDOW_LENGTH.seconds / INNER_WINDOW_LENGTH.seconds) - 1\n",
    "    assert len(dataList) >= 10\n",
    "\n",
    "    dataList = np.asarray(dataList).astype(float)\n",
    "    result = []\n",
    "    dataDim = dataList.ndim\n",
    "    assert dataDim == 1\n",
    "    assert len(dataList) == len(dataList[~np.isnan(dataList)])\n",
    "    dataList = dataList[~np.isnan(dataList)]\n",
    "\n",
    "    meanVal = np.nanmean(dataList)\n",
    "    stdVal = np.nanstd(dataList)\n",
    "    minVal = np.nanmin(dataList)\n",
    "    maxVal = np.nanmax(dataList)\n",
    "    rangeVal = maxVal - minVal\n",
    "    skewnessVal = skew(dataList, nan_policy=\"omit\")\n",
    "    kurtosisVal = kurtosis(dataList, nan_policy=\"omit\")\n",
    "\n",
    "    tempSize = int(len(dataList) / 4)\n",
    "    firstFourthSlopeVal = np.mean(dataList[0:tempSize])\n",
    "    secondFourthSlopeVal = np.mean(dataList[tempSize : 2 * tempSize])\n",
    "    thirdFourthSlopeVal = np.mean(dataList[2 * tempSize : 3 * tempSize])\n",
    "    forthFourthSlopeVal = np.mean(dataList[3 * tempSize :])\n",
    "    firstHalfSlopeVal = np.mean(dataList[0 : 2 * tempSize])\n",
    "    secondHalfSlopeVal = np.mean(dataList[2 * tempSize :])\n",
    "\n",
    "    dataListDiff = np.diff(dataList)\n",
    "    meanDiff = np.nanmean(dataListDiff)\n",
    "    stdDiff = np.nanstd(dataListDiff)\n",
    "    minDiff = np.nanmin(dataListDiff)\n",
    "    maxDiff = np.nanmax(dataListDiff)\n",
    "    rangeDiff = maxDiff - minDiff\n",
    "    skewnessDiff = skew(dataListDiff, nan_policy=\"omit\")\n",
    "    kurtosisDiff = kurtosis(dataListDiff, nan_policy=\"omit\")\n",
    "\n",
    "    tempSize = int(len(dataListDiff) / 4)\n",
    "    firstFourthSlopeDiff = np.mean(dataListDiff[0:tempSize])\n",
    "    secondFourthSlopeDiff = np.mean(dataListDiff[tempSize : 2 * tempSize])\n",
    "    thirdFourthSlopeDiff = np.mean(dataListDiff[2 * tempSize : 3 * tempSize])\n",
    "    forthFourthSlopeDiff = np.mean(dataListDiff[3 * tempSize :])\n",
    "    firstHalfSlopeDiff = np.mean(dataList[0 : 2 * tempSize])\n",
    "    secondHalfSlopeDiff = np.mean(dataList[2 * tempSize :])\n",
    "\n",
    "    result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal, firstFourthSlopeVal, secondFourthSlopeVal, thirdFourthSlopeVal, forthFourthSlopeVal, secondHalfSlopeVal - firstHalfSlopeVal])\n",
    "    result.extend([rangeDiff, meanDiff, stdDiff, minDiff, maxDiff, skewnessDiff, kurtosisDiff, firstFourthSlopeDiff, secondFourthSlopeDiff, thirdFourthSlopeDiff, forthFourthSlopeDiff, secondHalfSlopeDiff - firstHalfSlopeDiff])\n",
    "    return result\n",
    "\n",
    "\n",
    "def E4StatFeatures(df, sensor):\n",
    "    nanList = []\n",
    "    for counter in range(14 * 1):\n",
    "        nanList.extend([np.nan])\n",
    "\n",
    "    dfTemp = df[df[\"Field\"] == sensor]\n",
    "    tempVal = dfTemp[\"Data1\"].to_list()\n",
    "\n",
    "    if len(tempVal) < 10:\n",
    "        return nanList\n",
    "    else:\n",
    "        tempVal = np.asarray(tempVal).astype(float)\n",
    "        tempVal = tempVal[~np.isnan(tempVal)]\n",
    "\n",
    "        meanVal = np.nanmean(tempVal)\n",
    "        stdVal = np.nanstd(tempVal)\n",
    "        minVal = np.nanmin(tempVal)\n",
    "        maxVal = np.nanmax(tempVal)\n",
    "        rangeVal = maxVal - minVal\n",
    "        skewnessVal = skew(tempVal, nan_policy=\"omit\")\n",
    "        kurtosisVal = kurtosis(tempVal, nan_policy=\"omit\")\n",
    "\n",
    "        dataTempDiff = np.diff(tempVal)\n",
    "        meanDiff = np.nanmean(dataTempDiff)\n",
    "        stdDiff = np.nanstd(dataTempDiff)\n",
    "        minDiff = np.nanmin(dataTempDiff)\n",
    "        maxDiff = np.nanmax(dataTempDiff)\n",
    "        rangeDiff = maxDiff - minDiff\n",
    "        skewnessDiff = skew(dataTempDiff, nan_policy=\"omit\")\n",
    "        kurtosisDiff = kurtosis(dataTempDiff, nan_policy=\"omit\")\n",
    "        return [rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal, rangeDiff, meanDiff, stdDiff, minDiff, maxDiff, skewnessDiff, kurtosisDiff]\n",
    "\n",
    "\n",
    "def parallelCall(windowData):\n",
    "    tempList = []\n",
    "    outterWindowStart = windowData[0]\n",
    "    outterWindowEnd = windowData[1]\n",
    "    mealFlag = windowData[2]\n",
    "    participant = windowData[3]\n",
    "    mealStartList = windowData[4]\n",
    "    mealEndList = windowData[5]\n",
    "\n",
    "    nanList = []\n",
    "    for counter in range(40 * 1):\n",
    "        nanList.extend([np.nan])\n",
    "\n",
    "    dfTempCM = dfParticipantCM[(dfParticipantCM[\"Time\"] >= outterWindowStart) & (dfParticipantCM[\"Time\"] < outterWindowEnd)]\n",
    "    dfTempE4 = dfParticipantE4[(dfParticipantE4[\"Time\"] >= outterWindowStart) & (dfParticipantE4[\"Time\"] < outterWindowEnd)]\n",
    "    dfTempCGM = dfParticipantCGM[\n",
    "        (dfParticipantCGM[\"Time\"] >= outterWindowStart) & (dfParticipantCGM[\"Time\"] < outterWindowEnd + OUTTER_WINDOW_LENGTH)\n",
    "    ]  # We are looking forward. For example if the meal is started at 12.10 we are interested to see the data from 12.10 to 12.40 (assuming that the outer window length is 30 min)\n",
    "    if len(dfTempCM) >= MINIMUM_POINT * 10 * 0.5:  # Minimum point is the length of inner window per sec and this results in 50% of data\n",
    "        listCM = motionCalculator(dfTempCM)\n",
    "    else:\n",
    "        listCM = nanList\n",
    "\n",
    "    listEDA = E4StatFeatures(dfTempE4, \"EDA\")\n",
    "    listHR = E4StatFeatures(dfTempE4, \"HR\")\n",
    "    listTemperature = E4StatFeatures(dfTempE4, \"Temperature\")\n",
    "\n",
    "    listCGM = CGMStatFeatures(dfTempCGM[\"Abbot\"].to_list())\n",
    "\n",
    "    tempList.append(listCM)  # 1\n",
    "    tempList.append(listEDA)  # 1\n",
    "    tempList.append(listHR)  # 1\n",
    "    tempList.append(listTemperature)  # 1\n",
    "\n",
    "    tempList.append(listCGM)  # 1\n",
    "\n",
    "    tempList.append(outterWindowStart)  # 1\n",
    "    tempList.append(outterWindowEnd)  # 1\n",
    "    tempList.append(participant)  # 1\n",
    "\n",
    "    tempList.append(mealFlag)  # mealFlag\n",
    "    tempList.append(mealStartList)  # mealStarts\n",
    "    tempList.append(mealEndList)  # mealEnds\n",
    "\n",
    "    assert len(tempList) == 11\n",
    "    return tempList\n",
    "\n",
    "\n",
    "def outterWindowExtractorTotal(participant):\n",
    "    participantDataList = []\n",
    "    windowDatas = []\n",
    "    experimentStart = dfParticipantCM[\"Time\"].min()\n",
    "    experimentEnd = dfParticipantCM[\"Time\"].max()\n",
    "\n",
    "    startQuerry = experimentStart\n",
    "    endQuerry = startQuerry + OUTTER_WINDOW_STEP\n",
    "    while endQuerry <= experimentEnd:\n",
    "        dfTempMeal = dfParticipantMeal[(dfParticipantMeal[\"StartTime\"] <= startQuerry) & (dfParticipantMeal[\"StartTime\"] + timedelta(minutes=15) >= startQuerry)]\n",
    "        # dfTempMeal = dfParticipantMeal[(dfParticipantMeal[\"StartTime\"] >= startQuerry) & (dfParticipantMeal[\"StartTime\"] + timedelta(minutes=15) < endQuerry)]\n",
    "        mealFlag = min(len(dfTempMeal), 1)\n",
    "        mealStartList = dfTempMeal[\"StartTime\"].to_list()\n",
    "        mealEndList = dfTempMeal[\"FinishTime\"].to_list()\n",
    "\n",
    "        windowDatas.append([startQuerry, endQuerry, mealFlag, participant, mealStartList, mealEndList])\n",
    "        startQuerry += OUTTER_WINDOW_STEP\n",
    "        endQuerry += OUTTER_WINDOW_STEP\n",
    "    skipNumber = int(OUTTER_WINDOW_LENGTH.seconds / INNER_WINDOW_LENGTH.seconds)\n",
    "    windowDatas = windowDatas[: len(windowDatas) - skipNumber]  # Skipping the last 30 windows (assuming outter of 30 and inner of 1 min) because the last window has not enough points for looking back and this causes issues in stat calculation\n",
    "    # for counterOuter in tqdm(range(int(len(windowDatas)))):\n",
    "    #     windowData = windowDatas[counterOuter]\n",
    "    #     participantDataList.append(parallelCall(windowData))\n",
    "\n",
    "    # participantDataList = Parallel(n_jobs=coreNumber,batch_size=80)(delayed(parallelCall)(windowData) for windowData in tqdm(windowDatas))\n",
    "\n",
    "    pool = mp.Pool(coreNumber)\n",
    "    participantDataList = pool.map(parallelCall, tqdm(windowDatas), chunksize=80)\n",
    "    pool.close()\n",
    "    return participantDataList\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-All-Features.pkl\"))):\n",
    "#     os.remove(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-All-Features.pkl\")))\n",
    "if os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-All-Features.pkl\"))):\n",
    "    dfAllFeatures = pd.read_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-All-Features.pkl\")))\n",
    "else:\n",
    "    dfAllFeatures = []\n",
    "    participants = dfMeal[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    participants.sort()\n",
    "\n",
    "    columnHeaderList = [\"CM\", \"EDA\", \"HR\", \"Temperature\", \"CGM\", \"StartTime\", \"FinishTime\", \"Participant\", \"MealLabel\", \"MealStartList\", \"MealEndList\"]\n",
    "    for participant in participants:\n",
    "        print(\"Participant:\", participant)\n",
    "        if participant in exempts:\n",
    "            continue\n",
    "        dfParticipantMeal = dfMeal[dfMeal[\"Participant\"] == participant]\n",
    "        dfParticipantCM = dfCM[dfCM[\"Participant\"] == participant]\n",
    "        dfParticipantE4 = dfE4[dfE4[\"Participant\"] == participant]\n",
    "        dfParticipantCGM = dfCGM[dfCGM[\"Participant\"] == participant]\n",
    "        participantDataList = outterWindowExtractorTotal(participant)\n",
    "\n",
    "        participantDataList = pd.DataFrame(participantDataList, columns=columnHeaderList)\n",
    "        if len(dfAllFeatures) == 0:\n",
    "            dfAllFeatures = participantDataList\n",
    "        else:\n",
    "            frames = [dfAllFeatures, participantDataList]\n",
    "            dfAllFeatures = pd.concat(frames)\n",
    "    dfAllFeatures.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    dfAllFeatures.reset_index(drop=True, inplace=True)\n",
    "    dfAllFeatures.to_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-All-Features.pkl\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Samples: 163959 for combination: ['CM']\n",
      "************************* Participant: p1\n",
      "************************* Participant: p3\n",
      "************************* Participant: p5\n",
      "************************* Participant: p6\n",
      "************************* Participant: p7\n",
      "************************* Participant: p8\n",
      "Total Number of Samples: 163959 for combination: ['CGM']\n",
      "************************* Participant: p1\n",
      "************************* Participant: p3\n",
      "************************* Participant: p5\n",
      "************************* Participant: p6\n",
      "************************* Participant: p7\n",
      "************************* Participant: p8\n",
      "Total Number of Samples: 163959 for combination: ['CM', 'CGM']\n",
      "************************* Participant: p1\n",
      "************************* Participant: p3\n"
     ]
    }
   ],
   "source": [
    "def xgClassifier(xTrain, xTest, yTrain, yTest, featturesName):\n",
    "    thresholdBest = np.nan\n",
    "    clf = xgb.XGBClassifier(scale_pos_weight=len(yTrain) / np.sum(yTrain), n_jobs=coreNumber, n_estimators=250, max_depth=3, objective=\"binary:logistic\", eval_metric=\"error\")\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    # predVal = clf.predict(xVal)\n",
    "    # f1Best = sklearn.metrics.f1_score(yVal, predVal)\n",
    "    # thresholdBest = 0.5\n",
    "\n",
    "    # for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "    #     predVal = clf.predict_proba(xVal)\n",
    "    #     predVal = predVal[:, 1]\n",
    "    #     predVal[predVal >= threshold] = 1\n",
    "    #     predVal[predVal < threshold] = 0\n",
    "\n",
    "    #     f1Val = sklearn.metrics.f1_score(yVal, predVal)\n",
    "    #     if f1Val > 1.1 * f1Best:\n",
    "    #         thresholdBest = threshold\n",
    "    #         f1Best = f1Val\n",
    "\n",
    "    predictionsTest = clf.predict_proba(xTest)\n",
    "    predictionsTest = predictionsTest[:, 1]\n",
    "\n",
    "    # itemIndex = np.where(yTest == 1)\n",
    "    # itemIndex = itemIndex[0]\n",
    "    # itemIndex = itemIndex[0]\n",
    "\n",
    "    # predictionsTest = clf.predict_proba(xTest)\n",
    "    # predictionsTest = predictionsTest[:, 1]\n",
    "    # mamad=np.copy(predictionsTest)\n",
    "    # for counter in range(len(mamad)-5):\n",
    "    #     mamad[counter]=np.mean(predictionsTest[counter:counter+5])\n",
    "    # plt.figure(figsize=(20, 10))\n",
    "    # plt.plot(yTest[itemIndex: itemIndex + 2500], color=\"r\")\n",
    "    # plt.plot(predictionsTest[itemIndex: itemIndex + 2500], color=\"b\")\n",
    "    # plt.plot(mamad[itemIndex: itemIndex + 2500], color=\"g\",linewidth=7)\n",
    "\n",
    "    # plt.show()\n",
    "    # raise\n",
    "\n",
    "    featureImportance = clf.feature_importances_\n",
    "    featureImportance = dict(zip(featturesName, featureImportance))\n",
    "\n",
    "    return [thresholdBest, np.sum(yTest), len(yTest) - np.sum(yTest), featureImportance, yTest, predictionsTest]\n",
    "\n",
    "\n",
    "def featureImportanceAverager(featureImportances):\n",
    "    tempVals = []\n",
    "    tempLabels = []\n",
    "    for featureImportance in featureImportances:\n",
    "        tempVals.append(list(featureImportance.values()))\n",
    "        tempLabels = list(featureImportance.keys())\n",
    "    featureImportances = np.asarray(tempVals)\n",
    "    featureImportances = np.mean(featureImportances, axis=0)\n",
    "    featureImportances = dict(zip(tempLabels, featureImportances))\n",
    "    featureImportances = dict(sorted(featureImportances.items(), key=lambda item: item[1], reverse=True))\n",
    "    featureImportances = [[featureImportances]]\n",
    "\n",
    "    return featureImportances\n",
    "\n",
    "\n",
    "def xDataGetter(dfParticipant, sensor):\n",
    "    tempList = dfParticipant[sensor].to_list()\n",
    "    tempList = np.asarray(tempList)\n",
    "    return tempList\n",
    "\n",
    "\n",
    "def testTrainSplit(dfParticipant, combinationList, NORMAL_FLAG, HOOVER_FLAG, featturesName):\n",
    "    dfParticipant.insert(len(dfParticipant.columns), \"MultiModalProb\", np.nan)\n",
    "    dfParticipant.insert(len(dfParticipant.columns), \"Threshold\", np.nan)\n",
    "    dfParticipant.reset_index(drop=True, inplace=True)\n",
    "    yData = dfParticipant[\"MealLabel\"].to_list()\n",
    "    yData = np.asarray(yData).astype(int)\n",
    "    for combinationElement in combinationList:\n",
    "        if combinationElement == \"CM\" and HOOVER_FLAG:\n",
    "            continue  # Already handled by HooverModel\n",
    "        xData = xDataGetter(dfParticipant, combinationElement)\n",
    "\n",
    "        if NORMAL_FLAG:\n",
    "            xData -= np.nanmean(xData, axis=0)\n",
    "            xData /= np.nanstd(xData, axis=0)\n",
    "        kf = KFold(n_splits=FOLD_NUMBER, shuffle=False)\n",
    "        predictionTests = []\n",
    "        for trainIndex, testIndex in kf.split(xData, yData):\n",
    "            xTrain, xTest = xData[trainIndex, :], xData[testIndex, :]\n",
    "            yTrain, yTest = yData[trainIndex], yData[testIndex]\n",
    "\n",
    "            tempListReport = xgClassifier(xTrain, xTest, yTrain, yTest, featturesName)\n",
    "            # tempListReport = lrClassifier(xTrain, xTest, yTrain, yTest,featturesName)\n",
    "            # tempListReport = rfClassifier(xTrain, xTest, yTrain, yTest,featturesName)\n",
    "\n",
    "            predictionTests.extend(tempListReport[-1])\n",
    "        predictionTests = np.asarray(predictionTests)\n",
    "        dfParticipant[combinationElement] = predictionTests\n",
    "    # blockAverager(dfParticipant,combinationList)\n",
    "    multiModalModel(dfParticipant, combinationList)\n",
    "\n",
    "\n",
    "def multiModalModel(df, combinationList):\n",
    "    xData = []\n",
    "    yData = df[\"MealLabel\"].to_list()\n",
    "    yData = np.asarray(yData)\n",
    "\n",
    "    xData = df[combinationList].values\n",
    "    xData = np.asarray(xData)\n",
    "\n",
    "    kf = KFold(n_splits=FOLD_NUMBER, shuffle=False)\n",
    "    predictionsTests = []\n",
    "    thresholds = []\n",
    "\n",
    "    for trainIndex, testIndex in kf.split(xData, yData):\n",
    "        xTrain, xTest = xData[trainIndex, :], xData[testIndex, :]\n",
    "        yTrain, yTest = yData[trainIndex], yData[testIndex]\n",
    "\n",
    "        xVal = xTrain[int(0.8 * len(xTrain)) :, :]\n",
    "        yVal = yTrain[int(0.8 * len(yTrain)) :]\n",
    "\n",
    "        xTrain = xTrain[: int(0.8 * len(xTrain)), :]\n",
    "        yTrain = yTrain[: int(0.8 * len(yTrain))]\n",
    "\n",
    "        clf = LogisticRegression(class_weight=\"balanced\", n_jobs=coreNumber)\n",
    "        clf.fit(xTrain, yTrain)\n",
    "\n",
    "        thresholdBest = -1\n",
    "        f1Best = -1\n",
    "        for threshold in np.arange(0, 1, 0.01):\n",
    "            predVal = clf.predict_proba(xVal)\n",
    "            predVal = predVal[:, 1]\n",
    "            predVal[predVal >= threshold] = 1\n",
    "            predVal[predVal < threshold] = 0\n",
    "            f1Score = sklearn.metrics.f1_score(yVal, predVal)\n",
    "            if f1Score >= f1Best:\n",
    "                thresholdBest = threshold\n",
    "                f1Best = f1Score\n",
    "\n",
    "        predictionsTest = clf.predict_proba(xTest)\n",
    "        predictionsTest = predictionsTest[:, 1]\n",
    "\n",
    "        for counter in range(len(yTest)):\n",
    "            thresholds.append(thresholdBest)\n",
    "\n",
    "        predictionsTests.extend(predictionsTest)\n",
    "    df[\"MultiModalProb\"] = predictionsTests\n",
    "    df[\"Threshold\"] = thresholds\n",
    "\n",
    "\n",
    "def featuresNameGetter(combinationString):\n",
    "    CGMStat = [\"-Range\", \"-Mean\", \"-STD\", \"-Min\", \"-Max\", \"-Skewness\", \"-Kurtosis\", \"-FirstFourthSlope\", \"-SecondFourthSlope\", \"-ThirdFourthSlope\", \"-FourthFourthSlope\", \"-HalvesSlope\"]\n",
    "    CGMStat.extend([\"-RangeDiff\", \"-STDDiff\", \"-MinDiff\", \"-MaxDiff\", \"-SkewnessDiff\", \"-KurtosisDiff\", \"-FirstFourthSlopeDiff\", \"-SecondFourthSlopeDiff\", \"-ThirdFourthSlopeDiff\", \"-FourthFourthSlopeDiff\", \"-HalvesSlopeDiff\"])\n",
    "    E4Stat = [\"-RangeVal\", \"-MeanVal\", \"-StdVal\", \"-MinVal\", \"-MaxVal\", \"-SkewnessVal\", \"-KurtosisVal\", \"-RangeDiff\", \"-MeanDiff\", \"-StdDiff\", \"-MinDiff\", \"-MaxDiff\", \"-SkewnessDiff\", \"-KurtosisDiff\"]\n",
    "    CMStat = [\"-f1Mean\", \"-f1Std\", \"-f1Range\", \"-f2Mean\", \"-f2Std\", \"-f2Range\"]\n",
    "\n",
    "    statFeatures = []\n",
    "    if \"CGM\" in combinationString:\n",
    "        statFeatures.extend((\"CGM\" + element for element in CGMStat))\n",
    "\n",
    "    if \"CM\" in combinationString:\n",
    "        statFeatures.extend((\"CM\" + element for element in CMStat))\n",
    "\n",
    "    if \"EDA\" in combinationString:\n",
    "        statFeatures.extend((\"EDA\" + element for element in E4Stat))\n",
    "\n",
    "    if \"HR\" in combinationString:\n",
    "        statFeatures.extend((\"HR\" + element for element in E4Stat))\n",
    "\n",
    "    if \"Temperature\" in combinationString:\n",
    "        statFeatures.extend((\"Temperature\" + element for element in E4Stat))\n",
    "\n",
    "    return statFeatures\n",
    "\n",
    "\n",
    "def hooverPredictor(dfAllFeatures, NORMAL_FLAG):\n",
    "    xData = dfAllFeatures[\"CM\"].to_list()\n",
    "    xData = np.asarray(xData)\n",
    "    if NORMAL_FLAG:\n",
    "        xData -= np.nanmean(xData, axis=0)\n",
    "        xData /= np.nanstd(xData, axis=0)\n",
    "\n",
    "    hooverModelAdd = \"/home/grads/s/sorush.omidvar/CGMDataset/Hoover/HooverModel-0.5.sav\"\n",
    "    hooverModel = pickle.load(open(hooverModelAdd, \"rb\"))\n",
    "    hooverModel.n_jobs = coreNumber\n",
    "\n",
    "    hooverPredictions = hooverModel.predict_proba(xData)\n",
    "    hooverPredictions = hooverPredictions[:, 1]\n",
    "\n",
    "    hooverPredictions = np.asarray(hooverPredictions)\n",
    "    dfAllFeatures[\"CM\"] = hooverPredictions\n",
    "\n",
    "\n",
    "def dfReader(combinationString):\n",
    "    dfAllFeatures = pd.read_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-All-Features.pkl\")))\n",
    "    dfAllFeatures = dfAllFeatures.dropna()\n",
    "    featturesName = featuresNameGetter(combinationString)\n",
    "    return featturesName, dfAllFeatures\n",
    "\n",
    "def blockAverager(df,combinationList):\n",
    "    for counter in tqdm(range(len(df))):\n",
    "        startTime=df['StartTime'].iloc[counter]\n",
    "        dfTemp=df[(df['StartTime']>=startTime)&(df['FinishTime']<=startTime+timedelta(minutes=5))]\n",
    "        \n",
    "        mealLabel=dfTemp['MealLabel'].mean()\n",
    "        if mealLabel>=0.5:\n",
    "            mealLabel=1\n",
    "        else:\n",
    "            mealLabel=0\n",
    "        df['MealLabel'].iloc[counter]=mealLabel\n",
    "        for combinationElement in combinationList:\n",
    "            df[combinationElement].iloc[counter]=dfTemp[combinationElement].mean()\n",
    "\n",
    "def metricCalc(df, combinationList):\n",
    "    participants = df[\"Participant\"].unique()\n",
    "    combinationSummary = []\n",
    "    for participant in participants:\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        yTrues = dfParticipant[\"MealLabel\"].to_list()\n",
    "        yPreds = dfParticipant[\"MultiModalProb\"].to_list()\n",
    "        thresholds = dfParticipant[\"Threshold\"].to_list()\n",
    "\n",
    "        yTrues = np.asarray(yTrues).astype(int)\n",
    "        yPreds = np.asarray(yPreds)\n",
    "        thresholds = np.asarray(thresholds)\n",
    "\n",
    "        rocAuc = roc_auc_score(yTrues, yPreds)\n",
    "        precisionTemp, recallTemp, thresholdsTemp = precision_recall_curve(yTrues, yPreds)\n",
    "        prAuc = auc(recallTemp, precisionTemp)\n",
    "\n",
    "        for counter in range(len(yTrues)):\n",
    "            if yPreds[counter] >= thresholds[counter]:\n",
    "                yPreds[counter] = 1\n",
    "            else:\n",
    "                yPreds[counter] = 0\n",
    "\n",
    "        accuracy = accuracy_score(yTrues, yPreds)\n",
    "        recall = recall_score(yTrues, yPreds)\n",
    "        precision = precision_score(yTrues, yPreds)\n",
    "        f1Score = f1_score(yTrues, yPreds)\n",
    "\n",
    "        combinationSummary.append([participant, \"+\".join(combinationList), rocAuc, prAuc, accuracy, recall, precision, f1Score])\n",
    "    combinationSummary = pd.DataFrame(combinationSummary, columns=[\"Participant\", \"Combination\", \"ROC-AUC\", \"PR-AUC\", \"Accuracy\", \"Recall\", \"Precision\", \"F1\"])\n",
    "    return combinationSummary\n",
    "\n",
    "def predictionMain(dfCombination, combinationList, NORMAL_FLAG, HOOVER_FLAG, featturesName):\n",
    "    participants = dfCombination[\"Participant\"].unique()\n",
    "    participants.sort()\n",
    "    classifierReports = []\n",
    "    for participant in participants:\n",
    "        # if participant != \"p8\":\n",
    "        #     continue\n",
    "        dfParticipant = dfCombination[dfCombination[\"Participant\"] == participant]\n",
    "        dfParticipant.sort_values([\"StartTime\"], ascending=(True), inplace=True)\n",
    "        print(\"*************************\", \"Participant:\", participant)\n",
    "        testTrainSplit(dfParticipant, combinationList, NORMAL_FLAG, HOOVER_FLAG, featturesName)\n",
    "        # raise  # IMPLEMENET THE VOTE BLOCKER! SO SLIDE EVERY FIVE MIN AND TAKE THE VOTE FOR THE LABEL AND AVERAGE FOR THE PRED\n",
    "        if len(classifierReports) == 0:\n",
    "            classifierReports = dfParticipant\n",
    "        else:\n",
    "            frames = [classifierReports, dfParticipant]\n",
    "            classifierReports = pd.concat(frames)\n",
    "    return classifierReports\n",
    "\n",
    "\n",
    "NORMAL_FLAG = True\n",
    "HOOVER_FLAG = False\n",
    "if os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-Final-Classifier.xlsx\"))):\n",
    "    os.remove(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-Final-Classifier.xlsx\")))\n",
    "if not os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-Final-Classifier.xlsx\"))):\n",
    "    dfClassifier = []\n",
    "    # combinationLists = [[\"CGM\", \"CM\", \"EDA\"], [\"CGM\", \"CM\"], [\"CGM\"], [\"CM\"]]\n",
    "    combinationLists = [[\"CM\"], [\"CGM\"], [\"EDA\"], [\"CM\", \"CGM\"], [\"CM\", \"CGM\", \"EDA\"], [\"CM\", \"CGM\", \"EDA\", \"HR\"], [\"CM\", \"CGM\", \"EDA\", \"HR\", \"Temperature\"]]\n",
    "    combinationLists = [[\"CM\"],[\"CGM\"],['CM','CGM']]\n",
    "    combinationSummary = []\n",
    "    for combinationList in combinationLists:\n",
    "        featturesName, dfAllFeatures = dfReader(combinationList)\n",
    "        print(\"Total Number of Samples:\", len(dfAllFeatures), \"for combination:\", combinationList)\n",
    "        if \"CM\" in combinationList and HOOVER_FLAG:\n",
    "            hooverPredictor(dfAllFeatures, NORMAL_FLAG)\n",
    "        dfAllFeatures = predictionMain(dfAllFeatures, combinationList, NORMAL_FLAG, HOOVER_FLAG, featturesName)\n",
    "        dfAllFeatures.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "        dfAllFeatures.reset_index(drop=True, inplace=True)\n",
    "        combinationSummaryTemp = metricCalc(dfAllFeatures, combinationList)\n",
    "        if len(combinationSummary) == 0:\n",
    "            combinationSummary = combinationSummaryTemp\n",
    "        else:\n",
    "            frames = [combinationSummary, combinationSummaryTemp]\n",
    "            combinationSummary = pd.concat(frames)\n",
    "\n",
    "    combinationSummary.to_excel(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(INNER_WINDOW_LENGTH) + \"-Final-Classifier.xlsx\")), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(30, 10))\n",
    "#     gs = GridSpec(2, 5)\n",
    "#     colors = plt.cm.get_cmap(\"tab10\")\n",
    "\n",
    "#     ax_calibration_curve = fig.add_subplot(gs[:2, :2])\n",
    "#     calibration_displays = {}\n",
    "\n",
    "\n",
    "#     display = CalibrationDisplay.from_estimator(\n",
    "#         clf,\n",
    "#         xVal,\n",
    "#         yVal,\n",
    "#         n_bins=10,\n",
    "#         name='testmodel',\n",
    "#         ax=ax_calibration_curve,\n",
    "#         color=colors(0),\n",
    "#         strategy='quantile'\n",
    "#     )\n",
    "#     calibration_displays['testmodel'] = display\n",
    "\n",
    "#     ax_calibration_curve.grid()\n",
    "#     ax_calibration_curve.set_title(\"Calibration plots\")\n",
    "\n",
    "#     # Add histogram\n",
    "#     grid_positions = [(0, 2)]\n",
    "#     # for i, m in enumerate(models):\n",
    "#     name = 'CLF'\n",
    "#     row, col = grid_positions[0]\n",
    "#     ax = fig.add_subplot(gs[row, col])\n",
    "\n",
    "#     ax.hist(\n",
    "#         calibration_displays['testmodel'].y_prob,\n",
    "#         range=(0, 1),\n",
    "#         bins=10,\n",
    "#         label=name,\n",
    "#         color=colors(0)\n",
    "#     )\n",
    "#     ax.set(title=name, xlabel=\"Mean predicted probability\", ylabel=\"Count\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     ax_calibration_curve.legend(loc='upper left')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(addResults))\n",
    "\n",
    "\n",
    "def summaryPlotter(participant, metricType):\n",
    "    metricCMList = []\n",
    "    metricCGMList = []\n",
    "    metricCGMCMList = []\n",
    "    metricCGMCMTempList = []\n",
    "    metricCGMCMTempHREDAList = []\n",
    "    windowLenList = []\n",
    "    for root, dirs, files in os.walk(os.path.join(addResults)):\n",
    "        for file in sorted(files):\n",
    "            if \".xlsx\" in file.lower() and \"summary\" in file.lower() and \"classifier\" in file.lower():\n",
    "                windowLen = file[: file.find(\"-\")]\n",
    "\n",
    "                dfTemp = pd.read_excel(file)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CM\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCMList.append(metricVal)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCGMList.append(metricVal)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM+CM\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCGMCMList.append(metricVal)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM+CM+Temperature\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCGMCMTempList.append(metricVal)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM+CM+Temperature+HR+EDA\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCGMCMTempHREDAList.append(metricVal)\n",
    "                windowLenList.append(windowLen)\n",
    "\n",
    "    for counter in range(len(windowLenList)):\n",
    "        tempVal = datetime.strptime(windowLenList[counter], \"%H:%M:%S\")\n",
    "        tempVal = tempVal.time().hour * 60 + tempVal.time().minute\n",
    "        windowLenList[counter] = tempVal\n",
    "    return metricCMList, metricCGMList, metricCGMCMList, metricCGMCMTempList, metricCGMCMTempHREDAList, windowLenList\n",
    "\n",
    "\n",
    "def metricPlotter(metricName):\n",
    "    participants = [\"p1\", \"p3\", \"p5\", \"p6\", \"p7\", \"p8\"]\n",
    "    subplotCounter = 1\n",
    "    fig = plt.figure(figsize=(10, 15))\n",
    "    colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"]\n",
    "    for participant in participants:\n",
    "        metricCMList, metricCGMList, metricCGMCMList, metricCGMCMTempList, metricCGMCMTempHREDAList, windowLenList = summaryPlotter(participant, metricName)\n",
    "        slopeCGM, interceptCGM, r_valueCGM, p_valueCGM, std_errCGM = linregress(windowLenList, metricCGMList)\n",
    "        slopeCM, interceptCM, r_valueCM, p_valueCM, std_errCM = linregress(windowLenList, metricCMList)\n",
    "        slopeCGMCM, interceptCGMCM, r_valueCGMCM, p_valueCGMCM, std_errCGMCM = linregress(windowLenList, metricCGMCMList)\n",
    "\n",
    "        print(participant, (30 * slopeCGM + interceptCGM - interceptCGMCM) / slopeCGMCM)\n",
    "        # print(participant,slopeCGM,slopeCGMCM)\n",
    "        # print(participant,interceptCGM,interceptCGMCM)\n",
    "\n",
    "        plt.subplot(3, 2, subplotCounter)\n",
    "        sns.regplot(x=windowLenList, y=metricCMList, marker=\"+\", color=colors[0], label=\"CM\")\n",
    "        sns.regplot(x=windowLenList, y=metricCGMList, marker=\"s\", color=colors[1], label=\"CGM\")\n",
    "        sns.regplot(x=windowLenList, y=metricCGMCMList, marker=\"d\", color=colors[2], label=\"CGM+CM\")\n",
    "        # plt.plot(windowLenList, metricCGMCMTempList, \"--o\", color=colors[3], label=\"CGM+CM+Temperature\")\n",
    "        # plt.plot(windowLenList, metricCGMCMTempHREDAList, \":s\", color=colors[4], label=\"CGM+CM+Temperature+HR+EDA\")\n",
    "        plt.text(20, 0.9, participant.capitalize())\n",
    "        plt.ylim([0, 1])\n",
    "        if subplotCounter == 3:\n",
    "            plt.ylabel(metricName, labelpad=30)\n",
    "        if subplotCounter == 5:\n",
    "            # plt.xlabel(\"Window Length [min]\",labelpad=30)\n",
    "            frame1 = plt.gca()\n",
    "            frame1.axes.set_xlabel(\"Window Length [min]\", labelpad=30, x=1)\n",
    "        if subplotCounter == 2:\n",
    "            plt.legend(loc=\"upper right\")\n",
    "        if subplotCounter % 2 == 1:\n",
    "            plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [\"0.0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"])\n",
    "        else:\n",
    "            plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [])\n",
    "        if subplotCounter >= 5:\n",
    "            plt.xticks([15, 30, 45, 60, 75, 90], [\"15\", \"30\", \"45\", \"60\", \"75\", \"90\"])\n",
    "        else:\n",
    "            plt.xticks([15, 30, 45, 60, 75, 90], [])\n",
    "\n",
    "        subplotCounter += 1\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(addResults, \"Eating-ROC-AUC Summary-\" + metricName + \"-\" + str(INNER_WINDOW_LENGTH) + \".jpg\"), dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "metricPlotter(metricName=\"Recall\")\n",
    "metricPlotter(metricName=\"Precision\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noNormal=[{'-MaxDiff': 0.1078463, '-SecondFourthSlopeDiff': 0.103150845, '-FourthFourthSlopeDiff': 0.07462696, '-ThirdFourthSlope': 0.06913031, '-Skewness': 0.056625057, '-SkewnessDiff': 0.050760787, '-STDDiff': 0.048788596, '-FirstFourthSlopeDiff': 0.046131063, '-RangeDiff': 0.04021073, '-HalvesSlopeDiff': 0.04018015, '-MinDiff': 0.033765636, '-HalvesSlope': 0.03357451, '-SecondFourthSlope': 0.033038698, '-FourthFourthSlope': 0.029650774, '-FirstFourthSlope': 0.02836506, '-Min': 0.025608739, '-Max': 0.024943182, '-STD': 0.024530888, '-Mean': 0.02407294, '-Range': 0.023151893, '-MeanDiff': 0.022112701, '-KurtosisDiff': 0.02190013, '-ThirdFourthSlopeDiff': 0.02160139, '-Kurtosis': 0.016232677},\n",
    "# {'-MinDiff': 0.05836166, '-Max': 0.05825951, '-Mean': 0.056890287, '-FirstFourthSlopeDiff': 0.054751, '-SecondFourthSlope': 0.05199795, '-FirstFourthSlope': 0.051083237, '-RangeDiff': 0.047590412, '-FourthFourthSlopeDiff': 0.046937533, '-ThirdFourthSlope': 0.04655046, '-HalvesSlope': 0.044784807, '-Min': 0.043269206, '-SkewnessDiff': 0.042040505, '-MaxDiff': 0.041865278, '-HalvesSlopeDiff': 0.041717757, '-Skewness': 0.037697215, '-FourthFourthSlope': 0.034438096, '-MeanDiff': 0.03392487, '-STDDiff': 0.033244412, '-Range': 0.032868195, '-SecondFourthSlopeDiff': 0.031723518, '-KurtosisDiff': 0.029031616, '-Kurtosis': 0.028224358, '-ThirdFourthSlopeDiff': 0.027494926, '-STD': 0.025253225},\n",
    "# {'-Range': 0.07485981, '-MaxDiff': 0.07235001, '-FourthFourthSlope': 0.061106034, '-Min': 0.06102726, '-ThirdFourthSlope': 0.05558133, '-SkewnessDiff': 0.054457445, '-HalvesSlope': 0.051805902, '-RangeDiff': 0.050594293, '-FirstFourthSlope': 0.04973889, '-FourthFourthSlopeDiff': 0.049186327, '-Mean': 0.046296857, '-Kurtosis': 0.04171118, '-SecondFourthSlopeDiff': 0.03683889, '-MeanDiff': 0.034761127, '-Max': 0.03353867, '-MinDiff': 0.03286376, '-SecondFourthSlope': 0.03176475, '-STDDiff': 0.028456414, '-KurtosisDiff': 0.028452437, '-ThirdFourthSlopeDiff': 0.024667135, '-FirstFourthSlopeDiff': 0.022733245, '-Skewness': 0.021999788, '-STD': 0.020657314, '-HalvesSlopeDiff': 0.014551135},\n",
    "# {'-ThirdFourthSlope': 0.116321504, '-FourthFourthSlope': 0.06946923, '-MaxDiff': 0.06276192, '-Max': 0.059627842, '-Mean': 0.052711405, '-Range': 0.050306994, '-MinDiff': 0.049013417, '-RangeDiff': 0.048471592, '-Skewness': 0.047412317, '-FourthFourthSlopeDiff': 0.046264015, '-STDDiff': 0.040881716, '-SkewnessDiff': 0.038825456, '-SecondFourthSlope': 0.037260063, '-Min': 0.033757806, '-MeanDiff': 0.033217307, '-HalvesSlope': 0.031427175, '-KurtosisDiff': 0.03128091, '-FirstFourthSlope': 0.028787797, '-STD': 0.027287915, '-FirstFourthSlopeDiff': 0.024499362, '-Kurtosis': 0.021792239, '-SecondFourthSlopeDiff': 0.01951169, '-ThirdFourthSlopeDiff': 0.01877995, '-HalvesSlopeDiff': 0.010330347},\n",
    "# {'-MaxDiff': 0.06764946, '-STD': 0.056324393, '-FourthFourthSlopeDiff': 0.055581857, '-Mean': 0.051104046, '-Range': 0.0502673, '-SkewnessDiff': 0.049853936, '-RangeDiff': 0.044252936, '-Min': 0.043754313, '-Max': 0.04371197, '-MinDiff': 0.042753506, '-KurtosisDiff': 0.039921276, '-HalvesSlopeDiff': 0.03888581, '-FirstFourthSlope': 0.038707566, '-FourthFourthSlope': 0.03850367, '-STDDiff': 0.038403533, '-Skewness': 0.038231872, '-SecondFourthSlope': 0.03812664, '-SecondFourthSlopeDiff': 0.037757747, '-Kurtosis': 0.037050135, '-ThirdFourthSlopeDiff': 0.03525641, '-ThirdFourthSlope': 0.032925814, '-MeanDiff': 0.031699583, '-HalvesSlope': 0.028091868, '-FirstFourthSlopeDiff': 0.021184346},\n",
    "# {'-FourthFourthSlopeDiff': 0.07831435, '-SkewnessDiff': 0.06162001, '-Min': 0.050464742, '-SecondFourthSlopeDiff': 0.049488824, '-RangeDiff': 0.049330417, '-Range': 0.04861606, '-MaxDiff': 0.04708212, '-FourthFourthSlope': 0.046744823, '-KurtosisDiff': 0.046689652, '-STDDiff': 0.04431532, '-FirstFourthSlopeDiff': 0.042319566, '-MeanDiff': 0.041090157, '-MinDiff': 0.039877523, '-Skewness': 0.039017998, '-SecondFourthSlope': 0.038478997, '-Max': 0.03784959, '-Mean': 0.03724398, '-FirstFourthSlope': 0.037229583, '-ThirdFourthSlopeDiff': 0.033134893, '-Kurtosis': 0.031625576, '-HalvesSlope': 0.030476, '-ThirdFourthSlope': 0.026068594, '-STD': 0.023853524, '-HalvesSlopeDiff': 0.01906771}]\n",
    "\n",
    "# for counter in range(len(noNormal)):\n",
    "#     temp=noNormal[counter]\n",
    "#     noNormal[counter]=dict(sorted(temp.items(), key=lambda item: item[0],reverse=True))\n",
    "# y=[]\n",
    "# for counter in range(len(noNormal)):\n",
    "#     temp=noNormal[counter]\n",
    "#     x=temp.keys()\n",
    "#     y.append(list(temp.values()))\n",
    "# y=np.asarray(y)\n",
    "# x=list(x)\n",
    "\n",
    "# y=y.mean(axis=0)\n",
    "# indexSorted=np.argsort(y)\n",
    "# x=np.asarray(x)\n",
    "# x=x[indexSorted.astype(int)]\n",
    "# y=np.sort(y)\n",
    "# print(\"********\")\n",
    "\n",
    "# plt.figure(figsize=(15,15))\n",
    "# plt.bar(x,y)\n",
    "# plt.xticks(x, rotation='vertical')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65e249be015da37cfe4cfdd1da028fe4cb475c26be679b9e3e34696278a17c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
