{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pytz\n",
    "from datetime import datetime,timedelta,timezone\n",
    "from dateutil.tz import tzutc\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import pearsonr, mode\n",
    "from scipy.signal import savgol_filter\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error,plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "addDataPrefix='/Users/sorush/My Drive/Documents/Educational/TAMU/Research/Trial/Data/11-5-21-11-15-21'\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix='/home/grads/s/sorush.omidvar/CGMDataset/Trial/Data/11-5-21-11-15-21'\n",
    "addUserInput=os.path.join(addDataPrefix,'User inputted')\n",
    "addHKCM=os.path.join(addDataPrefix,'hk+cm')\n",
    "addCGM=os.path.join(addDataPrefix,'CGM')\n",
    "addE4=os.path.join(addDataPrefix,'E4')\n",
    "\n",
    "exempts=['p2']\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({'figure.facecolor':'white'})\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(os.path.join(addDataPrefix,'All_meals.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,'All_meals.pkl'))\n",
    "os.chdir(addUserInput)\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_meals.pkl')):    \n",
    "    df=[]\n",
    "    for root, dirs, files in os.walk(addUserInput):\n",
    "        for file in files:\n",
    "            if '.csv' in file.lower():\n",
    "                if 'meals' in file.lower():\n",
    "                    participantName=file[:file.find('Meals')]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\",file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\",file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    dfTemp.insert(0,'Participant',participantName)\n",
    "                    dfTemp.rename(columns={'startTime':'StartTime'}, inplace=True)\n",
    "                    dfTemp['StartTime']=pd.to_datetime(dfTemp['StartTime'])\n",
    "                    dfTemp['FinishTime']=pd.to_datetime(dfTemp['FinishTime'])\n",
    "\n",
    "                    dfTemp['StartTime']-=pd.DateOffset(hours=5)#fixing the time zone issue\n",
    "                    dfTemp['FinishTime']-=pd.DateOffset(hours=5)#fixing the time zone issue            \n",
    "                    dfTemp.sort_values([\"Participant\",'StartTime'],ascending = (True, True),inplace=True)\n",
    "                    if len(dfTemp.columns)!=10:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    if len(df)!=0:\n",
    "                        frames=[dfTemp,df]\n",
    "                        df=pd.concat(frames)\n",
    "                    else:\n",
    "                        df=dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfMeal=df    \n",
    "    dfMeal.to_pickle(os.path.join(addDataPrefix,'All_meals.pkl')) \n",
    "else:\n",
    "    dfMeal=pd.read_pickle(os.path.join(addDataPrefix,'All_meals.pkl'))\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addDataPrefix,'All_cgm.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,'All_cgm.pkl'))\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_cgm.pkl')):\n",
    "    os.chdir(addCGM)\n",
    "    df=[]\n",
    "    for root, dirs, files in os.walk(addCGM):\n",
    "        for file in files:\n",
    "            if '.csv' in file.lower():\n",
    "                if 'processed' in file.lower():\n",
    "                    participantName=file[:file.find('Processed')]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\",file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\",file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    dfTemp.insert(0,'Participant',participantName)\n",
    "                    dfTemp['Time']=pd.to_datetime(dfTemp['Time'])\n",
    "                    dfTemp.sort_values([\"Participant\",\"Time\"],ascending = (True,True),inplace=True)\n",
    "                    if len(dfTemp.columns)!=4:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    if len(df)!=0:\n",
    "                        frames=[dfTemp,df]\n",
    "                        df=pd.concat(frames)\n",
    "                    else:\n",
    "                        df=dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfCGM=df\n",
    "    dfCGM['Abbot'].interpolate(method='linear',limit_direction='both',axis=0,inplace=True)\n",
    "    dfCGM['Dexcom'].interpolate(method='linear',limit_direction='both',axis=0,inplace=True)\n",
    "    dfCGM.to_pickle(os.path.join(addDataPrefix,'All_cgm.pkl')) \n",
    "else:\n",
    "    dfCGM=pd.read_pickle(os.path.join(addDataPrefix,'All_cgm.pkl'))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# if os.path.exists(os.path.join(addDataPrefix,'All_cm.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,'All_cm.pkl'))\n",
    "os.chdir(addHKCM)\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'All_cm.pkl')):\n",
    "    df=[]\n",
    "    for root, dirs, files in os.walk(addHKCM):\n",
    "        for file in files:\n",
    "            if '.csv' in file.lower():\n",
    "                if 'cm' in file.lower() and 'modified' in file.lower():\n",
    "                    participantName=file[:file.find('_cm')]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\",file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\",file)\n",
    "                    dfTemp=pd.read_csv(file)\n",
    "                    print(\"File is read\")\n",
    "                    dfTemp['Time']=pd.to_datetime(dfTemp['Time'])\n",
    "                    dfTemp.insert(0,'Participant',participantName)\n",
    "                    dfTemp.insert(len(dfTemp.columns),'|Ax|+|Ay|+|Az|',dfTemp['Ax'].abs()+dfTemp['Ay'].abs()+dfTemp['Az'].abs()+0.001)#this is to avoid 0 later on for feature calculation\n",
    "                    dfTemp.insert(len(dfTemp.columns),'|Yaw|+|Roll|+|Pitch|',dfTemp['Yaw'].abs()+dfTemp['Roll'].abs()+dfTemp['Pitch'].abs())\n",
    "                    dfTemp.insert(len(dfTemp.columns),'RotationalToLinear',dfTemp['|Yaw|+|Roll|+|Pitch|']/dfTemp['|Ax|+|Ay|+|Az|'])\n",
    "                    print(\"modified\")\n",
    "                    dfTemp.sort_values(['Time'],ascending = (True),inplace=True)\n",
    "                    print(\"sorted\")\n",
    "                    if len(dfTemp.columns)!=14:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        print(dfTemp.columns)\n",
    "                        break\n",
    "                    if len(df)!=0:\n",
    "                        frames=[dfTemp,df]\n",
    "                        df=pd.concat(frames)\n",
    "                    else:\n",
    "                        df=dfTemp\n",
    "    dfCM=df\n",
    "    print(\"Processing is done\")\n",
    "    dfCM.to_pickle(os.path.join(addDataPrefix,'All_cm.pkl')) \n",
    "else:\n",
    "    dfCM = pd.read_pickle(os.path.join(addDataPrefix,'All_cm.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meal database is limited to the trial period\n",
      "CM databse is limited to the trial period\n",
      "Participant  p1  is started\n",
      "CM size for participant 7643165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6420/6420 [02:28<00:00, 43.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant  p3  is started\n",
      "CM size for participant 7567184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6420/6420 [02:26<00:00, 43.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant  p4  is started\n",
      "CM size for participant 7191513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6420/6420 [02:17<00:00, 46.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of skipped windows: 649  the shape of the data: (18611, 5)\n"
     ]
    }
   ],
   "source": [
    "def featureExtractorMotion(df):\n",
    "    f1=df['RotationalToLinear'].mean()\n",
    "    f2=df['|Ax|+|Ay|+|Az|'].mean()\n",
    "    f5=df['|Yaw|+|Roll|+|Pitch|'].mean()\n",
    "    return [f1,f2,f5]\n",
    "\n",
    "def featureExtractorCGM(df):\n",
    "    mean=df['Abbot'].mean()\n",
    "    std=df['Abbot'].std()\n",
    "    max=df['Abbot'].max()\n",
    "    min=df['Abbot'].min()\n",
    "    return mean, std, min,max\n",
    "\n",
    "MINIMUM_POINT_CM=10\n",
    "WINDOW_LENGTH=timedelta(minutes=2)\n",
    "MEAL_MAX_TIME=timedelta(minutes=30)\n",
    "MEAL_PORTION_RELAXATION=timedelta(seconds=10)\n",
    "START_OF_TRIAL = datetime.strptime('11 06 2021-02:00:00', '%m %d %Y-%H:%M:%S')#to handle the daylight saving issue in apple watches\n",
    "END_OF_TRIAL = datetime.strptime('11 15 2021-00:00:00', '%m %d %Y-%H:%M:%S')\n",
    "\n",
    "\n",
    "dfMeal=dfMeal[dfMeal['StartTime']>=START_OF_TRIAL]\n",
    "dfMeal=dfMeal[dfMeal['FinishTime']<END_OF_TRIAL]\n",
    "print(\"Meal database is limited to the trial period\")\n",
    "\n",
    "dfCM=dfCM[dfCM['Time']>=START_OF_TRIAL]\n",
    "dfCM=dfCM[dfCM['Time']<END_OF_TRIAL]\n",
    "print(\"CM databse is limited to the trial period\")\n",
    "\n",
    "participants=dfCM['Participant'].to_list()\n",
    "participants=list(set(participants))\n",
    "participantDataList=[]\n",
    "skippedWindows=0\n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix,'Features.npy')):\n",
    "    os.remove(os.path.join(addDataPrefix,'Features.npy'))\n",
    "if not os.path.exists(os.path.join(addDataPrefix,'Features.npy')):\n",
    "    for participant in participants:\n",
    "        windowStart=START_OF_TRIAL\n",
    "        windowEnd=windowStart+WINDOW_LENGTH        \n",
    "        print(\"Participant \",participant,\" is started\")\n",
    "        dfParticipantCM=dfCM[dfCM['Participant']==participant]\n",
    "        dfParticipantMeal=dfMeal[dfMeal['Participant']==participant]\n",
    "        print(\"CM size for participant\",len(dfParticipantCM))\n",
    "        for counter in tqdm(range(0,int((END_OF_TRIAL-START_OF_TRIAL).total_seconds()/WINDOW_LENGTH.total_seconds()),1)):\n",
    "            dfTempCM=dfParticipantCM[(dfParticipantCM['Time']>=windowStart) & (dfParticipantCM['Time']<=windowEnd)]\n",
    "            dfTempMeal=dfParticipantMeal[(dfParticipantMeal['StartTime']-MEAL_PORTION_RELAXATION<=windowStart) & (dfParticipantMeal['FinishTime']+MEAL_PORTION_RELAXATION>=windowEnd)]\n",
    "            dfTempMeal=dfTempMeal[dfTempMeal['StartTime']+MEAL_MAX_TIME>=dfTempMeal['FinishTime']]\n",
    "            if(len(dfTempCM)<MINIMUM_POINT_CM):\n",
    "                windowStart+=WINDOW_LENGTH\n",
    "                windowEnd+=WINDOW_LENGTH\n",
    "                skippedWindows+=1\n",
    "                continue\n",
    "            tempList=featureExtractorMotion(dfTempCM)\n",
    "            if(len(dfTempMeal)!=0):\n",
    "                tempList.append(1)\n",
    "            else:\n",
    "                tempList.append(0)\n",
    "            tempList.append(participant[1:])           \n",
    "            if(len(tempList)!=5):\n",
    "                print(\"MAYDAY. The length is not right\")\n",
    "                print(windowStart,windowEnd)\n",
    "                break\n",
    "            participantDataList.append(tempList)\n",
    "            windowStart+=WINDOW_LENGTH\n",
    "            windowEnd+=WINDOW_LENGTH\n",
    "    participantDataArray=np.asarray(participantDataList)\n",
    "    np.save(os.path.join(addDataPrefix,'Features'),participantDataArray)\n",
    "else:\n",
    "    participantDataArray = np.load(os.path.join(addDataPrefix,'Features.npy'))\n",
    "\n",
    "print(\"Total number of skipped windows:\",skippedWindows, \" the shape of the data:\",participantDataArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without NORMALIZATION\n",
      "Participant: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 24/29 [21:42<04:31, 54.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r9/63tl846j3ksdwv99wh0gv21m0000gn/T/ipykernel_64911/4250335983.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxVal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myVal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestTrainSplitFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipantDataArray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandomSeed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNORMALIZED_FLAG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxVal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myVal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataBalancer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxVal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myVal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mmodelBest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTMI_XGBoost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxVal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myVal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"With NORMALIZATION\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/r9/63tl846j3ksdwv99wh0gv21m0000gn/T/ipykernel_64911/4250335983.py\u001b[0m in \u001b[0;36mSTMI_XGBoost\u001b[0;34m(xTrain, xVal, xTest, yTrain, yVal, yTest)\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxDepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"binary:logistic\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"logloss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_label_encoder\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0mpredictionsVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxVal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mpredictionsVal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictionsVal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         )\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m   1251\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def STMI_XGBoost(xTrain,xVal,xTest,yTrain,yVal,yTest):\n",
    "    f1ScoreBest=0\n",
    "    for maxDepth in tqdm(np.arange(1,5,1)):\n",
    "        for estimator in np.arange(50,200,50):\n",
    "            for threshold in np.arange(0.2,0.9,0.2):\n",
    "                clf = xgb.XGBClassifier(scale_pos_weight = 50, n_jobs=18,n_estimators=estimator,max_depth=maxDepth, objective = \"binary:logistic\", eval_metric = \"error\")\n",
    "                clf.fit(xTrain,yTrain)\n",
    "                predictionsVal = clf.predict(xVal)\n",
    "                # predictionsVal = clf.predict_proba(xVal)\n",
    "                # predictionsVal=predictionsVal[:,1]\n",
    "                # predictionsVal[predictionsVal>=threshold]=1\n",
    "                # predictionsVal[predictionsVal<threshold]=0\n",
    "\n",
    "                confMatrix=sklearn.metrics.confusion_matrix(yVal,predictionsVal)\n",
    "                accuracy=sklearn.metrics.accuracy_score(yVal,predictionsVal)\n",
    "                recall=sklearn.metrics.recall_score(yVal,predictionsVal)\n",
    "                precision=sklearn.metrics.precision_score(yVal,predictionsVal)\n",
    "                f1Score=sklearn.metrics.f1_score(yVal,predictionsVal)\n",
    "\n",
    "                if f1Score>f1ScoreBest:\n",
    "                    confMatrixBest=confMatrix\n",
    "                    accuracyBest=accuracy\n",
    "                    modelBest=clf\n",
    "                    recallBest=recall\n",
    "                    precisionBest=precision\n",
    "                    thresholdBest=threshold\n",
    "                    f1ScoreBest=f1Score\n",
    "    print(\"***********Val:\")\n",
    "    print(confMatrixBest)\n",
    "    print(\"Accuracy:\",np.round(100*accuracyBest,0),\"Recall:\",np.round(100*recallBest,0),\"Precision:\",np.round(100*precisionBest,0))\n",
    "    print(\"***********Test:\")\n",
    "    predictionsTest=modelBest.predict(xTest)\n",
    "    # predictionsTest=modelBest.predict_proba(xTest)\n",
    "    # predictionsTest=predictionsTest[:,1]\n",
    "    # predictionsTest[predictionsTest>=thresholdBest]=1\n",
    "    # predictionsTest[predictionsTest<thresholdBest]=0    \n",
    "    \n",
    "    confMatrix=sklearn.metrics.confusion_matrix(yTest,predictionsTest)\n",
    "    accuracy=sklearn.metrics.accuracy_score(yTest,predictionsTest)\n",
    "    recall=sklearn.metrics.recall_score(yTest,predictionsTest)\n",
    "    precision=sklearn.metrics.precision_score(yTest,predictionsTest)\n",
    "    \n",
    "    print(confMatrix)\n",
    "    print(\"Accuracy:\",np.round(100*accuracy,0),\"Recall:\",np.round(100*recall,0),\"Precision:\",np.round(100*precision,0))\n",
    "    plot_confusion_matrix(modelBest, xTest, yTest,cmap='bone') \n",
    "\n",
    "def dataBalancer(xTrain,xVal,yTrain,yVal):\n",
    "    oversample = SMOTE()\n",
    "    xVal, yVal = oversample.fit_resample(xVal, yVal)\n",
    "    xTrain, yTrain = oversample.fit_resample(xTrain, yTrain)\n",
    "\n",
    "    return xTrain,xVal,yTrain,yVal\n",
    "\n",
    "def testTrainSplitFunc(data,randomSeed,normalFlag):\n",
    "    data=data.astype(float)\n",
    "    participants=data[:,data.shape[1]-1]\n",
    "    participants=list(set(participants))\n",
    "    for participant in participants:\n",
    "        print(\"Participant:\",participant)\n",
    "        indxList=[]\n",
    "        for counter in range(len(data)):\n",
    "            if(data[counter,data.shape[1]-1]==participant):\n",
    "                indxList.append(counter)\n",
    "        dataTemp=data[indxList,:]\n",
    "        dataX=dataTemp[:,0:dataTemp.shape[1]-2]\n",
    "        dataY=dataTemp[:,dataTemp.shape[1]-2]\n",
    "\n",
    "        random.seed(randomSeed)\n",
    "        np.random.shuffle(data)\n",
    "        if(normalFlag):\n",
    "            dataX=dataX-dataX.mean(axis=0)\n",
    "            dataX/=dataX.std(axis=0)\n",
    "        \n",
    "        stratidiedSampling = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=randomSeed)\n",
    "        for trainIndex, testIndex in stratidiedSampling.split(dataX, dataY):\n",
    "            xTrain,xTest=dataX[trainIndex],dataX[testIndex]\n",
    "            yTrain,yTest=dataY[trainIndex],dataY[testIndex]\n",
    "\n",
    "        stratidiedSampling = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=randomSeed)\n",
    "        for trainIndex, valIndex in stratidiedSampling.split(xTrain, yTrain):\n",
    "            xTrain,xVal=dataX[trainIndex],dataX[valIndex]\n",
    "            yTrain,yVal=dataY[trainIndex],dataY[valIndex]\n",
    "\n",
    "        # xTrain,xVal,yTrain,yVal=dataBalancer(xTrain,xVal,yTrain,yVal)\n",
    "        STMI_XGBoost(xTrain,xVal,xTest,yTrain,yVal,yTest)\n",
    "\n",
    "randomSeed=random.randrange(50)\n",
    "print(\"Without NORMALIZATION\")\n",
    "NORMALIZED_FLAG=False\n",
    "testTrainSplitFunc(participantDataArray,randomSeed,NORMALIZED_FLAG)\n",
    "\n",
    "\n",
    "print(\"With NORMALIZATION\")\n",
    "NORMALIZED_FLAG=True\n",
    "testTrainSplitFunc(participantDataArray,randomSeed,NORMALIZED_FLAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65e249be015da37cfe4cfdd1da028fe4cb475c26be679b9e3e34696278a17c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
