{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, mode, skew, kurtosis, linregress\n",
    "import xgboost as xgb\n",
    "from joblib import Parallel, delayed\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, ShuffleSplit, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import zipfile\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "# sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "font = {\"family\": \"normal\", \"weight\": \"bold\", \"size\": 22}\n",
    "\n",
    "plt.rc(\"font\", **font)\n",
    "\n",
    "CM_LAG_CORRECTION = [\n",
    "    (\"p1\", timedelta(minutes=2 * 60 + 36)),\n",
    "    (\"p3\", timedelta(minutes=2 * 60)),\n",
    "    (\"p5\", timedelta(minutes=-360)),\n",
    "    (\"p6\", timedelta(minutes=-360)),\n",
    "    (\"p7\", timedelta(minutes=-360)),\n",
    "    (\"p8\", timedelta(minutes=-360)),\n",
    "    # (\"p8\", datetime.strptime(\"02 02 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\"),datetime.strptime(\"02 06 2022-07:20:00\", \"%m %d %Y-%H:%M:%S\"),timedelta(minutes=-165)),\n",
    "    # (\"p8\", datetime.strptime(\"02 06 2022-07:20:00\", \"%m %d %Y-%H:%M:%S\"),datetime.strptime(\"02 09 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\"),timedelta(minutes=-165-190)),\n",
    "    # (\"p8\", datetime.strptime(\"02 09 2022-07:20:00\", \"%m %d %Y-%H:%M:%S\"),datetime.strptime(\"02 14 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\"),timedelta(minutes=93)),\n",
    "]\n",
    "# CGM_LAG_IMPOSING_STR = sys.argv[1]# ONLY TO IMPOSE A TIME LAG BETWEEN CGM READINGS AND CORE MOTION DATA!!!! WATCH OUT AND USE IT CAUTIOUSLY\n",
    "CGM_LAG_IMPOSING_STR = \"0\"\n",
    "# OUTTER_WINDOW_LENGTH = timedelta(minutes=int(sys.argv[2]))\n",
    "\n",
    "\n",
    "CGM_LAG_IMPOSING = timedelta(minutes=int(CGM_LAG_IMPOSING_STR))  # ONLY TO IMPOSE A TIME LAG BETWEEN CGM READINGS AND CORE MOTION DATA!!!! WATCH OUT AND USE IT CAUTIOUSLY\n",
    "OUTTER_WINDOW_LENGTH = timedelta(minutes=60)\n",
    "OUTTER_WINDOW_STEP = timedelta(minutes=15)\n",
    "FASTING_LENGTH = timedelta(minutes=30)\n",
    "BIG_MEAL_CALORIE = 200\n",
    "FOLD_NUMBER = 5\n",
    "INNER_WINDOW_LENGTH = timedelta(seconds=60)\n",
    "MINIMUM_POINT = INNER_WINDOW_LENGTH.total_seconds()\n",
    "COMPLEX_MEAL_DURATION = timedelta(minutes=60)\n",
    "\n",
    "\n",
    "START_OF_TRIAL = [datetime.strptime(\"11 06 2021-04:00:00\", \"%m %d %Y-%H:%M:%S\"), datetime.strptime(\"02 03 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\")]\n",
    "END_OF_TRIAL = [datetime.strptime(\"11 15 2021-00:00:00\", \"%m %d %Y-%H:%M:%S\"), datetime.strptime(\"02 13 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\")]\n",
    "DAY_LIGHT_SAVING = datetime.strptime(\"11 06 2021-02:00:00\", \"%m %d %Y-%H:%M:%S\")\n",
    "coreNumber = 48\n",
    "\n",
    "addDataPrefix = \"/Users/sorush/My Drive/Documents/Educational/TAMU/Research/TAMU/\"\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"/home/grads/s/sorush.omidvar/CGMDataset/TAMU/\"\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"C:\\\\GDrive\\\\Documents\\\\Educational\\\\TAMU\\\\Research\\\\Trial\\\\Data\\\\11-5-21-11-15-21\"\n",
    "\n",
    "addUserInput = os.path.join(addDataPrefix, \"User inputted\")\n",
    "addHKCM = os.path.join(addDataPrefix, \"hk+cm\")\n",
    "addCGM = os.path.join(addDataPrefix, \"CGM\")\n",
    "addE4 = os.path.join(addDataPrefix, \"E4\")\n",
    "addResults = os.path.join(addDataPrefix, \"Results\" + str(CGM_LAG_IMPOSING_STR))\n",
    "if not os.path.exists(addResults):\n",
    "    os.mkdir(addResults)\n",
    "\n",
    "exempts = [\"p2\", \"p4\"]\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({\"figure.facecolor\": \"white\"})\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # no GPU\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants=list(set(dfMeal['Participant'].to_list()))\n",
    "# participants.sort()\n",
    "# # dfMeal.insert(0,'Duration',0)\n",
    "# # dfMeal['Duration']=dfMeal['FinishTime']-dfMeal['StartTime']\n",
    "# for participant in participants:\n",
    "#     dfTemp=dfMeal[dfMeal['Participant']==participant]\n",
    "#     print(participant,'&',len(dfTemp),'&',np.round(dfTemp['Duration'].dt.total_seconds().mean()/60,1),'(',np.round(dfTemp['Duration'].dt.total_seconds().std()/60,1),')','&',np.round(dfTemp['Calories'].mean(),1),\"(\",np.round(dfTemp['Calories'].std(),1),\")\",'&',np.round(dfTemp['Carbs'].mean(),1),\"(\",np.round(dfTemp['Carbs'].std(),1),\")\",'&',np.round(dfTemp['Fat'].mean(),1),\"(\",np.round(dfTemp['Fat'].std(),1),\")\",'&',np.round(dfTemp['Protein'].mean(),1),\"(\",np.round(dfTemp['Protein'].std(),1),\")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = os.listdir(addResults)\n",
    "# for item in files:\n",
    "#     if \".xlsx\" in item or '.jpg' in item or 'All-Features' in item:\n",
    "#         os.remove(os.path.join(addResults, item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T1 = datetime.strptime(\"02 03 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\")\n",
    "# T2=T1+timedelta(hours=120)\n",
    "# a=dfE4[(dfE4['Time']>=T1) &(dfE4['Time']<=T2)]\n",
    "\n",
    "# plt.figure(figsize=(40,10))\n",
    "# x=a['Time'].to_list()\n",
    "# x=np.asarray(x)\n",
    "# y=a['Data1'].to_list()\n",
    "# plt.scatter(x,y)\n",
    "# plt.grid(which='both',color='r', linestyle='-', linewidth=0.5)\n",
    "# plt.minorticks_on()\n",
    "# plt.xlim([T1,T2])\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(40,10))\n",
    "# b=dfCM[(dfCM['Time']>=T1) &(dfCM['Time']<=T2)]\n",
    "# x=b['Time'].to_list()\n",
    "# x=np.asarray(x)\n",
    "# y=b['Yaw'].to_list()\n",
    "# y=np.asarray(y)/10+70\n",
    "# plt.scatter(x,y)\n",
    "# plt.grid(which='both',color='r', linestyle='-', linewidth=0.5)\n",
    "# plt.minorticks_on()\n",
    "# plt.xlim([T1,T2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unzipperE4(participantFolder):\n",
    "#     for root, dirs, files in os.walk(participantFolder):\n",
    "#         for file in files:\n",
    "#             if not '.zip' in file:\n",
    "#                 continue\n",
    "#             with zipfile.ZipFile(os.path.join(root,file), 'r') as zip_ref:\n",
    "#                 destFile=file[:file.find('.zip')]\n",
    "#                 destFile=os.path.join(root,destFile)\n",
    "#                 if not os.path.exists(destFile):\n",
    "#                     os.mkdir(destFile)\n",
    "#                 zip_ref.extractall(destFile)\n",
    "# def zipCleanerE4(E4Folder):\n",
    "#     for root, dirs, files in os.walk(E4Folder):\n",
    "#         for file in files:\n",
    "#             if '.zip' in file:\n",
    "#                 os.remove(os.path.join(root,file))\n",
    "\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p5')\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p6')\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p7')\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p8')\n",
    "# zipCleanerE4('/Users/sorush/Desktop/Round2E4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/grads/s/sorush.omidvar/CGMDataset/TAMU/User inputted\n",
      "Reading ... p1Meals.csv\n",
      "Reading ... p5Meals.csv\n",
      "Reading ... p7Meals.csv\n",
      "Reading ... p8Meals.csv\n",
      "Reading ... p6Meals.csv\n",
      "Reading ... p3Meals.csv\n",
      "Exemption... p4Meals.csv\n",
      "reading is done\n",
      "Meal database is limited to the trial period\n"
     ]
    }
   ],
   "source": [
    "def timeZoneFixer(df, LocalizeFlag, columnName):\n",
    "    if LocalizeFlag:\n",
    "        df[columnName] -= timedelta(hours=5)\n",
    "    tempColumn = df[columnName]\n",
    "    tempColumn[tempColumn >= DAY_LIGHT_SAVING] -= timedelta(hours=1)\n",
    "    df[columnName] = tempColumn\n",
    "    return df\n",
    "\n",
    "\n",
    "def trialTimeLimitter(df, columnName):\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    dfTotal = []\n",
    "    for participant in participants:\n",
    "        if participant == \"p1\" or participant == \"p2\" or participant == \"p3\" or participant == \"p4\":\n",
    "            startOfTrial = START_OF_TRIAL[0]\n",
    "            endOfTrial = END_OF_TRIAL[0]\n",
    "        elif participant == \"p5\" or participant == \"p6\" or participant == \"p7\" or participant == \"p8\":\n",
    "            startOfTrial = START_OF_TRIAL[1]\n",
    "            endOfTrial = END_OF_TRIAL[1]\n",
    "        else:\n",
    "            print(\"Mayday in trialTimeLimitter\")\n",
    "            print(participant)\n",
    "            raise\n",
    "        dfTemp = df[df[\"Participant\"] == participant]\n",
    "        dfTemp = dfTemp[(dfTemp[columnName] >= startOfTrial) & (dfTemp[columnName] <= endOfTrial)]\n",
    "        if len(dfTotal) == 0:\n",
    "            dfTotal = dfTemp\n",
    "        else:\n",
    "            frames = [dfTotal, dfTemp]\n",
    "            dfTotal = pd.concat(frames)\n",
    "    return dfTotal\n",
    "\n",
    "\n",
    "def mealMarker(df):\n",
    "    df.insert(len(df.columns), \"BigMeal\", False)\n",
    "    for counter in range(0, len(df)):\n",
    "        if df[\"Calories\"].iloc[counter] >= BIG_MEAL_CALORIE:\n",
    "            df[\"BigMeal\"].iloc[counter] = True\n",
    "\n",
    "    df.insert(len(df.columns), \"ComplexMeal\", False)\n",
    "    participants = df[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    for participant in participants:\n",
    "        dfTemp = df[df[\"Participant\"] == participant]\n",
    "        for counter in range(1, len(dfTemp)):\n",
    "            # bothComplexFlag = dfTemp[\"BigMeal\"].iloc[counter - 1] and dfTemp[\"BigMeal\"].iloc[counter]\n",
    "            # if dfTemp[\"StartTime\"].iloc[counter - 1] + OUTTER_WINDOW_LENGTH >= dfTemp[\"StartTime\"].iloc[counter] and bothComplexFlag:\n",
    "            if dfTemp[\"StartTime\"].iloc[counter - 1] + COMPLEX_MEAL_DURATION >= dfTemp[\"StartTime\"].iloc[counter]:\n",
    "                dfTemp[\"ComplexMeal\"].iloc[counter] = True\n",
    "                dfTemp[\"ComplexMeal\"].iloc[counter - 1] = True\n",
    "        indexs = dfTemp.index[dfTemp[\"ComplexMeal\"] == True]\n",
    "        df[\"ComplexMeal\"][indexs] = True\n",
    "    return df\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addResults, \"All_meals.pkl\")):\n",
    "    os.remove(os.path.join(addResults, \"All_meals.pkl\"))\n",
    "os.chdir(addUserInput)\n",
    "if not os.path.exists(os.path.join(addResults, \"All_meals.pkl\")):\n",
    "    dfMeal = []\n",
    "    for root, dirs, files in os.walk(addUserInput):\n",
    "        print(root)\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                if \"meals\" in file.lower() and \"modified\" not in file.lower():\n",
    "                    participantName = file[: file.find(\"Meals\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    dfTemp.rename(columns={\"startTime\": \"StartTime\"}, inplace=True)\n",
    "                    dfTemp[\"StartTime\"] = pd.to_datetime(dfTemp[\"StartTime\"])\n",
    "                    dfTemp[\"FinishTime\"] = pd.to_datetime(dfTemp[\"FinishTime\"])\n",
    "                    dfTemp.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                    if len(dfMeal) != 0:\n",
    "                        frames = [dfTemp, dfMeal]\n",
    "                        dfMeal = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfMeal = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfMeal = trialTimeLimitter(dfMeal, \"StartTime\")\n",
    "    dfMeal = trialTimeLimitter(dfMeal, \"FinishTime\")\n",
    "    dfMeal.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    dfMeal.reset_index(drop=True, inplace=True)\n",
    "    # dfMeal.insert(4, \"MealDuration\", -1)\n",
    "    # dfMeal[\"MealDuration\"] = dfMeal[\"FinishTime\"] - dfMeal[\"StartTime\"]\n",
    "    # dfMeal[\"MealDuration\"] = dfMeal[\"MealDuration\"].dt.total_seconds()\n",
    "    print(\"Meal database is limited to the trial period\")\n",
    "    dfMeal.to_pickle(os.path.join(addResults, \"All_meals.pkl\"))\n",
    "else:\n",
    "    dfMeal = pd.read_pickle(os.path.join(addResults, \"All_meals.pkl\"))\n",
    "dfMeal = mealMarker(dfMeal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdInterpolation(dfTemp):\n",
    "    index = dfTemp[\"Time\"]\n",
    "    seriesParticipant = pd.Series(dfTemp[\"Abbot\"].to_list(), index=index)\n",
    "    seriesParticipant = seriesParticipant.resample(\"1T\").asfreq()\n",
    "    seriesParticipant.interpolate(method=\"polynomial\", order=3, inplace=True)\n",
    "    tempTime = seriesParticipant.index\n",
    "    tempVal = seriesParticipant.values\n",
    "    dfTemp = pd.DataFrame(zip(tempTime, tempVal), columns=[\"Time\", \"Abbot\"])\n",
    "    return dfTemp\n",
    "\n",
    "\n",
    "def cmLagCorrector(df):\n",
    "    participants = df[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    dfTotal = []\n",
    "\n",
    "    for element in CM_LAG_CORRECTION:\n",
    "        participant = element[0]\n",
    "        timeLag = element[1]\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        if len(dfParticipant) == 0:\n",
    "            continue\n",
    "        dfParticipant[\"Time\"] += timeLag\n",
    "        if len(dfTotal) == 0:\n",
    "            dfTotal = dfParticipant\n",
    "        else:\n",
    "            frames = [dfTotal, dfParticipant]\n",
    "            dfTotal = pd.concat(frames)\n",
    "\n",
    "    return dfTotal\n",
    "\n",
    "\n",
    "def cmSmoother(df):\n",
    "    columnLabels = df.columns\n",
    "    for columnLabel in columnLabels:\n",
    "        if columnLabel == \"Time\":\n",
    "            continue\n",
    "        tempSerie = df[columnLabel]\n",
    "        tempSerie = tempSerie.ewm(span=10).mean()  # Considering the frequency of 10 Hz\n",
    "        df[columnLabel] = tempSerie\n",
    "    return df\n",
    "\n",
    "\n",
    "def CGMLagImposer(df):\n",
    "    df[\"Time\"] += CGM_LAG_IMPOSING\n",
    "    return df\n",
    "\n",
    "\n",
    "def CGMNormalizer(df):\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    participants.sort()\n",
    "    dfResult = []\n",
    "    for participant in participants:\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        dates = list(set(dfParticipant[\"Time\"].dt.date.to_list()))\n",
    "        dates.sort()\n",
    "        for date in dates:\n",
    "            dfDate = dfParticipant[dfParticipant[\"Time\"].dt.date == date]\n",
    "            minBG = dfDate[\"Abbot\"].min()\n",
    "            maxBG = dfDate[\"Abbot\"].max()\n",
    "            dfDate[\"Abbot\"] -= minBG\n",
    "            dfDate[\"Abbot\"] /= maxBG - minBG\n",
    "            assert not np.isnan(minBG)\n",
    "            assert not np.isnan(maxBG)\n",
    "            if len(dfResult) == 0:\n",
    "                dfResult = dfDate.copy()\n",
    "            else:\n",
    "                frames = [dfResult, dfDate]\n",
    "                dfResult = pd.concat(frames)\n",
    "    return dfResult\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addResults, \"All_cgm.pkl\")):\n",
    "    # os.remove(os.path.join(addResults, \"All_cgm.pkl\"))\n",
    "if not os.path.exists(os.path.join(addResults, \"All_cgm.pkl\")):\n",
    "    os.chdir(addCGM)\n",
    "    dfCGM = []\n",
    "    for root, dirs, files in os.walk(addCGM):\n",
    "        for file in files:\n",
    "            if \".txt\" in file.lower():\n",
    "                if \"_libre\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_libre\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file, sep=\"\\t\", skiprows=1)\n",
    "                    if len(dfTemp.columns) != 4:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    dfTemp.columns.values[0] = \"ID\"\n",
    "                    dfTemp.columns.values[1] = \"Time\"\n",
    "                    dfTemp.columns.values[2] = \"Record\"\n",
    "                    dfTemp.columns.values[3] = \"Abbot\"\n",
    "                    dfTemp.drop(columns=[\"ID\", \"Record\"], inplace=True)\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"])\n",
    "                    if participantName == \"p1\" or participantName == \"p2\" or participantName == \"p3\" or participantName == \"p4\":\n",
    "                        dfTemp[\"Time\"] += timedelta(hours=-1)  # This fixes the daylight saving for the first round\n",
    "                    dfTemp[\"Abbot\"] = pd.to_numeric(dfTemp[\"Abbot\"])\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                    dfTemp = pdInterpolation(dfTemp)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    if len(dfTemp.columns) != 3:\n",
    "                        print(\"MAYDAY. Error in processing csv\")\n",
    "                        break\n",
    "                    if len(dfCGM) != 0:\n",
    "                        frames = [dfTemp, dfCGM]\n",
    "                        dfCGM = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfCGM = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfCGM = CGMLagImposer(dfCGM)\n",
    "    dfCGM = trialTimeLimitter(dfCGM, \"Time\")\n",
    "    dfCGM.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfCGM = CGMNormalizer(dfCGM)\n",
    "    dfCGM.reset_index(drop=True, inplace=True)\n",
    "    print(\"CGM database is limited to the trial period\")\n",
    "    dfCGM.to_pickle(os.path.join(addResults, \"All_cgm.pkl\"))\n",
    "else:\n",
    "    dfCGM = pd.read_pickle(os.path.join(addResults, \"All_cgm.pkl\"))\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addResults, \"All_cm.pkl\")):\n",
    "#     os.remove(os.path.join(addResults, \"All_cm.pkl\"))\n",
    "os.chdir(addHKCM)\n",
    "if not os.path.exists(os.path.join(addResults, \"All_cm.pkl\")):\n",
    "    dfCM = []\n",
    "    for root, dirs, files in os.walk(addHKCM):\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                if \"corrected_cm_all\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_corrected\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    print(\"File is read\")\n",
    "                    dfTemp[\"UnixTime\"] = pd.to_datetime(dfTemp[\"UnixTime\"], unit=\"s\")\n",
    "\n",
    "                    dfTemp.rename(columns={\"UnixTime\": \"Time\"}, inplace=True)\n",
    "                    dfTemp.drop(columns=[\"UID\", \"Date\"], inplace=True)\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "\n",
    "                    dfTemp = cmSmoother(dfTemp)\n",
    "                    dfTemp[\"Yaw\"] *= 180 / 3.1415\n",
    "                    dfTemp[\"Pitch\"] *= 180 / 3.1415\n",
    "                    dfTemp[\"Roll\"] *= 180 / 3.1415\n",
    "\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    # this is to avoid 0 later on for feature calculation\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Ax|+|Ay|+|Az|\", dfTemp[\"Ax\"].abs() + dfTemp[\"Ay\"].abs() + dfTemp[\"Az\"].abs() + 0.001)\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Yaw|+|Roll|+|Pitch|\", dfTemp[\"Yaw\"].abs() + dfTemp[\"Roll\"].abs() + dfTemp[\"Pitch\"].abs())\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\", dfTemp[\"Rx\"].abs() + dfTemp[\"Ry\"].abs() + dfTemp[\"Rz\"].abs())\n",
    "                    dfTemp[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"] = dfTemp[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"]\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"RotationalToLinear\", dfTemp[\"|Yaw|+|Roll|+|Pitch|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"])\n",
    "                    print(\"modified\")\n",
    "\n",
    "                    if len(dfTemp.columns) != 15:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        print(dfTemp.columns)\n",
    "                        break\n",
    "                    if len(dfCM) != 0:\n",
    "                        frames = [dfTemp, dfCM]\n",
    "                        dfCM = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfCM = dfTemp\n",
    "    print(\"Processing is done\")\n",
    "    dfCM = cmLagCorrector(dfCM)\n",
    "    dfCM = trialTimeLimitter(dfCM, \"Time\")\n",
    "    dfCM.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfCM.reset_index(drop=True, inplace=True)\n",
    "    print(\"CM database is limited to the trial period\")\n",
    "    dfCM.to_pickle(os.path.join(addResults, \"All_cm.pkl\"))\n",
    "else:\n",
    "    dfCM = pd.read_pickle(os.path.join(addResults, \"All_cm.pkl\"))\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addResults, \"All_E4.pkl\")):\n",
    "#     os.remove(os.path.join(addResults, \"All_E4.pkl\"))\n",
    "os.chdir(addE4)\n",
    "# fields=['ACC','BVP','EDA','HR','IBI','TEMP']\n",
    "fields = [\"HR\", \"TEMP\", \"EDA\"]\n",
    "if not os.path.exists(os.path.join(addResults, \"All_E4.pkl\")):\n",
    "    dfE4 = []\n",
    "    for root, dirs, files in os.walk(addE4):\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                participantName = root[root.find(\"E4\") + 3 :]\n",
    "                participantName = participantName[:2]\n",
    "                field = file[: file.find(\".csv\")]\n",
    "                if field not in fields:\n",
    "                    print(\"File name does not comply with analyzed fields\", file)\n",
    "                    continue\n",
    "                print(participantName, field)\n",
    "                if participantName in exempts:\n",
    "                    print(\"Exemption...\", file)\n",
    "                    continue\n",
    "                print(\"Reading ...\", file)\n",
    "                os.chdir(root)\n",
    "                dfTemp = pd.read_csv(file, header=None)\n",
    "                # if field=='ACC':\n",
    "                #     assert len(dfTemp.columns)==3\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     timeStep=1/dfTemp.iloc[1,0]\n",
    "                #     dfTemp.drop([0,1],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Data1',1:'Data2',2:'Data3'}, inplace=True)#x,y,z for data1,data2,data3\n",
    "                #     timeTemp=[]\n",
    "                #     for counter in range(len(dfTemp)):\n",
    "                #         timeTemp.append(timeBase+counter*timeStep)\n",
    "                #     dfTemp.insert(0,'Time',timeTemp)\n",
    "                #     dfTemp.insert(0,'Field',\"Acceleration\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                # if field == \"BVP\":\n",
    "                #     assert len(dfTemp.columns) == 1\n",
    "                #     timeBase = dfTemp.iloc[0, 0]\n",
    "                #     timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                #     dfTemp.drop([0, 1], inplace=True)\n",
    "                #     dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                #     dfTemp[\"Data2\"] = \"\"\n",
    "                #     dfTemp[\"Data3\"] = \"\"\n",
    "                #     timeTemp = []\n",
    "                #     for counter in range(len(dfTemp)):\n",
    "                #         timeTemp.append(timeBase + counter * timeStep)\n",
    "                #     dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                #     dfTemp.insert(0, \"Field\", \"BVP\")\n",
    "                #     dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                if field == \"HR\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"HR\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                elif field == \"EDA\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"EDA\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                # elif field=='IBI':\n",
    "                #     assert len(dfTemp.columns)==2\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     dfTemp.drop([0],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Time',1:'Data1'}, inplace=True)\n",
    "                #     dfTemp[\"Data2\"]=\"\"\n",
    "                #     dfTemp[\"Data3\"]=\"\"\n",
    "                #     timeTemp=[]\n",
    "                #     dfTemp['Time']+=timeBase\n",
    "                #     dfTemp.insert(0,'Field',\"IBI\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                elif field == \"TEMP\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"Temperature\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                dfTemp.insert(0, \"Participant\", participantName)\n",
    "                dfTemp.sort_values([\"Participant\", \"Field\", \"Time\"], ascending=(True, True, True), inplace=True)\n",
    "                if len(dfTemp.columns) != 6:\n",
    "                    print(\"MAYDAY. Error in reading csv\")\n",
    "                    break\n",
    "                if len(dfE4) != 0:\n",
    "                    frames = [dfTemp, dfE4]\n",
    "                    dfE4 = pd.concat(frames)\n",
    "                else:\n",
    "                    dfE4 = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfE4 = timeZoneFixer(dfE4, True, \"Time\")\n",
    "    dfE4.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfE4 = trialTimeLimitter(dfE4, \"Time\")\n",
    "    dfE4.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfE4.reset_index(drop=True, inplace=True)\n",
    "    print(\"E4 database is limited to the trial period\")\n",
    "    dfE4.to_pickle(os.path.join(addResults, \"All_E4.pkl\"))\n",
    "else:\n",
    "    dfE4 = pd.read_pickle(os.path.join(addResults, \"All_E4.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants = list(set(dfCGM[\"Participant\"].to_list()))\n",
    "# participants.sort()\n",
    "# for participant in participants:\n",
    "#     dfCGMTemp = dfCGM[dfCGM[\"Participant\"] == participant]\n",
    "#     dfMealTemp = dfMeal[dfMeal[\"Participant\"] == participant]\n",
    "#     riseDuration = []\n",
    "#     for counter in range(len(dfMealTemp) - 1):\n",
    "#         currentMealStart = dfMealTemp.iloc[counter][\"StartTime\"]\n",
    "#         cgmValBase = dfCGMTemp[dfCGMTemp[\"Time\"] == currentMealStart]\n",
    "\n",
    "#         assert len(cgmValBase) == 1\n",
    "#         cgmValBase = cgmValBase[\"Abbot\"].values[0]\n",
    "#         for counter in range(45):\n",
    "#             timeTempMin = timedelta(minutes=counter)\n",
    "#             cgmVal = dfCGMTemp[dfCGMTemp[\"Time\"] == currentMealStart + timeTempMin]\n",
    "#             assert len(cgmVal) == 1\n",
    "#             cgmVal = cgmVal[\"Abbot\"].values[0]\n",
    "#             if cgmVal - cgmValBase >= 15:\n",
    "#                 riseDuration.append([counter, cgmValBase, cgmVal])\n",
    "#                 break\n",
    "#     riseDuration = np.asarray(riseDuration)\n",
    "#     print(\"BG average rise time for each participants over all meals:\", participant, np.mean(riseDuration[:, 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T1 = datetime.strptime(\"02 03 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\")\n",
    "# T2 = T1 + timedelta(hours=240)\n",
    "# myParticipant = \"p7\"\n",
    "# a = dfE4[dfE4[\"Participant\"] == myParticipant]\n",
    "# a = a[(a[\"Time\"] >= T1) & (a[\"Time\"] <= T2)]\n",
    "\n",
    "# plt.figure(figsize=(40, 10))\n",
    "# x = a[\"Time\"].to_list()\n",
    "# x = np.asarray(x)\n",
    "# y = a[\"Data1\"].to_list()\n",
    "# plt.scatter(x, y)\n",
    "# plt.grid(which=\"both\", color=\"r\", linestyle=\"-\", linewidth=0.5)\n",
    "# plt.minorticks_on()\n",
    "# plt.xlim([T1, T2])\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(40, 10))\n",
    "# b = dfCM[dfCM[\"Participant\"] == myParticipant]\n",
    "# b = b[(b[\"Time\"] >= T1) & (b[\"Time\"] <= T2)]\n",
    "# x = b[\"Time\"].to_list()\n",
    "# x = np.asarray(x)\n",
    "# y = b[\"Yaw\"].to_list()\n",
    "# y = np.asarray(y) / 10 + 70\n",
    "# plt.scatter(x, y)\n",
    "# plt.grid(which=\"both\", color=\"r\", linestyle=\"-\", linewidth=0.5)\n",
    "# plt.minorticks_on()\n",
    "# plt.xlim([T1, T2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=plt.figure(figsize=(18,24))\n",
    "# plt.subplot(6,1,1)\n",
    "# participant='p8'\n",
    "# colors=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# T1 = datetime.strptime(\"02 03 2022-12:00:00\", \"%m %d %Y-%H:%M:%S\")  # to handle the daylight saving issue in apple watches\n",
    "# T2 = T1 + timedelta(hours=5)\n",
    "# dfTempCGM=dfCGM[dfCGM['Participant']==participant]\n",
    "# dfTempCGM=dfTempCGM[(dfTempCGM['Time']>=T1) & (dfTempCGM['Time']<T2)]\n",
    "\n",
    "# x=dfTempCGM['Time'].to_list()\n",
    "# y=dfTempCGM['Abbot'].to_list()\n",
    "# y=np.asarray(y).astype(float)\n",
    "# for counter in range(len(x)):\n",
    "#     x[counter]=x[counter].to_pydatetime()\n",
    "#     x[counter]=x[counter].time().hour+x[counter].time().minute/60+x[counter].time().second/3600\n",
    "# x=x[1:len(x):15]\n",
    "# y=y[1:len(y):15]\n",
    "# myAx=plt.plot(x,y, '-*',c=colors[0])\n",
    "# frame1 = plt.gca()\n",
    "# frame1.axes.set_xticks([12,14,16,18])\n",
    "# frame1.axes.minorticks_on()\n",
    "# frame1.axes.set_xticklabels([])\n",
    "# frame1.tick_params('both', length=6, width=1, which='major')\n",
    "# frame1.tick_params('both', length=2, width=1, which='minor')\n",
    "# frame1.axes.set_xlim([12,17])\n",
    "# frame1.axes.yaxis.set_label_coords(-0.1,0.5)\n",
    "# plt.ylabel('BG [mg/dL]')\n",
    "# plt.scatter(x=12+43/60,y=120,color='red')\n",
    "\n",
    "\n",
    "# plt.subplot(6,1,2)\n",
    "# dfTempE4=dfE4[dfE4['Participant']==participant]\n",
    "# dfTempE4=dfTempE4[(dfTempE4['Time']>=T1) & (dfTempE4['Time']<T2) &(dfTempE4['Field']=='HR')]\n",
    "\n",
    "# x=dfTempE4['Time'].to_list()\n",
    "# y=dfTempE4['Data1'].to_list()\n",
    "# y=np.asarray(y).astype(float)\n",
    "# for counter in range(len(x)):\n",
    "#     x[counter]=x[counter].to_pydatetime()\n",
    "#     x[counter]=x[counter].time().hour+x[counter].time().minute/60+x[counter].time().second/3600\n",
    "# myAx=plt.plot(x,y ,'-',c=colors[1])\n",
    "# frame1 = plt.gca()\n",
    "# frame1.axes.set_xticks([12,14,16,18])\n",
    "# frame1.axes.minorticks_on()\n",
    "# frame1.axes.set_xticklabels([])\n",
    "# frame1.tick_params('both', length=6, width=1, which='major')\n",
    "# frame1.tick_params('both', length=2, width=1, which='minor')\n",
    "# frame1.axes.set_xlim([11,17])\n",
    "# frame1.axes.yaxis.set_label_coords(-0.1,0.5)\n",
    "# plt.ylabel('Heart Rate [BPM]')\n",
    "\n",
    "# plt.subplot(6,1,3)\n",
    "# dfTempE4=dfE4[dfE4['Participant']==participant]\n",
    "# dfTempE4=dfTempE4[(dfTempE4['Time']>=T1) & (dfTempE4['Time']<T2) &(dfTempE4['Field']=='Temperature')]\n",
    "\n",
    "# x=dfTempE4['Time'].to_list()\n",
    "# y=dfTempE4['Data1'].to_list()\n",
    "# y=np.asarray(y).astype(float)\n",
    "# for counter in range(len(x)):\n",
    "#     x[counter]=x[counter].to_pydatetime()\n",
    "#     x[counter]=x[counter].time().hour+x[counter].time().minute/60+x[counter].time().second/3600\n",
    "# myAx=plt.plot(x,y ,'-',c=colors[3])\n",
    "# frame1 = plt.gca()\n",
    "# frame1.axes.set_xticks([12,14,16,18])\n",
    "# frame1.axes.minorticks_on()\n",
    "# frame1.axes.set_xticklabels([])\n",
    "# frame1.tick_params('both', length=6, width=1, which='major')\n",
    "# frame1.tick_params('both', length=2, width=1, which='minor')\n",
    "# frame1.axes.set_xlim([12,17])\n",
    "# frame1.axes.yaxis.set_label_coords(-0.1,0.5)\n",
    "# plt.ylabel('Temperature [$^\\circ$C]')\n",
    "\n",
    "\n",
    "# plt.subplot(6,1,4)\n",
    "# dfTempE4=dfE4[dfE4['Participant']==participant]\n",
    "# dfTempE4=dfTempE4[(dfTempE4['Time']>=T1) & (dfTempE4['Time']<T2) &(dfTempE4['Field']=='EDA')]\n",
    "\n",
    "# x=dfTempE4['Time'].to_list()\n",
    "# y=dfTempE4['Data1'].to_list()\n",
    "# y=np.asarray(y).astype(float)\n",
    "# for counter in range(len(x)):\n",
    "#     x[counter]=x[counter].to_pydatetime()\n",
    "#     x[counter]=x[counter].time().hour+x[counter].time().minute/60+x[counter].time().second/3600\n",
    "# myAx=plt.plot(x,y ,'-',c=colors[4])\n",
    "# frame1 = plt.gca()\n",
    "# frame1.axes.set_xticks([12,14,16,18])\n",
    "# frame1.axes.minorticks_on()\n",
    "# frame1.axes.set_xticklabels([])\n",
    "# frame1.tick_params('both', length=6, width=1, which='major')\n",
    "# frame1.tick_params('both', length=2, width=1, which='minor')\n",
    "# frame1.axes.set_xlim([12,17])\n",
    "# frame1.axes.yaxis.set_label_coords(-0.1,0.5)\n",
    "# plt.ylabel('EDA [$^\\mu$S]')\n",
    "\n",
    "\n",
    "# plt.subplot(6,1,5)\n",
    "# dfCMTemp=dfCM[dfCM['Participant']==participant]\n",
    "# dfCMTemp=dfCMTemp[(dfCMTemp['Time']>=T1) & (dfCMTemp['Time']<T2)]\n",
    "\n",
    "# x=dfCMTemp['Time'].to_list()\n",
    "# y=dfCMTemp['Ax'].to_list()\n",
    "# y=np.asarray(y).astype(float)\n",
    "# for counter in range(len(x)):\n",
    "#     x[counter]=x[counter].to_pydatetime()\n",
    "#     x[counter]=x[counter].time().hour+x[counter].time().minute/60+x[counter].time().second/3600\n",
    "# myAx=plt.plot(x,y ,'-',c=colors[5])\n",
    "# frame1 = plt.gca()\n",
    "# frame1 = plt.gca()\n",
    "# frame1.axes.set_xticks([12,14,16,18])\n",
    "# frame1.axes.minorticks_on()\n",
    "# frame1.axes.set_xticklabels([])\n",
    "# frame1.tick_params('both', length=6, width=1, which='major')\n",
    "# frame1.tick_params('both', length=2, width=1, which='minor')\n",
    "# frame1.axes.set_xlim([12,17])\n",
    "# frame1.axes.yaxis.set_label_coords(-0.1,0.5)\n",
    "# plt.ylabel('Acceleration [$m^2$/s]')\n",
    "\n",
    "\n",
    "# plt.subplot(6,1,6)\n",
    "# dfCMTemp=dfCM[dfCM['Participant']==participant]\n",
    "# dfCMTemp=dfCMTemp[(dfCMTemp['Time']>=T1) & (dfCMTemp['Time']<T2)]\n",
    "\n",
    "# x=dfCMTemp['Time'].to_list()\n",
    "# y=dfCMTemp['Yaw'].to_list()\n",
    "# y=np.asarray(y).astype(float)\n",
    "# for counter in range(len(x)):\n",
    "#     x[counter]=x[counter].to_pydatetime()\n",
    "#     x[counter]=x[counter].time().hour+x[counter].time().minute/60+x[counter].time().second/3600\n",
    "# myAx=plt.plot(x,y ,'-',c=colors[6])\n",
    "# frame1 = plt.gca()\n",
    "# frame1.axes.set_xticks([12,14,16,18])\n",
    "# frame1.axes.minorticks_on()\n",
    "# frame1.tick_params('both', length=6, width=1, which='major')\n",
    "# frame1.tick_params('both', length=2, width=1, which='minor')\n",
    "# frame1.axes.set_xlim([12, 17])\n",
    "# frame1.axes.yaxis.set_label_coords(-0.1,0.5)\n",
    "\n",
    "# plt.ylabel('Yaw [$^\\circ$]')\n",
    "# plt.xlabel('Time [hr]')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: p1\n",
      "All windows:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 844/844 [02:27<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: p3\n",
      "All windows:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 844/844 [02:25<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: p5\n",
      "All windows:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 956/956 [02:40<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: p6\n",
      "All windows:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 956/956 [02:36<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: p7\n",
      "All windows:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 898/898 [02:18<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: p8\n",
      "All windows:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 956/956 [02:46<00:00,  5.75it/s]\n"
     ]
    }
   ],
   "source": [
    "def e4Reporter(df):\n",
    "    # topics = [\"BVP\", \"EDA\", \"HR\", \"Temperature\"]\n",
    "    topics = [\"EDA\", \"HR\", \"Temperature\"]\n",
    "    report = []\n",
    "    for topic in topics:\n",
    "        dfTemp = df[df[\"Field\"] == topic]\n",
    "        # if topic == \"BVP\":\n",
    "        #     MIN_POINT = MINIMUM_POINT * 64 * 0.3\n",
    "        if topic == \"EDA\":\n",
    "            MIN_POINT = MINIMUM_POINT * 4 * 0.3\n",
    "        elif topic == \"HR\":\n",
    "            MIN_POINT = MINIMUM_POINT / 10 * 0.3\n",
    "        elif topic == \"Temperature\":\n",
    "            MIN_POINT = MINIMUM_POINT * 4 * 0.3\n",
    "        else:\n",
    "            print(topic)\n",
    "            print(\"MAYDAY at sensor reader\")\n",
    "            os._exit()\n",
    "        if len(dfTemp) < MIN_POINT:\n",
    "            report.append(\"Nan\")\n",
    "        else:\n",
    "            val = dfTemp[\"Data1\"].mean()\n",
    "            report.append(val)\n",
    "    return report\n",
    "\n",
    "\n",
    "def motionCalculator(df):\n",
    "    f1 = df[\"RotationalToLinear\"]\n",
    "    f2 = df[\"|Ax|+|Ay|+|Az|\"]\n",
    "    return [f1.mean(), f1.std(), f1.max() - f1.min(), f2.mean(), f2.std(), f2.max() - f2.min()]\n",
    "\n",
    "\n",
    "def CGMStatFeatures(dataList):\n",
    "    dataList = np.asarray(dataList).astype(float)\n",
    "    result = []\n",
    "    dataDim = dataList.ndim\n",
    "    assert dataDim == 1\n",
    "    assert len(dataList) == len(dataList[~np.isnan(dataList)])\n",
    "    dataList = dataList[~np.isnan(dataList)]\n",
    "\n",
    "    meanVal = np.nanmean(dataList)\n",
    "    stdVal = np.nanstd(dataList)\n",
    "    minVal = np.nanmin(dataList)\n",
    "    maxVal = np.nanmax(dataList)\n",
    "    rangeVal = maxVal - minVal\n",
    "    skewnessVal = skew(dataList, nan_policy=\"omit\")\n",
    "    kurtosisVal = kurtosis(dataList, nan_policy=\"omit\")\n",
    "\n",
    "    tempSize = int(len(dataList) / 4)\n",
    "    firstFourthSlopeVal = np.mean(dataList[0:tempSize])\n",
    "    secondFourthSlopeVal = np.mean(dataList[tempSize : 2 * tempSize])\n",
    "    thirdFourthSlopeVal = np.mean(dataList[2 * tempSize : 3 * tempSize])\n",
    "    forthFourthSlopeVal = np.mean(dataList[4 * tempSize :])\n",
    "\n",
    "    dataListDiff = np.diff(dataList)\n",
    "    meanDiff = np.nanmean(dataListDiff)\n",
    "    stdDiff = np.nanstd(dataListDiff)\n",
    "    minDiff = np.nanmin(dataListDiff)\n",
    "    maxDiff = np.nanmax(dataListDiff)\n",
    "    rangeDiff = maxDiff - minDiff\n",
    "\n",
    "    tempSize = int(len(dataListDiff) / 4)\n",
    "    firstFourthSlopeDiff = np.mean(dataListDiff[0:tempSize])\n",
    "    secondFourthSlopeDiff = np.mean(dataListDiff[tempSize : 2 * tempSize])\n",
    "    thirdFourthSlopeDiff = np.mean(dataListDiff[2 * tempSize : 3 * tempSize])\n",
    "    forthFourthSlopeDiff = np.mean(dataListDiff[3 * tempSize :])\n",
    "\n",
    "    result.extend(\n",
    "        [\n",
    "            rangeVal,\n",
    "            meanVal,\n",
    "            stdVal,\n",
    "            minVal,\n",
    "            maxVal,\n",
    "            skewnessVal,\n",
    "            kurtosisVal,\n",
    "            firstFourthSlopeVal,\n",
    "            secondFourthSlopeVal,\n",
    "            thirdFourthSlopeVal,\n",
    "            forthFourthSlopeVal,\n",
    "            forthFourthSlopeVal + thirdFourthSlopeVal - firstFourthSlopeVal - secondFourthSlopeVal,\n",
    "            rangeDiff,\n",
    "            meanDiff,\n",
    "            stdDiff,\n",
    "            minDiff,\n",
    "            maxDiff,\n",
    "            firstFourthSlopeDiff,\n",
    "            secondFourthSlopeDiff,\n",
    "            thirdFourthSlopeDiff,\n",
    "            forthFourthSlopeDiff,\n",
    "            forthFourthSlopeDiff + thirdFourthSlopeDiff - firstFourthSlopeDiff - secondFourthSlopeDiff,\n",
    "        ]\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def statFeatures(dataList):\n",
    "    dataList = np.asarray(dataList).astype(float)\n",
    "    result = []\n",
    "    dataDim = dataList.ndim\n",
    "    if dataDim > 1:\n",
    "        for counter in range(dataList.shape[1]):\n",
    "            if not np.isnan(dataList[:, counter]).all():\n",
    "                meanVal = np.nanmean(dataList[:, counter], axis=0)\n",
    "                stdVal = np.nanstd(dataList[:, counter], axis=0)\n",
    "                minVal = np.nanmin(dataList[:, counter], axis=0)\n",
    "                maxVal = np.nanmax(dataList[:, counter], axis=0)\n",
    "                rangeVal = maxVal - minVal\n",
    "                skewnessVal = skew(dataList[:, counter], nan_policy=\"omit\", axis=0)\n",
    "                kurtosisVal = kurtosis(dataList[:, counter], nan_policy=\"omit\", axis=0)\n",
    "                result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal])\n",
    "            else:\n",
    "                result.extend([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    else:\n",
    "        if not np.isnan(dataList).all():\n",
    "            meanVal = np.nanmean(dataList)\n",
    "            stdVal = np.nanstd(dataList)\n",
    "            minVal = np.nanmin(dataList)\n",
    "            maxVal = np.nanmax(dataList)\n",
    "            rangeVal = maxVal - minVal\n",
    "            skewnessVal = skew(dataList, nan_policy=\"omit\")\n",
    "            kurtosisVal = kurtosis(dataList, nan_policy=\"omit\")\n",
    "            result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal])\n",
    "        else:\n",
    "            result.extend([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    return result\n",
    "\n",
    "\n",
    "def innerWindowExtractor(outterWindowStart, innerWindowNumber, dfParticipantCM, dfParticipantE4):\n",
    "    tempListCM = []\n",
    "    tempListE4 = []\n",
    "    for counterInner in range(0, innerWindowNumber, 1):\n",
    "        innerWindowStart = outterWindowStart + counterInner * INNER_WINDOW_LENGTH\n",
    "        innerWindowEnd = innerWindowStart + INNER_WINDOW_LENGTH\n",
    "        dfTempCM = dfParticipantCM[(dfParticipantCM[\"Time\"] >= innerWindowStart) & (dfParticipantCM[\"Time\"] < innerWindowEnd)]\n",
    "\n",
    "        if len(dfTempCM) < MINIMUM_POINT * 10 * 0.3:\n",
    "            tempListCM.append([\"Nan\", \"Nan\", \"Nan\", \"Nan\", \"Nan\", \"Nan\"])\n",
    "        else:\n",
    "            tempListCM.append(motionCalculator(dfTempCM))\n",
    "\n",
    "        dfTempE4 = dfParticipantE4[(dfParticipantE4[\"Time\"] >= innerWindowStart) & (dfParticipantE4[\"Time\"] < innerWindowEnd)]\n",
    "        tempListE4.append(e4Reporter(dfTempE4))\n",
    "\n",
    "    return tempListCM, tempListE4\n",
    "\n",
    "\n",
    "def parallelCall(windowData, dfParticipantCM, dfParticipantE4, dfParticipantCGM):\n",
    "    tempList = []\n",
    "    outterWindowStart = windowData[0]\n",
    "    outterWindowEnd = windowData[1]\n",
    "    innerWindowNumber = windowData[2]\n",
    "    carbs = windowData[3]\n",
    "    fat = windowData[4]\n",
    "    protein = windowData[5]\n",
    "    mealFlag = windowData[6]\n",
    "    participant = windowData[7]\n",
    "\n",
    "    dfTempCM = dfParticipantCM[(dfParticipantCM[\"Time\"] >= outterWindowStart) & (dfParticipantCM[\"Time\"] < outterWindowEnd)]\n",
    "    dfTempE4 = dfParticipantE4[(dfParticipantE4[\"Time\"] >= outterWindowStart) & (dfParticipantE4[\"Time\"] < outterWindowEnd)]\n",
    "    tempListCM, tempListE4 = innerWindowExtractor(outterWindowStart, innerWindowNumber, dfTempCM, dfTempE4)\n",
    "\n",
    "    # tempListCM = statFeatures(tempListCM)\n",
    "    tempList.append(tempListCM)  # 1\n",
    "\n",
    "    tempListE4 = statFeatures(tempListE4)\n",
    "    tempList.extend(tempListE4)  # 21\n",
    "\n",
    "    dfTempCGM = dfParticipantCGM[(dfParticipantCGM[\"Time\"] >= outterWindowStart) & (dfParticipantCGM[\"Time\"] < outterWindowEnd)]\n",
    "    tempListCGM = dfTempCGM[\"Abbot\"].to_list()\n",
    "    # tempListCGM = statFeatures(tempListCGM)#I changed the stat feature calculator to consider the slope of BG\n",
    "    tempListCGM = CGMStatFeatures(tempListCGM)\n",
    "    tempList.extend(tempListCGM)  # 7\n",
    "\n",
    "    tempList.append(outterWindowStart)  # 1\n",
    "    tempList.append(outterWindowEnd)  # 1\n",
    "    tempList.append(participant)  # 1\n",
    "\n",
    "    tempList.append(carbs)  # 1\n",
    "    tempList.append(fat)  # 1\n",
    "    tempList.append(protein)  # 1\n",
    "\n",
    "    tempList.append(mealFlag)  # mealFlag\n",
    "\n",
    "    assert len(tempList) == 1 + 21 + 22 + 3 + 3 + 1\n",
    "    return tempList\n",
    "\n",
    "\n",
    "def outterWindowExtractorTotal(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant):\n",
    "    print(\"All windows:\")\n",
    "    participantDataList = []\n",
    "    windowDatas = []\n",
    "    experimentStart = dfParticipantCM[\"Time\"].min()\n",
    "    experimentEnd = dfParticipantCM[\"Time\"].max()\n",
    "\n",
    "    startQuerry = experimentStart\n",
    "    endQuerry = startQuerry + OUTTER_WINDOW_LENGTH\n",
    "    while endQuerry <= experimentEnd:\n",
    "        innerWindowNumber = int(OUTTER_WINDOW_LENGTH.total_seconds() / INNER_WINDOW_LENGTH.total_seconds())\n",
    "        dfTempMeal = dfParticipantMeal[(dfParticipantMeal[\"StartTime\"] >= startQuerry) & (dfParticipantMeal[\"StartTime\"] <= endQuerry - timedelta(minutes=15))]\n",
    "\n",
    "        mealFlag = min(len(dfTempMeal), 1)\n",
    "        carbs = dfTempMeal[\"Carbs\"].sum()\n",
    "        fat = dfTempMeal[\"Fat\"].sum()\n",
    "        protein = dfTempMeal[\"Protein\"].sum()\n",
    "\n",
    "        windowDatas.append([startQuerry, endQuerry, innerWindowNumber, carbs, fat, protein, mealFlag, participant])\n",
    "        startQuerry += OUTTER_WINDOW_STEP\n",
    "        endQuerry += OUTTER_WINDOW_STEP\n",
    "    for counterOuter in tqdm(range(len(windowDatas))):\n",
    "        windowData = windowDatas[counterOuter]\n",
    "        participantDataList.append(parallelCall(windowData, dfParticipantCM, dfParticipantE4, dfParticipantCGM))\n",
    "    # participantDataList = Parallel(n_jobs=coreNumber)(delayed(parallelCall)(windowData, dfParticipantCM, dfParticipantE4, dfParticipantCGM) for windowData in tqdm(windowDatas))\n",
    "    return participantDataList\n",
    "\n",
    "\n",
    "def main():\n",
    "    allDataList = []\n",
    "    participants = dfMeal[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    participants.sort()\n",
    "    columnHeaderList = [\"CM\"]\n",
    "    sensors = [\"EDA\", \"HR\", \"Temperature\"]\n",
    "    statFeatureNames = [\"-Mean\", \"-Std\", \"-Min\", \"-Max\", \"-Range\", \"-Skewness\", \"-Kurtosis\"]\n",
    "    for sensor in sensors:\n",
    "        for statFeatureName in statFeatureNames:\n",
    "            columnHeaderList.append(sensor + statFeatureName)\n",
    "    sensors = [\"CGM\"]\n",
    "    statFeatureNames = [\n",
    "        \"-Range\",\n",
    "        \"-Mean\",\n",
    "        \"-STD\",\n",
    "        \"-Min\",\n",
    "        \"-Max\",\n",
    "        \"-Skewness\",\n",
    "        \"-Kurtosis\",\n",
    "        \"-FirstFourthSlope\",\n",
    "        \"-SecondFourthSlope\",\n",
    "        \"-ThirdFourthSlope\",\n",
    "        \"-FourthFourthSlope\",\n",
    "        \"-HalvesSlope\",\n",
    "        \"-RangeDiff\",\n",
    "        \"-MeanDiff\",\n",
    "        \"-STDDiff\",\n",
    "        \"-MinDiff\",\n",
    "        \"-MaxDiff\",\n",
    "        \"-FirstFourthSlopeDiff\",\n",
    "        \"-SecondFourthSlopeDiff\",\n",
    "        \"-ThirdFourthSlopeDiff\",\n",
    "        \"-FourthFourthSlopeDiff\",\n",
    "        \"-HalvesSlopeDiff\",\n",
    "    ]\n",
    "    for sensor in sensors:\n",
    "        for statFeatureName in statFeatureNames:\n",
    "            columnHeaderList.append(sensor + statFeatureName)\n",
    "\n",
    "    columnHeaderList.extend([\"StartTime\", \"FinishTime\", \"Participant\", \"Carb\", \"Fat\", \"Protein\", \"MealLabel\"])\n",
    "    for participant in participants:\n",
    "        print(\"Participant:\", participant)\n",
    "        if participant in exempts:\n",
    "            continue\n",
    "        # if participant!='p8':\n",
    "        #     continue\n",
    "        dfParticipantMeal = dfMeal[dfMeal[\"Participant\"] == participant]\n",
    "        dfParticipantCM = dfCM[dfCM[\"Participant\"] == participant]\n",
    "        dfParticipantE4 = dfE4[dfE4[\"Participant\"] == participant]\n",
    "        dfParticipantCGM = dfCGM[dfCGM[\"Participant\"] == participant]\n",
    "        participantDataList = outterWindowExtractorTotal(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant)\n",
    "\n",
    "        participantDataList = pd.DataFrame(participantDataList, columns=columnHeaderList)\n",
    "        if len(allDataList) == 0:\n",
    "            allDataList = participantDataList\n",
    "        else:\n",
    "            frames = [allDataList, participantDataList]\n",
    "            allDataList = pd.concat(frames)\n",
    "\n",
    "    allDataList.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    allDataList.reset_index(drop=True, inplace=True)\n",
    "    # Dropping rows without CoreMotion\n",
    "    CMData = allDataList[\"CM\"].to_list()\n",
    "    CMData = np.asarray(CMData).astype(float)\n",
    "    nanList = []\n",
    "    for counter in range(CMData.shape[0]):\n",
    "        if np.isnan(CMData[counter, :, 0]).all():\n",
    "            nanList.append(counter)\n",
    "    allDataList.drop(allDataList.index[nanList], inplace=True)\n",
    "\n",
    "    allDataList.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    allDataList.reset_index(drop=True, inplace=True)\n",
    "    allDataList.to_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.pkl\"),))\n",
    "    return allDataList\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.pkl\"))):\n",
    "    os.remove(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.pkl\")))\n",
    "if not os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.pkl\"),)):\n",
    "    dfAllFeatures = main()\n",
    "else:\n",
    "    dfAllFeatures = pd.read_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.pkl\"),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBModel' object has no attribute 'enable_categorical'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 95>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=90'>91</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dfTotal\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=93'>94</a>\u001b[0m dfAllFeatures \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(addResults, (\u001b[39mstr\u001b[39m(OUTTER_WINDOW_LENGTH) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(FASTING_LENGTH) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-All-Features.pkl\u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=94'>95</a>\u001b[0m dfAllFeaturesHoover \u001b[39m=\u001b[39m hooverPredictor(dfAllFeatures)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=95'>96</a>\u001b[0m dfAllFeaturesHoover \u001b[39m=\u001b[39m dfAllFeaturesHoover\u001b[39m.\u001b[39mdropna()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=96'>97</a>\u001b[0m dfAllFeaturesHoover\u001b[39m.\u001b[39mto_excel(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(addResults, (\u001b[39mstr\u001b[39m(OUTTER_WINDOW_LENGTH) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(FASTING_LENGTH) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-All-Features-AfterHoover.xlsx\u001b[39m\u001b[39m\"\u001b[39m)), index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb Cell 12'\u001b[0m in \u001b[0;36mhooverPredictor\u001b[0;34m(dfAllFeatures)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=37'>38</a>\u001b[0m hooverModelAdd \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/grads/s/sorush.omidvar/CGMDataset/Hoover/HooverModel-0.8.sav\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=38'>39</a>\u001b[0m hooverModel \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(hooverModelAdd, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=39'>40</a>\u001b[0m \u001b[39mprint\u001b[39;49m(hooverModel)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=40'>41</a>\u001b[0m hooverModel\u001b[39m.\u001b[39mn_jobs \u001b[39m=\u001b[39m coreNumber\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=41'>42</a>\u001b[0m participants \u001b[39m=\u001b[39m dfAllFeatures[\u001b[39m\"\u001b[39m\u001b[39mParticipant\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto_list()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:279\u001b[0m, in \u001b[0;36mBaseEstimator.__repr__\u001b[0;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=270'>271</a>\u001b[0m \u001b[39m# use ellipsis for sequences with a lot of elements\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=271'>272</a>\u001b[0m pp \u001b[39m=\u001b[39m _EstimatorPrettyPrinter(\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=272'>273</a>\u001b[0m     compact\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=273'>274</a>\u001b[0m     indent\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=274'>275</a>\u001b[0m     indent_at_name\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=275'>276</a>\u001b[0m     n_max_elements_to_show\u001b[39m=\u001b[39mN_MAX_ELEMENTS_TO_SHOW,\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=276'>277</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=278'>279</a>\u001b[0m repr_ \u001b[39m=\u001b[39m pp\u001b[39m.\u001b[39;49mpformat(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=280'>281</a>\u001b[0m \u001b[39m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=281'>282</a>\u001b[0m n_nonblank \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(repr_\u001b[39m.\u001b[39msplit()))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/pprint.py:153\u001b[0m, in \u001b[0;36mPrettyPrinter.pformat\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=150'>151</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpformat\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mobject\u001b[39m):\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=151'>152</a>\u001b[0m     sio \u001b[39m=\u001b[39m _StringIO()\n\u001b[0;32m--> <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=152'>153</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_format(\u001b[39mobject\u001b[39;49m, sio, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, {}, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=153'>154</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m sio\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/pprint.py:170\u001b[0m, in \u001b[0;36mPrettyPrinter._format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=167'>168</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=168'>169</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=169'>170</a>\u001b[0m rep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_repr(\u001b[39mobject\u001b[39;49m, context, level)\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=170'>171</a>\u001b[0m max_width \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_width \u001b[39m-\u001b[39m indent \u001b[39m-\u001b[39m allowance\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=171'>172</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(rep) \u001b[39m>\u001b[39m max_width:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/pprint.py:431\u001b[0m, in \u001b[0;36mPrettyPrinter._repr\u001b[0;34m(self, object, context, level)\u001b[0m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=429'>430</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_repr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mobject\u001b[39m, context, level):\n\u001b[0;32m--> <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=430'>431</a>\u001b[0m     \u001b[39mrepr\u001b[39m, readable, recursive \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\u001b[39mobject\u001b[39;49m, context\u001b[39m.\u001b[39;49mcopy(),\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=431'>432</a>\u001b[0m                                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_depth, level)\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=432'>433</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m readable:\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/pprint.py?line=433'>434</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py:189\u001b[0m, in \u001b[0;36m_EstimatorPrettyPrinter.format\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=187'>188</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mobject\u001b[39m, context, maxlevels, level):\n\u001b[0;32m--> <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=188'>189</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _safe_repr(\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=189'>190</a>\u001b[0m         \u001b[39mobject\u001b[39;49m, context, maxlevels, level, changed_only\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_changed_only\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=190'>191</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py:440\u001b[0m, in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=437'>438</a>\u001b[0m recursive \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m changed_only:\n\u001b[0;32m--> <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=439'>440</a>\u001b[0m     params \u001b[39m=\u001b[39m _changed_params(\u001b[39mobject\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=440'>441</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=441'>442</a>\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py:93\u001b[0m, in \u001b[0;36m_changed_params\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m     <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=88'>89</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_changed_params\u001b[39m(estimator):\n\u001b[1;32m     <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=89'>90</a>\u001b[0m     \u001b[39m\"\"\"Return dict (param_name: value) of parameters that were given to\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=90'>91</a>\u001b[0m \u001b[39m    estimator with non-default values.\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=92'>93</a>\u001b[0m     params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=93'>94</a>\u001b[0m     init_func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(estimator\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdeprecated_original\u001b[39m\u001b[39m\"\u001b[39m, estimator\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m)\n\u001b[1;32m     <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/utils/_pprint.py?line=94'>95</a>\u001b[0m     init_params \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(init_func)\u001b[39m.\u001b[39mparameters\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:505\u001b[0m, in \u001b[0;36mXGBModel.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=502'>503</a>\u001b[0m cp \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(\u001b[39mself\u001b[39m)\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=503'>504</a>\u001b[0m cp\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__bases__\u001b[39m[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=504'>505</a>\u001b[0m params\u001b[39m.\u001b[39mupdate(cp\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(cp, deep))\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=505'>506</a>\u001b[0m \u001b[39m# if kwargs is a dict, update params accordingly\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=506'>507</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkwargs\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:502\u001b[0m, in \u001b[0;36mXGBModel.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=494'>495</a>\u001b[0m \u001b[39m\"\"\"Get parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=495'>496</a>\u001b[0m \u001b[39m# Based on: https://stackoverflow.com/questions/59248211\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=496'>497</a>\u001b[0m \u001b[39m# The basic flow in `get_params` is:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=497'>498</a>\u001b[0m \u001b[39m# 0. Return parameters in subclass first, by using inspect.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=498'>499</a>\u001b[0m \u001b[39m# 1. Return parameters in `XGBModel` (the base class).\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=499'>500</a>\u001b[0m \u001b[39m# 2. Return whatever in `**kwargs`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=500'>501</a>\u001b[0m \u001b[39m# 3. Merge them.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=501'>502</a>\u001b[0m params \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mget_params(deep)\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=502'>503</a>\u001b[0m cp \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(\u001b[39mself\u001b[39m)\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py?line=503'>504</a>\u001b[0m cp\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__bases__\u001b[39m[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:210\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=207'>208</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=208'>209</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_param_names():\n\u001b[0;32m--> <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=209'>210</a>\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, key)\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=210'>211</a>\u001b[0m     \u001b[39mif\u001b[39;00m deep \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(value, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///home/grads/s/sorush.omidvar/anaconda3/lib/python3.9/site-packages/sklearn/base.py?line=211'>212</a>\u001b[0m         deep_items \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mget_params()\u001b[39m.\u001b[39mitems()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBModel' object has no attribute 'enable_categorical'"
     ]
    }
   ],
   "source": [
    "def meanSTDFinder(df):\n",
    "    cmData = []\n",
    "    for counter in range(len(df)):\n",
    "        elements = df[\"CM\"].iloc[counter]\n",
    "        for element in elements:\n",
    "            cmData.append(element)\n",
    "    cmData = np.asarray(cmData).astype(float)\n",
    "    cmDataMean = np.nanmean(cmData, axis=0)\n",
    "    cmDataStd = np.nanstd(cmData, axis=0)\n",
    "    return cmDataMean, cmDataStd\n",
    "\n",
    "\n",
    "def cmNormalizerPredictor(element, cmDataMean, cmDataStd, hooverModel):\n",
    "    element = np.asarray(element).astype(float)\n",
    "    element -= cmDataMean\n",
    "    element /= cmDataStd\n",
    "    element = np.expand_dims(element, axis=0)\n",
    "    # print(element)\n",
    "    hooverPrediction = hooverModel.predict_proba(element)\n",
    "    hooverPrediction = hooverPrediction[0, 1]\n",
    "\n",
    "    return hooverPrediction\n",
    "\n",
    "\n",
    "def maxProbWinodFinder(tempPredictions):  # we are finding the maximum probability for a 5-min period which is located 15-min sooner than the end of the windows 15+5=20 min\n",
    "    assert OUTTER_WINDOW_LENGTH >= timedelta(minutes=20)\n",
    "    tempMax = -1\n",
    "    for innerCounter in range(len(tempPredictions) - 20):\n",
    "        tempArray = np.asarray(tempPredictions[innerCounter : innerCounter + 5])\n",
    "        tempArray = np.mean(tempArray)\n",
    "        if tempArray > tempMax:\n",
    "            tempMax = tempArray\n",
    "    assert tempMax >= 0\n",
    "    return tempMax\n",
    "\n",
    "\n",
    "def hooverPredictor(dfAllFeatures):\n",
    "    hooverModelAdd = \"/home/grads/s/sorush.omidvar/CGMDataset/Hoover/HooverModel-0.8.sav\"\n",
    "    hooverModel = pickle.load(open(hooverModelAdd, \"rb\"))\n",
    "    print(hooverModel)\n",
    "    hooverModel.n_jobs = coreNumber\n",
    "    participants = dfAllFeatures[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    participants.sort()\n",
    "    dfTotal = []\n",
    "    fig = plt.figure(figsize=(10, 15))\n",
    "    subplotCounter = 1\n",
    "    for participant in participants:\n",
    "        dfTemp = dfAllFeatures[dfAllFeatures[\"Participant\"] == participant]\n",
    "        cmDataMean, cmDataStd = meanSTDFinder(dfTemp)\n",
    "        predictions = []\n",
    "        groundTruth = []\n",
    "        for counter in tqdm(range(len(dfTemp))):\n",
    "            elements = dfTemp[\"CM\"].iloc[counter]\n",
    "            tempPredictions = []\n",
    "            for element in elements:\n",
    "                tempPredictions.append(cmNormalizerPredictor(element, cmDataMean, cmDataStd, hooverModel))\n",
    "            # predictions.append(maxProbWinodFinder(tempPredictions))\n",
    "            dfTemp[\"CM\"].iloc[counter] = maxProbWinodFinder(tempPredictions)\n",
    "            # groundTruth.append(dfTemp[\"MealLabel\"].iloc[counter])\n",
    "        if len(dfTotal) != 0:\n",
    "            frames = [dfTotal, dfTemp]\n",
    "            dfTotal = pd.concat(frames)\n",
    "        else:\n",
    "            dfTotal = dfTemp\n",
    "        predictions = dfTemp[\"CM\"].to_list()\n",
    "        groundTruth = dfTemp[\"MealLabel\"].to_list()\n",
    "        print(\"Total:\", len(groundTruth), \"Positive windows:\", np.sum(groundTruth))\n",
    "        fpr, tpr, thresholds = roc_curve(groundTruth, predictions, pos_label=1)\n",
    "        print(roc_auc_score(groundTruth, predictions))\n",
    "        plt.subplot(3, 2, subplotCounter)\n",
    "        if subplotCounter % 2 == 1:\n",
    "            plt.ylabel(\"TPR\")\n",
    "            plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [\"0.0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"])\n",
    "        else:\n",
    "            plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [])\n",
    "        if subplotCounter >= 5:\n",
    "            plt.xlabel(\"FPR\")\n",
    "            plt.xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [\"0.0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"])\n",
    "        else:\n",
    "            plt.xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [])\n",
    "\n",
    "        plt.plot(fpr, tpr, label=participant.capitalize() + \" AUC=\" + str(np.round(roc_auc_score(groundTruth, predictions), 3)))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.plot([0, 1], [0, 1], \"r:\")\n",
    "        subplotCounter += 1\n",
    "    plt.suptitle(\"Outer Window=\" + str(OUTTER_WINDOW_LENGTH.total_seconds() / 60) + \" min\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-ROC.jpg\")), dpi=600)\n",
    "    plt.show()\n",
    "    return dfTotal\n",
    "\n",
    "\n",
    "dfAllFeatures = pd.read_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.pkl\")))\n",
    "dfAllFeaturesHoover = hooverPredictor(dfAllFeatures)\n",
    "dfAllFeaturesHoover = dfAllFeaturesHoover.dropna()\n",
    "dfAllFeaturesHoover.to_excel(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features-AfterHoover.xlsx\")), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgClassifier(xTrain, xTest, yTrain, yTest):\n",
    "    clf = xgb.XGBClassifier(scale_pos_weight=len(yTrain) / np.sum(yTrain), n_jobs=coreNumber, n_estimators=250, max_depth=3, objective=\"binary:logistic\", eval_metric=\"error\",)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "\n",
    "    predictionsTest = clf.predict_proba(xTest)\n",
    "    predictionsTest = predictionsTest[:, 1]\n",
    "    rocAuc = roc_auc_score(yTest, predictionsTest)\n",
    "\n",
    "    # fpr, tpr, thresholds = roc_curve(yTest, predictionsTest, pos_label=1)\n",
    "    # plt.xlabel(\"FPR\")\n",
    "    # plt.ylabel(\"TPR\")\n",
    "    # plt.title(\"ROC-AUC:\" + str(np.round(roc_auc_score(yTest, predictionsTest), 3)))\n",
    "    # plt.scatter(fpr, tpr)\n",
    "    # plt.plot([0, 0], [1, 1], color=\"red\")\n",
    "    # plt.show()\n",
    "\n",
    "    predictionsTest = clf.predict(xTest)\n",
    "    accuracy = sklearn.metrics.accuracy_score(yTest, predictionsTest)\n",
    "    recall = sklearn.metrics.recall_score(yTest, predictionsTest)\n",
    "    precision = sklearn.metrics.precision_score(yTest, predictionsTest)\n",
    "    f1Score = sklearn.metrics.f1_score(yTest, predictionsTest, average=\"weighted\")\n",
    "\n",
    "    return [rocAuc, accuracy, recall, precision, f1Score, np.sum(yTest), len(yTest) - np.sum(yTest)]\n",
    "\n",
    "\n",
    "def testTrainSplit(dfParticipant, participant, combination, normalFlag):\n",
    "    dfParticipant.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "\n",
    "    yDataBinary = dfParticipant[\"MealLabel\"].to_list()\n",
    "    yDataBinary = np.asarray(yDataBinary).astype(int)\n",
    "\n",
    "    dfParticipant.drop(columns=[\"StartTime\", \"FinishTime\", \"MealLabel\", \"Participant\", \"Carb\", \"Fat\", \"Protein\"], inplace=True)\n",
    "    xDataBinary = dfParticipant.values\n",
    "    xDataBinary = np.asarray(xDataBinary).astype(float)\n",
    "\n",
    "    classifierReport = []\n",
    "    if normalFlag:\n",
    "        xDataBinary -= np.mean(xDataBinary, axis=0)\n",
    "        xDataBinary /= np.std(xDataBinary, axis=0)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "    setNumber = 0\n",
    "    for trainIndex, testIndex in skf.split(xDataBinary, yDataBinary):\n",
    "        xTrain, xTest = xDataBinary[trainIndex, :], xDataBinary[testIndex, :]\n",
    "        yTrain, yTest = yDataBinary[trainIndex], yDataBinary[testIndex]\n",
    "        tempListReport = xgClassifier(xTrain, xTest, yTrain, yTest)\n",
    "        tempListReport.extend([participant, combination, setNumber])\n",
    "        classifierReport.append(tempListReport)\n",
    "        setNumber += 1\n",
    "\n",
    "    return classifierReport\n",
    "\n",
    "\n",
    "def predictionMain(dfCombination, randomSeed, normalFlag, combination):\n",
    "    participants = list(set(dfCombination[\"Participant\"].to_list()))\n",
    "    classifierReports = []\n",
    "    # for participantCounter in tqdm(range(len(participants) + 1)):\n",
    "    for participantCounter in range(len(participants)):\n",
    "        if participantCounter == len(participants):  # General Model (one model for all participants)\n",
    "            dfParticipant = dfCombination\n",
    "            participant = \"All\"\n",
    "        else:  # Personal Model (each participant have a his/her own model)\n",
    "            participant = participants[participantCounter]\n",
    "            dfParticipant = dfCombination[dfCombination[\"Participant\"] == participant]\n",
    "        dfParticipant.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "        print(\"*************************\", \"Participant:\", participant)\n",
    "        classifierReports.extend(testTrainSplit(dfParticipant, participant, combination, normalFlag))\n",
    "    return classifierReports\n",
    "\n",
    "\n",
    "def foldSummarizerBinary(df):\n",
    "    combinations = list(set(df[\"Combination\"].to_list()))\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    dfSummarizeds = []\n",
    "    headers = [\"Participant\", \"Combination\", \"ROC-AUC\", \"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"TestPositive\", \"TestNegative\", \"SetNumber\"]\n",
    "    for participant in participants:\n",
    "        for combination in combinations:\n",
    "            dfSummarized = [participant, combination]\n",
    "            dfTemp = df[(df[\"Participant\"] == participant) & (df[\"Combination\"] == combination)]\n",
    "            assert len(dfTemp) == FOLD_NUMBER\n",
    "            dfSummarized.extend(dfTemp.mean())\n",
    "            dfSummarizeds.append(dfSummarized)\n",
    "    dfSummarizeds = pd.DataFrame(dfSummarizeds, columns=headers)\n",
    "    dfSummarizeds.drop(columns=[\"SetNumber\"], inplace=True)\n",
    "    dfSummarizeds.sort_values([\"Participant\", \"Combination\"], ascending=(True, True), inplace=True)\n",
    "    dfSummarizeds.to_excel(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier-Summary.xlsx\"),), index=False)\n",
    "\n",
    "    print(\"Outter:\", str(OUTTER_WINDOW_LENGTH), \"Fasting:\", str(FASTING_LENGTH))\n",
    "    print((\"---------------------------------------------------------\"))\n",
    "    print(dfSummarizeds)\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\"))):\n",
    "    os.remove(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\")))\n",
    "if not os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\"))):\n",
    "    dfAllFeaturesHoover = pd.read_excel(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features-AfterHoover.xlsx\")))\n",
    "    print(len(dfAllFeaturesHoover))\n",
    "    dfAllFeaturesHoover = dfAllFeaturesHoover.dropna()\n",
    "    print(len(dfAllFeaturesHoover))\n",
    "    combinations = [[\"CGM\"], [\"CM\"], [\"CGM\", \"CM\"], [\"CGM\", \"CM\", \"Temperature\"], [\"CGM\", \"CM\", \"Temperature\", \"HR\", \"EDA\"]]\n",
    "    columns = dfAllFeaturesHoover.columns\n",
    "    headersClassifier = [\"ROC-AUC\", \"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"TestPositive\", \"TestNegative\", \"Participant\", \"Combination\", \"SetNumber\"]\n",
    "    dfClassifier = []\n",
    "    for combination in combinations:\n",
    "        columnList = [\"StartTime\", \"FinishTime\", \"Participant\", \"Carb\", \"Fat\", \"Protein\", \"MealLabel\"]\n",
    "        for topic in combination:\n",
    "            for column in columns:\n",
    "                if topic in column:\n",
    "                    columnList.append(column)\n",
    "\n",
    "        dfCombination = dfAllFeaturesHoover[dfAllFeaturesHoover.columns.intersection(columnList)]\n",
    "        randomSeed = 60\n",
    "        print(\"----------------------\")\n",
    "        print(\"Combination:\", \"+\".join(combination))\n",
    "        NORMALIZED_FLAG = True\n",
    "        classifierReport = predictionMain(dfCombination, randomSeed, NORMALIZED_FLAG, \"+\".join(combination))\n",
    "        dfTempClassifier = pd.DataFrame(classifierReport, columns=headersClassifier)\n",
    "        if len(dfClassifier) > 0:\n",
    "            frames = [dfTempClassifier, dfClassifier]\n",
    "            dfClassifier = pd.concat(frames)\n",
    "        else:\n",
    "            dfClassifier = dfTempClassifier\n",
    "\n",
    "    dfClassifier.reset_index(drop=True, inplace=True)\n",
    "    dfClassifier.to_excel(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\")), index=False)\n",
    "\n",
    "else:\n",
    "    dfClassifier = pd.read_excel(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\")))\n",
    "foldSummarizerBinary(dfClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(addResults))\n",
    "\n",
    "\n",
    "def summaryPlotter(participant, metricType):\n",
    "    metricCMList = []\n",
    "    metricCGMList = []\n",
    "    metricCGMCMList = []\n",
    "    metricCGMCMTempList = []\n",
    "    metricCGMCMTempHREDAList = []\n",
    "    windowLenList = []\n",
    "    for root, dirs, files in os.walk(os.path.join(addResults)):\n",
    "        for file in sorted(files):\n",
    "            if \".xlsx\" in file.lower() and \"summary\" in file.lower() and \"classifier\" in file.lower():\n",
    "                windowLen = file[: file.find(\"-\")]\n",
    "\n",
    "                dfTemp = pd.read_excel(file)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CM\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCMList.append(metricVal)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCGMList.append(metricVal)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM+CM\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCGMCMList.append(metricVal)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM+CM+Temperature\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCGMCMTempList.append(metricVal)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM+CM+Temperature+HR+EDA\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCGMCMTempHREDAList.append(metricVal)\n",
    "                windowLenList.append(windowLen)\n",
    "\n",
    "    for counter in range(len(windowLenList)):\n",
    "        tempVal = datetime.strptime(windowLenList[counter], \"%H:%M:%S\")\n",
    "        tempVal = tempVal.time().hour * 60 + tempVal.time().minute\n",
    "        windowLenList[counter] = tempVal\n",
    "    return metricCMList, metricCGMList, metricCGMCMList, metricCGMCMTempList, metricCGMCMTempHREDAList, windowLenList\n",
    "\n",
    "\n",
    "participants = [\"p1\", \"p3\", \"p5\", \"p6\", \"p7\", \"p8\"]\n",
    "subplotCounter = 1\n",
    "fig = plt.figure(figsize=(10, 15))\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"]\n",
    "for participant in participants:\n",
    "    metricName = \"Recall\"\n",
    "    metricCMList, metricCGMList, metricCGMCMList, metricCGMCMTempList, metricCGMCMTempHREDAList, windowLenList = summaryPlotter(participant, metricName)\n",
    "    slopeCGM, interceptCGM, r_valueCGM, p_valueCGM, std_errCGM = linregress(windowLenList, metricCGMList)\n",
    "    slopeCM, interceptCM, r_valueCM, p_valueCM, std_errCM = linregress(windowLenList, metricCMList)\n",
    "    slopeCGMCM, interceptCGMCM, r_valueCGMCM, p_valueCGMCM, std_errCGMCM = linregress(windowLenList, metricCGMCMList)\n",
    "\n",
    "    print(participant, (30 * slopeCGM + interceptCGM - interceptCGMCM) / slopeCGMCM)\n",
    "    # print(participant,slopeCGM,slopeCGMCM)\n",
    "    # print(participant,interceptCGM,interceptCGMCM)\n",
    "\n",
    "    plt.subplot(3, 2, subplotCounter)\n",
    "    sns.regplot(x=windowLenList, y=metricCMList, marker=\"+\", color=colors[0], label=\"CM\")\n",
    "    sns.regplot(x=windowLenList, y=metricCGMList, marker=\"s\", color=colors[1], label=\"CGM\")\n",
    "    sns.regplot(x=windowLenList, y=metricCGMCMList, marker=\"d\", color=colors[2], label=\"CGM+CM\")\n",
    "    # plt.plot(windowLenList, metricCGMCMTempList, \"--o\", color=colors[3], label=\"CGM+CM+Temperature\")\n",
    "    # plt.plot(windowLenList, metricCGMCMTempHREDAList, \":s\", color=colors[4], label=\"CGM+CM+Temperature+HR+EDA\")\n",
    "    plt.text(20, 0.9, participant.capitalize())\n",
    "    plt.ylim([0, 1])\n",
    "    if subplotCounter == 3:\n",
    "        plt.ylabel(metricName, labelpad=30)\n",
    "    if subplotCounter == 5:\n",
    "        # plt.xlabel(\"Window Length [min]\",labelpad=30)\n",
    "        frame1 = plt.gca()\n",
    "        frame1.axes.set_xlabel(\"Window Length [min]\", labelpad=30, x=1)\n",
    "    if subplotCounter == 2:\n",
    "        plt.legend(loc=\"upper right\")\n",
    "    if subplotCounter % 2 == 1:\n",
    "        plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [\"0.0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"])\n",
    "    else:\n",
    "        plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [])\n",
    "    if subplotCounter >= 5:\n",
    "        plt.xticks([15, 30, 45, 60, 75, 90], [\"15\", \"30\", \"45\", \"60\", \"75\", \"90\"])\n",
    "    else:\n",
    "        plt.xticks([15, 30, 45, 60, 75, 90], [])\n",
    "\n",
    "    subplotCounter += 1\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(addResults, \"Eating-ROC-AUC Summary-\" + metricName + \"-\" + str(FASTING_LENGTH) + \".jpg\"), dpi=600)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65e249be015da37cfe4cfdd1da028fe4cb475c26be679b9e3e34696278a17c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
