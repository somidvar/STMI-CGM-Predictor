{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from dateutil.tz import tzutc\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from scipy.stats import pearsonr, mode, skew, kurtosis\n",
    "from scipy.signal import savgol_filter\n",
    "import xgboost as xgb\n",
    "from joblib import Parallel, delayed\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, plot_confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, ShuffleSplit\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "OUTTER_WINDOW_LENGTH = timedelta(minutes=30)\n",
    "INNER_WINDOW_LENGTH = timedelta(seconds=60)\n",
    "COMPLEX_MEAL_LENGTH = timedelta(minutes=180)\n",
    "FASTING_LENGTH = timedelta(minutes=30)\n",
    "MINIMUM_POINT = INNER_WINDOW_LENGTH.total_seconds()\n",
    "\n",
    "START_OF_TRIAL = datetime.strptime(\"11 06 2021-02:00:00\", \"%m %d %Y-%H:%M:%S\")  # to handle the daylight saving issue in apple watches\n",
    "END_OF_TRIAL = datetime.strptime(\"11 15 2021-00:00:00\", \"%m %d %Y-%H:%M:%S\")\n",
    "coreNumber = 1\n",
    "\n",
    "addDataPrefix = \"/Users/sorush/My Drive/Documents/Educational/TAMU/Research/Trial/Data/11-5-21-11-15-21\"\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"/home/grads/s/sorush.omidvar/CGMDataset/Trial/Data/11-5-21-11-15-21\"\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"C:\\\\GDrive\\\\Documents\\\\Educational\\\\TAMU\\\\Research\\\\Trial\\\\Data\\\\11-5-21-11-15-21\"\n",
    "\n",
    "addUserInput = os.path.join(addDataPrefix, \"User inputted\")\n",
    "addHKCM = os.path.join(addDataPrefix, \"hk+cm\")\n",
    "addCGM = os.path.join(addDataPrefix, \"CGM\")\n",
    "addE4 = os.path.join(addDataPrefix, \"E4\")\n",
    "\n",
    "exempts = [\"p2\"]\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({\"figure.facecolor\": \"white\"})\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # no GPU\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(addDataPrefix, \"Results\", \"All_meals.pkl\")):\n",
    "    os.remove(os.path.join(addDataPrefix, \"Results\", \"All_meals.pkl\"))\n",
    "os.chdir(addUserInput)\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"Results\", \"All_meals.pkl\")):\n",
    "    dfMeal = []\n",
    "    for root, dirs, files in os.walk(addUserInput):\n",
    "        for file in files:\n",
    "            if \".xlsx\" in file.lower():\n",
    "                if \"meals-modified\" in file.lower():\n",
    "                    participantName = file[: file.find(\"Meals\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_excel(file)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    dfTemp.drop(columns=[\"startTime\", \"FinishTime\", \"Duration\"], inplace=True)\n",
    "                    dfTemp.rename(columns={\"startTimeModified\": \"StartTime\"}, inplace=True)\n",
    "                    dfTemp.rename(columns={\"FinishTimeModified\": \"FinishTime\"}, inplace=True)\n",
    "                    dfTemp[\"StartTime\"] = pd.to_datetime(dfTemp[\"StartTime\"])\n",
    "                    dfTemp[\"FinishTime\"] = pd.to_datetime(dfTemp[\"FinishTime\"])\n",
    "                    dfTemp = dfTemp[dfTemp[\"StartTime\"].notna()]\n",
    "                    # dfTemp['StartTime']-=pd.DateOffset(hours=5)#fixing the time zone issue\n",
    "                    # dfTemp['FinishTime']-=pd.DateOffset(hours=5)#fixing the time zone issue\n",
    "                    dfTemp.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "                    for counter in range(1, len(dfTemp)):\n",
    "                        if dfTemp[\"StartTime\"].iloc[counter] == dfTemp[\"StartTime\"].iloc[counter - 1]:\n",
    "                            dfTemp[\"Carbs\"].iloc[counter] += dfTemp[\"Carbs\"].iloc[counter - 1]\n",
    "                            dfTemp[\"Fat\"].iloc[counter] += dfTemp[\"Fat\"].iloc[counter - 1]\n",
    "                            dfTemp[\"Protein\"].iloc[counter] += dfTemp[\"Protein\"].iloc[counter - 1]\n",
    "                            dfTemp[\"StartTime\"].iloc[counter] = \"\"\n",
    "                    dfTemp = dfTemp[dfTemp[\"StartTime\"].notna()]\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "                    for counter in range(1, len(dfTemp)):\n",
    "                        if dfTemp[\"StartTime\"].iloc[counter] - dfTemp[\"StartTime\"].iloc[counter - 1] <= timedelta(hours=1):\n",
    "                            print(\"The meals are not compressed for participant:\", participantName, dfTemp[\"StartTime\"].iloc[counter], dfTemp[\"StartTime\"].iloc[counter - 1])\n",
    "                            print(dfTemp)\n",
    "                            os._exit()\n",
    "                    if len(dfMeal) != 0:\n",
    "                        frames = [dfTemp, dfMeal]\n",
    "                        dfMeal = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfMeal = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfMeal = dfMeal[dfMeal[\"StartTime\"] >= START_OF_TRIAL]\n",
    "    dfMeal = dfMeal[dfMeal[\"FinishTime\"] < END_OF_TRIAL]\n",
    "    dfMeal.reset_index(drop=True, inplace=True)\n",
    "    print(\"Meal database is limited to the trial period\")\n",
    "    dfMeal.to_pickle(os.path.join(addDataPrefix, \"Results\", \"All_meals.pkl\"))\n",
    "else:\n",
    "    dfMeal = pd.read_pickle(os.path.join(addDataPrefix, \"Results\", \"All_meals.pkl\"))\n",
    "\n",
    "\n",
    "def pdInterpolation(dfTemp):\n",
    "    index = dfTemp[\"Time\"]\n",
    "    seriesParticipant = pd.Series(dfTemp[\"Abbot\"].to_list(), index=index)\n",
    "    seriesParticipant = seriesParticipant.resample(\"1T\").asfreq()\n",
    "    seriesParticipant.interpolate(method=\"polynomial\", order=3, inplace=True)\n",
    "    tempTime = seriesParticipant.index\n",
    "    tempVal = seriesParticipant.values\n",
    "    dfTemp = pd.DataFrame(zip(tempTime, tempVal), columns=[\"Time\", \"Abbot\"])\n",
    "    return dfTemp\n",
    "\n",
    "\n",
    "def cmSmoother(df):\n",
    "    columnLabels = df.columns\n",
    "    for columnLabel in columnLabels:\n",
    "        if columnLabel == \"Time\":\n",
    "            continue\n",
    "        tempSerie = df[columnLabel]\n",
    "        tempSerie = tempSerie.ewm(span=10).mean()  # Considering the frequency of 10 Hz\n",
    "        df[columnLabel] = tempSerie\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addDataPrefix,\"Results\",'All_cgm.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,\"Results\",'All_cgm.pkl'))\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"Results\", \"All_cgm.pkl\")):\n",
    "    os.chdir(addCGM)\n",
    "    dfCGM = []\n",
    "    for root, dirs, files in os.walk(addCGM):\n",
    "        for file in files:\n",
    "            if \".txt\" in file.lower():\n",
    "                if \"_fl\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_fl\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file, sep=\"\\t\", skiprows=1)\n",
    "                    if len(dfTemp.columns) != 4:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    dfTemp.columns.values[0] = \"ID\"\n",
    "                    dfTemp.columns.values[1] = \"Time\"\n",
    "                    dfTemp.columns.values[2] = \"Record\"\n",
    "                    dfTemp.columns.values[3] = \"Abbot\"\n",
    "                    dfTemp.drop(columns=[\"ID\", \"Record\"], inplace=True)\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"])\n",
    "                    dfTemp[\"Abbot\"] = pd.to_numeric(dfTemp[\"Abbot\"])\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                    dfTemp = pdInterpolation(dfTemp)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    if len(dfTemp.columns) != 3:\n",
    "                        print(\"MAYDAY. Error in processing csv\")\n",
    "                        break\n",
    "                    if len(dfCGM) != 0:\n",
    "                        frames = [dfTemp, dfCGM]\n",
    "                        dfCGM = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfCGM = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfCGM = dfCGM[dfCGM[\"Time\"] >= START_OF_TRIAL]\n",
    "    dfCGM = dfCGM[dfCGM[\"Time\"] < END_OF_TRIAL]\n",
    "    print(\"CGM database is limited to the trial period\")\n",
    "    dfCGM.to_pickle(os.path.join(addDataPrefix, \"Results\", \"All_cgm.pkl\"))\n",
    "else:\n",
    "    dfCGM = pd.read_pickle(os.path.join(addDataPrefix, \"Results\", \"All_cgm.pkl\"))\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addDataPrefix,\"Results\",'All_cm.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix,\"Results\",'All_cm.pkl'))\n",
    "os.chdir(addHKCM)\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"Results\", \"All_cm.pkl\")):\n",
    "    df = []\n",
    "    for root, dirs, files in os.walk(addHKCM):\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                if \"cm\" in file.lower() and \"modified\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_cm\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    print(\"File is read\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"])\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "\n",
    "                    dfTemp = cmSmoother(dfTemp)\n",
    "                    dfTemp[\"Yaw\"] *= 180 / 3.1415\n",
    "                    dfTemp[\"Pitch\"] *= 180 / 3.1415\n",
    "                    dfTemp[\"Roll\"] *= 180 / 3.1415\n",
    "\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Ax|+|Ay|+|Az|\", dfTemp[\"Ax\"].abs() + dfTemp[\"Ay\"].abs() + dfTemp[\"Az\"].abs() + 0.001)  # this is to avoid 0 later on for feature calculation\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Yaw|+|Roll|+|Pitch|\", dfTemp[\"Yaw\"].abs() + dfTemp[\"Roll\"].abs() + dfTemp[\"Pitch\"].abs())\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\", dfTemp[\"Rx\"].abs() + dfTemp[\"Ry\"].abs() + dfTemp[\"Rz\"].abs())\n",
    "                    dfTemp[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"] = dfTemp[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"]\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"RotationalToLinear\", dfTemp[\"|Yaw|+|Roll|+|Pitch|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"])\n",
    "                    print(\"modified\")\n",
    "\n",
    "                    if len(dfTemp.columns) != 15:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        print(dfTemp.columns)\n",
    "                        break\n",
    "                    if len(df) != 0:\n",
    "                        frames = [dfTemp, df]\n",
    "                        df = pd.concat(frames)\n",
    "                    else:\n",
    "                        df = dfTemp\n",
    "    dfCM = df\n",
    "    print(\"Processing is done\")\n",
    "    dfCM = dfCM[dfCM[\"Time\"] >= START_OF_TRIAL]\n",
    "    dfCM = dfCM[dfCM[\"Time\"] < END_OF_TRIAL]\n",
    "    print(\"CM database is limited to the trial period\")\n",
    "    dfCM.to_pickle(os.path.join(addDataPrefix, \"Results\", \"All_cm.pkl\"))\n",
    "else:\n",
    "    dfCM = pd.read_pickle(os.path.join(addDataPrefix, \"Results\", \"All_cm.pkl\"))\n",
    "\n",
    "# if os.path.exists(os.path.join(addDataPrefix, \"Results\",'All_E4.pkl')):\n",
    "#     os.remove(os.path.join(addDataPrefix, \"Results\",'All_E4.pkl'))\n",
    "os.chdir(addE4)\n",
    "# fields=['ACC','BVP','EDA','HR','IBI','TEMP']\n",
    "fields = [\"BVP\", \"EDA\", \"HR\", \"TEMP\"]\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"Results\", \"All_E4.pkl\")):\n",
    "    dfE4 = []\n",
    "    for root, dirs, files in os.walk(addE4):\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                participantName = root[root.find(\"E4\") + 3 :]\n",
    "                participantName = participantName[:2]\n",
    "                field = file[: file.find(\".csv\")]\n",
    "                if field not in fields:\n",
    "                    print(\"File name does not comply with analyzed fields\", file)\n",
    "                    continue\n",
    "                print(participantName, field)\n",
    "                if participantName in exempts:\n",
    "                    print(\"Exemption...\", file)\n",
    "                    continue\n",
    "                print(\"Reading ...\", file)\n",
    "                os.chdir(root)\n",
    "                dfTemp = pd.read_csv(file, header=None)\n",
    "                # if field=='ACC':\n",
    "                #     assert len(dfTemp.columns)==3\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     timeStep=1/dfTemp.iloc[1,0]\n",
    "                #     dfTemp.drop([0,1],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Data1',1:'Data2',2:'Data3'}, inplace=True)#x,y,z for data1,data2,data3\n",
    "                #     timeTemp=[]\n",
    "                #     for counter in range(len(dfTemp)):\n",
    "                #         timeTemp.append(timeBase+counter*timeStep)\n",
    "                #     dfTemp.insert(0,'Time',timeTemp)\n",
    "                #     dfTemp.insert(0,'Field',\"Acceleration\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                if field == \"BVP\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"BVP\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                elif field == \"HR\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"HR\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                elif field == \"EDA\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"EDA\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                # elif field=='IBI':\n",
    "                #     assert len(dfTemp.columns)==2\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     dfTemp.drop([0],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Time',1:'Data1'}, inplace=True)\n",
    "                #     dfTemp[\"Data2\"]=\"\"\n",
    "                #     dfTemp[\"Data3\"]=\"\"\n",
    "                #     timeTemp=[]\n",
    "                #     dfTemp['Time']+=timeBase\n",
    "                #     dfTemp.insert(0,'Field',\"IBI\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                elif field == \"TEMP\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"Temperature\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                dfTemp.insert(0, \"Participant\", participantName)\n",
    "\n",
    "                dfTemp[\"Time\"] -= pd.DateOffset(hours=6)  # Empatica records in GMT and also during the trial we had daylight saving\n",
    "                dfTemp.sort_values([\"Participant\", \"Field\", \"Time\"], ascending=(True, True, True), inplace=True)\n",
    "                if len(dfTemp.columns) != 6:\n",
    "                    print(\"MAYDAY. Error in reading csv\")\n",
    "                    break\n",
    "                if len(dfE4) != 0:\n",
    "                    frames = [dfTemp, dfE4]\n",
    "                    dfE4 = pd.concat(frames)\n",
    "                else:\n",
    "                    dfE4 = dfTemp\n",
    "\n",
    "    print(\"reading is done\")\n",
    "    dfE4 = dfE4[dfE4[\"Time\"] >= START_OF_TRIAL]\n",
    "    dfE4 = dfE4[dfE4[\"Time\"] < END_OF_TRIAL]\n",
    "    print(\"E4 database is limited to the trial period\")\n",
    "    dfE4.to_pickle(os.path.join(addDataPrefix, \"Results\", \"All_E4.pkl\"))\n",
    "else:\n",
    "    dfE4 = pd.read_pickle(os.path.join(addDataPrefix, \"Results\", \"All_E4.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e4Reporter(df):\n",
    "    topics = [\"BVP\", \"EDA\", \"HR\", \"Temperature\"]\n",
    "    report = []\n",
    "    for topic in topics:\n",
    "        dfTemp = df[df[\"Field\"] == topic]\n",
    "        if topic == \"BVP\":\n",
    "            MIN_POINT = MINIMUM_POINT * 64 * 0.3\n",
    "        elif topic == \"EDA\":\n",
    "            MIN_POINT = MINIMUM_POINT * 4 * 0.3\n",
    "        elif topic == \"HR\":\n",
    "            MIN_POINT = MINIMUM_POINT / 10 * 0.3\n",
    "        elif topic == \"Temperature\":\n",
    "            MIN_POINT = MINIMUM_POINT * 4 * 0.3\n",
    "        else:\n",
    "            print(\"MAYDAY at sensor reader\")\n",
    "            os._exit()\n",
    "        if len(dfTemp) < MIN_POINT:\n",
    "            report.append(\"Nan\")\n",
    "        else:\n",
    "            val = dfTemp[\"Data1\"].mean()\n",
    "            report.append(val)\n",
    "    return report\n",
    "\n",
    "\n",
    "def motionCalculator(df):\n",
    "    f1 = df[\"RotationalToLinear\"]\n",
    "    f2 = df[\"|Ax|+|Ay|+|Az|\"]\n",
    "    return [f1.mean(), f1.std(), f1.max() - f1.min(), f2.mean(), f2.std(), f2.max() - f2.min()]\n",
    "\n",
    "\n",
    "def statFeatures(dataList):\n",
    "    dataList = np.asarray(dataList).astype(float)\n",
    "    result = []\n",
    "    dataDim = dataList.ndim\n",
    "    if dataDim > 1:\n",
    "        for counter in range(dataList.shape[1]):\n",
    "            if not np.isnan(dataList[:, counter]).all():\n",
    "                meanVal = np.nanmean(dataList[:, counter], axis=0)\n",
    "                stdVal = np.nanstd(dataList[:, counter], axis=0)\n",
    "                minVal = np.nanmin(dataList[:, counter], axis=0)\n",
    "                maxVal = np.nanmax(dataList[:, counter], axis=0)\n",
    "                rangeVal = maxVal - minVal\n",
    "                skewnessVal = skew(dataList[:, counter], nan_policy=\"omit\", axis=0)\n",
    "                kurtosisVal = kurtosis(dataList[:, counter], nan_policy=\"omit\", axis=0)\n",
    "                result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal])\n",
    "            else:\n",
    "                result.extend([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    else:\n",
    "        if not np.isnan(dataList).all():\n",
    "            meanVal = np.nanmean(dataList)\n",
    "            stdVal = np.nanstd(dataList)\n",
    "            minVal = np.nanmin(dataList)\n",
    "            maxVal = np.nanmax(dataList)\n",
    "            rangeVal = maxVal - minVal\n",
    "            skewnessVal = skew(dataList, nan_policy=\"omit\")\n",
    "            kurtosisVal = kurtosis(dataList, nan_policy=\"omit\")\n",
    "            result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal])\n",
    "        else:\n",
    "            result.extend([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    return result\n",
    "\n",
    "\n",
    "def innerWindowExtractor(outterWindowStart, innerWindowNumber, dfParticipantCM, dfParticipantE4):\n",
    "    tempListCM = []\n",
    "    tempListE4 = []\n",
    "    for counterInner in range(0, innerWindowNumber, 1):\n",
    "        innerWindowStart = outterWindowStart + counterInner * INNER_WINDOW_LENGTH\n",
    "        innerWindowEnd = innerWindowStart + INNER_WINDOW_LENGTH\n",
    "        dfTempCM = dfParticipantCM[(dfParticipantCM[\"Time\"] >= innerWindowStart) & (dfParticipantCM[\"Time\"] < innerWindowEnd)]\n",
    "\n",
    "        if len(dfTempCM) < MINIMUM_POINT * 10 * 0.3:\n",
    "            tempListCM.append([\"Nan\", \"Nan\", \"Nan\", \"Nan\", \"Nan\", \"Nan\"])\n",
    "        else:\n",
    "            tempListCM.append(motionCalculator(dfTempCM))\n",
    "\n",
    "        tempListE4.append([\"Nan\", \"Nan\", \"Nan\", \"Nan\", \"Nan\", \"Nan\"])\n",
    "        # dfTempE4 = dfParticipantE4[(dfParticipantE4[\"Time\"] >= innerWindowStart) & (dfParticipantE4[\"Time\"] < innerWindowEnd)]\n",
    "        # if len(dfTempE4) < MINIMUM_POINT * 32 * 0.3:\n",
    "        #     tempListE4.append([\"Nan\", \"Nan\", \"Nan\", \"Nan\",\"Nan\",\"Nan\"])\n",
    "        # else:\n",
    "        #     tempListE4.append(e4Reporter(dfTempE4))\n",
    "\n",
    "    return tempListCM, tempListE4\n",
    "\n",
    "\n",
    "def parallelCall(windowData, dfParticipantCM, dfParticipantE4, dfParticipantCGM):\n",
    "    tempList = []\n",
    "    outterWindowStart = windowData[0]\n",
    "    outterWindowEnd = windowData[1]\n",
    "    innerWindowNumber = windowData[2]\n",
    "    carbs = windowData[3]\n",
    "    fat = windowData[4]\n",
    "    protein = windowData[5]\n",
    "    mealFlag = windowData[6]\n",
    "    participant = windowData[7]\n",
    "\n",
    "    dfTempCM = dfParticipantCM[(dfParticipantCM[\"Time\"] >= outterWindowStart) & (dfParticipantCM[\"Time\"] < outterWindowEnd)]\n",
    "    dfTempE4 = dfParticipantE4[(dfParticipantE4[\"Time\"] >= outterWindowStart) & (dfParticipantE4[\"Time\"] < outterWindowEnd)]\n",
    "    tempListCM, tempListE4 = innerWindowExtractor(outterWindowStart, innerWindowNumber, dfTempCM, dfTempE4)\n",
    "\n",
    "    # tempListCM = statFeatures(tempListCM)\n",
    "    tempList.append(tempListCM)  # 1\n",
    "\n",
    "    # tempListE4 = statFeatures(tempListE4)\n",
    "    tempList.append(tempListE4)  # 1\n",
    "\n",
    "    dfTempCGM = dfParticipantCGM[(dfParticipantCGM[\"Time\"] >= outterWindowStart) & (dfParticipantCGM[\"Time\"] < outterWindowEnd)]\n",
    "    tempListCGM = dfTempCGM[\"Abbot\"].to_list()\n",
    "    tempListCGM = statFeatures(tempListCGM)\n",
    "    tempList.append(tempListCGM)  # 1\n",
    "\n",
    "    tempList.append(outterWindowStart)  # 1\n",
    "    tempList.append(outterWindowEnd)  # 1\n",
    "    tempList.append(participant)  # 1\n",
    "\n",
    "    tempList.append(carbs)  # 1\n",
    "    tempList.append(fat)  # 1\n",
    "    tempList.append(protein)  # 1\n",
    "\n",
    "    tempList.append(mealFlag)  # mealFlag\n",
    "\n",
    "    assert len(tempList) == 1 + 1 + 1 + 3 + 3 + 1\n",
    "\n",
    "    return tempList\n",
    "\n",
    "\n",
    "def outterPosWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant):\n",
    "    print(\"Positive windows:\")\n",
    "    windowDatas = []\n",
    "    participantDataList = []\n",
    "    for counterOuter in range(len(dfParticipantMeal)):\n",
    "        outterWindowStart = dfParticipantMeal[\"StartTime\"].iloc[counterOuter]\n",
    "        outterWindowEnd = outterWindowStart + OUTTER_WINDOW_LENGTH\n",
    "        innerWindowNumber = int(OUTTER_WINDOW_LENGTH.total_seconds() / INNER_WINDOW_LENGTH.total_seconds())\n",
    "\n",
    "        carbs = dfParticipantMeal[\"Carbs\"].iloc[counterOuter]\n",
    "        fat = dfParticipantMeal[\"Fat\"].iloc[counterOuter]\n",
    "        protein = dfParticipantMeal[\"Protein\"].iloc[counterOuter]\n",
    "\n",
    "        windowDatas.append([outterWindowStart, outterWindowEnd, innerWindowNumber, carbs, fat, protein, 1, participant])\n",
    "    for counterOuter in tqdm(range(len(windowDatas))):\n",
    "        windowData = windowDatas[counterOuter]\n",
    "        participantDataList.append(parallelCall(windowData, dfParticipantCM, dfParticipantE4, dfParticipantCGM))\n",
    "    # participantDataList = Parallel(n_jobs=coreNumber)(delayed(parallelCall)(windowData, dfParticipantCM, dfParticipantE4, dfParticipantCGM) for windowData in tqdm(windowDatas))\n",
    "    return participantDataList\n",
    "\n",
    "\n",
    "def outterNegWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant):\n",
    "    print(\"Negative windows:\")\n",
    "    participantDataList = []\n",
    "    gaps = []\n",
    "    for counterOuter in range(1, len(dfParticipantMeal)):\n",
    "        if dfParticipantMeal[\"StartTime\"].iloc[counterOuter] - dfParticipantMeal[\"StartTime\"].iloc[counterOuter - 1] >= FASTING_LENGTH:\n",
    "            counter = 0\n",
    "            while True:\n",
    "                endQuerry = dfParticipantMeal[\"StartTime\"].iloc[counterOuter] - counter * OUTTER_WINDOW_LENGTH\n",
    "                startQuerry = endQuerry - OUTTER_WINDOW_LENGTH\n",
    "                if startQuerry > dfParticipantMeal[\"StartTime\"].iloc[counterOuter - 1] + FASTING_LENGTH:\n",
    "                    gaps.append([startQuerry, endQuerry])\n",
    "                else:\n",
    "                    break\n",
    "                if counter == 3:  # Each positive window can have 3 negative winodws at most\n",
    "                    break\n",
    "                counter += 1\n",
    "    windowDatas = []\n",
    "    for counterOuter in range(len(gaps)):\n",
    "        element = gaps[counterOuter]\n",
    "        outterWindowStart = element[0]\n",
    "        outterWindowEnd = element[1]\n",
    "        innerWindowNumber = int(OUTTER_WINDOW_LENGTH.total_seconds() / INNER_WINDOW_LENGTH.total_seconds())\n",
    "\n",
    "        carbs = 0\n",
    "        fat = 0\n",
    "        protein = 0\n",
    "\n",
    "        windowDatas.append([outterWindowStart, outterWindowEnd, innerWindowNumber, carbs, fat, protein, 0, participant])\n",
    "    for counterOuter in tqdm(range(len(windowDatas))):\n",
    "        windowData = windowDatas[counterOuter]\n",
    "        participantDataList.append(parallelCall(windowData, dfParticipantCM, dfParticipantE4, dfParticipantCGM))\n",
    "    # participantDataList = Parallel(n_jobs=coreNumber)(delayed(parallelCall)(windowData, dfParticipantCM, dfParticipantE4, dfParticipantCGM) for windowData in tqdm(windowDatas))\n",
    "    return participantDataList\n",
    "\n",
    "\n",
    "def main():\n",
    "    allDataList = []\n",
    "    participants = dfMeal[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    for participant in participants:\n",
    "        print(\"Participant:\", participant)\n",
    "        if participant in exempts:\n",
    "            continue\n",
    "        dfParticipantMeal = dfMeal[dfMeal[\"Participant\"] == participant]\n",
    "        dfParticipantCM = dfCM[dfCM[\"Participant\"] == participant]\n",
    "        dfParticipantE4 = dfE4[dfE4[\"Participant\"] == participant]\n",
    "        dfParticipantCGM = dfCGM[dfCGM[\"Participant\"] == participant]\n",
    "        participantDataList = outterPosWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant)\n",
    "        participantDataList.extend(outterNegWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant))\n",
    "        participantDataList = pd.DataFrame(participantDataList, columns=[\"CM\", \"E4\", \"CGM\", \"Start\", \"End\", \"Participant\", \"Carb\", \"Fat\", \"Protein\", \"MealLabel\"])\n",
    "        if len(allDataList) == 0:\n",
    "            allDataList = participantDataList\n",
    "        else:\n",
    "            frames = [allDataList, participantDataList]\n",
    "            allDataList = pd.concat(frames)\n",
    "    allDataList.to_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\")))\n",
    "    return allDataList\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\"))):\n",
    "    os.remove(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\")))\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\"))):\n",
    "    dfTemp.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    dfTemp.reset_index(drop=True, inplace=True)\n",
    "    dfAllFeatures = main()\n",
    "else:\n",
    "    dfAllFeatures = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\")))\n",
    "print(dfAllFeatures)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:07<00:00, 18.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 3960 Positive windows: 960\n",
      "0.5230961805555555\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def meanSTDFinder(df):\n",
    "    cmData = []\n",
    "    for counter in range(len(df)):\n",
    "        elements = df[\"CM\"].iloc[counter]\n",
    "        for element in elements:\n",
    "            cmData.append(element)\n",
    "    cmData = np.asarray(cmData).astype(float)\n",
    "    cmDataMean = np.nanmean(cmData, axis=0)\n",
    "    cmDataStd = np.nanstd(cmData, axis=0)\n",
    "    return cmDataMean, cmDataStd\n",
    "\n",
    "\n",
    "hooverModelAdd = \"/home/grads/s/sorush.omidvar/CGMDataset/Hoover/HooverModel-0.8.sav\"\n",
    "hooverModel = pickle.load(open(hooverModelAdd, \"rb\"))\n",
    "\n",
    "participants = dfAllFeatures[\"Participant\"].to_list()\n",
    "participants = list(set(participants))\n",
    "for participant in participants:\n",
    "    if participant != \"p1\":\n",
    "        continue\n",
    "    dfTemp = dfAllFeatures[dfAllFeatures[\"Participant\"] == participant]\n",
    "    cmDataMean, cmDataStd = meanSTDFinder(dfTemp)\n",
    "\n",
    "    predictions = []\n",
    "    groundTruth = []\n",
    "    for counter in tqdm(range(len(dfTemp))):\n",
    "        elements = dfTemp[\"CM\"].iloc[counter]\n",
    "        for element in elements:\n",
    "            element = np.asarray(element).astype(float)\n",
    "            element -= cmDataMean\n",
    "            element /= cmDataStd\n",
    "            element = np.expand_dims(element, axis=0)\n",
    "            hooverPrediction = hooverModel.predict_proba(element)\n",
    "            hooverPrediction = hooverPrediction[0, 1]\n",
    "            predictions.append(hooverPrediction)\n",
    "            groundTruth.append(dfTemp[\"MealLabel\"].iloc[counter])\n",
    "    predictions = np.asarray(predictions)\n",
    "    groundTruth = np.asarray(groundTruth)\n",
    "    print(\"Total:\",len(groundTruth), \"Positive windows:\",np.sum(groundTruth))\n",
    "    fpr, tpr, thresholds = roc_curve(groundTruth, predictions, pos_label=1)\n",
    "    print(roc_auc_score(groundTruth,predictions))\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfAllFeatures.drop(columns=['E4'],inplace=True)\n",
    "a = dfAllFeatures[\"CM\"].to_list()\n",
    "a = a[0]\n",
    "a = np.asarray(a).astype(float)\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def e4Reporter(df):\n",
    "#     topics = [\"BVP\", \"EDA\", \"HR\", \"Temperature\"]\n",
    "#     report = []\n",
    "#     for topic in topics:\n",
    "#         dfTemp = df[df[\"Field\"] == topic]\n",
    "#         if topic == \"BVP\":\n",
    "#             MIN_POINT = MINIMUM_POINT * 64 * 0.3\n",
    "#         elif topic == \"EDA\":\n",
    "#             MIN_POINT = MINIMUM_POINT * 4 * 0.3\n",
    "#         elif topic == \"HR\":\n",
    "#             MIN_POINT = MINIMUM_POINT / 10 * 0.3\n",
    "#         elif topic == \"Temperature\":\n",
    "#             MIN_POINT = MINIMUM_POINT * 4 * 0.3\n",
    "#         else:\n",
    "#             print(\"MAYDAY at sensor reader\")\n",
    "#             os._exit()\n",
    "#         if len(dfTemp) < MIN_POINT:\n",
    "#             report.append(\"Nan\")\n",
    "#         else:\n",
    "#             val = dfTemp[\"Data1\"].mean()\n",
    "#             report.append(val)\n",
    "#     return report\n",
    "\n",
    "\n",
    "# def motionCalculator(df):\n",
    "#     f1 = df[\"RotationalToLinear\"].mean()\n",
    "#     f2 = df[\"|Ax|+|Ay|+|Az|\"].mean()\n",
    "#     f3 = df[\"|Yaw|+|Roll|+|Pitch|\"].mean()\n",
    "#     f4 = df[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"].mean()\n",
    "#     return [f1, f2, f3, f4]\n",
    "\n",
    "\n",
    "# def statFeatures(dataList):\n",
    "#     dataList = np.asarray(dataList).astype(float)\n",
    "#     result = []\n",
    "#     dataDim = dataList.ndim\n",
    "#     if dataDim > 1:\n",
    "#         for counter in range(dataList.shape[1]):\n",
    "#             if not np.isnan(dataList[:, counter]).all():\n",
    "#                 meanVal = np.nanmean(dataList[:, counter], axis=0)\n",
    "#                 stdVal = np.nanstd(dataList[:, counter], axis=0)\n",
    "#                 minVal = np.nanmin(dataList[:, counter], axis=0)\n",
    "#                 maxVal = np.nanmax(dataList[:, counter], axis=0)\n",
    "#                 rangeVal = maxVal - minVal\n",
    "#                 skewnessVal = skew(dataList[:, counter], nan_policy=\"omit\", axis=0)\n",
    "#                 kurtosisVal = kurtosis(dataList[:, counter], nan_policy=\"omit\", axis=0)\n",
    "#                 result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal])\n",
    "#             else:\n",
    "#                 result.extend([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "#     else:\n",
    "#         if not np.isnan(dataList).all():\n",
    "#             meanVal = np.nanmean(dataList)\n",
    "#             stdVal = np.nanstd(dataList)\n",
    "#             minVal = np.nanmin(dataList)\n",
    "#             maxVal = np.nanmax(dataList)\n",
    "#             rangeVal = maxVal - minVal\n",
    "#             skewnessVal = skew(dataList, nan_policy=\"omit\")\n",
    "#             kurtosisVal = kurtosis(dataList, nan_policy=\"omit\")\n",
    "#             result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal])\n",
    "#         else:\n",
    "#             result.extend([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "#     return result\n",
    "\n",
    "\n",
    "# def innerWindowExtractor(outterWindowStart, innerWindowNumber, dfParticipantCM, dfParticipantE4):\n",
    "#     tempListCM = []\n",
    "#     tempListE4 = []\n",
    "#     for counterInner in range(0, innerWindowNumber, 1):\n",
    "#         innerWindowStart = outterWindowStart + counterInner * INNER_WINDOW_LENGTH\n",
    "#         innerWindowEnd = innerWindowStart + INNER_WINDOW_LENGTH\n",
    "#         dfTempCM = dfParticipantCM[(dfParticipantCM[\"Time\"] >= innerWindowStart) & (dfParticipantCM[\"Time\"] < innerWindowEnd)]\n",
    "\n",
    "#         if len(dfTempCM) < MINIMUM_POINT * 10 * 0.3:\n",
    "#             tempListCM.append([\"Nan\", \"Nan\", \"Nan\", \"Nan\"])\n",
    "#         else:\n",
    "#             tempListCM.append(motionCalculator(dfTempCM))\n",
    "#         tempListE4.append([\"Nan\", \"Nan\", \"Nan\", \"Nan\"])\n",
    "#         # dfTempE4 = dfParticipantE4[(dfParticipantE4[\"Time\"] >= innerWindowStart) & (dfParticipantE4[\"Time\"] < innerWindowEnd)]\n",
    "#         # if len(dfTempE4) < MINIMUM_POINT * 32 * 0.3:\n",
    "#         #     tempListE4.append([\"Nan\", \"Nan\", \"Nan\", \"Nan\"])\n",
    "#         # else:\n",
    "#         #     tempListE4.append(e4Reporter(dfTempE4))\n",
    "\n",
    "#     return tempListCM, tempListE4\n",
    "\n",
    "\n",
    "# def outterPosWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant):\n",
    "#     print(\"Positive windows:\")\n",
    "#     participantDataList = []\n",
    "#     for counterOuter in tqdm(range(0, len(dfParticipantMeal))):\n",
    "#         outterWindowStart = dfParticipantMeal[\"StartTime\"].iloc[counterOuter]\n",
    "#         outterWindowEnd = outterWindowStart + OUTTER_WINDOW_LENGTH\n",
    "#         innerWindowNumber = int(OUTTER_WINDOW_LENGTH.total_seconds() / INNER_WINDOW_LENGTH.total_seconds())\n",
    "#         tempListInfo = [outterWindowStart, outterWindowEnd, participant]\n",
    "#         tempList = []\n",
    "#         tempListCM, tempListE4 = innerWindowExtractor(outterWindowStart, innerWindowNumber, dfParticipantCM, dfParticipantE4)\n",
    "\n",
    "#         carbs = dfParticipantMeal[\"Carbs\"].iloc[counterOuter]\n",
    "#         protein = dfParticipantMeal[\"Protein\"].iloc[counterOuter]\n",
    "#         fat = dfParticipantMeal[\"Fat\"].iloc[counterOuter]\n",
    "\n",
    "#         tempListCM = statFeatures(tempListCM)\n",
    "#         tempList.extend(tempListCM)  # 7*4=28\n",
    "\n",
    "#         tempListE4 = statFeatures(tempListE4)\n",
    "#         tempList.extend(tempListE4)  # 7*4=28\n",
    "\n",
    "#         dfTempCGM = dfParticipantCGM[(dfParticipantCGM[\"Time\"] >= outterWindowStart) & (dfParticipantCGM[\"Time\"] < outterWindowEnd)]\n",
    "#         tempListCGM = dfTempCGM[\"Abbot\"].to_list()\n",
    "#         tempListCGM = statFeatures(tempListCGM)\n",
    "#         tempList.extend(tempListCGM)  # 7\n",
    "#         tempList.extend(tempListInfo)  # 3\n",
    "#         tempList.append(carbs)\n",
    "#         tempList.append(fat)\n",
    "#         tempList.append(protein)\n",
    "#         tempList.append(1)  # mealFlag\n",
    "#         assert len(tempList) == 7 * 4 + 7 * 4 + 7 + 3 + 4\n",
    "#         participantDataList.append(tempList)\n",
    "#     return participantDataList\n",
    "\n",
    "\n",
    "# def outterNegWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant):\n",
    "#     print(\"Negative windows:\")\n",
    "#     participantDataList = []\n",
    "#     gaps = []\n",
    "\n",
    "#     for counterOuter in range(1, len(dfParticipantMeal)):\n",
    "#         if dfParticipantMeal[\"StartTime\"].iloc[counterOuter] - dfParticipantMeal[\"StartTime\"].iloc[counterOuter - 1] >= FASTING_LENGTH:\n",
    "#             gaps.append([dfParticipantMeal[\"StartTime\"].iloc[counterOuter - 1], dfParticipantMeal[\"StartTime\"].iloc[counterOuter]])\n",
    "\n",
    "#     for counterOuter in tqdm(range(len(gaps))):\n",
    "#         querryTemp = gaps[counterOuter]\n",
    "#         querryStart = querryTemp[0] + FASTING_LENGTH\n",
    "#         querryEnd = querryTemp[1]\n",
    "#         querryWindNum = datetime.timestamp(querryEnd) - datetime.timestamp(querryStart)\n",
    "#         querryWindNum = int(querryWindNum / OUTTER_WINDOW_LENGTH.total_seconds())\n",
    "\n",
    "#         proccessedNegWindowCounter = 0\n",
    "#         for counter in range(querryWindNum):\n",
    "#             outterWindowStart = querryStart + counter * OUTTER_WINDOW_LENGTH\n",
    "#             outterWindowEnd = outterWindowStart + OUTTER_WINDOW_LENGTH\n",
    "\n",
    "#             dfTempE4 = dfParticipantE4[dfParticipantE4[\"Time\"] >= outterWindowStart]\n",
    "#             dfTempE4 = dfTempE4[dfTempE4[\"Time\"] < outterWindowEnd]\n",
    "#             if len(dfTempE4) < OUTTER_WINDOW_LENGTH.total_seconds() * (64 + 4 + 4) * 0.3:\n",
    "#                 print(\"Not enough data for E4\", outterWindowStart, outterWindowEnd)\n",
    "#                 continue\n",
    "\n",
    "#             dfTempCM = dfParticipantCM[dfParticipantCM[\"Time\"] >= outterWindowStart]\n",
    "#             dfTempCM = dfTempCM[dfTempCM[\"Time\"] < outterWindowEnd]\n",
    "#             if len(dfTempCM) < OUTTER_WINDOW_LENGTH.total_seconds() * 10 * 0.3:\n",
    "#                 print(\"Not enough data for Apple\", outterWindowStart, outterWindowEnd)\n",
    "#                 continue\n",
    "\n",
    "#             innerWindowNumber = int(OUTTER_WINDOW_LENGTH.total_seconds() / INNER_WINDOW_LENGTH.total_seconds())\n",
    "#             tempListInfo = [outterWindowStart, outterWindowEnd, participant]\n",
    "#             tempList = []\n",
    "#             tempListCM, tempListE4 = innerWindowExtractor(outterWindowStart, innerWindowNumber, dfParticipantCM, dfParticipantE4)\n",
    "\n",
    "#             carbs = 0\n",
    "#             protein = 0\n",
    "#             fat = 0\n",
    "\n",
    "#             tempListCM = statFeatures(tempListCM)\n",
    "#             tempList.extend(tempListCM)  # 7*4=28\n",
    "\n",
    "#             tempListE4 = statFeatures(tempListE4)\n",
    "#             tempList.extend(tempListE4)  # 7*4=28\n",
    "\n",
    "#             dfTempCGM = dfParticipantCGM[(dfParticipantCGM[\"Time\"] >= outterWindowStart) & (dfParticipantCGM[\"Time\"] < outterWindowEnd)]\n",
    "#             tempListCGM = dfTempCGM[\"Abbot\"].to_list()\n",
    "#             tempListCGM = statFeatures(tempListCGM)\n",
    "#             tempList.extend(tempListCGM)  # 7\n",
    "#             tempList.extend(tempListInfo)  # 3\n",
    "\n",
    "#             tempList.append(carbs)\n",
    "#             tempList.append(fat)\n",
    "#             tempList.append(protein)\n",
    "#             tempList.append(0)  # mealFlag\n",
    "#             assert len(tempList) == 7 * 4 + 7 * 4 + 7 + 3 + 4\n",
    "#             participantDataList.append(tempList)\n",
    "#             if counter == 2:\n",
    "#                 break  # Making sure that each positive window has two negative window afterward at max and also the negative window is located close to a positive one\n",
    "#     return participantDataList\n",
    "\n",
    "\n",
    "# def participantFeatureWriter(participantDataList, participant):\n",
    "#     participantDataArray = np.asarray(participantDataList)\n",
    "#     columnTopics = [\"F1\", \"F2\", \"F3\", \"F4\", \"BVP\", \"EDA\", \"HR\", \"Temperature\", \"CGM\"]\n",
    "#     columnStats = [\"Range\", \"Mean\", \"Std\", \"Min\", \"Max\", \"Skewness\", \"Kurtosis\"]\n",
    "#     columns = []\n",
    "#     for topic in columnTopics:\n",
    "#         for stat in columnStats:\n",
    "#             columns.append(topic + \"-\" + stat)\n",
    "#     columns.extend([\"StartTime\", \"EndTime\", \"Participant\", \"Carb\", \"Fat\", \"Protein\", \"MealLabel\"])\n",
    "#     dfFeatures = pd.DataFrame(participantDataArray, columns=columns)\n",
    "#     dfFeatures.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "#     dfFeatures.reset_index(drop=True, inplace=True)\n",
    "#     dfFeatures.insert(len(dfFeatures.columns), \"ComplexFlag\", 0)\n",
    "#     for counter in range(1, len(dfFeatures)):\n",
    "#         if dfFeatures[\"StartTime\"].iloc[counter] <= dfFeatures[\"StartTime\"].iloc[counter - 1] + COMPLEX_MEAL_LENGTH:\n",
    "#             dfFeatures[\"ComplexFlag\"].iloc[counter - 1] = 1\n",
    "#     dfFeatures.to_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + participant + \"-Features.xlsx\")), index=False)\n",
    "\n",
    "\n",
    "# def allFeatureWriter(participants):\n",
    "#     dfFeatures = []\n",
    "#     for participant in participants:\n",
    "#         if participant in exempts:\n",
    "#             continue\n",
    "#         if not os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + participant + \"-Features.xlsx\"))):\n",
    "#             print(\"MAYDAY, no feature for participant:\", participant)\n",
    "#             continue\n",
    "#         dfTemp = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + participant + \"-Features.xlsx\")))\n",
    "#         if len(dfFeatures) == 0:\n",
    "#             dfFeatures = dfTemp\n",
    "#         else:\n",
    "#             frames = [dfTemp, dfFeatures]\n",
    "#             dfFeatures = pd.concat(frames)\n",
    "#     dfFeatures.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "#     dfFeatures.reset_index(drop=True, inplace=True)\n",
    "#     dfFeatures.to_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\")), index=False)\n",
    "#     return dfFeatures\n",
    "\n",
    "\n",
    "# participants = dfCM[\"Participant\"].to_list()\n",
    "# participants = list(set(participants))\n",
    "# # if os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\"))):\n",
    "# #     os.remove(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\")))\n",
    "# if not os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\"))):\n",
    "#     for participant in participants:\n",
    "#         if participant in exempts:\n",
    "#             continue\n",
    "#         # if os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + participant+\"-Features.xlsx\"))):\n",
    "#         #     os.remove(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + participant+\"-Features.xlsx\")))\n",
    "#         if not os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + participant + \"-Features.xlsx\"))):\n",
    "#             print(\"Participant \", participant, \" is started\")\n",
    "#             dfParticipantCM = dfCM[dfCM[\"Participant\"] == participant]\n",
    "#             dfParticipantMeal = dfMeal[dfMeal[\"Participant\"] == participant]\n",
    "#             dfParticipantCGM = dfCGM[dfCGM[\"Participant\"] == participant]\n",
    "#             dfParticipantE4 = dfE4[dfE4[\"Participant\"] == participant]\n",
    "\n",
    "#             participantDataList = outterPosWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant)\n",
    "#             participantDataList.extend(outterNegWindowExtractor(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant))\n",
    "#             participantFeatureWriter(participantDataList, participant)\n",
    "#     dfFeatures = allFeatureWriter(participants)\n",
    "# else:\n",
    "#     dfFeatures = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.xlsx\")))\n",
    "# print(len(dfFeatures))\n",
    "# dfFeatures.dropna(inplace=True)\n",
    "# print(len(dfFeatures))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmseCalculator(trueGround, prediction):\n",
    "    rmse = 0\n",
    "    assert len(trueGround) == len(prediction)\n",
    "    for counter in range(len(trueGround)):\n",
    "        tempVal = trueGround[counter] - prediction[counter]\n",
    "        tempVal *= tempVal\n",
    "        rmse += tempVal\n",
    "    rmse /= len(trueGround)\n",
    "    rmse = np.sqrt(rmse)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def rmsleCalculator(trueGround, prediction):\n",
    "    rmsle = 0\n",
    "    assert len(trueGround) == len(prediction)\n",
    "    for counter in range(len(trueGround)):\n",
    "        tempVal = np.log(1 + prediction[counter]) - np.log(1 + trueGround[counter])\n",
    "        tempVal *= tempVal\n",
    "        rmsle += tempVal\n",
    "    rmsle /= len(trueGround)\n",
    "    rmsle = np.sqrt(rmsle)\n",
    "    return rmsle\n",
    "\n",
    "\n",
    "def randomForester(xTrain, xTest, yTrain, yTest):\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=3)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    predictionsTest = clf.predict(xTest)\n",
    "\n",
    "    confMatrix = sklearn.metrics.confusion_matrix(yTest, predictionsTest)\n",
    "    accuracy = sklearn.metrics.accuracy_score(yTest, predictionsTest)\n",
    "    recall = sklearn.metrics.recall_score(yTest, predictionsTest)\n",
    "    precision = sklearn.metrics.precision_score(yTest, predictionsTest)\n",
    "    f1Score = sklearn.metrics.f1_score(yTest, predictionsTest)\n",
    "    return [accuracy, recall, precision, f1Score]\n",
    "\n",
    "\n",
    "def xgRegressor(xTrain, xVal, xTest, yTrain, yVal, yTest, headerNames):\n",
    "    rmseBest = 100000000000\n",
    "    for maxDepth in np.arange(2, 8, 1):\n",
    "        for estimator in np.arange(50, 200, 50):\n",
    "            clf = xgb.XGBRegressor(n_jobs=24, n_estimators=estimator, max_depth=maxDepth, objective=\"reg:squarederror\")\n",
    "            # clf = xgb.XGBRegressor(n_jobs=24, n_estimators=estimator, max_depth=maxDepth, objective=\"reg:squaredlogerror\")\n",
    "            clf.fit(xTrain, yTrain)\n",
    "            predictionsVal = clf.predict(xVal)\n",
    "            rmse = rmseCalculator(yVal, predictionsVal)\n",
    "            rmsle = rmsleCalculator(yVal, predictionsVal)\n",
    "            if rmse < rmseBest:\n",
    "                rmseBest = rmse\n",
    "                modelBest = clf\n",
    "\n",
    "    predictionsTest = modelBest.predict(xTest)\n",
    "    rmse = rmseCalculator(yTest, predictionsTest)\n",
    "    rmsle = rmsleCalculator(yTest, predictionsTest)\n",
    "    featureImportance = modelBest.feature_importances_\n",
    "    return [rmse, rmsle, headerNames, featureImportance, yTest, predictionsTest]\n",
    "\n",
    "\n",
    "def xgClassifier(xTrain, xVal, xTest, yTrain, yVal, yTest):\n",
    "    f1ScoreBest = -1\n",
    "    for maxDepth in np.arange(2, 6, 1):\n",
    "        for estimator in np.arange(50, 200, 50):\n",
    "            for posWeight in np.arange(1, 3, 0.5):\n",
    "                for featureLength in [8]:\n",
    "                    clf = xgb.XGBClassifier(scale_pos_weight=posWeight, n_jobs=18, n_estimators=estimator, max_depth=maxDepth, objective=\"binary:logistic\", eval_metric=\"error\")\n",
    "                    clf.fit(xTrain, yTrain)\n",
    "                    featureImportanceTemp = clf.feature_importances_\n",
    "                    featureImportanceTemp *= -1\n",
    "                    sortedIndex = np.argsort(featureImportanceTemp)\n",
    "                    if len(sortedIndex) > featureLength:\n",
    "                        sortedIndex = sortedIndex[:featureLength]\n",
    "                    xTrainTransform = xTrain[:, sortedIndex]\n",
    "                    clf.fit(xTrainTransform, yTrain)\n",
    "                    xValTransfore = xVal[:, sortedIndex]\n",
    "                    predictionsVal = clf.predict(xValTransfore)\n",
    "\n",
    "                    accuracy = sklearn.metrics.accuracy_score(yVal, predictionsVal)\n",
    "                    recall = sklearn.metrics.recall_score(yVal, predictionsVal)\n",
    "                    precision = sklearn.metrics.precision_score(yVal, predictionsVal)\n",
    "                    f1Score = sklearn.metrics.f1_score(yVal, predictionsVal)\n",
    "\n",
    "                    if f1Score > f1ScoreBest:\n",
    "                        modelBest = clf\n",
    "                        f1ScoreBest = f1Score\n",
    "                        sortedIndexBest = sortedIndex\n",
    "    xTestTransform = xTest[:, sortedIndexBest]\n",
    "    predictionsTest = modelBest.predict(xTestTransform)\n",
    "    confMatrix = sklearn.metrics.confusion_matrix(yTest, predictionsTest)\n",
    "    accuracy = sklearn.metrics.accuracy_score(yTest, predictionsTest)\n",
    "    recall = sklearn.metrics.recall_score(yTest, predictionsTest)\n",
    "    precision = sklearn.metrics.precision_score(yTest, predictionsTest)\n",
    "    f1Score = sklearn.metrics.f1_score(yTest, predictionsTest)\n",
    "    return [accuracy, recall, precision, f1Score]\n",
    "\n",
    "\n",
    "def testTrainSplitFunc(dfCombination, randomSeed, normalFlag, combination):\n",
    "    participants = list(set(dfCombination[\"Participant\"].to_list()))\n",
    "    dataColumnIndex = dfCombination.columns.get_loc(\"StartTime\")\n",
    "    regressorReports = []\n",
    "    classifierReports = []\n",
    "    # for participantCounter in tqdm(range(len(participants) + 1)):\n",
    "    for participantCounter in tqdm(range(len(participants))):\n",
    "        if participantCounter == len(participants):  # General Model (one model for all participants)\n",
    "            dfParticipant = dfCombination\n",
    "            participant = \"All\"\n",
    "        else:  # Personal Model (each participant have a his/her own model)\n",
    "            participant = participants[participantCounter]\n",
    "            dfParticipant = dfCombination[dfCombination[\"Participant\"] == participant]\n",
    "\n",
    "        print(\"Participant:\", participant)\n",
    "        headerNames = dfParticipant[dfParticipant.columns[0:dataColumnIndex]]\n",
    "        headerNames = headerNames.columns.to_list()\n",
    "\n",
    "        dataXBinary = dfParticipant[dfParticipant.columns[0:dataColumnIndex]].to_numpy()\n",
    "        dataYBinary = dfParticipant[\"MealLabel\"].to_numpy()\n",
    "        dataTimeBinary = dfParticipant[[\"StartTime\", \"EndTime\"]].to_numpy()\n",
    "        dataXRegression = dfParticipant[dfParticipant.columns[0:dataColumnIndex]].to_numpy()\n",
    "        dataYRegression = dfParticipant[[\"Carb\", \"Fat\", \"Protein\"]].to_numpy()\n",
    "        dataTimeRegression = dfParticipant[[\"StartTime\", \"EndTime\"]].to_numpy()\n",
    "\n",
    "        dataXBinary = dataXBinary.astype(float)\n",
    "        dataYBinary = dataYBinary.astype(float)\n",
    "        dataXRegression = dataXRegression.astype(float)\n",
    "        dataYRegression = dataYRegression.astype(float)\n",
    "\n",
    "        if normalFlag:\n",
    "            dataXBinary -= -dataXBinary.mean(axis=0)\n",
    "            dataXBinary /= dataXBinary.std(axis=0)\n",
    "            dataXRegression -= -dataXRegression.mean(axis=0)\n",
    "            dataXRegression /= dataXRegression.std(axis=0)\n",
    "\n",
    "        splitterOuter = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=randomSeed)\n",
    "        setNumber = 0\n",
    "        for trainIndex1, testIndex in splitterOuter.split(dataXBinary, dataYBinary):\n",
    "            xTrainBinary, xTestBinary = (dataXBinary[trainIndex1, :], dataXBinary[testIndex, :])\n",
    "            yTrainBinary, yTestBinary = dataYBinary[trainIndex1], dataYBinary[testIndex]\n",
    "            timeTrainBinary, timeTestBinary = dataTimeBinary[trainIndex1, :], dataTimeBinary[testIndex, :]\n",
    "\n",
    "            splitterInner = StratifiedShuffleSplit(n_splits=1, test_size=0.35, random_state=randomSeed)\n",
    "            for trainIndex2, valIndex in splitterInner.split(xTrainBinary, yTrainBinary):\n",
    "                xTrainBinary, xValBinary = xTrainBinary[trainIndex2, :], xTrainBinary[valIndex, :]\n",
    "                yTrainBinary, yValBinary = yTrainBinary[trainIndex2], yTrainBinary[valIndex]\n",
    "                timeTrainBinary, timeValBinary = timeTrainBinary[trainIndex2, :], timeTrainBinary[valIndex, :]\n",
    "\n",
    "            tempListReport = xgClassifier(xTrainBinary, xValBinary, xTestBinary, yTrainBinary, yValBinary, yTestBinary)\n",
    "            tempListReport.extend([participant, combination, timeTestBinary[:, 0], timeTestBinary[:, 1], setNumber, \"Classification\"])\n",
    "            classifierReports.append(tempListReport)\n",
    "            setNumber += 1\n",
    "\n",
    "        # kf = KFold(n_splits=5,shuffle=True,random_state=randomSeed)\n",
    "        # setNumber = 0\n",
    "        # for train_index, test_index in kf.split(dataYBinary):\n",
    "        #     xTrainBinary, xTestBinary=dataXBinary[train_index,:],dataXBinary[test_index,:]\n",
    "        #     yTrainBinary, yTestBinary=dataYBinary[train_index],dataYBinary[test_index]\n",
    "        #     timeTrainBinary, timeTestBinary = dataTimeBinary[train_index, :], dataTimeBinary[test_index, :]\n",
    "        #     tempListReport = xgClassifier(xTrainBinary, xTestBinary, yTrainBinary,yTestBinary)\n",
    "        #     # tempListReport = randomForester(xTrainBinary, xTestBinary, yTrainBinary,yTestBinary)\n",
    "        #     tempListReport.extend([participant, combination, timeTestBinary[:, 0], timeTestBinary[:, 1], setNumber, \"Classification\"])\n",
    "        #     classifierReports.append(tempListReport)\n",
    "        #     setNumber += 1\n",
    "\n",
    "        # print(\"All winodws:\", len(dataXRegression))\n",
    "        positiveWindowIndex = []\n",
    "        for counter in range(len(dataYRegression)):\n",
    "            if np.sum(dataYRegression[counter, :]) != 0:  # this is a positive window as fat+protein+carb!=0\n",
    "                positiveWindowIndex.append(counter)\n",
    "        dataXRegression = dataXRegression[positiveWindowIndex, :]\n",
    "        dataYRegression = dataYRegression[positiveWindowIndex, :]\n",
    "        # print(\"Positive winodws:\", len(dataXRegression))\n",
    "\n",
    "        # setNumber = 0\n",
    "        # components = [\"Carb\", \"Fat\", \"Protein\"]\n",
    "        # splitterOuter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=randomSeed)\n",
    "        # for trainIndex1, testIndex in splitterOuter.split(dataXRegression, dataYRegression):\n",
    "        #     xTrainRegression, xTestRegression = dataXRegression[trainIndex1, :], dataXRegression[testIndex, :]\n",
    "        #     yTrainRegression, yTestRegression = dataYRegression[trainIndex1, :], dataYRegression[testIndex, :]\n",
    "        #     timeTrainRegression, timeTestRegression = dataTimeRegression[trainIndex1, :], dataTimeRegression[testIndex, :]\n",
    "\n",
    "        #     splitterInner = ShuffleSplit(n_splits=1, test_size=0.3, random_state=randomSeed)\n",
    "        #     for trainIndex2, valIndex in splitterInner.split(xTrainRegression, yTrainRegression):\n",
    "        #         xTrainRegression, xValRegression = xTrainRegression[trainIndex2, :], xTrainRegression[valIndex, :]\n",
    "        #         yTrainRegression, yValRegression = yTrainRegression[trainIndex2, :], yTrainRegression[valIndex, :]\n",
    "        #         timeTrainRegression, timeValRegression = timeTrainRegression[trainIndex2, :], timeTrainRegression[valIndex, :]\n",
    "\n",
    "        #     for counter in range(3):\n",
    "        #         tempListReport = xgRegressor(xTrainRegression, xValRegression, xTestRegression, yTrainRegression[:, counter], yValRegression[:, counter], yTestRegression[:, counter], headerNames)\n",
    "        #         tempListReport.extend([participant, combination, timeTestRegression[:, 0], timeTestRegression[:, 1], setNumber, components[counter]])\n",
    "        #         regressorReports.append(tempListReport)\n",
    "        #     setNumber += 1\n",
    "    return classifierReports, regressorReports\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\"))):\n",
    "    os.remove(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\")))\n",
    "    os.remove(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Regressor.xlsx\")))\n",
    "if not os.path.exists(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\"))):\n",
    "    combinations = [\n",
    "        [\"CGM\"],\n",
    "        [\"F1\", \"F2\", \"F3\", \"F4\"],\n",
    "        [\"CGM\", \"F1\", \"F3\", \"F4\"],\n",
    "        # [\"CGM\", \"F1\", \"F2\", \"Temperature\"],\n",
    "        # [\"CGM\", \"BVP\", \"EDA\", \"HR\", \"Temperature\", \"F1\", \"F2\", \"F5\"],\n",
    "    ]\n",
    "    columns = dfFeatures.columns\n",
    "    headersClassifier = [\n",
    "        \"Accuracy\",\n",
    "        \"Recall\",\n",
    "        \"Precision\",\n",
    "        \"F1\",\n",
    "        \"Participant\",\n",
    "        \"Combination\",\n",
    "        \"StartTime\",\n",
    "        \"EndTime\",\n",
    "        \"SetNumber\",\n",
    "        \"Component\",\n",
    "    ]\n",
    "    headersRegressor = [\n",
    "        \"RMSquaredError\",\n",
    "        \"RMSquaredLogError\",\n",
    "        \"Features\",\n",
    "        \"FeatureImportance\",\n",
    "        \"TrueMacro\",\n",
    "        \"PredictedMacro\",\n",
    "        \"Participant\",\n",
    "        \"Combination\",\n",
    "        \"StartTime\",\n",
    "        \"EndTime\",\n",
    "        \"SetNumber\",\n",
    "        \"Component\",\n",
    "    ]\n",
    "    dfClassifier = []\n",
    "    dfRegressor = []\n",
    "    for combination in combinations:\n",
    "        columnList = [\"StartTime\", \"EndTime\", \"Participant\", \"Carb\", \"Fat\", \"Protein\", \"MealLabel\"]\n",
    "        for topic in combination:\n",
    "            for column in columns:\n",
    "                # if topic in column and not 'Kurtosis' in column and not 'Skewness' in column and not 'Min' in column and not 'Max' in column:\n",
    "                if topic in column:\n",
    "                    columnList.append(column)\n",
    "\n",
    "        dfCombination = dfFeatures[dfFeatures.columns.intersection(columnList)]\n",
    "\n",
    "        randomSeed = 60\n",
    "        print(\"----------------------\")\n",
    "        print(\"Combination:\", \"+\".join(combination))\n",
    "        NORMALIZED_FLAG = False\n",
    "        classifierReports, regressorReports = testTrainSplitFunc(dfCombination, randomSeed, NORMALIZED_FLAG, \"+\".join(combination))\n",
    "        dfTempClassifier = pd.DataFrame(classifierReports, columns=headersClassifier)\n",
    "        dfTempRegressor = pd.DataFrame(regressorReports, columns=headersRegressor)\n",
    "        if len(dfClassifier) > 0:\n",
    "            frames = [dfTempClassifier, dfClassifier]\n",
    "            dfClassifier = pd.concat(frames)\n",
    "\n",
    "            frames = [dfTempRegressor, dfRegressor]\n",
    "            dfRegressor = pd.concat(frames)\n",
    "        else:\n",
    "            dfClassifier = dfTempClassifier\n",
    "            dfRegressor = dfTempRegressor\n",
    "    dfClassifier.reset_index(drop=True, inplace=True)\n",
    "    dfRegressor.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    dfClassifier.to_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\")), index=False)\n",
    "    dfRegressor.to_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Regressor.xlsx\")), index=False)\n",
    "else:\n",
    "    dfClassifier = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\")))\n",
    "    dfRegressor = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Regressor.xlsx\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringFixer(df):\n",
    "    dfColumns = [\"TrueMacro\", \"PredictedMacro\"]\n",
    "    for dfColumn in dfColumns:\n",
    "        for counter in range(len(df)):\n",
    "            tempVal = df[dfColumn].iloc[counter]\n",
    "            tempVal = tempVal.replace(\"[\", \"\")\n",
    "            tempVal = tempVal.replace(\"]\", \"\")\n",
    "            tempVal = list(tempVal.split(\" \"))\n",
    "            tempVal = list(filter(None, tempVal))\n",
    "            tempVal = np.asarray(tempVal).astype(float)\n",
    "            df[dfColumn].iloc[counter] = tempVal\n",
    "    return df\n",
    "\n",
    "\n",
    "dfRegressor = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Regressor.xlsx\")))\n",
    "dfRegressor = stringFixer(dfRegressor)\n",
    "\n",
    "dfRegressor.reset_index(drop=True, inplace=True)\n",
    "# dfRegressor.replace(\"CGM\", \"C\", inplace=True)\n",
    "# dfRegressor.replace(\"CGM+F1+F2+F5\", \"CM\", inplace=True)\n",
    "# dfRegressor.replace(\"CGM+BVP+EDA+HR+Temperature\", \"CE\", inplace=True)\n",
    "# dfRegressor.replace(\"CGM+BVP+EDA+HR+Temperature+F1+F2+F5\", \"CEM\", inplace=True)\n",
    "components = [\"Carb\", \"Fat\", \"Protein\"]\n",
    "colors = [\"red\", \"green\", \"blue\", \"magenta\"]\n",
    "participants = list(set(dfRegressor[\"Participant\"].to_list()))\n",
    "combinations = list(set(dfRegressor[\"Combination\"].to_list()))\n",
    "\n",
    "dfPearson = []\n",
    "for participant in participants:\n",
    "    dfParticipant = dfRegressor[dfRegressor[\"Participant\"] == participant]\n",
    "    for component in components:\n",
    "        dfComponent = dfParticipant[dfParticipant[\"Component\"] == component]\n",
    "        # myFig = plt.figure(figsize=(10, 10))\n",
    "        for counter in range(len(combinations)):\n",
    "            dfCombination = dfComponent[dfComponent[\"Combination\"] == combinations[counter]]\n",
    "            trueVal = dfCombination[\"TrueMacro\"].to_list()\n",
    "            trueVal = np.asarray(trueVal).astype(float)\n",
    "            trueVal = trueVal.flatten()\n",
    "\n",
    "            predVal = dfCombination[\"PredictedMacro\"].to_list()\n",
    "            predVal = np.asarray(predVal).astype(float)\n",
    "            predVal = predVal.flatten()\n",
    "\n",
    "            figName = \"Participant:\" + participant + \", Macro:\" + component\n",
    "            # plt.scatter(x=trueVal, y=predVal, c=colors[counter], label=combinations[counter], alpha=0.5, s=20)\n",
    "            # plt.title(figName)\n",
    "            # plt.plot([0, np.max(trueVal)], [0, np.max(trueVal)], \"k--\")\n",
    "            tempVal = pearsonr(trueVal, predVal)[0]\n",
    "            dfPearson.append([participant, component, combinations[counter], tempVal])\n",
    "            # plt.xlabel(\"True\")\n",
    "            # plt.ylabel(\"Pred\")\n",
    "        # plt.legend(loc=\"upper left\")\n",
    "        # plt.savefig(os.path.join(addDataPrefix, \"Results\", figName + \".png\"), dpi=600)\n",
    "        # plt.show()\n",
    "dfPearson = pd.DataFrame(dfPearson, columns=[\"Participant\", \"Component\", \"Combination\", \"Pearson\"])\n",
    "dfPearson.insert(len(dfPearson.columns), \"RelativePearson\", -100)\n",
    "dfPearson[\"RelativePearson\"] = dfPearson[\"Pearson\"]\n",
    "for participant in participants:  # Finding the difference of C with other Combinations\n",
    "    for component in components:\n",
    "        dfTemp = dfPearson[dfPearson[\"Participant\"] == participant]\n",
    "        dfTemp = dfTemp[dfTemp[\"Component\"] == component]\n",
    "        baseLine = dfTemp[dfTemp[\"Combination\"] == \"C\"]\n",
    "        baseLine = baseLine[\"RelativePearson\"].sum()\n",
    "        for counter in range(len(dfPearson)):\n",
    "            if dfPearson[\"Participant\"].iloc[counter] == participant and dfPearson[\"Component\"].iloc[counter] == component:\n",
    "                dfPearson[\"RelativePearson\"].iloc[counter] -= baseLine\n",
    "dfPearson.to_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Pearson.xlsx\")), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRegressor = pd.read_excel(os.path.join(addDataPrefix, \"Results\", (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Regressor.xlsx\")))\n",
    "for root, dirs, files in os.walk(os.path.join(addDataPrefix, \"Results\")):\n",
    "    for file in files:\n",
    "        if \".xlsx\" in file.lower():\n",
    "            if \"classifier\" in file.lower() and not \"summary\" in file.lower():\n",
    "                dfClassifier = pd.read_excel(os.path.join(root, file))\n",
    "                newFileName = \"Summary-\" + file[: file.find(\".xlsx\")] + \".xlsx\"\n",
    "                newFileName = os.path.join(root, newFileName)\n",
    "                newFileData = []\n",
    "                participants = list(set(dfClassifier[\"Participant\"].to_list()))\n",
    "                combinations = list(set(dfClassifier[\"Combination\"].to_list()))\n",
    "                components = list(set(dfClassifier[\"Component\"].to_list()))\n",
    "                for participant in participants:\n",
    "                    dfParticipant = dfClassifier[dfClassifier[\"Participant\"] == participant]\n",
    "                    for combination in combinations:\n",
    "                        dfCombination = dfParticipant[dfParticipant[\"Combination\"] == combination]\n",
    "                        for component in components:\n",
    "                            dfComponent = dfCombination[dfCombination[\"Component\"] == component]\n",
    "                            assert len(dfComponent) == 5\n",
    "                            accuracyTemp = dfComponent[\"Accuracy\"].mean()\n",
    "                            recallTemp = dfComponent[\"Recall\"].mean()\n",
    "                            precisionTemp = dfComponent[\"Precision\"].mean()\n",
    "                            f1Temp = 2 * recallTemp * precisionTemp / (precisionTemp + recallTemp)\n",
    "                            newFileData.append([accuracyTemp, recallTemp, precisionTemp, f1Temp, participant, combination, component])\n",
    "                dfNewFile = pd.DataFrame(newFileData, columns=[\"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"Participant\", \"Combination\", \"Component\"])\n",
    "                dfNewFile.sort_values([\"Participant\", \"F1\"], ascending=(True, True), inplace=True)\n",
    "                dfNewFile.to_excel(newFileName, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfFeatures[\"MealLabel\"].sum())\n",
    "print(len(dfFeatures))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65e249be015da37cfe4cfdd1da028fe4cb475c26be679b9e3e34696278a17c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
