{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, mode, skew, kurtosis, linregress\n",
    "import xgboost as xgb\n",
    "from joblib import Parallel, delayed\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, ShuffleSplit, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import zipfile\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import multiprocessing as mp\n",
    "from matplotlib import patches\n",
    "# sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "# plt.rcParams[\"text.usetex\"] = True\n",
    "# font = {\"family\": \"normal\", \"weight\": \"bold\", \"size\": 22}\n",
    "\n",
    "# plt.rc(\"font\", **font)\n",
    "\n",
    "CM_LAG_CORRECTION = [\n",
    "    (\"p1\", timedelta(minutes=2 * 60 + 36)),\n",
    "    (\"p3\", timedelta(minutes=2 * 60)),\n",
    "    (\"p5\", timedelta(minutes=-360)),\n",
    "    (\"p6\", timedelta(minutes=-360)),\n",
    "    (\"p7\", timedelta(minutes=-360)),\n",
    "    (\"p8\", timedelta(minutes=-360)),\n",
    "    # (\"p8\", datetime.strptime(\"02 02 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\"),datetime.strptime(\"02 06 2022-07:20:00\", \"%m %d %Y-%H:%M:%S\"),timedelta(minutes=-165)),\n",
    "    # (\"p8\", datetime.strptime(\"02 06 2022-07:20:00\", \"%m %d %Y-%H:%M:%S\"),datetime.strptime(\"02 09 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\"),timedelta(minutes=-165-190)),\n",
    "    # (\"p8\", datetime.strptime(\"02 09 2022-07:20:00\", \"%m %d %Y-%H:%M:%S\"),datetime.strptime(\"02 14 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\"),timedelta(minutes=93)),\n",
    "]\n",
    "# CGM_LAG_IMPOSING_STR = sys.argv[1]# ONLY TO IMPOSE A TIME LAG BETWEEN CGM READINGS AND CORE MOTION DATA!!!! WATCH OUT AND USE IT CAUTIOUSLY\n",
    "CGM_LAG_IMPOSING_STR = \"0\"\n",
    "# OUTTER_WINDOW_LENGTH = timedelta(minutes=int(sys.argv[2]))\n",
    "\n",
    "\n",
    "CGM_LAG_IMPOSING = timedelta(minutes=int(CGM_LAG_IMPOSING_STR))  # ONLY TO IMPOSE A TIME LAG BETWEEN CGM READINGS AND CORE MOTION DATA!!!! WATCH OUT AND USE IT CAUTIOUSLY\n",
    "OUTTER_WINDOW_LENGTH = timedelta(minutes=30)\n",
    "OUTTER_WINDOW_STEP = timedelta(minutes=15)\n",
    "\n",
    "FASTING_LENGTH = timedelta(minutes=30)\n",
    "BIG_MEAL_CALORIE = 200\n",
    "FOLD_NUMBER = 5\n",
    "INNER_WINDOW_LENGTH = timedelta(seconds=60)\n",
    "MINIMUM_POINT = INNER_WINDOW_LENGTH.total_seconds()\n",
    "COMPLEX_MEAL_DURATION = timedelta(minutes=60)\n",
    "\n",
    "\n",
    "START_OF_TRIAL = [datetime.strptime(\"11 06 2021-04:00:00\", \"%m %d %Y-%H:%M:%S\"), datetime.strptime(\"02 03 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\")]\n",
    "END_OF_TRIAL = [datetime.strptime(\"11 15 2021-00:00:00\", \"%m %d %Y-%H:%M:%S\"), datetime.strptime(\"02 13 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\")]\n",
    "DAY_LIGHT_SAVING = datetime.strptime(\"11 06 2021-02:00:00\", \"%m %d %Y-%H:%M:%S\")\n",
    "coreNumber = 48\n",
    "\n",
    "addDataPrefix = \"/Users/sorush/My Drive/Documents/Educational/TAMU/Research/TAMU/\"\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"/home/grads/s/sorush.omidvar/CGMDataset/TAMU/\"\n",
    "if not os.path.exists(addDataPrefix):\n",
    "    addDataPrefix = \"C:\\\\GDrive\\\\Documents\\\\Educational\\\\TAMU\\\\Research\\\\Trial\\\\Data\\\\11-5-21-11-15-21\"\n",
    "\n",
    "addUserInput = os.path.join(addDataPrefix, \"User inputted\")\n",
    "addHKCM = os.path.join(addDataPrefix, \"hk+cm\")\n",
    "addCGM = os.path.join(addDataPrefix, \"CGM\")\n",
    "addE4 = os.path.join(addDataPrefix, \"E4\")\n",
    "addResults = os.path.join(addDataPrefix, \"Results\" + str(CGM_LAG_IMPOSING_STR))\n",
    "if not os.path.exists(addResults):\n",
    "    os.mkdir(addResults)\n",
    "\n",
    "exempts = [\"p2\", \"p4\"]\n",
    "# exempts = [\"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"p6\"]\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({\"figure.facecolor\": \"white\"})\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # no GPU\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants=list(set(dfMeal['Participant'].to_list()))\n",
    "# participants.sort()\n",
    "# # dfMeal.insert(0,'Duration',0)\n",
    "# # dfMeal['Duration']=dfMeal['FinishTime']-dfMeal['StartTime']\n",
    "# for participant in participants:\n",
    "#     dfTemp=dfMeal[dfMeal['Participant']==participant]\n",
    "#     print(participant,'&',len(dfTemp),'&',np.round(dfTemp['Duration'].dt.total_seconds().mean()/60,1),'(',np.round(dfTemp['Duration'].dt.total_seconds().std()/60,1),')','&',np.round(dfTemp['Calories'].mean(),1),\"(\",np.round(dfTemp['Calories'].std(),1),\")\",'&',np.round(dfTemp['Carbs'].mean(),1),\"(\",np.round(dfTemp['Carbs'].std(),1),\")\",'&',np.round(dfTemp['Fat'].mean(),1),\"(\",np.round(dfTemp['Fat'].std(),1),\")\",'&',np.round(dfTemp['Protein'].mean(),1),\"(\",np.round(dfTemp['Protein'].std(),1),\")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = os.listdir(addResults)\n",
    "# for item in files:\n",
    "#     if \".xlsx\" in item or '.jpg' in item or 'All-Features' in item:\n",
    "#         os.remove(os.path.join(addResults, item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T1 = datetime.strptime(\"02 03 2022-00:00:00\", \"%m %d %Y-%H:%M:%S\")\n",
    "# T2=T1+timedelta(hours=120)\n",
    "# a=dfE4[(dfE4['Time']>=T1) &(dfE4['Time']<=T2)]\n",
    "\n",
    "# plt.figure(figsize=(40,10))\n",
    "# x=a['Time'].to_list()\n",
    "# x=np.asarray(x)\n",
    "# y=a['Data1'].to_list()\n",
    "# plt.scatter(x,y)\n",
    "# plt.grid(which='both',color='r', linestyle='-', linewidth=0.5)\n",
    "# plt.minorticks_on()\n",
    "# plt.xlim([T1,T2])\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(40,10))\n",
    "# b=dfCM[(dfCM['Time']>=T1) &(dfCM['Time']<=T2)]\n",
    "# x=b['Time'].to_list()\n",
    "# x=np.asarray(x)\n",
    "# y=b['Yaw'].to_list()\n",
    "# y=np.asarray(y)/10+70\n",
    "# plt.scatter(x,y)\n",
    "# plt.grid(which='both',color='r', linestyle='-', linewidth=0.5)\n",
    "# plt.minorticks_on()\n",
    "# plt.xlim([T1,T2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unzipperE4(participantFolder):\n",
    "#     for root, dirs, files in os.walk(participantFolder):\n",
    "#         for file in files:\n",
    "#             if not '.zip' in file:\n",
    "#                 continue\n",
    "#             with zipfile.ZipFile(os.path.join(root,file), 'r') as zip_ref:\n",
    "#                 destFile=file[:file.find('.zip')]\n",
    "#                 destFile=os.path.join(root,destFile)\n",
    "#                 if not os.path.exists(destFile):\n",
    "#                     os.mkdir(destFile)\n",
    "#                 zip_ref.extractall(destFile)\n",
    "# def zipCleanerE4(E4Folder):\n",
    "#     for root, dirs, files in os.walk(E4Folder):\n",
    "#         for file in files:\n",
    "#             if '.zip' in file:\n",
    "#                 os.remove(os.path.join(root,file))\n",
    "\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p5')\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p6')\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p7')\n",
    "# unzipperE4('/Users/sorush/Desktop/Round2E4/p8')\n",
    "# zipCleanerE4('/Users/sorush/Desktop/Round2E4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/grads/s/sorush.omidvar/CGMDataset/TAMU/User inputted\n",
      "Reading ... p1Meals.csv\n",
      "Reading ... p5Meals.csv\n",
      "Reading ... p7Meals.csv\n",
      "Reading ... p8Meals.csv\n",
      "Reading ... p6Meals.csv\n",
      "Reading ... p3Meals.csv\n",
      "Exemption... p4Meals.csv\n",
      "reading is done\n",
      "Meal database is limited to the trial period\n"
     ]
    }
   ],
   "source": [
    "def timeZoneFixer(df, LocalizeFlag, columnName):\n",
    "    if LocalizeFlag:\n",
    "        df[columnName] -= timedelta(hours=5)\n",
    "    tempColumn = df[columnName]\n",
    "    tempColumn[tempColumn >= DAY_LIGHT_SAVING] -= timedelta(hours=1)\n",
    "    df[columnName] = tempColumn\n",
    "    return df\n",
    "\n",
    "\n",
    "def trialTimeLimitter(df, columnName):\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    dfTotal = []\n",
    "    for participant in participants:\n",
    "        if participant == \"p1\" or participant == \"p2\" or participant == \"p3\" or participant == \"p4\":\n",
    "            startOfTrial = START_OF_TRIAL[0]\n",
    "            endOfTrial = END_OF_TRIAL[0]\n",
    "        elif participant == \"p5\" or participant == \"p6\" or participant == \"p7\" or participant == \"p8\":\n",
    "            startOfTrial = START_OF_TRIAL[1]\n",
    "            endOfTrial = END_OF_TRIAL[1]\n",
    "        else:\n",
    "            print(\"Mayday in trialTimeLimitter\")\n",
    "            print(participant)\n",
    "            raise\n",
    "        dfTemp = df[df[\"Participant\"] == participant]\n",
    "        dfTemp = dfTemp[(dfTemp[columnName] >= startOfTrial) & (dfTemp[columnName] <= endOfTrial)]\n",
    "        if len(dfTotal) == 0:\n",
    "            dfTotal = dfTemp\n",
    "        else:\n",
    "            frames = [dfTotal, dfTemp]\n",
    "            dfTotal = pd.concat(frames)\n",
    "    return dfTotal\n",
    "\n",
    "\n",
    "def mealMarker(df):\n",
    "    df.insert(len(df.columns), \"BigMeal\", False)\n",
    "    for counter in range(0, len(df)):\n",
    "        if df[\"Calories\"].iloc[counter] >= BIG_MEAL_CALORIE:\n",
    "            df[\"BigMeal\"].iloc[counter] = True\n",
    "\n",
    "    df.insert(len(df.columns), \"ComplexMeal\", False)\n",
    "    participants = df[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    for participant in participants:\n",
    "        dfTemp = df[df[\"Participant\"] == participant]\n",
    "        for counter in range(1, len(dfTemp)):\n",
    "            # bothComplexFlag = dfTemp[\"BigMeal\"].iloc[counter - 1] and dfTemp[\"BigMeal\"].iloc[counter]\n",
    "            # if dfTemp[\"StartTime\"].iloc[counter - 1] + OUTTER_WINDOW_LENGTH >= dfTemp[\"StartTime\"].iloc[counter] and bothComplexFlag:\n",
    "            if dfTemp[\"StartTime\"].iloc[counter - 1] + COMPLEX_MEAL_DURATION >= dfTemp[\"StartTime\"].iloc[counter]:\n",
    "                dfTemp[\"ComplexMeal\"].iloc[counter] = True\n",
    "                dfTemp[\"ComplexMeal\"].iloc[counter - 1] = True\n",
    "        indexs = dfTemp.index[dfTemp[\"ComplexMeal\"] == True]\n",
    "        df[\"ComplexMeal\"][indexs] = True\n",
    "    return df\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addResults, \"All_meals.pkl\")):\n",
    "    os.remove(os.path.join(addResults, \"All_meals.pkl\"))\n",
    "os.chdir(addUserInput)\n",
    "if not os.path.exists(os.path.join(addResults, \"All_meals.pkl\")):\n",
    "    dfMeal = []\n",
    "    for root, dirs, files in os.walk(addUserInput):\n",
    "        print(root)\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                if \"meals\" in file.lower() and \"modified\" not in file.lower():\n",
    "                    participantName = file[: file.find(\"Meals\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    dfTemp.rename(columns={\"startTime\": \"StartTime\"}, inplace=True)\n",
    "                    dfTemp[\"StartTime\"] = pd.to_datetime(dfTemp[\"StartTime\"])\n",
    "                    dfTemp[\"FinishTime\"] = pd.to_datetime(dfTemp[\"FinishTime\"])\n",
    "                    dfTemp.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                    if len(dfMeal) != 0:\n",
    "                        frames = [dfTemp, dfMeal]\n",
    "                        dfMeal = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfMeal = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfMeal = trialTimeLimitter(dfMeal, \"StartTime\")\n",
    "    dfMeal = trialTimeLimitter(dfMeal, \"FinishTime\")\n",
    "    dfMeal.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    dfMeal.reset_index(drop=True, inplace=True)\n",
    "    # dfMeal.insert(4, \"MealDuration\", -1)\n",
    "    # dfMeal[\"MealDuration\"] = dfMeal[\"FinishTime\"] - dfMeal[\"StartTime\"]\n",
    "    # dfMeal[\"MealDuration\"] = dfMeal[\"MealDuration\"].dt.total_seconds()\n",
    "    print(\"Meal database is limited to the trial period\")\n",
    "    dfMeal.to_pickle(os.path.join(addResults, \"All_meals.pkl\"))\n",
    "else:\n",
    "    dfMeal = pd.read_pickle(os.path.join(addResults, \"All_meals.pkl\"))\n",
    "dfMeal = mealMarker(dfMeal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ... p7_libre data_02_14_2022.txt\n",
      "Exemption... p4_libre.txt\n",
      "Reading ... p1_libre.txt\n",
      "Reading ... p5_libre data_02_14_2022.txt\n",
      "Exemption... p2_libre.txt\n",
      "Reading ... p3_libre.txt\n",
      "Reading ... p6_libre data_02_14_2022.txt\n",
      "Reading ... p8_libre data_02_14_2022.txt\n",
      "reading is done\n",
      "CGM database is limited to the trial period\n"
     ]
    }
   ],
   "source": [
    "def pdInterpolation(dfTemp):\n",
    "    index = dfTemp[\"Time\"]\n",
    "    seriesParticipant = pd.Series(dfTemp[\"Abbot\"].to_list(), index=index)\n",
    "    seriesParticipant = seriesParticipant.resample(\"1T\").asfreq()\n",
    "    seriesParticipant.interpolate(method=\"polynomial\", order=3, inplace=True)\n",
    "    tempTime = seriesParticipant.index\n",
    "    tempVal = seriesParticipant.values\n",
    "    dfTemp = pd.DataFrame(zip(tempTime, tempVal), columns=[\"Time\", \"Abbot\"])\n",
    "    return dfTemp\n",
    "\n",
    "\n",
    "def cmLagCorrector(df):\n",
    "    participants = df[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    dfTotal = []\n",
    "\n",
    "    for element in CM_LAG_CORRECTION:\n",
    "        participant = element[0]\n",
    "        timeLag = element[1]\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        if len(dfParticipant) == 0:\n",
    "            continue\n",
    "        dfParticipant[\"Time\"] += timeLag\n",
    "        if len(dfTotal) == 0:\n",
    "            dfTotal = dfParticipant\n",
    "        else:\n",
    "            frames = [dfTotal, dfParticipant]\n",
    "            dfTotal = pd.concat(frames)\n",
    "\n",
    "    return dfTotal\n",
    "\n",
    "\n",
    "def cmSmoother(df):\n",
    "    columnLabels = df.columns\n",
    "    for columnLabel in columnLabels:\n",
    "        if columnLabel == \"Time\":\n",
    "            continue\n",
    "        tempSerie = df[columnLabel]\n",
    "        tempSerie = tempSerie.ewm(span=10).mean()  # Considering the frequency of 10 Hz\n",
    "        df[columnLabel] = tempSerie\n",
    "    return df\n",
    "\n",
    "\n",
    "def CGMLagImposer(df):\n",
    "    df[\"Time\"] += CGM_LAG_IMPOSING\n",
    "    return df\n",
    "\n",
    "\n",
    "def CGMNormalizer(df):\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    participants.sort()\n",
    "    dfResult = []\n",
    "    for participant in participants:\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        dates = list(set(dfParticipant[\"Time\"].dt.date.to_list()))\n",
    "        dates.sort()\n",
    "        for date in dates:\n",
    "            dfDate = dfParticipant[dfParticipant[\"Time\"].dt.date == date]\n",
    "            if len(dfDate) <= 10:\n",
    "                continue\n",
    "            minBG = dfDate[\"Abbot\"].min()\n",
    "            maxBG = dfDate[\"Abbot\"].max()\n",
    "\n",
    "            meanBG = dfDate[\"Abbot\"].mean()\n",
    "            stdBG = dfDate[\"Abbot\"].std()\n",
    "            dfDate[\"Abbot\"] -= minBG\n",
    "            dfDate[\"Abbot\"] /= maxBG - minBG\n",
    "            # dfDate[\"Abbot\"] -= meanBG\n",
    "            # dfDate[\"Abbot\"] /= stdBG\n",
    "\n",
    "            assert not np.isnan(minBG)\n",
    "            assert not np.isnan(maxBG)\n",
    "            assert not np.isnan(meanBG)\n",
    "            assert not np.isnan(stdBG)\n",
    "            if len(dfResult) == 0:\n",
    "                dfResult = dfDate.copy()\n",
    "            else:\n",
    "                frames = [dfResult, dfDate]\n",
    "                dfResult = pd.concat(frames)\n",
    "    return dfResult\n",
    "\n",
    "\n",
    "def CGMLowPass(df):\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    participants.sort()\n",
    "    dfResult = []\n",
    "    for participant in participants:\n",
    "        dfParticipant = df[df[\"Participant\"] == participant]\n",
    "        cgmVals = dfParticipant[\"Abbot\"].to_list()\n",
    "        cgmVals = np.asarray(cgmVals)\n",
    "        lowPassFilter = signal.butter(3, 12, \"lp\", fs=60 * 24, output=\"sos\")  # high pass of period of 2 hours (12 per day)\n",
    "        cgmVals = signal.sosfilt(lowPassFilter, cgmVals)\n",
    "        dfParticipant[\"Abbot\"] = cgmVals\n",
    "        if len(dfResult) == 0:\n",
    "            dfResult = dfParticipant.copy()\n",
    "        else:\n",
    "            frames = [dfResult, dfParticipant]\n",
    "            dfResult = pd.concat(frames)\n",
    "    return dfResult\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addResults, \"All_cgm.pkl\")):\n",
    "    os.remove(os.path.join(addResults, \"All_cgm.pkl\"))\n",
    "if not os.path.exists(os.path.join(addResults, \"All_cgm.pkl\")):\n",
    "    os.chdir(addCGM)\n",
    "    dfCGM = []\n",
    "    for root, dirs, files in os.walk(addCGM):\n",
    "        for file in files:\n",
    "            if \".txt\" in file.lower():\n",
    "                if \"_libre\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_libre\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file, sep=\"\\t\", skiprows=1)\n",
    "                    if len(dfTemp.columns) != 4:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        break\n",
    "                    dfTemp.columns.values[0] = \"ID\"\n",
    "                    dfTemp.columns.values[1] = \"Time\"\n",
    "                    dfTemp.columns.values[2] = \"Record\"\n",
    "                    dfTemp.columns.values[3] = \"Abbot\"\n",
    "                    dfTemp.drop(columns=[\"ID\", \"Record\"], inplace=True)\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"])\n",
    "                    if participantName == \"p1\" or participantName == \"p2\" or participantName == \"p3\" or participantName == \"p4\":\n",
    "                        dfTemp[\"Time\"] += timedelta(hours=-1)  # This fixes the daylight saving for the first round\n",
    "                    dfTemp[\"Abbot\"] = pd.to_numeric(dfTemp[\"Abbot\"])\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "                    dfTemp = pdInterpolation(dfTemp)\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    if len(dfTemp.columns) != 3:\n",
    "                        print(\"MAYDAY. Error in processing csv\")\n",
    "                        break\n",
    "                    if len(dfCGM) != 0:\n",
    "                        frames = [dfTemp, dfCGM]\n",
    "                        dfCGM = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfCGM = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfCGM = CGMLagImposer(dfCGM)\n",
    "    dfCGM = trialTimeLimitter(dfCGM, \"Time\")\n",
    "    dfCGM.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfCGM.reset_index(drop=True, inplace=True)\n",
    "    # dfCGM = CGMLowPass(dfCGM)\n",
    "    # dfCGM = CGMNormalizer(dfCGM)\n",
    "    dfCGM.reset_index(drop=True, inplace=True)\n",
    "    print(\"CGM database is limited to the trial period\")\n",
    "    dfCGM.to_pickle(os.path.join(addResults, \"All_cgm.pkl\"))\n",
    "else:\n",
    "    dfCGM = pd.read_pickle(os.path.join(addResults, \"All_cgm.pkl\"))\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addResults, \"All_cm.pkl\")):\n",
    "#     os.remove(os.path.join(addResults, \"All_cm.pkl\"))\n",
    "os.chdir(addHKCM)\n",
    "if not os.path.exists(os.path.join(addResults, \"All_cm.pkl\")):\n",
    "    dfCM = []\n",
    "    for root, dirs, files in os.walk(addHKCM):\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                if \"corrected_cm_all\" in file.lower():\n",
    "                    participantName = file[: file.find(\"_corrected\")]\n",
    "                    if participantName in exempts:\n",
    "                        print(\"Exemption...\", file)\n",
    "                        continue\n",
    "                    print(\"Reading ...\", file)\n",
    "                    dfTemp = pd.read_csv(file)\n",
    "                    print(\"File is read\")\n",
    "                    dfTemp[\"UnixTime\"] = pd.to_datetime(dfTemp[\"UnixTime\"], unit=\"s\")\n",
    "\n",
    "                    dfTemp.rename(columns={\"UnixTime\": \"Time\"}, inplace=True)\n",
    "                    dfTemp.drop(columns=[\"UID\", \"Date\"], inplace=True)\n",
    "                    dfTemp.sort_values([\"Time\"], ascending=(True), inplace=True)\n",
    "                    dfTemp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                    dfTemp = cmSmoother(dfTemp)\n",
    "                    dfTemp[\"Yaw\"] *= 180 / np.pi\n",
    "                    dfTemp[\"Pitch\"] *= 180 / np.pi\n",
    "                    dfTemp[\"Roll\"] *= 180 / np.pi\n",
    "\n",
    "                    dfTemp.insert(0, \"Participant\", participantName)\n",
    "                    # this is to avoid 0 later on for feature calculation\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Ax|+|Ay|+|Az|\", dfTemp[\"Ax\"].abs() + dfTemp[\"Ay\"].abs() + dfTemp[\"Az\"].abs() + 0.0001)\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Yaw|+|Roll|+|Pitch|\", dfTemp[\"Yaw\"].abs() + dfTemp[\"Roll\"].abs() + dfTemp[\"Pitch\"].abs())\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\", dfTemp[\"Rx\"].abs() + dfTemp[\"Ry\"].abs() + dfTemp[\"Rz\"].abs())\n",
    "                    dfTemp[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"] = dfTemp[\"|Rx|+|Ry|+|Rz|To|Ax|+|Ay|+|Az|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"]\n",
    "                    dfTemp.insert(len(dfTemp.columns), \"RotationalToLinear\", dfTemp[\"|Yaw|+|Roll|+|Pitch|\"] / dfTemp[\"|Ax|+|Ay|+|Az|\"])\n",
    "                    print(\"modified\")\n",
    "\n",
    "                    if len(dfTemp.columns) != 15:\n",
    "                        print(\"MAYDAY. Error in reading csv\")\n",
    "                        print(dfTemp.columns)\n",
    "                        break\n",
    "                    if len(dfCM) != 0:\n",
    "                        frames = [dfTemp, dfCM]\n",
    "                        dfCM = pd.concat(frames)\n",
    "                    else:\n",
    "                        dfCM = dfTemp\n",
    "    print(\"Processing is done\")\n",
    "    dfCM = cmLagCorrector(dfCM)\n",
    "    dfCM = trialTimeLimitter(dfCM, \"Time\")\n",
    "    dfCM.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfCM.reset_index(drop=True, inplace=True)\n",
    "    print(\"CM database is limited to the trial period\")\n",
    "    dfCM.to_pickle(os.path.join(addResults, \"All_cm.pkl\"))\n",
    "else:\n",
    "    dfCM = pd.read_pickle(os.path.join(addResults, \"All_cm.pkl\"))\n",
    "\n",
    "\n",
    "def E4Smoother(df):\n",
    "    dfE4EDA = df[df[\"Field\"] == \"EDA\"]\n",
    "    dfE4HR = df[df[\"Field\"] == \"HR\"]\n",
    "    dfE4Temperature = df[df[\"Field\"] == \"Temperature\"]\n",
    "\n",
    "    tempSerie = dfE4EDA[\"Data1\"]\n",
    "    tempSerie = tempSerie.ewm(span=5 * 4).mean()  # Considering the frequency of 4 Hz\n",
    "    dfE4EDA[\"Data1\"] = tempSerie\n",
    "\n",
    "    tempSerie = dfE4HR[\"Data1\"]\n",
    "    tempSerie = tempSerie.ewm(span=5).mean()  # Considering the frequency of 1 Hz\n",
    "    dfE4HR[\"Data1\"] = tempSerie\n",
    "\n",
    "    tempSerie = dfE4Temperature[\"Data1\"]\n",
    "    tempSerie = tempSerie.ewm(span=5 * 4).mean()  # Considering the frequency of 4 Hz\n",
    "    dfE4Temperature[\"Data1\"] = tempSerie\n",
    "    frames = [dfE4EDA, dfE4HR, dfE4Temperature]\n",
    "    df = pd.concat(frames)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# if os.path.exists(os.path.join(addResults, \"All_E4.pkl\")):\n",
    "#     os.remove(os.path.join(addResults, \"All_E4.pkl\"))\n",
    "os.chdir(addE4)\n",
    "# fields=['ACC','BVP','EDA','HR','IBI','TEMP']\n",
    "fields = [\"HR\", \"TEMP\", \"EDA\"]\n",
    "if not os.path.exists(os.path.join(addResults, \"All_E4.pkl\")):\n",
    "    dfE4 = []\n",
    "    for root, dirs, files in os.walk(addE4):\n",
    "        for file in files:\n",
    "            if \".csv\" in file.lower():\n",
    "                participantName = root[root.find(\"E4\") + 3 :]\n",
    "                participantName = participantName[:2]\n",
    "                field = file[: file.find(\".csv\")]\n",
    "                if field not in fields:\n",
    "                    print(\"File name does not comply with analyzed fields\", file)\n",
    "                    continue\n",
    "                print(participantName, field)\n",
    "                if participantName in exempts:\n",
    "                    print(\"Exemption...\", file)\n",
    "                    continue\n",
    "                print(\"Reading ...\", file)\n",
    "                os.chdir(root)\n",
    "                dfTemp = pd.read_csv(file, header=None)\n",
    "                # if field=='ACC':\n",
    "                #     assert len(dfTemp.columns)==3\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     timeStep=1/dfTemp.iloc[1,0]\n",
    "                #     dfTemp.drop([0,1],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Data1',1:'Data2',2:'Data3'}, inplace=True)#x,y,z for data1,data2,data3\n",
    "                #     timeTemp=[]\n",
    "                #     for counter in range(len(dfTemp)):\n",
    "                #         timeTemp.append(timeBase+counter*timeStep)\n",
    "                #     dfTemp.insert(0,'Time',timeTemp)\n",
    "                #     dfTemp.insert(0,'Field',\"Acceleration\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                # if field == \"BVP\":\n",
    "                #     assert len(dfTemp.columns) == 1\n",
    "                #     timeBase = dfTemp.iloc[0, 0]\n",
    "                #     timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                #     dfTemp.drop([0, 1], inplace=True)\n",
    "                #     dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                #     dfTemp[\"Data2\"] = \"\"\n",
    "                #     dfTemp[\"Data3\"] = \"\"\n",
    "                #     timeTemp = []\n",
    "                #     for counter in range(len(dfTemp)):\n",
    "                #         timeTemp.append(timeBase + counter * timeStep)\n",
    "                #     dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                #     dfTemp.insert(0, \"Field\", \"BVP\")\n",
    "                #     dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                if field == \"HR\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"HR\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                elif field == \"EDA\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"EDA\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                # elif field=='IBI':\n",
    "                #     assert len(dfTemp.columns)==2\n",
    "                #     timeBase=dfTemp.iloc[0,0]\n",
    "                #     dfTemp.drop([0],inplace=True)\n",
    "                #     dfTemp.rename(columns={0:'Time',1:'Data1'}, inplace=True)\n",
    "                #     dfTemp[\"Data2\"]=\"\"\n",
    "                #     dfTemp[\"Data3\"]=\"\"\n",
    "                #     timeTemp=[]\n",
    "                #     dfTemp['Time']+=timeBase\n",
    "                #     dfTemp.insert(0,'Field',\"IBI\")\n",
    "                #     dfTemp['Time'] = pd.to_datetime(dfTemp['Time'],unit='s')\n",
    "                elif field == \"TEMP\":\n",
    "                    assert len(dfTemp.columns) == 1\n",
    "                    timeBase = dfTemp.iloc[0, 0]\n",
    "                    timeStep = 1 / dfTemp.iloc[1, 0]\n",
    "                    dfTemp.drop([0, 1], inplace=True)\n",
    "                    dfTemp.rename(columns={0: \"Data1\"}, inplace=True)\n",
    "                    dfTemp[\"Data2\"] = \"\"\n",
    "                    dfTemp[\"Data3\"] = \"\"\n",
    "                    timeTemp = []\n",
    "                    for counter in range(len(dfTemp)):\n",
    "                        timeTemp.append(timeBase + counter * timeStep)\n",
    "                    dfTemp.insert(0, \"Time\", timeTemp)\n",
    "                    dfTemp.insert(0, \"Field\", \"Temperature\")\n",
    "                    dfTemp[\"Time\"] = pd.to_datetime(dfTemp[\"Time\"], unit=\"s\")\n",
    "                dfTemp.insert(0, \"Participant\", participantName)\n",
    "                dfTemp.sort_values([\"Participant\", \"Field\", \"Time\"], ascending=(True, True, True), inplace=True)\n",
    "                dfTemp.reset_index(drop=True, inplace=True)\n",
    "                dfTemp = E4Smoother(dfTemp)\n",
    "                if len(dfTemp.columns) != 6:\n",
    "                    print(\"MAYDAY. Error in reading csv\")\n",
    "                    break\n",
    "                if len(dfE4) != 0:\n",
    "                    frames = [dfTemp, dfE4]\n",
    "                    dfE4 = pd.concat(frames)\n",
    "                else:\n",
    "                    dfE4 = dfTemp\n",
    "    print(\"reading is done\")\n",
    "    dfE4 = timeZoneFixer(dfE4, True, \"Time\")\n",
    "    dfE4.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfE4.reset_index(drop=True, inplace=True)\n",
    "    dfE4 = trialTimeLimitter(dfE4, \"Time\")\n",
    "    dfE4.sort_values([\"Participant\", \"Time\"], ascending=(True, True), inplace=True)\n",
    "    dfE4.reset_index(drop=True, inplace=True)\n",
    "    print(\"E4 database is limited to the trial period\")\n",
    "    dfE4.to_pickle(os.path.join(addResults, \"All_E4.pkl\"))\n",
    "else:\n",
    "    dfE4 = pd.read_pickle(os.path.join(addResults, \"All_E4.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants = list(set(dfCGM[\"Participant\"].to_list()))\n",
    "# participants.sort()\n",
    "# for participant in participants:\n",
    "#     dfCGMTemp = dfCGM[dfCGM[\"Participant\"] == participant]\n",
    "#     dfMealTemp = dfMeal[dfMeal[\"Participant\"] == participant]\n",
    "#     riseDuration = []\n",
    "#     for counter in range(len(dfMealTemp) - 1):\n",
    "#         currentMealStart = dfMealTemp.iloc[counter][\"StartTime\"]\n",
    "#         cgmValBase = dfCGMTemp[dfCGMTemp[\"Time\"] == currentMealStart]\n",
    "\n",
    "#         assert len(cgmValBase) == 1\n",
    "#         cgmValBase = cgmValBase[\"Abbot\"].values[0]\n",
    "#         for counter in range(45):\n",
    "#             timeTempMin = timedelta(minutes=counter)\n",
    "#             cgmVal = dfCGMTemp[dfCGMTemp[\"Time\"] == currentMealStart + timeTempMin]\n",
    "#             assert len(cgmVal) == 1\n",
    "#             cgmVal = cgmVal[\"Abbot\"].values[0]\n",
    "#             if cgmVal - cgmValBase >= 15:\n",
    "#                 riseDuration.append([counter, cgmValBase, cgmVal])\n",
    "#                 break\n",
    "#     riseDuration = np.asarray(riseDuration)\n",
    "#     print(\"BG average rise time for each participants over all meals:\", participant, np.mean(riseDuration[:, 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T1 = datetime.strptime(\"11 06 2021-00:00:00\", \"%m %d %Y-%H:%M:%S\")\n",
    "# T2 = T1 + timedelta(hours=120)\n",
    "# myParticipant = \"p1\"\n",
    "# a = dfE4[dfE4[\"Participant\"] == myParticipant]\n",
    "# a = a[a[\"Field\"] == \"HR\"]\n",
    "# a = a[(a[\"Time\"] >= T1) & (a[\"Time\"] <= T2)]\n",
    "\n",
    "# plt.figure(figsize=(40, 10))\n",
    "# x = a[\"Time\"].to_list()\n",
    "# x = np.asarray(x)\n",
    "# y = a[\"Data1\"].to_list()\n",
    "# plt.scatter(x, y)\n",
    "# plt.grid(which=\"both\", color=\"r\", linestyle=\"-\", linewidth=0.5)\n",
    "# plt.minorticks_on()\n",
    "# plt.xlim([T1, T2])\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(40, 10))\n",
    "# b = dfCM[dfCM[\"Participant\"] == myParticipant]\n",
    "# b = b[(b[\"Time\"] >= T1) & (b[\"Time\"] <= T2)]\n",
    "# x = b[\"Time\"].to_list()\n",
    "# x = np.asarray(x)\n",
    "# y = b[\"Yaw\"].to_list()\n",
    "# y = np.asarray(y) / 10 + 70\n",
    "# plt.scatter(x, y)\n",
    "# plt.grid(which=\"both\", color=\"r\", linestyle=\"-\", linewidth=0.5)\n",
    "# plt.minorticks_on()\n",
    "# plt.xlim([T1, T2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=plt.figure(figsize=(18,24))\n",
    "# plt.subplot(6,1,1)\n",
    "# participant='p8'\n",
    "# colors=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "# T1 = datetime.strptime(\"02 03 2022-12:00:00\", \"%m %d %Y-%H:%M:%S\")  # to handle the daylight saving issue in apple watches\n",
    "# T2 = T1 + timedelta(hours=5)\n",
    "# dfTempCGM=dfCGM[dfCGM['Participant']==participant]\n",
    "# dfTempCGM=dfTempCGM[(dfTempCGM['Time']>=T1) & (dfTempCGM['Time']<T2)]\n",
    "\n",
    "# x=dfTempCGM['Time'].to_list()\n",
    "# y=dfTempCGM['Abbot'].to_list()\n",
    "# y=np.asarray(y).astype(float)\n",
    "# for counter in range(len(x)):\n",
    "#     x[counter]=x[counter].to_pydatetime()\n",
    "#     x[counter]=x[counter].time().hour+x[counter].time().minute/60+x[counter].time().second/3600\n",
    "# x=x[1:len(x):15]\n",
    "# y=y[1:len(y):15]\n",
    "# myAx=plt.plot(x,y, '-*',c=colors[0])\n",
    "# frame1 = plt.gca()\n",
    "# frame1.axes.set_xticks([12,14,16,18])\n",
    "# frame1.axes.minorticks_on()\n",
    "# frame1.axes.set_xticklabels([])\n",
    "# frame1.tick_params('both', length=6, width=1, which='major')\n",
    "# frame1.tick_params('both', length=2, width=1, which='minor')\n",
    "# frame1.axes.set_xlim([12,17])\n",
    "# frame1.axes.yaxis.set_label_coords(-0.1,0.5)\n",
    "# plt.ylabel('BG [mg/dL]')\n",
    "# plt.scatter(x=12+43/60,y=120,color='red')\n",
    "\n",
    "\n",
    "# plt.subplot(6,1,2)\n",
    "# dfTempE4=dfE4[dfE4['Participant']==participant]\n",
    "# dfTempE4=dfTempE4[(dfTempE4['Time']>=T1) & (dfTempE4['Time']<T2) &(dfTempE4['Field']=='HR')]\n",
    "\n",
    "# x=dfTempE4['Time'].to_list()\n",
    "# y=dfTempE4['Data1'].to_list()\n",
    "# y=np.asarray(y).astype(float)\n",
    "# for counter in range(len(x)):\n",
    "#     x[counter]=x[counter].to_pydatetime()\n",
    "#     x[counter]=x[counter].time().hour+x[counter].time().minute/60+x[counter].time().second/3600\n",
    "# myAx=plt.plot(x,y ,'-',c=colors[1])\n",
    "# frame1 = plt.gca()\n",
    "# frame1.axes.set_xticks([12,14,16,18])\n",
    "# frame1.axes.minorticks_on()\n",
    "# frame1.axes.set_xticklabels([])\n",
    "# frame1.tick_params('both', length=6, width=1, which='major')\n",
    "# frame1.tick_params('both', length=2, width=1, which='minor')\n",
    "# frame1.axes.set_xlim([11,17])\n",
    "# frame1.axes.yaxis.set_label_coords(-0.1,0.5)\n",
    "# plt.ylabel('Heart Rate [BPM]')\n",
    "\n",
    "# plt.subplot(6,1,3)\n",
    "# dfTempE4=dfE4[dfE4['Participant']==participant]\n",
    "# dfTempE4=dfTempE4[(dfTempE4['Time']>=T1) & (dfTempE4['Time']<T2) &(dfTempE4['Field']=='Temperature')]\n",
    "\n",
    "# x=dfTempE4['Time'].to_list()\n",
    "# y=dfTempE4['Data1'].to_list()\n",
    "# y=np.asarray(y).astype(float)\n",
    "# for counter in range(len(x)):\n",
    "#     x[counter]=x[counter].to_pydatetime()\n",
    "#     x[counter]=x[counter].time().hour+x[counter].time().minute/60+x[counter].time().second/3600\n",
    "# myAx=plt.plot(x,y ,'-',c=colors[3])\n",
    "# frame1 = plt.gca()\n",
    "# frame1.axes.set_xticks([12,14,16,18])\n",
    "# frame1.axes.minorticks_on()\n",
    "# frame1.axes.set_xticklabels([])\n",
    "# frame1.tick_params('both', length=6, width=1, which='major')\n",
    "# frame1.tick_params('both', length=2, width=1, which='minor')\n",
    "# frame1.axes.set_xlim([12,17])\n",
    "# frame1.axes.yaxis.set_label_coords(-0.1,0.5)\n",
    "# plt.ylabel('Temperature [$^\\circ$C]')\n",
    "\n",
    "\n",
    "# plt.subplot(6,1,4)\n",
    "# dfTempE4=dfE4[dfE4['Participant']==participant]\n",
    "# dfTempE4=dfTempE4[(dfTempE4['Time']>=T1) & (dfTempE4['Time']<T2) &(dfTempE4['Field']=='EDA')]\n",
    "\n",
    "# x=dfTempE4['Time'].to_list()\n",
    "# y=dfTempE4['Data1'].to_list()\n",
    "# y=np.asarray(y).astype(float)\n",
    "# for counter in range(len(x)):\n",
    "#     x[counter]=x[counter].to_pydatetime()\n",
    "#     x[counter]=x[counter].time().hour+x[counter].time().minute/60+x[counter].time().second/3600\n",
    "# myAx=plt.plot(x,y ,'-',c=colors[4])\n",
    "# frame1 = plt.gca()\n",
    "# frame1.axes.set_xticks([12,14,16,18])\n",
    "# frame1.axes.minorticks_on()\n",
    "# frame1.axes.set_xticklabels([])\n",
    "# frame1.tick_params('both', length=6, width=1, which='major')\n",
    "# frame1.tick_params('both', length=2, width=1, which='minor')\n",
    "# frame1.axes.set_xlim([12,17])\n",
    "# frame1.axes.yaxis.set_label_coords(-0.1,0.5)\n",
    "# plt.ylabel('EDA [$^\\mu$S]')\n",
    "\n",
    "\n",
    "# plt.subplot(6,1,5)\n",
    "# dfCMTemp=dfCM[dfCM['Participant']==participant]\n",
    "# dfCMTemp=dfCMTemp[(dfCMTemp['Time']>=T1) & (dfCMTemp['Time']<T2)]\n",
    "\n",
    "# x=dfCMTemp['Time'].to_list()\n",
    "# y=dfCMTemp['Ax'].to_list()\n",
    "# y=np.asarray(y).astype(float)\n",
    "# for counter in range(len(x)):\n",
    "#     x[counter]=x[counter].to_pydatetime()\n",
    "#     x[counter]=x[counter].time().hour+x[counter].time().minute/60+x[counter].time().second/3600\n",
    "# myAx=plt.plot(x,y ,'-',c=colors[5])\n",
    "# frame1 = plt.gca()\n",
    "# frame1 = plt.gca()\n",
    "# frame1.axes.set_xticks([12,14,16,18])\n",
    "# frame1.axes.minorticks_on()\n",
    "# frame1.axes.set_xticklabels([])\n",
    "# frame1.tick_params('both', length=6, width=1, which='major')\n",
    "# frame1.tick_params('both', length=2, width=1, which='minor')\n",
    "# frame1.axes.set_xlim([12,17])\n",
    "# frame1.axes.yaxis.set_label_coords(-0.1,0.5)\n",
    "# plt.ylabel('Acceleration [$m^2$/s]')\n",
    "\n",
    "\n",
    "# plt.subplot(6,1,6)\n",
    "# dfCMTemp=dfCM[dfCM['Participant']==participant]\n",
    "# dfCMTemp=dfCMTemp[(dfCMTemp['Time']>=T1) & (dfCMTemp['Time']<T2)]\n",
    "\n",
    "# x=dfCMTemp['Time'].to_list()\n",
    "# y=dfCMTemp['Yaw'].to_list()\n",
    "# y=np.asarray(y).astype(float)\n",
    "# for counter in range(len(x)):\n",
    "#     x[counter]=x[counter].to_pydatetime()\n",
    "#     x[counter]=x[counter].time().hour+x[counter].time().minute/60+x[counter].time().second/3600\n",
    "# myAx=plt.plot(x,y ,'-',c=colors[6])\n",
    "# frame1 = plt.gca()\n",
    "# frame1.axes.set_xticks([12,14,16,18])\n",
    "# frame1.axes.minorticks_on()\n",
    "# frame1.tick_params('both', length=6, width=1, which='major')\n",
    "# frame1.tick_params('both', length=2, width=1, which='minor')\n",
    "# frame1.axes.set_xlim([12, 17])\n",
    "# frame1.axes.yaxis.set_label_coords(-0.1,0.5)\n",
    "\n",
    "# plt.ylabel('Yaw [$^\\circ$]')\n",
    "# plt.xlabel('Time [hr]')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myParticipant='p8'\n",
    "# dfTempCGM=dfCGM[dfCGM['Participant']==myParticipant]\n",
    "# dfTempEDA=dfE4[dfE4['Participant']==myParticipant]\n",
    "# dfTempEDA=dfTempEDA[dfTempEDA['Field']=='EDA']\n",
    "# dfTempMeal=dfMeal[dfMeal['Participant']==myParticipant]\n",
    "# daysTemp=dfTempMeal['StartTime'].to_list()\n",
    "# days=[]\n",
    "# for myDay in daysTemp:\n",
    "#     days.append(myDay.date())\n",
    "# days=list(set(days))\n",
    "# for myDay in days:\n",
    "#     dfTempMealDay=dfTempMeal[(dfTempMeal['StartTime'].dt.date>=myDay)&(dfTempMeal['StartTime'].dt.date<myDay+timedelta(hours=24))]\n",
    "#     # dfTemp=dfTempEDA[(dfTempEDA['Time'].dt.date>=myDay) & (dfTempEDA['Time'].dt.date<myDay+timedelta(hours=24))]\n",
    "#     # y=dfTemp['Data1'].to_list()\n",
    "    \n",
    "#     dfTemp=dfTempCGM[(dfTempCGM['Time'].dt.date>=myDay) & (dfTempCGM['Time'].dt.date<myDay+timedelta(hours=24))]\n",
    "#     y=dfTemp['Abbot'].to_list()\n",
    "#     x=dfTemp['Time'].to_list()\n",
    "    \n",
    "#     y=np.asarray(y)\n",
    "#     plt.figure(figsize=(15,15))\n",
    "#     plt.plot(x,y)\n",
    "#     for counter in range(len(dfTempMealDay)):\n",
    "#         mealStart=dfTempMealDay['StartTime'].iloc[counter]\n",
    "\n",
    "#         # plt.plot([mealStart,mealStart+timedelta(minutes=15)],[0.2,0.2],color='red')\n",
    "#         plt.plot([mealStart,mealStart+timedelta(minutes=15)],[100,100],color='red')\n",
    "#     # plt.ylim([0,1.5])\n",
    "#     plt.ylim([40,180])\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: p1\n",
      "All windows:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 228/846 [00:24<01:10,  8.82it/s]"
     ]
    }
   ],
   "source": [
    "def e4Reporter(df):\n",
    "    # topics = [\"BVP\", \"EDA\", \"HR\", \"Temperature\"]\n",
    "    sensors = [\"EDA\", \"HR\", \"Temperature\"]\n",
    "    report = []\n",
    "    for sensor in sensors:\n",
    "        dfTemp = df[df[\"Field\"] == sensor]\n",
    "        # if sensor == \"BVP\":\n",
    "        #     MIN_POINT = MINIMUM_POINT * 64 * 0.3\n",
    "        if sensor == \"EDA\":\n",
    "            MIN_POINT = MINIMUM_POINT * 4 * 0.3\n",
    "        elif sensor == \"HR\":\n",
    "            MIN_POINT = MINIMUM_POINT / 10 * 0.3\n",
    "        elif sensor == \"Temperature\":\n",
    "            MIN_POINT = MINIMUM_POINT * 4 * 0.3\n",
    "        else:\n",
    "            print(sensor)\n",
    "            print(\"MAYDAY at sensor reader\")\n",
    "            raise\n",
    "        if len(dfTemp) < MIN_POINT:\n",
    "            report.append(\"Nan\")\n",
    "        else:\n",
    "            val = dfTemp[\"Data1\"].mean()\n",
    "            report.append(val)\n",
    "    return report\n",
    "\n",
    "\n",
    "def motionCalculator(df):\n",
    "    f1 = df[\"RotationalToLinear\"]\n",
    "    f2 = df[\"|Ax|+|Ay|+|Az|\"]\n",
    "    featureData = [f1.mean(skipna=True), f1.std(skipna=True), f1.max(skipna=True) - f1.min(skipna=True), f2.mean(skipna=True), f2.std(skipna=True), f2.max(skipna=True) - f2.min(skipna=True)]\n",
    "    # featureData = [\n",
    "    #     np.mean(f1),\n",
    "    #     np.std(f1),\n",
    "    #     np.max(f1) - np.min(f1),\n",
    "    #     np.mean(f2),\n",
    "    #     np.std(f2),\n",
    "    #     np.max(f2) - np.min(f2),\n",
    "    #     df[\"Ax\"].mean(skipna=True),\n",
    "    #     df[\"Ax\"].std(skipna=True),\n",
    "    #     df[\"Ax\"].skew(skipna=True),\n",
    "    #     df[\"Ax\"].kurtosis(skipna=True),\n",
    "    #     df[\"Ay\"].mean(skipna=True),\n",
    "    #     df[\"Ay\"].std(skipna=True),\n",
    "    #     df[\"Ay\"].skew(skipna=True),\n",
    "    #     df[\"Ay\"].kurtosis(skipna=True),\n",
    "    #     df[\"Az\"].mean(skipna=True),\n",
    "    #     df[\"Az\"].std(skipna=True),\n",
    "    #     df[\"Az\"].skew(skipna=True),\n",
    "    #     df[\"Az\"].kurtosis(skipna=True),\n",
    "    #     df[\"Yaw\"].mean(skipna=True),\n",
    "    #     df[\"Yaw\"].std(skipna=True),\n",
    "    #     df[\"Yaw\"].skew(skipna=True),\n",
    "    #     df[\"Yaw\"].kurtosis(skipna=True),\n",
    "    #     df[\"Pitch\"].mean(skipna=True),\n",
    "    #     df[\"Pitch\"].std(skipna=True),\n",
    "    #     df[\"Pitch\"].skew(skipna=True),\n",
    "    #     df[\"Pitch\"].kurtosis(skipna=True),\n",
    "    #     df[\"Roll\"].mean(skipna=True),\n",
    "    #     df[\"Roll\"].std(skipna=True),\n",
    "    #     df[\"Roll\"].skew(skipna=True),\n",
    "    #     df[\"Roll\"].kurtosis(skipna=True),\n",
    "    # ]\n",
    "    return featureData\n",
    "\n",
    "\n",
    "def CGMStatFeatures(dataList):\n",
    "    nanList = []\n",
    "    for counter in range(24):\n",
    "        nanList.extend([-1000])\n",
    "    return nanList\n",
    "\n",
    "    dataList = np.asarray(dataList).astype(float)\n",
    "    result = []\n",
    "    dataDim = dataList.ndim\n",
    "    assert dataDim == 1\n",
    "    assert len(dataList) == len(dataList[~np.isnan(dataList)])\n",
    "    dataList = dataList[~np.isnan(dataList)]\n",
    "\n",
    "    meanVal = np.nanmean(dataList)\n",
    "    stdVal = np.nanstd(dataList)\n",
    "    minVal = np.nanmin(dataList)\n",
    "    maxVal = np.nanmax(dataList)\n",
    "    rangeVal = maxVal - minVal\n",
    "    skewnessVal = skew(dataList, nan_policy=\"omit\")\n",
    "    kurtosisVal = kurtosis(dataList, nan_policy=\"omit\")\n",
    "\n",
    "    tempSize = int(len(dataList) / 4)\n",
    "    firstFourthSlopeVal = np.mean(dataList[0:tempSize])\n",
    "    secondFourthSlopeVal = np.mean(dataList[tempSize : 2 * tempSize])\n",
    "    thirdFourthSlopeVal = np.mean(dataList[2 * tempSize : 3 * tempSize])\n",
    "    forthFourthSlopeVal = np.mean(dataList[3 * tempSize :])\n",
    "    firstHalfSlopeVal = np.mean(dataList[0 : 2 * tempSize])\n",
    "    secondHalfSlopeVal = np.mean(dataList[2 * tempSize :])\n",
    "\n",
    "    dataListDiff = np.diff(dataList)\n",
    "    meanDiff = np.nanmean(dataListDiff)\n",
    "    stdDiff = np.nanstd(dataListDiff)\n",
    "    minDiff = np.nanmin(dataListDiff)\n",
    "    maxDiff = np.nanmax(dataListDiff)\n",
    "    rangeDiff = maxDiff - minDiff\n",
    "    skewnessDiff = skew(dataListDiff, nan_policy=\"omit\")\n",
    "    kurtosisDiff = kurtosis(dataListDiff, nan_policy=\"omit\")\n",
    "\n",
    "    tempSize = int(len(dataListDiff) / 4)\n",
    "    firstFourthSlopeDiff = np.mean(dataListDiff[0:tempSize])\n",
    "    secondFourthSlopeDiff = np.mean(dataListDiff[tempSize : 2 * tempSize])\n",
    "    thirdFourthSlopeDiff = np.mean(dataListDiff[2 * tempSize : 3 * tempSize])\n",
    "    forthFourthSlopeDiff = np.mean(dataListDiff[3 * tempSize :])\n",
    "    firstHalfSlopeDiff = np.mean(dataList[0 : 2 * tempSize])\n",
    "    secondHalfSlopeDiff = np.mean(dataList[2 * tempSize :])\n",
    "\n",
    "    result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal, firstFourthSlopeVal, secondFourthSlopeVal, thirdFourthSlopeVal, forthFourthSlopeVal, secondHalfSlopeVal - firstHalfSlopeVal])\n",
    "    result.extend([rangeDiff, meanDiff, stdDiff, minDiff, maxDiff, skewnessDiff, kurtosisDiff, firstFourthSlopeDiff, secondFourthSlopeDiff, thirdFourthSlopeDiff, forthFourthSlopeDiff, secondHalfSlopeDiff - firstHalfSlopeDiff])\n",
    "    return result\n",
    "\n",
    "\n",
    "def E4StatFeatures(df):\n",
    "    result = []\n",
    "    nanList = []\n",
    "    # for counter in range(14*3):\n",
    "    for counter in range(14*1):\n",
    "        nanList.extend([np.nan])\n",
    "\n",
    "    # sensors = [\"EDA\", \"HR\", \"Temperature\"]\n",
    "    sensors = [\"EDA\"]\n",
    "    for sensor in sensors:\n",
    "        dfTemp = df[df[\"Field\"] == sensor]\n",
    "        tempVal = dfTemp[\"Data1\"].to_list()\n",
    "\n",
    "        if len(tempVal) < 10:\n",
    "            return nanList\n",
    "        else:\n",
    "            tempVal = np.asarray(tempVal).astype(float)\n",
    "            # tempVal = tempVal[~np.isnan(tempVal).any(axis=1)]\n",
    "            tempVal = tempVal[~np.isnan(tempVal)]\n",
    "\n",
    "            meanVal = np.nanmean(tempVal)\n",
    "            stdVal = np.nanstd(tempVal)\n",
    "            minVal = np.nanmin(tempVal)\n",
    "            maxVal = np.nanmax(tempVal)\n",
    "            rangeVal = maxVal - minVal\n",
    "            skewnessVal = skew(tempVal, nan_policy=\"omit\")\n",
    "            kurtosisVal = kurtosis(tempVal, nan_policy=\"omit\")\n",
    "\n",
    "            dataTempDiff = np.diff(tempVal)\n",
    "            meanDiff = np.nanmean(dataTempDiff)\n",
    "            stdDiff = np.nanstd(dataTempDiff)\n",
    "            minDiff = np.nanmin(dataTempDiff)\n",
    "            maxDiff = np.nanmax(dataTempDiff)\n",
    "            rangeDiff = maxDiff - minDiff\n",
    "            skewnessDiff = skew(dataTempDiff, nan_policy=\"omit\")\n",
    "            kurtosisDiff = kurtosis(dataTempDiff, nan_policy=\"omit\")\n",
    "            result.extend([rangeVal, meanVal, stdVal, minVal, maxVal, skewnessVal, kurtosisVal, rangeDiff, meanDiff, stdDiff, minDiff, maxDiff, skewnessDiff, kurtosisDiff])\n",
    "    return result\n",
    "\n",
    "\n",
    "def innerWindowExtractor(outterWindowStart, innerWindowNumber, dfParticipantCM, dfParticipantE4):\n",
    "    tempListCM = []\n",
    "    tempListE4 = []\n",
    "    for counterInner in range(0, innerWindowNumber, 1):\n",
    "        innerWindowStart = outterWindowStart + counterInner * INNER_WINDOW_LENGTH\n",
    "        innerWindowEnd = innerWindowStart + INNER_WINDOW_LENGTH\n",
    "        dfTempCM = dfParticipantCM[(dfParticipantCM[\"Time\"] >= innerWindowStart) & (dfParticipantCM[\"Time\"] < innerWindowEnd)]\n",
    "        dfTempE4 = dfParticipantE4[(dfParticipantE4[\"Time\"] >= innerWindowStart) & (dfParticipantE4[\"Time\"] < innerWindowEnd)]\n",
    "\n",
    "        if len(dfTempCM) >= MINIMUM_POINT * 10 * 0.3:\n",
    "            tempListCM.append(motionCalculator(dfTempCM))\n",
    "        else:\n",
    "            tempListCM.append([np.nan,np.nan,np.nan,np.nan,np.nan,np.nan])\n",
    "\n",
    "        tempListE4.append(E4StatFeatures(dfTempE4))\n",
    "\n",
    "    # if len(tempListCM) < 0.5 * innerWindowNumber:\n",
    "    #     tempListCM = np.nan\n",
    "\n",
    "    return tempListCM, tempListE4\n",
    "\n",
    "\n",
    "def parallelCall(windowData, dfParticipantCM, dfParticipantE4, dfParticipantCGM):\n",
    "    tempList = []\n",
    "    outterWindowStart = windowData[0]\n",
    "    outterWindowEnd = windowData[1]\n",
    "    innerWindowNumber = windowData[2]\n",
    "    carbs = windowData[3]\n",
    "    fat = windowData[4]\n",
    "    protein = windowData[5]\n",
    "    mealFlag = windowData[6]\n",
    "    participant = windowData[7]\n",
    "    mealStartList = windowData[8]\n",
    "    mealEndList = windowData[9]\n",
    "\n",
    "    dfTempCM = dfParticipantCM[(dfParticipantCM[\"Time\"] >= outterWindowStart) & (dfParticipantCM[\"Time\"] < outterWindowEnd)]\n",
    "    dfTempE4 = dfParticipantE4[(dfParticipantE4[\"Time\"] >= outterWindowStart) & (dfParticipantE4[\"Time\"] < outterWindowEnd)]\n",
    "    dfTempCGM = dfParticipantCGM[(dfParticipantCGM[\"Time\"] >= outterWindowStart) & (dfParticipantCGM[\"Time\"] < outterWindowEnd)]\n",
    "    tempListCM, tempListE4 = innerWindowExtractor(outterWindowStart, innerWindowNumber, dfTempCM, dfTempE4)  ################## MODIFICATION\n",
    "    # tempListCM = motionCalculator(dfTempCM)\n",
    "    # dfTempE4SensorEDA = dfTempE4[dfTempE4[\"Field\"] == \"EDA\"]  ################## MODIFICATION\n",
    "    # dfTempE4SensorHR = dfTempE4[dfTempE4[\"Field\"] == \"HR\"]  ################## MODIFICATION\n",
    "    # dfTempE4SensorTemperature = dfTempE4[dfTempE4[\"Field\"] == \"Temperature\"]  ################## MODIFICATION\n",
    "    # tempListE4 = [dfTempE4SensorEDA[\"Data1\"].to_list(), dfTempE4SensorHR[\"Data1\"].to_list(), dfTempE4SensorTemperature[\"Data1\"].to_list()]  ################## MODIFICATION\n",
    "\n",
    "    tempList.append(tempListCM)  # 1\n",
    "    # tempListE4 = E4StatFeatures(tempListE4)\n",
    "    # tempList.extend(tempListE4)  # 14*3\n",
    "    tempList.append(tempListE4)  # 1\n",
    "\n",
    "    tempListCGM = dfTempCGM[\"Abbot\"].to_list()\n",
    "\n",
    "    tempListCGM = CGMStatFeatures(tempListCGM)\n",
    "    tempList.extend(tempListCGM)  # 24\n",
    "\n",
    "    tempList.append(outterWindowStart)  # 1\n",
    "    tempList.append(outterWindowEnd)  # 1\n",
    "    tempList.append(participant)  # 1\n",
    "\n",
    "    tempList.append(carbs)  # 1\n",
    "    tempList.append(fat)  # 1\n",
    "    tempList.append(protein)  # 1\n",
    "\n",
    "    tempList.append(mealFlag)  # mealFlag\n",
    "    tempList.append(mealStartList)  # mealStarts\n",
    "    tempList.append(mealEndList)  # mealEnds\n",
    "\n",
    "    # assert len(tempList) == 1 + 14 * 3 + 24 + 3 + 3 + 1 + 1 + 1\n",
    "    assert len(tempList) == 1 + 1 + 24 + 3 + 3 + 1 + 1 + 1\n",
    "    return tempList\n",
    "\n",
    "\n",
    "def outterWindowExtractorTotal(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant):\n",
    "    print(\"All windows:\")\n",
    "    participantDataList = []\n",
    "    windowDatas = []\n",
    "    experimentStart = dfParticipantCM[\"Time\"].min()\n",
    "    experimentEnd = dfParticipantCM[\"Time\"].max()\n",
    "\n",
    "    startQuerry = experimentStart\n",
    "    endQuerry = startQuerry + OUTTER_WINDOW_LENGTH\n",
    "    while endQuerry <= experimentEnd:\n",
    "        innerWindowNumber = int(OUTTER_WINDOW_LENGTH.total_seconds() / INNER_WINDOW_LENGTH.total_seconds())\n",
    "        dfTempMeal = dfParticipantMeal[(dfParticipantMeal[\"StartTime\"] <= startQuerry) & (dfParticipantMeal[\"StartTime\"] + timedelta(minutes=15) >= startQuerry)]\n",
    "        # dfTempMeal = dfParticipantMeal[(dfParticipantMeal[\"StartTime\"] >= startQuerry) & (dfParticipantMeal[\"StartTime\"] + timedelta(minutes=15) < endQuerry)]\n",
    "        mealFlag = min(len(dfTempMeal), 1)\n",
    "        carbs = dfTempMeal[\"Carbs\"].sum()\n",
    "        fat = dfTempMeal[\"Fat\"].sum()\n",
    "        protein = dfTempMeal[\"Protein\"].sum()\n",
    "        mealStartList = dfTempMeal[\"StartTime\"].to_list()\n",
    "        mealEndList = dfTempMeal[\"FinishTime\"].to_list()\n",
    "\n",
    "        windowDatas.append([startQuerry, endQuerry, innerWindowNumber, carbs, fat, protein, mealFlag, participant, mealStartList, mealEndList])\n",
    "        startQuerry += OUTTER_WINDOW_STEP\n",
    "        endQuerry += OUTTER_WINDOW_STEP\n",
    "    for counterOuter in tqdm(range(int(len(windowDatas)))):\n",
    "        windowData = windowDatas[counterOuter]\n",
    "        participantDataList.append(parallelCall(windowData, dfParticipantCM, dfParticipantE4, dfParticipantCGM))\n",
    "    # participantDataList = Parallel(n_jobs=coreNumber)(delayed(parallelCall)(windowData, dfParticipantCM, dfParticipantE4, dfParticipantCGM) for windowData in tqdm(windowDatas))\n",
    "    return participantDataList\n",
    "\n",
    "\n",
    "def main():\n",
    "    allDataList = []\n",
    "    participants = dfMeal[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    participants.sort()\n",
    "    columnHeaderList = [\"CM\", \"E4\"]\n",
    "    # sensors = [\"EDA\", \"HR\", \"Temperature\"]\n",
    "    # statFeatureNames = [\"-Range\", \"-Mean\", \"-Std\", \"-Min\", \"-Max\", \"-Skewness\", \"-Kurtosis\", \"-RangeDiff\", \"-MeanDiff\", \"-StdDiff\", \"-MinDiff\", \"-MaxDiff\", \"-SkewnessDiff\", \"-KurtosisDiff\"]\n",
    "    # for sensor in sensors:\n",
    "    #     for statFeatureName in statFeatureNames:\n",
    "    #         columnHeaderList.append(sensor + statFeatureName)\n",
    "\n",
    "    statFeatureNames = [\"-Range\", \"-Mean\", \"-STD\", \"-Min\", \"-Max\", \"-Skewness\", \"-Kurtosis\", \"-FirstFourthSlope\", \"-SecondFourthSlope\", \"-ThirdFourthSlope\", \"-FourthFourthSlope\", \"-HalvesSlope\"]\n",
    "    statFeatureNames.extend([\"-RangeDiff\", \"-MeanDiff\", \"-STDDiff\", \"-MinDiff\", \"-MaxDiff\", \"-SkewnessDiff\", \"-KurtosisDiff\", \"-FirstFourthSlopeDiff\", \"-SecondFourthSlopeDiff\", \"-ThirdFourthSlopeDiff\", \"-FourthFourthSlopeDiff\", \"-HalvesSlopeDiff\"])\n",
    "    for statFeatureName in statFeatureNames:\n",
    "        columnHeaderList.append(\"CGM\" + statFeatureName)\n",
    "    columnHeaderList.extend([\"StartTime\", \"FinishTime\", \"Participant\", \"Carb\", \"Fat\", \"Protein\", \"MealLabel\", \"MealStartList\", \"MealEndList\"])\n",
    "    for participant in participants:\n",
    "        print(\"Participant:\", participant)\n",
    "        if participant in exempts:\n",
    "            continue\n",
    "        # if participant != \"p7\":\n",
    "        #     continue\n",
    "        dfParticipantMeal = dfMeal[dfMeal[\"Participant\"] == participant]\n",
    "        dfParticipantCM = dfCM[dfCM[\"Participant\"] == participant]\n",
    "        dfParticipantE4 = dfE4[dfE4[\"Participant\"] == participant]\n",
    "        dfParticipantCGM = dfCGM[dfCGM[\"Participant\"] == participant]\n",
    "        participantDataList = outterWindowExtractorTotal(dfParticipantMeal, dfParticipantCM, dfParticipantE4, dfParticipantCGM, participant)\n",
    "\n",
    "        participantDataList = pd.DataFrame(participantDataList, columns=columnHeaderList)\n",
    "        if len(allDataList) == 0:\n",
    "            allDataList = participantDataList\n",
    "        else:\n",
    "            frames = [allDataList, participantDataList]\n",
    "            allDataList = pd.concat(frames)\n",
    "    allDataList.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    allDataList.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    allDataList = allDataList.dropna()\n",
    "\n",
    "    allDataList.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "    allDataList.reset_index(drop=True, inplace=True)\n",
    "    allDataList.to_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.pkl\")))\n",
    "    return allDataList\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.pkl\"))):\n",
    "    os.remove(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.pkl\")))\n",
    "if not os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.pkl\"))):\n",
    "    dfAllFeatures = main()\n",
    "else:\n",
    "    dfAllFeatures = pd.read_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.pkl\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC: 0.5359914708114548 Acc: 0.7909957953030459 Rec: 0.19160104986876642 Precision: 0.01900546732621713 F1: 0.03458076740881099\n",
      "ROC: 0.5143245783414669 Acc: 0.7850989642087991 Rec: 0.2125984251968504 Precision: 0.02039274924471299 F1: 0.037215713301171606\n",
      "ROC: 0.5206568172493422 Acc: 0.7626397292585376 Rec: 0.2099737532808399 Precision: 0.018148820326678767 F1: 0.03340989768218835\n",
      "ROC: 0.5397201951482006 Acc: 0.7061176349930772 Rec: 0.34908136482939633 Precision: 0.023682336182336183 F1: 0.04435551108887777\n",
      "ROC: 0.49823692605892883 Acc: 0.66037639095431 Rec: 0.30708661417322836 Precision: 0.018066707844348363 F1: 0.034125710952311504\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 168>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=165'>166</a>\u001b[0m dfAllFeatures \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(addResults, (\u001b[39mstr\u001b[39m(OUTTER_WINDOW_LENGTH) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(FASTING_LENGTH) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-All-Features.pkl\u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=166'>167</a>\u001b[0m dfAllFeatures \u001b[39m=\u001b[39m dfAllFeatures\u001b[39m.\u001b[39mdropna()\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=167'>168</a>\u001b[0m CMData,CMLabel\u001b[39m=\u001b[39mtrainTestTAMU(dfAllFeatures)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=168'>169</a>\u001b[0m \u001b[39m# raise\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=169'>170</a>\u001b[0m dfAllFeatures\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb Cell 12'\u001b[0m in \u001b[0;36mtrainTestTAMU\u001b[0;34m(dfAllFeatures)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=158'>159</a>\u001b[0m     f1Score \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mf1_score(yTest, predictionsTest)\u001b[39m#, average=\"weighted\")\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=159'>160</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mROC:\u001b[39m\u001b[39m\"\u001b[39m,rocAuc,\u001b[39m\"\u001b[39m\u001b[39mAcc:\u001b[39m\u001b[39m\"\u001b[39m,accuracy,\u001b[39m\"\u001b[39m\u001b[39mRec:\u001b[39m\u001b[39m\"\u001b[39m,recall,\u001b[39m\"\u001b[39m\u001b[39mPrecision:\u001b[39m\u001b[39m\"\u001b[39m,precision,\u001b[39m\"\u001b[39m\u001b[39mF1:\u001b[39m\u001b[39m\"\u001b[39m,f1Score)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=160'>161</a>\u001b[0m \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000011vscode-remote?line=161'>162</a>\u001b[0m \u001b[39mreturn\u001b[39;00m CMData,CMLabel\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "def meanSTDFinder(df):\n",
    "    cmData = []\n",
    "    for counter in range(len(df)):\n",
    "        elements = df[\"CM\"].iloc[counter]\n",
    "        for element in elements:\n",
    "            cmData.append(element)\n",
    "    cmData = np.asarray(cmData).astype(float)\n",
    "    cmDataMean = np.nanmean(cmData, axis=0)\n",
    "    cmDataStd = np.nanstd(cmData, axis=0)\n",
    "    return cmDataMean, cmDataStd\n",
    "\n",
    "\n",
    "def cmNormalizerPredictor(element, cmDataMean, cmDataStd, hooverModel):\n",
    "    element = np.asarray(element).astype(float)\n",
    "    element -= cmDataMean\n",
    "    element /= cmDataStd\n",
    "    element = np.expand_dims(element, axis=0)\n",
    "    # print(element)\n",
    "    hooverPrediction = hooverModel.predict_proba(element)\n",
    "    hooverPrediction = hooverPrediction[0, 1]\n",
    "    return hooverPrediction\n",
    "\n",
    "\n",
    "def maxProbWinodFinder(tempPredictions):  # we are finding the maximum probability for a 5-min period which is located 15-min sooner than the end of the windows 15+5=20 min\n",
    "    augmentationPeriod=timedelta(minutes=5)\n",
    "    assert OUTTER_WINDOW_LENGTH >= augmentationPeriod\n",
    "    augmentationPeriod = int(augmentationPeriod.seconds / INNER_WINDOW_LENGTH.seconds)\n",
    "    if len(tempPredictions) <= augmentationPeriod:\n",
    "        return 0\n",
    "    tempMax = -1\n",
    "    for innerCounter in range(len(tempPredictions) - augmentationPeriod):\n",
    "        tempArray = np.asarray(tempPredictions[innerCounter : innerCounter + augmentationPeriod])\n",
    "        tempArray = np.mean(tempArray)\n",
    "        if tempArray > tempMax:\n",
    "            tempMax = tempArray\n",
    "    assert tempMax >= 0\n",
    "    return tempMax\n",
    "\n",
    "\n",
    "def hooverPredictor(dfAllFeatures):\n",
    "    hooverModelAdd = \"/home/grads/s/sorush.omidvar/CGMDataset/Hoover/HooverModel-0.5.sav\"\n",
    "    hooverModel = pickle.load(open(hooverModelAdd, \"rb\"))\n",
    "    hooverModel.n_jobs = coreNumber\n",
    "\n",
    "    participants = dfAllFeatures[\"Participant\"].to_list()\n",
    "    participants = list(set(participants))\n",
    "    participants.sort()\n",
    "    dfTotal = []\n",
    "    fig = plt.figure(figsize=(10, 15))\n",
    "    subplotCounter = 1\n",
    "    cmDataMean, cmDataStd = meanSTDFinder(dfAllFeatures)\n",
    "    for participant in participants:\n",
    "        dfTemp = dfAllFeatures[dfAllFeatures[\"Participant\"] == participant]\n",
    "        predictions = []\n",
    "        groundTruth = []\n",
    "        for counter in tqdm(range(len(dfTemp))):\n",
    "            elements = dfTemp[\"CM\"].iloc[counter]\n",
    "            tempPredictions = []\n",
    "            for element in elements:\n",
    "                tempPredictions.append(cmNormalizerPredictor(element, cmDataMean, cmDataStd, hooverModel))########MODIFICATION\n",
    "            # tempPredictions.append(cmNormalizerPredictor(elements, cmDataMean, cmDataStd, hooverModel))\n",
    "            dfTemp.iloc[counter, 0] = maxProbWinodFinder(tempPredictions)\n",
    "\n",
    "        dfTemp = dfTemp.dropna()\n",
    "        dfTemp.reset_index(drop=True, inplace=True)\n",
    "        if len(dfTotal) != 0:\n",
    "            frames = [dfTotal, dfTemp]\n",
    "            dfTotal = pd.concat(frames)\n",
    "        else:\n",
    "            dfTotal = dfTemp\n",
    "        predictions = dfTemp[\"CM\"].to_list()\n",
    "        groundTruth = dfTemp[\"MealLabel\"].to_list()\n",
    "\n",
    "        print(\"Participant:\", participant, \" with total:\", len(groundTruth), \"Positive windows:\", np.sum(groundTruth))\n",
    "        fpr, tpr, thresholds = roc_curve(groundTruth, predictions, pos_label=1)\n",
    "        print(roc_auc_score(groundTruth, predictions, average=\"weighted\"))\n",
    "        plt.subplot(3, 2, subplotCounter)\n",
    "        if subplotCounter % 2 == 1:\n",
    "            plt.ylabel(\"TPR\")\n",
    "            plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [\"0.0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"])\n",
    "        else:\n",
    "            plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [])\n",
    "        if subplotCounter >= 5:\n",
    "            plt.xlabel(\"FPR\")\n",
    "            plt.xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [\"0.0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"])\n",
    "        else:\n",
    "            plt.xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [])\n",
    "\n",
    "        plt.plot(fpr, tpr, label=participant.capitalize() + \" AUC=\" + str(np.round(roc_auc_score(groundTruth, predictions, average=\"weighted\"), 3)))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.plot([0, 1], [0, 1], \"r:\")\n",
    "        subplotCounter += 1\n",
    "    plt.suptitle(\"Outer Window=\" + str(OUTTER_WINDOW_LENGTH.total_seconds() / 60) + \" min\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-ROC.jpg\")), dpi=600)\n",
    "    plt.show()\n",
    "    return dfTotal\n",
    "\n",
    "def trainTestTAMU(dfAllFeatures):\n",
    "    CMLabel=[]\n",
    "    CMData=[]\n",
    "    # dfAllFeatures=dfAllFeatures[dfAllFeatures['Participant']=='p6']\n",
    "    # print(list(set(dfAllFeatures['Participant'].to_list())))\n",
    "    for counter in range(len(dfAllFeatures)):\n",
    "        mealFlag=dfAllFeatures.loc[counter,'MealLabel']\n",
    "        cmDataTemp=dfAllFeatures.loc[counter,'E4']\n",
    "        if mealFlag==0:\n",
    "            for innerCounter in range(len(cmDataTemp)):\n",
    "                CMData.append(cmDataTemp[innerCounter])\n",
    "                CMLabel.append(0)\n",
    "        else:\n",
    "            mealStart=dfAllFeatures.loc[counter,'MealStartList']\n",
    "            mealStart=mealStart[0]\n",
    "\n",
    "            windowStart=dfAllFeatures.loc[counter,\"StartTime\"]\n",
    "            if windowStart>=mealStart:\n",
    "                mealStartIndex=0\n",
    "                mealEndIndex=windowStart-mealStart\n",
    "                mealEndIndex=15-int(mealEndIndex.seconds/60)\n",
    "            else:\n",
    "                mealStartIndex=mealStart-windowStart\n",
    "                mealStartIndex=int(mealStartIndex.seconds/60)                \n",
    "                mealEndIndex=mealStartIndex+15\n",
    "            for innerCounter in range(len(cmDataTemp)):\n",
    "                CMData.append(cmDataTemp[innerCounter])\n",
    "                if innerCounter>=mealStartIndex and innerCounter<mealEndIndex:\n",
    "                    CMLabel.append(1)\n",
    "                else:\n",
    "                    CMLabel.append(0)\n",
    "            # print(mealStart,windowStart,dfAllFeatures.loc[counter,'Participant'])\n",
    "            # print(CMLabel[-30:])\n",
    "            # raise\n",
    "\n",
    "    CMData=np.asarray(CMData)\n",
    "    CMLabel=np.asarray(CMLabel)\n",
    "\n",
    "    nanIndices=np.argwhere(np.isnan(CMData).any(axis=1))\n",
    "    nanIndices=np.asarray(nanIndices,dtype=int)\n",
    "\n",
    "    CMLabel[nanIndices]=-1\n",
    "    CMLabel=CMLabel[CMLabel!=-1]\n",
    "    CMData=CMData[~np.isnan(CMData).any(axis=1)]\n",
    "\n",
    "    splitter=StratifiedKFold(n_splits=5,shuffle=False)\n",
    "    for train_index, test_index in splitter.split(CMData, CMLabel):\n",
    "        xTrain, xTest = CMData[train_index,:], CMData[test_index,:]\n",
    "        yTrain, yTest = CMLabel[train_index], CMLabel[test_index]\n",
    "        clf = xgb.XGBClassifier(scale_pos_weight=len(yTrain) / np.sum(yTrain), n_jobs=coreNumber, n_estimators=250, max_depth=3, objective=\"binary:logistic\", eval_metric=\"error\")\n",
    "        clf.fit(xTrain, yTrain)\n",
    "\n",
    "        predictionsTest = clf.predict_proba(xTest)\n",
    "        predictionsTest = predictionsTest[:, 1]\n",
    "        rocAuc = roc_auc_score(yTest, predictionsTest, average=\"weighted\")\n",
    "        \n",
    "        predictionsTest = clf.predict(xTest)\n",
    "        accuracy = sklearn.metrics.accuracy_score(yTest, predictionsTest)\n",
    "        recall = sklearn.metrics.recall_score(yTest, predictionsTest)\n",
    "        precision = sklearn.metrics.precision_score(yTest, predictionsTest)\n",
    "        f1Score = sklearn.metrics.f1_score(yTest, predictionsTest)#, average=\"weighted\")\n",
    "        print(\"ROC:\",rocAuc,\"Acc:\",accuracy,\"Rec:\",recall,\"Precision:\",precision,\"F1:\",f1Score)\n",
    "    raise\n",
    "    return CMData,CMLabel\n",
    "\n",
    "        \n",
    "\n",
    "dfAllFeatures = pd.read_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features.pkl\")))\n",
    "dfAllFeatures = dfAllFeatures.dropna()\n",
    "CMData,CMLabel=trainTestTAMU(dfAllFeatures)\n",
    "# raise\n",
    "dfAllFeatures.reset_index(drop=True, inplace=True)\n",
    "dfAllFeaturesHoover = hooverPredictor(dfAllFeatures)\n",
    "dfAllFeaturesHoover = dfAllFeaturesHoover.dropna()\n",
    "dfAllFeatures.reset_index(drop=True, inplace=True)\n",
    "dfAllFeaturesHoover.to_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features-AfterHoover.pkl\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Samples: 4845\n",
      "----------------------\n",
      "Combination: CM\n",
      "************************* Participant: p1\n",
      "************************* Participant: p3\n",
      "************************* Participant: p5\n",
      "************************* Participant: p6\n",
      "************************* Participant: p7\n",
      "************************* Participant: p8\n",
      "Outter: 0:30:00 Fasting: 0:30:00\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def xgClassifier(xTrain, xTest, yTrain, yTest):\n",
    "    clf = xgb.XGBClassifier(scale_pos_weight=len(yTrain) / np.sum(yTrain), n_jobs=coreNumber, n_estimators=250, max_depth=3, objective=\"binary:logistic\", eval_metric=\"error\")\n",
    "    clf.fit(xTrain, yTrain)\n",
    "\n",
    "    predictionsTest = clf.predict_proba(xTest)\n",
    "    predictionsTest = predictionsTest[:, 1]\n",
    "    rocAuc = roc_auc_score(yTest, predictionsTest, average=\"weighted\")\n",
    "\n",
    "    # fpr, tpr, thresholds = roc_curve(yTest, predictionsTest, pos_label=1)\n",
    "    # plt.xlabel(\"FPR\")\n",
    "    # plt.ylabel(\"TPR\")\n",
    "    # plt.title(\"ROC-AUC:\" + str(np.round(roc_auc_score(yTest, predictionsTest,average='weighted'), 3)))\n",
    "    # plt.scatter(fpr, tpr)\n",
    "    # plt.plot([0, 0], [1, 1], color=\"red\")\n",
    "    # plt.show()\n",
    "\n",
    "    predictionsTest = clf.predict(xTest)\n",
    "    accuracy = sklearn.metrics.accuracy_score(yTest, predictionsTest)\n",
    "    recall = sklearn.metrics.recall_score(yTest, predictionsTest)\n",
    "    precision = sklearn.metrics.precision_score(yTest, predictionsTest)\n",
    "    f1Score = sklearn.metrics.f1_score(yTest, predictionsTest, average=\"weighted\")\n",
    "    featureImportance = clf.feature_importances_\n",
    "    statFeatureNames = [\n",
    "        \"-Range\",\n",
    "        \"-Mean\",\n",
    "        \"-STD\",\n",
    "        \"-Min\",\n",
    "        \"-Max\",\n",
    "        \"-Skewness\",\n",
    "        \"-Kurtosis\",\n",
    "        \"-FirstFourthSlope\",\n",
    "        \"-SecondFourthSlope\",\n",
    "        \"-ThirdFourthSlope\",\n",
    "        \"-FourthFourthSlope\",\n",
    "        \"-HalvesSlope\",\n",
    "        \"-RangeDiff\",\n",
    "        \"-MeanDiff\",\n",
    "        \"-STDDiff\",\n",
    "        \"-MinDiff\",\n",
    "        \"-MaxDiff\",\n",
    "        \"-SkewnessDiff\",\n",
    "        \"-KurtosisDiff\",\n",
    "        \"-FirstFourthSlopeDiff\",\n",
    "        \"-SecondFourthSlopeDiff\",\n",
    "        \"-ThirdFourthSlopeDiff\",\n",
    "        \"-FourthFourthSlopeDiff\",\n",
    "        \"-HalvesSlopeDiff\",\n",
    "    ]\n",
    "    featureImportance = dict(zip(statFeatureNames, featureImportance))\n",
    "\n",
    "    return [rocAuc, accuracy, recall, precision, f1Score, np.sum(yTest), len(yTest) - np.sum(yTest), featureImportance, yTest, predictionsTest]\n",
    "\n",
    "\n",
    "def lrClassifier(xTrain, xTest, yTrain, yTest):\n",
    "    clf = LogisticRegression(random_state=0, class_weight=\"balanced\", n_jobs=coreNumber)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "\n",
    "    predictionsTest = clf.predict_proba(xTest)\n",
    "    predictionsTest = predictionsTest[:, 1]\n",
    "    rocAuc = roc_auc_score(yTest, predictionsTest, average=\"weighted\")\n",
    "\n",
    "    # fpr, tpr, thresholds = roc_curve(yTest, predictionsTest, pos_label=1)\n",
    "    # plt.xlabel(\"FPR\")\n",
    "    # plt.ylabel(\"TPR\")\n",
    "    # plt.title(\"ROC-AUC:\" + str(np.round(roc_auc_score(yTest, predictionsTest,average='weighted'), 3)))\n",
    "    # plt.scatter(fpr, tpr)\n",
    "    # plt.plot([0, 0], [1, 1], color=\"red\")\n",
    "    # plt.show()\n",
    "\n",
    "    predictionsTest = clf.predict(xTest)\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(yTest, predictionsTest)\n",
    "    recall = sklearn.metrics.recall_score(yTest, predictionsTest)\n",
    "    precision = sklearn.metrics.precision_score(yTest, predictionsTest)\n",
    "    f1Score = sklearn.metrics.f1_score(yTest, predictionsTest, average=\"weighted\")\n",
    "    featureImportance = clf.coef_\n",
    "    featureImportance = featureImportance[0]\n",
    "    statFeatureNames = [\n",
    "        \"-Range\",\n",
    "        \"-Mean\",\n",
    "        \"-STD\",\n",
    "        \"-Min\",\n",
    "        \"-Max\",\n",
    "        \"-Skewness\",\n",
    "        \"-Kurtosis\",\n",
    "        \"-FirstFourthSlope\",\n",
    "        \"-SecondFourthSlope\",\n",
    "        \"-ThirdFourthSlope\",\n",
    "        \"-FourthFourthSlope\",\n",
    "        \"-HalvesSlope\",\n",
    "        \"-RangeDiff\",\n",
    "        \"-MeanDiff\",\n",
    "        \"-STDDiff\",\n",
    "        \"-MinDiff\",\n",
    "        \"-MaxDiff\",\n",
    "        \"-SkewnessDiff\",\n",
    "        \"-KurtosisDiff\",\n",
    "        \"-FirstFourthSlopeDiff\",\n",
    "        \"-SecondFourthSlopeDiff\",\n",
    "        \"-ThirdFourthSlopeDiff\",\n",
    "        \"-FourthFourthSlopeDiff\",\n",
    "        \"-HalvesSlopeDiff\",\n",
    "    ]\n",
    "    featureImportance = dict(zip(statFeatureNames, featureImportance))\n",
    "    return [rocAuc, accuracy, recall, precision, f1Score, np.sum(yTest), len(yTest) - np.sum(yTest), featureImportance, yTest, predictionsTest]\n",
    "\n",
    "\n",
    "def rfClassifier(xTrain, xTest, yTrain, yTest):\n",
    "    clf = RandomForestClassifier(max_depth=3, random_state=0, n_jobs=coreNumber, class_weight=\"balanced\")\n",
    "    clf.fit(xTrain, yTrain)\n",
    "\n",
    "    predictionsTest = clf.predict_proba(xTest)\n",
    "    predictionsTest = predictionsTest[:, 1]\n",
    "    rocAuc = roc_auc_score(yTest, predictionsTest, average=\"weighted\")\n",
    "\n",
    "    # fpr, tpr, thresholds = roc_curve(yTest, predictionsTest, pos_label=1)\n",
    "    # plt.xlabel(\"FPR\")\n",
    "    # plt.ylabel(\"TPR\")\n",
    "    # plt.title(\"ROC-AUC:\" + str(np.round(roc_auc_score(yTest, predictionsTest,average='weighted'), 3)))\n",
    "    # plt.scatter(fpr, tpr)\n",
    "    # plt.plot([0, 0], [1, 1], color=\"red\")\n",
    "    # plt.show()\n",
    "\n",
    "    predictionsTest = clf.predict(xTest)\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(yTest, predictionsTest)\n",
    "    recall = sklearn.metrics.recall_score(yTest, predictionsTest)\n",
    "    precision = sklearn.metrics.precision_score(yTest, predictionsTest)\n",
    "    f1Score = sklearn.metrics.f1_score(yTest, predictionsTest, average=\"weighted\")\n",
    "    featureImportance = clf.feature_importances_\n",
    "    statFeatureNames = [\n",
    "        \"-Range\",\n",
    "        \"-Mean\",\n",
    "        \"-STD\",\n",
    "        \"-Min\",\n",
    "        \"-Max\",\n",
    "        \"-Skewness\",\n",
    "        \"-Kurtosis\",\n",
    "        \"-FirstFourthSlope\",\n",
    "        \"-SecondFourthSlope\",\n",
    "        \"-ThirdFourthSlope\",\n",
    "        \"-FourthFourthSlope\",\n",
    "        \"-HalvesSlope\",\n",
    "        \"-RangeDiff\",\n",
    "        \"-MeanDiff\",\n",
    "        \"-STDDiff\",\n",
    "        \"-MinDiff\",\n",
    "        \"-MaxDiff\",\n",
    "        \"-SkewnessDiff\",\n",
    "        \"-KurtosisDiff\",\n",
    "        \"-FirstFourthSlopeDiff\",\n",
    "        \"-SecondFourthSlopeDiff\",\n",
    "        \"-ThirdFourthSlopeDiff\",\n",
    "        \"-FourthFourthSlopeDiff\",\n",
    "        \"-HalvesSlopeDiff\",\n",
    "    ]\n",
    "    featureImportance = dict(zip(statFeatureNames, featureImportance))\n",
    "    return [rocAuc, accuracy, recall, precision, f1Score, np.sum(yTest), len(yTest) - np.sum(yTest), featureImportance, yTest, predictionsTest]\n",
    "\n",
    "\n",
    "def testTrainSplit(dfParticipant, participant, combination, normalFlag):\n",
    "    dfParticipant.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "\n",
    "    yDataBinary = dfParticipant[\"MealLabel\"].to_list()\n",
    "    yDataBinary = np.asarray(yDataBinary).astype(int)\n",
    "    timingInfo = dfParticipant[[\"StartTime\", \"FinishTime\", \"MealStartList\", \"MealEndList\"]].values\n",
    "    dfParticipant.drop(columns=[\"StartTime\", \"FinishTime\", \"MealLabel\", \"Participant\", \"Carb\", \"Fat\", \"Protein\", \"MealStartList\", \"MealEndList\"], inplace=True)\n",
    "\n",
    "    xDataBinary = dfParticipant.values\n",
    "    xDataBinary = np.asarray(xDataBinary).astype(float)\n",
    "\n",
    "    classifierReport = []\n",
    "    if normalFlag:\n",
    "        xDataBinary -= np.mean(xDataBinary, axis=0)\n",
    "        xDataBinary /= np.std(xDataBinary, axis=0)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "    setNumber = 0\n",
    "    comprehensive = []\n",
    "    for trainIndex, testIndex in skf.split(xDataBinary, yDataBinary):\n",
    "        xTrain, xTest = xDataBinary[trainIndex, :], xDataBinary[testIndex, :]\n",
    "        yTrain, yTest = yDataBinary[trainIndex], yDataBinary[testIndex]\n",
    "\n",
    "        timingInfoTest = timingInfo[testIndex, :]\n",
    "        comprehensiveCGM = []\n",
    "        for element in timingInfoTest:\n",
    "            dfCGMTemp = dfCGM[dfCGM[\"Participant\"] == participant]\n",
    "            dfCGMTemp = dfCGMTemp[dfCGMTemp[\"Time\"] >= element[0]]\n",
    "            dfCGMTemp = dfCGMTemp[dfCGMTemp[\"Time\"] < element[1]]\n",
    "            comprehensiveCGM.append(dfCGMTemp[\"Abbot\"].to_list())\n",
    "\n",
    "        tempListReport = xgClassifier(xTrain, xTest, yTrain, yTest)\n",
    "        # tempListReport = lrClassifier(xTrain, xTest, yTrain, yTest)\n",
    "        # tempListReport = rfClassifier(xTrain, xTest, yTrain, yTest)\n",
    "\n",
    "        tempListReport.extend([participant, combination, setNumber])\n",
    "        classifierReport.append(tempListReport)\n",
    "\n",
    "        comprehensiveCGM = np.asarray(comprehensiveCGM)\n",
    "        comprehensiveCGM = np.concatenate((comprehensiveCGM, timingInfoTest), axis=1)\n",
    "\n",
    "        predVal = tempListReport[-4]\n",
    "        groundTruthVal = tempListReport[-5]\n",
    "\n",
    "        predVal = np.asarray(predVal)\n",
    "        groundTruthVal = np.asarray(groundTruthVal)\n",
    "\n",
    "        predVal = np.expand_dims(predVal, axis=1)\n",
    "        groundTruthVal = np.expand_dims(groundTruthVal, axis=1)\n",
    "        tempArray = np.repeat(participant, len(predVal))\n",
    "        tempArray = np.expand_dims(tempArray, axis=1)\n",
    "        comprehensiveCGM = np.concatenate((comprehensiveCGM, groundTruthVal, predVal, tempArray), axis=1)\n",
    "        if len(comprehensive) == 0:\n",
    "            comprehensive = comprehensiveCGM\n",
    "        else:\n",
    "            comprehensive = np.concatenate((comprehensive, comprehensiveCGM), axis=0)\n",
    "\n",
    "        setNumber += 1\n",
    "    # comprehensiveHeaders=[]\n",
    "    # for counter in range(60):\n",
    "    #     comprehensiveHeaders.append(\"CGM-\"+str(counter))\n",
    "    # comprehensiveHeaders.extend([\"WindowStart\",\"WindowEnd\",\"MealStart\",\"MealEnd\",\"Truth\",\"Pred\",\"Participant\"])\n",
    "    # comprehensive=pd.DataFrame(comprehensive,columns=comprehensiveHeaders)\n",
    "    # comprehensive.to_excel(os.path.join(addResults,\"comprehensive.xlsx\"))\n",
    "    # mealStartTemp=comprehensive[\"MealStart\"].iloc[counter]\n",
    "    # for counter in range(len(comprehensive)):\n",
    "    #     if comprehensive[\"Truth\"].iloc[counter]==comprehensive[\"Pred\"].iloc[counter]:\n",
    "    #         continue\n",
    "    #     plt.figure(figsize=(10,10))\n",
    "    #     if len(comprehensive[\"MealStart\"].iloc[counter])==0:\n",
    "    #         myColor='red'\n",
    "    #     else:\n",
    "\n",
    "    #         plt.scatter(mealStartTemp[0],100)\n",
    "    #         myColor='blue'\n",
    "    # print(comprehensive[\"WindowStart\"].iloc[counter],comprehensive[\"WindowEnd\"].iloc[counter],comprehensive[\"MealStart\"].iloc[counter])\n",
    "    # xVals=[]\n",
    "    # for minuteCounter in range(60):\n",
    "    #     xVals.append(comprehensive[\"WindowStart\"].iloc[counter]+timedelta(minutes=minuteCounter))\n",
    "    # xVals=np.asarray(xVals)\n",
    "\n",
    "    # yVals=comprehensive.iloc[counter,0:60].values\n",
    "    # yVals=np.asarray(yVals)\n",
    "\n",
    "    # plt.plot(xVals,yVals,color=myColor)\n",
    "\n",
    "    # plt.ylim([60,160])\n",
    "    # plt.show()\n",
    "\n",
    "    return classifierReport\n",
    "\n",
    "\n",
    "def predictionMain(dfCombination, randomSeed, normalFlag, combination):\n",
    "    participants = list(set(dfCombination[\"Participant\"].to_list()))\n",
    "    participants.sort()\n",
    "    classifierReports = []\n",
    "    # for participantCounter in tqdm(range(len(participants) + 1)):\n",
    "    for participantCounter in range(len(participants)):\n",
    "        if participantCounter == len(participants):  # General Model (one model for all participants)\n",
    "            dfParticipant = dfCombination\n",
    "            participant = \"All\"\n",
    "        else:  # Personal Model (each participant have a his/her own model)\n",
    "            participant = participants[participantCounter]\n",
    "            dfParticipant = dfCombination[dfCombination[\"Participant\"] == participant]\n",
    "        dfParticipant.sort_values([\"Participant\", \"StartTime\"], ascending=(True, True), inplace=True)\n",
    "        print(\"*************************\", \"Participant:\", participant)\n",
    "        classifierReports.extend(testTrainSplit(dfParticipant, participant, combination, normalFlag))\n",
    "    return classifierReports\n",
    "\n",
    "\n",
    "def featureImportanceAverager(featureImportances):\n",
    "    tempVals = []\n",
    "    tempLabels = []\n",
    "    for featureImportance in featureImportances:\n",
    "        tempVals.append(list(featureImportance.values()))\n",
    "        tempLabels = list(featureImportance.keys())\n",
    "    featureImportances = np.asarray(tempVals)\n",
    "    featureImportances = np.mean(featureImportances, axis=0)\n",
    "    featureImportances = dict(zip(tempLabels, featureImportances))\n",
    "    featureImportances = dict(sorted(featureImportances.items(), key=lambda item: item[1], reverse=True))\n",
    "    featureImportances = [[featureImportances]]\n",
    "    return featureImportances\n",
    "\n",
    "\n",
    "def foldSummarizerBinary(df):\n",
    "    combinations = list(set(df[\"Combination\"].to_list()))\n",
    "    participants = list(set(df[\"Participant\"].to_list()))\n",
    "    participants.sort()\n",
    "    dfSummarizeds = []\n",
    "    headers = [\"Participant\", \"Combination\", \"ROC-AUC\", \"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"TestPositive\", \"TestNegative\", \"SetNumber\", \"FeatureImportance\"]\n",
    "    for participant in participants:\n",
    "        for combination in combinations:\n",
    "            dfSummarized = [participant, combination]\n",
    "            dfTemp = df[(df[\"Participant\"] == participant) & (df[\"Combination\"] == combination)]\n",
    "            assert len(dfTemp) == FOLD_NUMBER\n",
    "            featureImportances = dfTemp[\"FeatureImportance\"].to_list()\n",
    "            featureImportances = featureImportanceAverager(featureImportances)\n",
    "            dfTemp.drop(columns=[\"FeatureImportance\"], inplace=True)\n",
    "            dfSummarized.extend(dfTemp.mean())\n",
    "            dfSummarized.extend(featureImportances)\n",
    "            dfSummarizeds.append(dfSummarized)\n",
    "    dfSummarizeds = pd.DataFrame(dfSummarizeds, columns=headers)\n",
    "    dfSummarizeds.drop(columns=[\"SetNumber\"], inplace=True)\n",
    "    dfSummarizeds.sort_values([\"Participant\", \"Combination\"], ascending=(True, True), inplace=True)\n",
    "    dfSummarizeds.to_excel(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier-Summary.xlsx\"),), index=False)\n",
    "\n",
    "    print(\"Outter:\", str(OUTTER_WINDOW_LENGTH), \"Fasting:\", str(FASTING_LENGTH))\n",
    "    print((\"---------------------------------------------------------\"))\n",
    "\n",
    "    return dfSummarizeds\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\"))):\n",
    "    os.remove(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\")))\n",
    "if not os.path.exists(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\"))):\n",
    "    dfAllFeaturesHoover = pd.read_pickle(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-All-Features-AfterHoover.pkl\")))\n",
    "    dfAllFeaturesHoover = dfAllFeaturesHoover.dropna()\n",
    "    print(\"Total Number of Samples:\", len(dfAllFeaturesHoover))\n",
    "    # combinations = [[\"EDA\"], [\"CM\"], [\"EDA\", \"CM\"], [\"Temperature\", \"EDA\"]]\n",
    "    # combinations = [[\"EDA\"], [\"Temperature\"]]\n",
    "    combinations=[[\"CM\"]]###################CHANGE THIS!!!!!!!!!!!!!!!!!!\n",
    "    columns = dfAllFeaturesHoover.columns\n",
    "    headersClassifier = [\"ROC-AUC\", \"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"TestPositive\", \"TestNegative\", \"FeatureImportance\", \"Truth\", \"Predictions\", \"Participant\", \"Combination\", \"SetNumber\"]\n",
    "    dfClassifier = []\n",
    "    for combination in combinations:\n",
    "        columnList = [\"StartTime\", \"FinishTime\", \"Participant\", \"Carb\", \"Fat\", \"Protein\", \"MealLabel\", \"MealStartList\", \"MealEndList\"]\n",
    "        for topic in combination:\n",
    "            for column in columns:\n",
    "                if topic in column:\n",
    "                    columnList.append(column)\n",
    "        dfCombination = dfAllFeaturesHoover[dfAllFeaturesHoover.columns.intersection(columnList)]\n",
    "\n",
    "        randomSeed = 60\n",
    "        print(\"----------------------\")\n",
    "        print(\"Combination:\", \"+\".join(combination))\n",
    "        NORMALIZED_FLAG = True\n",
    "        classifierReport = predictionMain(dfCombination, randomSeed, NORMALIZED_FLAG, \"+\".join(combination))\n",
    "        dfTempClassifier = pd.DataFrame(classifierReport, columns=headersClassifier)\n",
    "\n",
    "        if len(dfClassifier) > 0:\n",
    "            frames = [dfTempClassifier, dfClassifier]\n",
    "            dfClassifier = pd.concat(frames)\n",
    "        else:\n",
    "            dfClassifier = dfTempClassifier\n",
    "\n",
    "    dfClassifier.reset_index(drop=True, inplace=True)\n",
    "    dfClassifier.to_excel(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\")), index=False)\n",
    "else:\n",
    "    dfClassifier = pd.read_excel(os.path.join(addResults, (str(OUTTER_WINDOW_LENGTH) + \"-\" + str(FASTING_LENGTH) + \"-Final-Classifier.xlsx\")))\n",
    "dfSummarizeds = foldSummarizerBinary(dfClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 103>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=98'>99</a>\u001b[0m     fig\u001b[39m.\u001b[39msavefig(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(addResults, \u001b[39m\"\u001b[39m\u001b[39mEating-ROC-AUC Summary-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m metricName \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(FASTING_LENGTH) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m), dpi\u001b[39m=\u001b[39m\u001b[39m600\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=99'>100</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=102'>103</a>\u001b[0m metricPlotter(metricName\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRecall\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=103'>104</a>\u001b[0m metricPlotter(metricName\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb Cell 14'\u001b[0m in \u001b[0;36mmetricPlotter\u001b[0;34m(metricName)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=59'>60</a>\u001b[0m colors \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m#1f77b4\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#ff7f0e\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#2ca02c\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#d62728\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#9467bd\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#8c564b\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#e377c2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#7f7f7f\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#bcbd22\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#17becf\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=60'>61</a>\u001b[0m \u001b[39mfor\u001b[39;00m participant \u001b[39min\u001b[39;00m participants:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=61'>62</a>\u001b[0m     metricCMList, metricCGMList, metricCGMCMList, metricCGMCMTempList, metricCGMCMTempHREDAList, windowLenList \u001b[39m=\u001b[39m summaryPlotter(participant, metricName)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=62'>63</a>\u001b[0m     slopeCGM, interceptCGM, r_valueCGM, p_valueCGM, std_errCGM \u001b[39m=\u001b[39m linregress(windowLenList, metricCGMList)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=63'>64</a>\u001b[0m     slopeCM, interceptCM, r_valueCM, p_valueCM, std_errCM \u001b[39m=\u001b[39m linregress(windowLenList, metricCMList)\n",
      "\u001b[1;32m/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb Cell 14'\u001b[0m in \u001b[0;36msummaryPlotter\u001b[0;34m(participant, metricType)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=17'>18</a>\u001b[0m metricVal \u001b[39m=\u001b[39m dfTemp[(dfTemp[\u001b[39m\"\u001b[39m\u001b[39mParticipant\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m participant) \u001b[39m&\u001b[39m (dfTemp[\u001b[39m\"\u001b[39m\u001b[39mCombination\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCM\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=18'>19</a>\u001b[0m metricVal \u001b[39m=\u001b[39m metricVal[metricType]\u001b[39m.\u001b[39mto_list()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=19'>20</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(metricVal) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=20'>21</a>\u001b[0m metricVal \u001b[39m=\u001b[39m metricVal[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcse-stmi-s2.engr.tamu.edu/home/grads/s/sorush.omidvar/STMI-CGM-Predictor/trialProcessor.ipynb#ch0000013vscode-remote?line=21'>22</a>\u001b[0m metricCMList\u001b[39m.\u001b[39mappend(metricVal)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.chdir(os.path.join(addResults))\n",
    "\n",
    "\n",
    "def summaryPlotter(participant, metricType):\n",
    "    metricCMList = []\n",
    "    metricCGMList = []\n",
    "    metricCGMCMList = []\n",
    "    metricCGMCMTempList = []\n",
    "    metricCGMCMTempHREDAList = []\n",
    "    windowLenList = []\n",
    "    for root, dirs, files in os.walk(os.path.join(addResults)):\n",
    "        for file in sorted(files):\n",
    "            if \".xlsx\" in file.lower() and \"summary\" in file.lower() and \"classifier\" in file.lower():\n",
    "                windowLen = file[: file.find(\"-\")]\n",
    "\n",
    "                dfTemp = pd.read_excel(file)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CM\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCMList.append(metricVal)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCGMList.append(metricVal)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM+CM\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCGMCMList.append(metricVal)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM+CM+Temperature\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCGMCMTempList.append(metricVal)\n",
    "\n",
    "                metricVal = dfTemp[(dfTemp[\"Participant\"] == participant) & (dfTemp[\"Combination\"] == \"CGM+CM+Temperature+HR+EDA\")]\n",
    "                metricVal = metricVal[metricType].to_list()\n",
    "                assert len(metricVal) == 1\n",
    "                metricVal = metricVal[0]\n",
    "                metricCGMCMTempHREDAList.append(metricVal)\n",
    "                windowLenList.append(windowLen)\n",
    "\n",
    "    for counter in range(len(windowLenList)):\n",
    "        tempVal = datetime.strptime(windowLenList[counter], \"%H:%M:%S\")\n",
    "        tempVal = tempVal.time().hour * 60 + tempVal.time().minute\n",
    "        windowLenList[counter] = tempVal\n",
    "    return metricCMList, metricCGMList, metricCGMCMList, metricCGMCMTempList, metricCGMCMTempHREDAList, windowLenList\n",
    "\n",
    "\n",
    "def metricPlotter(metricName):\n",
    "    participants = [\"p1\", \"p3\", \"p5\", \"p6\", \"p7\", \"p8\"]\n",
    "    subplotCounter = 1\n",
    "    fig = plt.figure(figsize=(10, 15))\n",
    "    colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"]\n",
    "    for participant in participants:\n",
    "        metricCMList, metricCGMList, metricCGMCMList, metricCGMCMTempList, metricCGMCMTempHREDAList, windowLenList = summaryPlotter(participant, metricName)\n",
    "        slopeCGM, interceptCGM, r_valueCGM, p_valueCGM, std_errCGM = linregress(windowLenList, metricCGMList)\n",
    "        slopeCM, interceptCM, r_valueCM, p_valueCM, std_errCM = linregress(windowLenList, metricCMList)\n",
    "        slopeCGMCM, interceptCGMCM, r_valueCGMCM, p_valueCGMCM, std_errCGMCM = linregress(windowLenList, metricCGMCMList)\n",
    "\n",
    "        print(participant, (30 * slopeCGM + interceptCGM - interceptCGMCM) / slopeCGMCM)\n",
    "        # print(participant,slopeCGM,slopeCGMCM)\n",
    "        # print(participant,interceptCGM,interceptCGMCM)\n",
    "\n",
    "        plt.subplot(3, 2, subplotCounter)\n",
    "        sns.regplot(x=windowLenList, y=metricCMList, marker=\"+\", color=colors[0], label=\"CM\")\n",
    "        sns.regplot(x=windowLenList, y=metricCGMList, marker=\"s\", color=colors[1], label=\"CGM\")\n",
    "        sns.regplot(x=windowLenList, y=metricCGMCMList, marker=\"d\", color=colors[2], label=\"CGM+CM\")\n",
    "        # plt.plot(windowLenList, metricCGMCMTempList, \"--o\", color=colors[3], label=\"CGM+CM+Temperature\")\n",
    "        # plt.plot(windowLenList, metricCGMCMTempHREDAList, \":s\", color=colors[4], label=\"CGM+CM+Temperature+HR+EDA\")\n",
    "        plt.text(20, 0.9, participant.capitalize())\n",
    "        plt.ylim([0, 1])\n",
    "        if subplotCounter == 3:\n",
    "            plt.ylabel(metricName, labelpad=30)\n",
    "        if subplotCounter == 5:\n",
    "            # plt.xlabel(\"Window Length [min]\",labelpad=30)\n",
    "            frame1 = plt.gca()\n",
    "            frame1.axes.set_xlabel(\"Window Length [min]\", labelpad=30, x=1)\n",
    "        if subplotCounter == 2:\n",
    "            plt.legend(loc=\"upper right\")\n",
    "        if subplotCounter % 2 == 1:\n",
    "            plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [\"0.0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"])\n",
    "        else:\n",
    "            plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], [])\n",
    "        if subplotCounter >= 5:\n",
    "            plt.xticks([15, 30, 45, 60, 75, 90], [\"15\", \"30\", \"45\", \"60\", \"75\", \"90\"])\n",
    "        else:\n",
    "            plt.xticks([15, 30, 45, 60, 75, 90], [])\n",
    "\n",
    "        subplotCounter += 1\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(addResults, \"Eating-ROC-AUC Summary-\" + metricName + \"-\" + str(FASTING_LENGTH) + \".jpg\"), dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "metricPlotter(metricName=\"Recall\")\n",
    "metricPlotter(metricName=\"Precision\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noNormal=[{'-MaxDiff': 0.1078463, '-SecondFourthSlopeDiff': 0.103150845, '-FourthFourthSlopeDiff': 0.07462696, '-ThirdFourthSlope': 0.06913031, '-Skewness': 0.056625057, '-SkewnessDiff': 0.050760787, '-STDDiff': 0.048788596, '-FirstFourthSlopeDiff': 0.046131063, '-RangeDiff': 0.04021073, '-HalvesSlopeDiff': 0.04018015, '-MinDiff': 0.033765636, '-HalvesSlope': 0.03357451, '-SecondFourthSlope': 0.033038698, '-FourthFourthSlope': 0.029650774, '-FirstFourthSlope': 0.02836506, '-Min': 0.025608739, '-Max': 0.024943182, '-STD': 0.024530888, '-Mean': 0.02407294, '-Range': 0.023151893, '-MeanDiff': 0.022112701, '-KurtosisDiff': 0.02190013, '-ThirdFourthSlopeDiff': 0.02160139, '-Kurtosis': 0.016232677},\n",
    "# {'-MinDiff': 0.05836166, '-Max': 0.05825951, '-Mean': 0.056890287, '-FirstFourthSlopeDiff': 0.054751, '-SecondFourthSlope': 0.05199795, '-FirstFourthSlope': 0.051083237, '-RangeDiff': 0.047590412, '-FourthFourthSlopeDiff': 0.046937533, '-ThirdFourthSlope': 0.04655046, '-HalvesSlope': 0.044784807, '-Min': 0.043269206, '-SkewnessDiff': 0.042040505, '-MaxDiff': 0.041865278, '-HalvesSlopeDiff': 0.041717757, '-Skewness': 0.037697215, '-FourthFourthSlope': 0.034438096, '-MeanDiff': 0.03392487, '-STDDiff': 0.033244412, '-Range': 0.032868195, '-SecondFourthSlopeDiff': 0.031723518, '-KurtosisDiff': 0.029031616, '-Kurtosis': 0.028224358, '-ThirdFourthSlopeDiff': 0.027494926, '-STD': 0.025253225},\n",
    "# {'-Range': 0.07485981, '-MaxDiff': 0.07235001, '-FourthFourthSlope': 0.061106034, '-Min': 0.06102726, '-ThirdFourthSlope': 0.05558133, '-SkewnessDiff': 0.054457445, '-HalvesSlope': 0.051805902, '-RangeDiff': 0.050594293, '-FirstFourthSlope': 0.04973889, '-FourthFourthSlopeDiff': 0.049186327, '-Mean': 0.046296857, '-Kurtosis': 0.04171118, '-SecondFourthSlopeDiff': 0.03683889, '-MeanDiff': 0.034761127, '-Max': 0.03353867, '-MinDiff': 0.03286376, '-SecondFourthSlope': 0.03176475, '-STDDiff': 0.028456414, '-KurtosisDiff': 0.028452437, '-ThirdFourthSlopeDiff': 0.024667135, '-FirstFourthSlopeDiff': 0.022733245, '-Skewness': 0.021999788, '-STD': 0.020657314, '-HalvesSlopeDiff': 0.014551135},\n",
    "# {'-ThirdFourthSlope': 0.116321504, '-FourthFourthSlope': 0.06946923, '-MaxDiff': 0.06276192, '-Max': 0.059627842, '-Mean': 0.052711405, '-Range': 0.050306994, '-MinDiff': 0.049013417, '-RangeDiff': 0.048471592, '-Skewness': 0.047412317, '-FourthFourthSlopeDiff': 0.046264015, '-STDDiff': 0.040881716, '-SkewnessDiff': 0.038825456, '-SecondFourthSlope': 0.037260063, '-Min': 0.033757806, '-MeanDiff': 0.033217307, '-HalvesSlope': 0.031427175, '-KurtosisDiff': 0.03128091, '-FirstFourthSlope': 0.028787797, '-STD': 0.027287915, '-FirstFourthSlopeDiff': 0.024499362, '-Kurtosis': 0.021792239, '-SecondFourthSlopeDiff': 0.01951169, '-ThirdFourthSlopeDiff': 0.01877995, '-HalvesSlopeDiff': 0.010330347},\n",
    "# {'-MaxDiff': 0.06764946, '-STD': 0.056324393, '-FourthFourthSlopeDiff': 0.055581857, '-Mean': 0.051104046, '-Range': 0.0502673, '-SkewnessDiff': 0.049853936, '-RangeDiff': 0.044252936, '-Min': 0.043754313, '-Max': 0.04371197, '-MinDiff': 0.042753506, '-KurtosisDiff': 0.039921276, '-HalvesSlopeDiff': 0.03888581, '-FirstFourthSlope': 0.038707566, '-FourthFourthSlope': 0.03850367, '-STDDiff': 0.038403533, '-Skewness': 0.038231872, '-SecondFourthSlope': 0.03812664, '-SecondFourthSlopeDiff': 0.037757747, '-Kurtosis': 0.037050135, '-ThirdFourthSlopeDiff': 0.03525641, '-ThirdFourthSlope': 0.032925814, '-MeanDiff': 0.031699583, '-HalvesSlope': 0.028091868, '-FirstFourthSlopeDiff': 0.021184346},\n",
    "# {'-FourthFourthSlopeDiff': 0.07831435, '-SkewnessDiff': 0.06162001, '-Min': 0.050464742, '-SecondFourthSlopeDiff': 0.049488824, '-RangeDiff': 0.049330417, '-Range': 0.04861606, '-MaxDiff': 0.04708212, '-FourthFourthSlope': 0.046744823, '-KurtosisDiff': 0.046689652, '-STDDiff': 0.04431532, '-FirstFourthSlopeDiff': 0.042319566, '-MeanDiff': 0.041090157, '-MinDiff': 0.039877523, '-Skewness': 0.039017998, '-SecondFourthSlope': 0.038478997, '-Max': 0.03784959, '-Mean': 0.03724398, '-FirstFourthSlope': 0.037229583, '-ThirdFourthSlopeDiff': 0.033134893, '-Kurtosis': 0.031625576, '-HalvesSlope': 0.030476, '-ThirdFourthSlope': 0.026068594, '-STD': 0.023853524, '-HalvesSlopeDiff': 0.01906771}]\n",
    "\n",
    "# for counter in range(len(noNormal)):\n",
    "#     temp=noNormal[counter]\n",
    "#     noNormal[counter]=dict(sorted(temp.items(), key=lambda item: item[0],reverse=True))\n",
    "# y=[]\n",
    "# for counter in range(len(noNormal)):\n",
    "#     temp=noNormal[counter]\n",
    "#     x=temp.keys()\n",
    "#     y.append(list(temp.values()))\n",
    "# y=np.asarray(y)\n",
    "# x=list(x)\n",
    "\n",
    "# y=y.mean(axis=0)\n",
    "# indexSorted=np.argsort(y)\n",
    "# x=np.asarray(x)\n",
    "# x=x[indexSorted.astype(int)]\n",
    "# y=np.sort(y)\n",
    "# print(\"********\")\n",
    "\n",
    "# plt.figure(figsize=(15,15))\n",
    "# plt.bar(x,y)\n",
    "# plt.xticks(x, rotation='vertical')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65e249be015da37cfe4cfdd1da028fe4cb475c26be679b9e3e34696278a17c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
